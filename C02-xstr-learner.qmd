# S-, X-, T-, and R-learner {#sec-het-dml}

In this section, we look at the S-, X-, T-, and R-learner, which are method that estimate heterogeneous treatment effects when the treatment is binary. While X-learner and T-learner cannot be extended to continuous treatment cases, S-learner and R-learner can be. Mathematical notations used in this chapter closely follow those of [@kunzel_metalearners_2019] and [@nie_quasi-oracle_2021].


:::{.callout-important}

## What you will learn
:::

:::{.callout-tip}

## Key points

+ R-learner is the same as DML approaches by @Chernozhukov2018 except that it estimates CATE eat the second stag instead of ATE.
+ In many practical cases, R-learner performs better than S-, X-, and T-learners. 
+ S- and T-learners are especially undesirable due to its tendency to underestimate CATE

:::

## Motivation

In @sec-dml, the basic idea of double machine learning (DML) methods was introduced when the treatment effect is homogeneous. We now turn our focus to the task of estimating heterogeneous treatment effects: the impact of a treatment varies based on observed attributes of the subjects. Heterogeneous treatment effect is also referred to as <span style="color:blue"> conditional </span> average treatment effect (CATE).

::: {.column-margin}
<span style="color:blue"> Conditional </span> on observed attributes.
:::

Understanding how treatment effects vary can be highly valuable in many circumstances. 

<span style="color:blue"> Example 1: </span>
If we come to know a particular drug is effective on elderly people but detrimental to kids, then doctors can make a smart decision of prescribing the drug to elderly people, but not to kids. 

::: {.column-margin}
In this example, the heterogeneity driver is age.
:::

<span style="color:blue"> Example 2: </span>
If we come to know that fertilizer is more effective in increasing corn yield in soil type A than B, then farmers can apply more fertilizer on the parts of the field where soil type is A but less on where soil type is B. 

::: {.column-margin}
In this example, the heterogeneity driver is soil type.
:::

As you can see in these examples, knowledge on the heterogeneity of the treatment effect and its drivers can help decision makers smart-target treatments and policies. 

## Modeling Framework

The model of interest in general form is as follows:

$$
\begin{aligned}
Y_i & = \theta(X_i)\cdot T_i + g(X_i, W_i) + \varepsilon_i \\
T_i & = f(X_i, W_i) + \eta_i 
\end{aligned}
$$ {#eq-model-framework}

+ $Y$: dependent variable
+ $T$: treatment variable
+ $X$: collection of variables that affect Y indirectly through the treatment ($\theta(X)\cdot T$) and directly ($g(X, W)$) independent of the treatment
+ $W$: collection of variables that affect directly ($g(X, W)$) independent of the treatment, but not through the treatment

Here are the assumptions:

+ $E[\varepsilon|X, W] = 0$
+ $E[\eta|X, W] = 0$
+ $E[\eta\cdot\varepsilon|X, W] = 0$

For the notational convenicence, let $\mu_1(X)$ and $\mu_0(X)$ denote the expected value of the potential conditional outcomes:

$$
\begin{align}
\mu_1(X) & = E[Y|W=1, X] = g(X, W)\\ 
\mu_0(X) & = E[Y|W=0, X] =  \theta(X) + g(X, W)
\end{align}
$$


## S-, T-, and X-Learner

### S-learner

S-learner estimates CATE by taking the following steps:

1. Regress $Y$ on $W$ and $X$ to estimate $E[Y|W,X]$ using any appropriate ML regression methods and call it $\hat{\mu}(W,X)$.
2. Estimate $\hat{\theta}(X)$ as $\hat{\mu}(W=1,X)-\hat{\mu}(W=0,X)$

In this approach, no special treatment is given to $W$. It is just a covariate along with others ($X$). This approach is named S-learner by @kunzel_metalearners_2019 because it involves estimating a <span style='color:red'>s</span>ingle response function.

### T-learner

1. Regress $Y$ on $W$ and $X$ using the treated observations to estimate $\mu_1(X)$ using any appropriate ML regression methods.
2. Regress $Y$ on $W$ and $X$ using the control  observations to estimate $\mu_0(X)$ using any appropriate ML regression methods.
3. Estimate $\hat{\theta}(X)$ as $\hat{\mu}_1(X)-\hat{\mu}(X)$

This approach is named T-learner by @kunzel_metalearners_2019 because it involves estimating <span style='color:red'>t</span>wo functions.

### X-learner

1. Estimate $\mu_1(X)$ and $\mu_0(X)$ using any appropriate ML regression methods. (Steps 1 and 2 of the T-learner)
2. Impute individual treatment effect for the treated and control groups as follows

$$
\begin{align}
\tilde{D}_i^1(X_i) = Y^1_i - \hat{\mu}_0(X_i)\\
\tilde{D}_i^0(X_i) =  \hat{\mu}_1(X_i) - Y^0_i 
\end{align}
$$ 

::: {.column-margin}
This is similar to cross-fitting we saw in @sec-dml, where the folds are the treated and control groups.
:::

3. 

+ Regress $\tilde{D}_i^1(X_i)$ on $X$ using the observations in the treated group and denote the predicted value as $\hat{\theta}_1(X)$

+ Regress $\tilde{D}_i^0(X_i)$ on $X$ using the observations in the control group and denote the predicted value as $\hat{\theta}_0(X)$

4. Calculate $\hat{\theta}(X)$ as their weighted average

$$
\begin{align}
\hat{\theta}(X) = g(X)\cdot\hat{\theta}_0(X) + [1-g(X)]\cdot\hat{\theta}_1(X)
\end{align}
$$ {#eq-final-X}

Any value of $g(X)$ is acceptable. One option of $g(X)$ may be the estimated propensity score $E[W|X]$.

## T-learner v.s. X-learner

Here, an advantage of X-learner over T-learner is demonstrated. This example also serves as an illustration of how these learners are implemented. Specifically, X-learner can be advantageous when the control-treatment assignments in the sample are unbalanced. For example, it is often the case that there are plenty of observations in the control group, while there are not many treated observations. For the purpose of illustration, consider a rather extreme case where there are only 10 observations in the treated group, while there are 300 observations in the control group. We use the following toy data generating process:

::: {.column-margin}
**Packages to load for replication**

```{r}
#| include: false

library(data.table)
library(tidyverse)
library(ranger)
library(rlearner)
library(mgcv)
library(rsample)
library(xgboost)
```

```{r}
#| eval: false
library(data.table)
library(tidyverse)
library(ranger)
library(rlearner)
library(mgcv)
library(rsample)
library(xgboost)
```
:::

$$
\begin{align}
y = \tau W + |x| + v
\end{align}
$$ 

where $\tau = 1$. So, the treatment effect is not heterogeneous. For the purpose of illustrating the advantage of X-learner over T-learner, it is convenient if the underlying model is simpler.

```{r}
set.seed(4345)

N_trt <- 20
N_ctrl <- 300
N <- N_trt + N_ctrl

data <- 
  data.table(
    W = c(rep(1,N_trt), rep(0, N_ctrl)),
    type = c(rep("Treated", N_trt), rep("Control", N_ctrl)),
    x = 2 * runif(N)-1,
    v = rnorm(N) / 2
  ) %>% 
  .[, y := W + abs(x) + v]
```

```{r}
ggplot(data = data) +
  geom_point(aes(y = y, x = x, color = type)) +
  theme_bw()
```

Let's first estimate $\mu_1(X)$ and $\mu_0(X)$ (Step 1). Since we have only $`r N_trt`$ observations in the treated group, we will use a linear regression to avoid over-fitting (following the example in @kunzel_metalearners_2019).

```{r}
mu_1_trained <- lm(y ~ x, data = data[type == "Treated", ])

mu_0_trained <- gam(y ~ s(x, k = 4), data = data[type == "Control", ])
```

Now that  $\mu_1(X)$ and $\mu_0(X)$ are estimated, we can estimate $\hat{\theta}(X)$ by T-learner.

```{r}
x_seq <- data.table(x = seq(-1, 1, length = 100))
#=== T-learner ===#
tau_hat_data <- 
  x_seq %>%
  .[, mu_1_hat := predict(mu_1_trained, newdata = x_seq)] %>%
  .[, mu_0_hat := predict(mu_0_trained, newdata = x_seq)] %>%
  .[, tau_hat_T := mu_1_hat - mu_0_hat]
```

As you can see, T-learner is heavily biased. This is because of the unreliable estimation of $\mu_1(X)$ due to lack of observations in the treated group.

```{r}
#| code-fold: true

ggplot(data = tau_hat_data) +
  geom_line(aes(y = tau_hat_T, x = x)) +
  theme_bw()
```

Now, let's move on to X-learner. We impute individual treatment effects (Step 2).

```{r}
#=== mu (treated) ===#
mu_hat_1 <- predict(mu_0_trained, newdata = data[type == "Treated", ])

#=== mu (control) ===#
mu_hat_0 <- predict(mu_1_trained, newdata = data[type == "Control", ])

#=== assign the values ===#
data[type == "Treated", mu_hat := mu_hat_1]
data[type == "Control", mu_hat := mu_hat_0]

#=== find individual TE ===#
data[, D := ifelse(type == "Treated", y - mu_hat, mu_hat - y)]
```

We can now regress $D$ on $X$ (Step 3),

```{r}
#--------------------------
# tau (treated)
#--------------------------
tau_1_trained <- lm(D ~ x, data = data[type == "Treated", ])

#=== estimate tau_1 ===#
tau_hat_data[, tau_hat_1 := predict(tau_1_trained, newdata = tau_hat_data)]

#--------------------------
# tau (control)
#--------------------------
tau_0_trained <- gam(D ~ s(x, k = 4), data = data[type == "Control", ])

#=== estimate tau_1 ===#
tau_hat_data[, tau_hat_0 := predict(tau_0_trained, newdata = tau_hat_data)]
```

```{r}
#| code-fold: true

ggplot(data = tau_hat_data) +
  geom_line(aes(y = tau_hat_1, x = x, color = "Treated")) +
  geom_line(aes(y = tau_hat_0, x = x, color = "Control")) +
  scale_color_manual(values = c("Treated" = "blue", "Control" = "red")) +
  theme_bw()
```

Let's use propensity score as $g(X)$ in Step 4.

```{r}
w_gam_trained <- 
  gam(
    W ~ s(x, k = 4), 
    data = data, 
    family = binomial(link = "probit")
  )
```

Let's predict $E[W|X]$ at each value of $X$ at which we are estiamting $\tau$. 

```{r}
tau_hat_data[, g_x := predict(w_gam_trained, newdata = tau_hat_data, type = "response")]
```

As you can see below, the mean value of $g(x)$ is small because the treatment probability is very low (it is only $`r N_trt`$ out of $`r N`$).

```{r}
mean(tau_hat_data[, g_x])
```

This number is basically $`r N_trt`/320$. So, in this example, we could have just used the proportion of the treated observations. Notice that $g(X)$ is multiplied to $\hat{\theta}_0(X)$ in @eq-final-X. So, we are giving a lower weight to $\hat{\theta}_0(X)$. This is because $\hat{\theta}_0(X)$ is less reliable because $\hat{\mu}_1(X)$ is less reliable due to the lack of samples in the treated group. 

```{r}
tau_hat_data[, tau_hat_X := g_x * tau_hat_0 + (1-g_x) * tau_hat_1]
```

As you can see, X-learner outperforms T-learner in this particular instance at least in terms of point estimates of $\tau(X)$. 

```{r}
#| code-fold: true

ggplot(data = tau_hat_data) +
  geom_line(aes(y = tau_hat_T, x = x, color = "T-learner")) +
  geom_line(aes(y = tau_hat_X, x = x, color = "X-learner")) +
  geom_hline(yintercept = 1, aes(color = "True Treatment Effect")) +
  scale_color_manual(
    values = c(
        "T-learner" = "red", 
        "X-learner" = "blue", 
        "True Treatment Effect" = "black"
      ),
    name = ""
    ) +
  ylab("Treatment Effect") +
  theme_bw() +
  theme(legend.position = "bottom")
```

## R-learner {#sec-r-learner}

### Theoretical background

Under the assumptions,

$$
\begin{aligned}
E[Y|X, W] = \theta(X)\cdot f(X,W) + g(X,W)
\end{aligned}
$$ {#eq-yxw}

:::{.column-margin}
$f(X,W) = E[T|X,W]$ 
:::

Let, $l(X,W)$ denote $E[Y|X, W]$. Taking the difference of @eq-model-framework and @eq-yxw on both sides,

$$
\begin{aligned}
Y_i - l(X_i,W_i) & = \theta(X_i)\cdot T_i + g(X_i,W_i) + \varepsilon_i - [\theta(X_i)\cdot f(X_i,W_i) + g(X_i,W_i)] \\
\Rightarrow Y_i - l(X_i,W_i) & = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i \\
\end{aligned}
$$

:::{.column-margin}
This is akin to residualization/orthogonalization seen in the DML approach in @sec-dml.
:::

So, the problem of identifying $\theta(X)$ reduces to estimating the following model:

$$
\begin{aligned}
Y_i - l(X_i,W_i) & = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i
\end{aligned}
$$

Since $E[(T_i -f(X_i,W_i))\cdot\varepsilon_i|X] = E[\eta_i\cdot\varepsilon_i|X] = 0$ by assumption, we can regress $Y_i - l(X_i,W_i)$ on $X_i$ and $T_i -f(X_i,W_i)$ to estimate $\theta(X)$. Specifically, we can minimize the following objective function:

$$
\begin{aligned}
Min_{\theta(X)}\sum_{i=1}^N \large(\normalsize[Y_i - l(X_i,W_i)] - [\theta(X_i)\cdot (T_i -f(X_i,W_i))]\large)^2 
\end{aligned}
$$ {#eq-est-equation}

### Estimation steps {#sec-est-steps}

In practice, we of course do not observe $l(X,W)$ and $f(X,W)$. So, we first need to estimate them using the data at hand and then subtract them from $Y_i$ and $T_i$, respectively. You can use any suitable statistical methods to estimate $l(X, W)$ and $f(X,W)$. Some machine learning methods allow you to estimate them without assuming any functional form or structural assumptions. If you believe they are linear functions of $X$ and $W$, you could alternatively use lasso or other linear models. @nie_quasi-oracle_2021 proposes that the estimation of $l(X,W)$ and $f(X,W)$ is done by cross-fitting (see @sec-cf) to avoid over-fitting bias. Let $I_{-i}$ denote all the observations that belong to the folds that $i$ does <span style="color:blue"> not </span> belong to. Further, let $\hat{l}(X_i, W_i)^{I_{-i}}$ and $\hat{f}(X_i, W_i)^{I_{-i}}$ denote $l(X_i, W_i)$ and $f(X_i, W_i)$ estimated using $I_{-i}$. 

::: {.column-margin}
Just like the DML approach discussed in @sec-dml, both $Y$ and $T$ are orthogonalized.
:::

Then the quality of fit (explaining the heterogeneity in the impact of treatment) can be expressed as follows, which is the empirical version of @eq-est-equation:

$$
\begin{aligned}
\sum_{i=1}^N [Y_i - \hat{l}(X_i,W_i)^{I_{-i}} - \theta(X)\cdot (T_i - \hat{f}(X_i,W_i)^{I_{-i}})]^2
\end{aligned}
$$

This is called <span style="color:blue"> R-score</span>, and it can be used for causal model selection, which will be covered later. 

Let $\tilde{Y}_i$ and $\tilde{T}_i$ denote $Y_i - \hat{l}(X_i,W_i)^{I_{-i}}$ and $T_i - \hat{f}(X_i,W_i)^{I_{-i}}$, respectively. The final stage of the R-learner is to estimate $\theta(X)$ by minimizing the R-score plus the regularization term (if desirable).

$$
\begin{aligned}
\hat{\theta}(X) = argmin_{\theta(X)}\;\;\sum_{i=1}^N [\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i]^2 + \Lambda(\theta(X))
\end{aligned}
$$ {#eq-r-min}

where $\Lambda(\theta(X))$ is the penalty on the complexity of $\theta(X)$. For example, if you choose to use lasso, then $\Lambda(\theta(X))$ is the L1 norm. You have lots of freedom as to what model you use in the final stage. The `econml` package offers several off-the-shelf choices of R-learner (DML) approaches that differ in the model used at the final stage, including causal forest, lasso, etc.

### R-learner by hand

This section goes through the estimation steps provided above to further the understanding of how R-learner works using a synthetic dataset that follows the DGP below.

$$
\begin{aligned}
Y_i & = (x_{i,1} + x_{i,2}^2)\cdot T_i + \sqrt{x_{i,3}} + \mu_i \\
T_i|X_i & = Bernouli((1+x_{i,1})/2) \\
\mu_i|X_i & = N(0,1)
\end{aligned}
$$

Let's generate a dataset according to the DGP.

```{r}
set.seed(58734)

N <- 1000

(
data <-
  data.table(
    x1 = runif(N),
    x2 = runif(N),
    x3 = runif(N),
    mu = rnorm(N)
  ) %>% 
  .[, T := runif(N) < ((0.5+x1)/2)] %>% 
  .[, Y := (x1 + x2^2) * T + sqrt(x3) + mu] %>% 
  .[, id := 1:.N]
) 
```

---

We first cross-fit $E[Y|X]$ and $E[T|X]$ using random forest for both cases. We will use repeated (3 times) 5-fold cross-fitting. Resampling the data,

```{r}
(
data_folds <- rsample::vfold_cv(data, v = 5, repeats = 3)
)
```

The following function takes a row number (`n`) and cross-fits $E[Y|X]$ and $E[T|X]$ for the training and test data split stored in the `n`th row of `data_folds`.

```{r}
cross_fit <- function(n, data_folds) 
{
  training_data <- analysis(data_folds[n, ]$splits[[1]])
  eval_data <- assessment(data_folds[n, ]$splits[[1]])

  #--------------------------
  # E[Y|X]
  #--------------------------
  #=== train ===#
  rf_trained_y <-
    ranger(
      Y ~ x1 + x2 + x3,
      data = training_data
    )

  #=== fit ===#
  eval_data[, y_hat := predict(rf_trained_y, data = eval_data)$predictions]

  #--------------------------
  # E[T|X]
  #--------------------------
  rf_trained_t <-
    ranger(
      T ~ x1 + x2 + x3,
      data = training_data,
      probability = TRUE
    )

  eval_data[, t_hat := predict(rf_trained_t, data = eval_data)$predictions[, 2]]

  return(eval_data[, .(id, y_hat, t_hat)])
}
```

Here is what the output of the function for the first split looks like.

```{r}
cross_fit(1, data_folds)
```

Repeating this for all the splits,

```{r}
(
cross_fitted_data_rp <-
  lapply(
    seq_len(nrow(data_folds)),
    function(x) cross_fit(x, data_folds)
  ) %>% 
  rbindlist()
)
```

We finally take the mean of the cross-fits by `id` as each `id` has tree estimates. 

```{r}
(
cross_fitted_data <- 
  cross_fitted_data_rp[, .(
    t_hat = mean(t_hat),
    y_hat = mean(y_hat)
  ), by = id]
)
```

We then merge the data to the original data, and define $\tilde{Y}$ and $\tilde{T}$.

```{r}
(
data_2nd <- 
  cross_fitted_data[data, on = "id"] %>% 
  .[, `:=`(
    y_tilde = Y - y_hat,
    t_tilde = T - t_hat
  )] %>% 
  .[, .(y_tilde, t_tilde, x1, x2, x3)]
)
```

---

The first order condition of @eq-r-min without $\Lambda(\theta(X))$ is

$$
\begin{aligned}
\sum_{i=1}^N (\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i)\cdot \tilde{T}_i = 0
\end{aligned}
$$

This can be rewritten as 

$$
\begin{aligned}
\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0
\end{aligned}
$$

So, this problem can be considered the problem of estimating $\theta(X)$ when the dependent variable is $\frac{\tilde{Y}_i}{\tilde{T}_i}$ with individual weights of $\tilde{T}_i^2$.

```{r}
data_2nd[, `:=`(
  weight = t_tilde^2,
  y_to_t = y_tilde / t_tilde
)]
```

We use `xgboost()` for a non-parametric estimation of $\theta(X)$.

```{r}
#| include: false

#=== set up the data with weights ===#
data_2nd_xgb <- 
  xgb.DMatrix(
    data = data_2nd[, .(x1, x2, x3)] %>% as.matrix(),
    label = data_2nd[, y_to_t],
    weight = data_2nd[, weight]
  )

#=== train ===#
xgb_trained_2nd <-
  xgboost(
    data = data_2nd_xgb,
    nrounds = 200,
    objective = "reg:squarederror"
  )
```

```{r}
#| eval: false

#=== set up the data with weights ===#
data_2nd_xgb <- 
  xgb.DMatrix(
    data = data_2nd[, .(x1, x2, x3)] %>% as.matrix(),
    label = data_2nd[, y_to_t],
    weight = data_2nd[, weight]
  )

#=== train ===#
xgb_trained_2nd <-
  xgboost(
    data = data_2nd_xgb,
    nrounds = 200,
    objective = "reg:squarederror"
  )
```

You can now predict $\theta(X)$ at particular values of $X$. Let's estimate $\theta(X)$ at $X_0 = \{x_1 = 0.5, x_2 = 0.5, x_3 = 0.5\}$.

```{r}
eval_data <- 
  data.table(x1 = 0.5, x2 = 0.5, x3 = 0.5) %>% 
  as.matrix() %>% 
  xgb.DMatrix(data = .)

(
theta_hat <- predict(xgb_trained_2nd, eval_data)
)
```

You could alternatively estimate $\theta(X)$ parametrically using OLS. Suppose we somehow know that $\theta(X)$ takes the following form $\beta_1 x_1 + \beta_2 x_2^2 + \beta_3 x_3$. Then, the second stage estimation would be regressing $\tilde{Y}$ on $x_1\times T$, $x_2^2\times T$, and $x_2\times T$.

```{r}
#=== train ===#
ols_2nd_stage <- lm(y_tilde ~ I(x1*t_tilde) + I(x2^2*t_tilde) + I(x3*t_tilde), data = data_2nd)

#=== summary ===#
summary(ols_2nd_stage)
```

The results look pretty good mostly because we are cheating and using the correct functional form. Of course, in practice, you would not know the correct functional form of $\theta(X)$. Finally, note that you should not use the codes here since they are just for demonstration to enhance our understanding of how R-learner works. 


## Comparing the learners

$$
\begin{aligned}
Y_i =\theta(X_i)\cdot T + \alpha g(X_i) + \mu_i
\end{aligned}
$$

+ $X_i = \{X_{i,1}, X_{i,2}, X_{i,3}, X_{i,4}, X_{i,5}\}$
+ $T_i|X_i \sim Bernouli(f(X_i))$
+ $\mu_i|X_i \sim N(0,1)$

:::{.callout-note}

## Case A

$$
\begin{aligned}
g(X_i) & = sin(\pi X_{i,1}X_{i,2}) + 2(X_{i,3}-0.5)^2 + X_{i,4} + 0.5 X_{i,5}\\
e(X_i) & = max(0.1, min(sin(\pi X_{i,1}X_{i,2}), 0.9)) \\
\theta(X_i) & = (X_{i,1}, X_{i,2}) / 2 \\
X_i & \sim Uni(0,1)^5
\end{aligned}
$$

:::
  
```{r}
#| code-fold: true 
gen_data_A <- function(N){
  data <-
    data.table(
      x1 = runif(N),
      x2 = runif(N),
      x3 = runif(N),
      x4 = runif(N),
      x5 = runif(N),
      u = rnorm(N)
    ) %>% 
    .[, `:=`(
      g_x = sin(pi * x1*x2) + 2*(x3-0.5)^2 + x4 + 0.5*x5,
      e_x = pmax(0.1, pmin(sin(pi * x1*x2), 0.9)),
      theta_x = (x1+x2)/2
    )] %>% 
    .[, t := as.numeric(runif(N) < e_x)] %>% 
    .[, y := theta_x * t + g_x + u]

  return(data)
}

```

```{r}
#| eval: false
#| echo: false

library(rlearner)
data <- gen_data_A(N)

#--------------------------
# R-learner
#--------------------------
rboost_fit <- 
  rboost(
    data[, .(x1, x2, x3, x4, x5)] %>% as.matrix(), 
    data$t, 
    data$y
  )

rboost_est <- predict(rboost_fit, data$x)

#--------------------------
# S-learner
#--------------------------
sboost_fit <- 
  sboost(
    data[, .(x1, x2, x3, x4, x5)] %>% as.matrix(), 
    data$t, 
    data$y
  )

sboost_est <- predict(rboost_fit, data$x)

#--------------------------
# T-learner
#--------------------------
tboost_fit <- 
  tboost(
    data[, .(x1, x2, x3, x4, x5)] %>% as.matrix(), 
    data$t, 
    data$y
  )

tboost_est <- predict(rboost_fit, data$x)

#--------------------------
# X-learner
#--------------------------
xboost_fit <- 
  xboost(
    data[, .(x1, x2, x3, x4, x5)] %>% as.matrix(), 
    data$t, 
    data$y
  )

xboost_est <- predict(rboost_fit, data$x)

```

:::{.callout-note}

## Case B (randomized trial)

$$
\begin{aligned}
g(X_i) & = max(X_{i,1} + X_{i,2}, X_{i,3}, 0) + max(X_{i,4}+ X_{i,5},0)\\
e(X_i) & = 1/2 \\
\theta(X_i) & = X_{i,1} + log(1+exp(X_{i,2})) \\
X_i & \sim N(0,I_5)
\end{aligned}
$$

:::
 
```{r}
#| code-fold: true 
gen_data_B <- function(N){
  data <-
    data.table(
      x1 = rnorm(N),
      x2 = rnorm(N),
      x3 = rnorm(N),
      x4 = rnorm(N),
      x5 = rnorm(N),
      u = rnorm(N)
    ) %>% 
    .[, `:=`(
      g_x = pmax(x1 + x2, x3) + pmax(x4 + x5, 0),
      e_x = 1/2,
      theta_x = x1+log(1 + exp(x2))
    )] %>% 
    .[, t := (runif(N) < e_x)] %>% 
    .[, y := theta_x * t + g_x + u]

  return(data)
}
```


## X-, S-, T-, R-learner in Python

We saw a general R-learner framework for CATE estimation. We now look at an example of Linear DML, which uses a linear model at the final stage. So, we are assuming that $\theta(X)$ can be written as follows in @eq-model-framework:

$$
\begin{aligned}
\theta(X) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k
\end{aligned}
$$

where $x_1$ through $x_k$ are the drivers of heterogeneity in treatment effects and $\beta_1$ through $\beta_k$ are their coefficients.

::: {.column-margin}
**Packages to load for replication**

```{r }
#| include: false
library(data.table)
library(magick)
library(fixest)
library(officer)
library(dplyr)
library(ggplot2)
library(reticulate)
library(DoubleML)
library(MASS)
```

```{r}
#| eval: false
library(data.table)
library(magick)
library(fixest)
library(officer)
library(dplyr)
library(ggplot2)
library(reticulate)
library(DoubleML)
library(MASS)
```
:::

We use both Python and R for this demonstration. So, let's set things up for that.

```{r}
#| eval: false 
library(reticulate)
use_virtualenv("ml-learning")
```

For this demonstration, we use synthetic data according to the following data generating process:

$$
\begin{aligned}
y_i = exp(x_{i,1}) d_i + x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} + \mu_i \\
d_i = \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3}+ \eta_i
\end{aligned}
$$

Note that this is the same data generating process used in @sec-dml except that the impact of the treatment ($d$) now depends on $x_1$. We can use `gen_data()` function that is defined in @sec-dml-naive.

```{r}
#| eval: false 

#=== sample size ===#
N <- 1000 

#=== generate data ===#
synth_data <-
  gen_data(
    te_formula = formula(~ I(exp(x1)*d)),
    n_obs = N *2
  )

X <- dplyr::select(synth_data, starts_with("x")) %>% as.matrix()
y <- synth_data[, y]
d <- synth_data[, d]
```

We now split the data into training and test datasets. 

```{python}
#| eval: false

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test, d_train, d_test= train_test_split(r.X, r.y, r.d,  test_size = 0.5, random_state = 8923)
```

Here, to train a linear DML model, we use the Python `econml` package, which offers one of the most comprehensive sets of off-the-shelf R-learner (DML) methods [@econml]. We can use the `DML` class to implement linear DML.

```{python}
#| eval: false
from econml.dml import DML
```

::: {.column-margin}
`DML` is a child class of `_Rlearner`, which is a private class. The `DML` class has several child classes: `LinearDML`, `SpatseLinearDML`, `NonParamDML`, and `CausalForestDML`. 
:::

As we saw above in @sec-est-steps, we need to specify three models:

+ `model_y`: model for estimating $E[Y|X,W]$
+ `model_t`: model for estimating $E[T|X,W]$
+ `model_final`: model for estimating $\theta(X)$

In this example, let's use gradient boosting regression for both `model_y` and `model_t` and use lasso with cross-validation for `model_final`. Let's import `GradientBoostingRegressor()` and `LassoCV()` from the `scikitlearn` package.

```{python}
#| eval: false
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.linear_model import LassoCV
```

We can now set up our DML framework like below:

```{python}
#| eval: false
est = DML(
    model_y = GradientBoostingRegressor(),
    model_t = GradientBoostingRegressor(),
    model_final = LassoCV(fit_intercept = False) 
  )
```

Note that no training has happened yet at this point. We simply created a recipe. Once we provide ingredients (data), we can cook (train) with the `fit()` method. 

```{python}
#| eval: false
est.fit(y_train, d_train, X = X_train, W = X_train)
```

+ first argument: dependent variable
+ second argument: treatment variable 
+ `X`: variables that drive treatment effect heterogeneity
+ `W`: variables that affect the dependent variable directly

::: {.column-margin}
Here, we set `X = W`.
:::

Once, the training is done. We can use the `effect()` method to predict $\theta(X)$.

```{python}
#| eval: false
te_test = est.effect(X_test)
```

@fig-est-theta-hat presents the estimated and true marginal treatment effect ($\theta(X)$) as a function of `x1`. 

```{r}
#| eval: false 
plot_data <- 
  data.table(
    x1 = py$X_test[, 1],
    te = py$te_test
  )

ggplot(plot_data) +
  geom_point(aes(y = te, x = x1)) +
  geom_line(aes(y = exp(x1), x = x1), color = "blue") +
  theme_bw()
```

```{r}
#| fig-cap: Estimated and true marginal treatment effects
#| label: fig-est-theta-hat
#| echo: false
# plot_data <- 
#   data.table(
#     x1 = py$X_test[, 1],
#     te = py$te_test
#   )

# g_het_te <-
#   ggplot(plot_data) +
#   geom_point(aes(y = te, x = x1)) +
#   geom_line(aes(y = exp(x1), x = x1), color = "blue") +
#   theme_bw()

g_het_te <- readRDS("g_hte_te.rds")
g_het_te
```

Since we forced $\theta(X)$ to be linear in `x1`, it is not surprising that the estimated MTE looks linear in `x1` even though the true MTE is an exponential function of `x1`. In the next chapter (@sec-forest-cate), we discuss CATE estimators based on forest, which estimates $\theta(X)$ non-parametrically, relaxing the assumption of $\theta(X)$ being linear-in-parameter.

:::{.callout-tip}
There are many more variations in DML than the one presented here. For those who are interested, I recommend going through examples presented [here](https://github.com/microsoft/EconML/blob/main/notebooks/Double%20Machine%20Learning%20Examples.ipynb) for `DML`
:::





