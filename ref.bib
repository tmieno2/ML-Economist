@book{wooldridge2015introductory,
  title     = {Introductory econometrics: A modern approach},
  author    = {Wooldridge, Jeffrey M},
  year      = {2015},
  publisher = {Cengage learning}
}

@book{james2013introduction,
  title     = {An introduction to statistical learning},
  author    = {James, Gareth and Witten, Daniela and Hastie, Trevor and Tibshirani, Robert},
  volume    = {112},
  publisher = {Springer}
}

@book{hastie2009elements,
  title     = {The elements of statistical learning: data mining, inference, and prediction},
  author    = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome H and Friedman, Jerome H},
  volume    = {2},
  year      = {2009},
  publisher = {Springer}
}

@article{athey2016recursive,
  title={Recursive partitioning for heterogeneous causal effects},
  author={Athey, Susan and Imbens, Guido},
  journal={Proceedings of the National Academy of Sciences},
  volume={113},
  number={27},
  pages={7353--7360},
  year={2016},
  publisher={National Acad Sciences}
}

@book{wood2006generalized,
  title     = {Generalized additive models: an introduction with R},
  author    = {Wood, Simon N},
  year      = {2006},
  publisher = {chapman and hall/CRC}
}

@article{Chernozhukov2018,
  author  = {Chernozhukov, Victor and Chetverikov, Denis and Demirer, Mert and Duflo, Esther and Hansen, Christian and Newey, Whitney and Robins, James},
  title   = {{Double/debiased machine learning for treatment and structural parameters}},
  journal = {The Econometrics Journal},
  volume  = {21},
  number  = {1},
  pages   = {C1-C68},
  year    = {2018},
  month   = {01},
  issn    = {1368-4221},
  doi     = {10.1111/ectj.12097},
  url     = {https://doi.org/10.1111/ectj.12097},
  eprint  = {https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf}
}

@misc{econml,
  author       = {Keith Battocchi, Eleanor Dillon, Maggie Hei, Greg Lewis, Paul Oka, Miruna Oprescu, Vasilis Syrgkanis},
  title        = {{EconML}: {A Python Package for ML-Based Heterogeneous Treatment Effects Estimation}},
  howpublished = {https://github.com/microsoft/EconML},
  note         = {Version 0.x},
  year         = {2019}
}

@article{wager_estimation_2018,
  title    = {Estimation and {Inference} of {Heterogeneous} {Treatment} {Effects} using {Random} {Forests}},
  volume   = {113},
  issn     = {1537274X},
  url      = {https://doi.org/10.1080/01621459.2017.1319839},
  doi      = {10.1080/01621459.2017.1319839},
  abstract = {Many scientific and engineering challenges—ranging from personalized medicine to customized marketing recommendations—require an understanding of treatment effect heterogeneity. In this article, we develop a nonparametric causal forest for estimating heterogeneous treatment effects that extends Breiman's widely used random forest algorithm. In the potential outcomes framework with unconfoundedness, we show that causal forests are pointwise consistent for the true treatment effect and have an asymptotically Gaussian and centered sampling distribution. We also discuss a practical method for constructing asymptotic confidence intervals for the true treatment effect that are centered at the causal forest estimates. Our theoretical results rely on a generic Gaussian theory for a large family of random forest algorithms. To our knowledge, this is the first set of results that allows any type of random forest, including classification and regression forests, to be used for provably valid statistical inference. In experiments, we find causal forests to be substantially more powerful than classical methods based on nearest-neighbor matching, especially in the presence of irrelevant covariates.},
  number   = {523},
  journal  = {Journal of the American Statistical Association},
  author   = {Wager, Stefan and Athey, Susan},
  year     = {2018},
  note     = {Publisher: Taylor \& Francis
              \_eprint: 1510.04342},
  keywords = {Adaptive nearest neighbors matching, Asymptotic normality, Potential outcomes, Unconfoundedness},
  pages    = {1228--1242}
}


@article{kleiner_scalable_2014,
  title    = {A scalable bootstrap for massive data},
  volume   = {76},
  issn     = {13697412},
  url      = {https://onlinelibrary.wiley.com/doi/10.1111/rssb.12050},
  doi      = {10.1111/rssb.12050},
  language = {en},
  number   = {4},
  urldate  = {2022-07-06},
  journal  = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  author   = {Kleiner, Ariel and Talwalkar, Ameet and Sarkar, Purnamrita and Jordan, Michael I.},
  month    = sep,
  year     = {2014},
  pages    = {795--816},
  file     = {Kleiner et al. - 2014 - A scalable bootstrap for massive data.pdf:/Users/tmieno2/Zotero/storage/C2U6WR69/Kleiner et al. - 2014 - A scalable bootstrap for massive data.pdf:application/pdf}
}

@article{athey2019generalized,
  title={Generalized random forests},
  author={Athey, Susan and Tibshirani, Julie and Wager, Stefan},
  journal={The Annals of Statistics},
  volume={47},
  number={2},
  pages={1148--1178},
  year={2019},
  publisher={Institute of Mathematical Statistics}
}

@article{cawley_over-tting_nodate, title = {On {Over}-ﬁtting in {Model} {Selection} and {Subsequent} {Selection} {Bias} in {Performance} {Evaluation}},
  language = {en},
  author = {Cawley, Gavin C and Talbot, Nicola L C},
  pages = {29},
  file = {Cawley and Talbot - On Over-ﬁtting in Model Selection and Subsequent S.pdf:/Users/tmieno2/Zotero/storage/PXYDHQAJ/Cawley and Talbot - On Over-ﬁtting in Model Selection and Subsequent S.pdf:application/pdf},
}
