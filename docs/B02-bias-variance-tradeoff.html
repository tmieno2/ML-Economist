<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 2&nbsp; Bias-variance Trade-off</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./B03-cross-validation.html" rel="next">
<link href="./B01-nonlinear.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C04-cf-extension.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Extensions of Causal Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C05-causal-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Model Selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Programming: R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Programming: Python</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-01-scikitlearn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-02-CATE-econml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Treatment Effect Estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-03-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Model selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#training-and-test-mse" id="toc-training-and-test-mse" class="nav-link active" data-scroll-target="#training-and-test-mse"> <span class="header-section-number">2.1</span> Training and Test MSE</a></li>
  <li><a href="#bias-variance-trade-off" id="toc-bias-variance-trade-off" class="nav-link" data-scroll-target="#bias-variance-trade-off"> <span class="header-section-number">2.2</span> Bias-variance trade-off</a></li>
  <li><a href="#additional-example-k-nearest-neighbor-regression" id="toc-additional-example-k-nearest-neighbor-regression" class="nav-link" data-scroll-target="#additional-example-k-nearest-neighbor-regression"> <span class="header-section-number">2.3</span> Additional Example (K-nearest neighbor regression)</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/B02-bias-variance-tradeoff.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<!--
#==========================================
# General MC application steps 
#==========================================
-->
<section id="training-and-test-mse" class="level2 page-columns page-full" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="training-and-test-mse"><span class="header-section-number">2.1</span> Training and Test MSE</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p>Suppose you have a dataset: <span class="math inline">\(D = \{X_1, y_1\}, \{X_2, y_2\}, \dots, \{X_N, y_N\}\)</span>, where <span class="math inline">\(X_i\)</span> is a collection of features and <span class="math inline">\(y_i\)</span> is the dependent variable for <span class="math inline">\(i\)</span>th observation. Further, suppose you use <span class="math inline">\(D\)</span> for training ML models and <span class="math inline">\(\hat{f}()\)</span> is a trained model.</p>
<p>A most common measure of how good a model is <em>mean squared error</em> (MSE) defined as below:</p>
<p><span class="math display">\[
MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{f}(x_i))^2
\]</span></p>
<p><span class="math inline">\(\hat{f}(x_i)\)</span> is the value of <span class="math inline">\(y\)</span> predicted by the trained model <span class="math inline">\(\hat{f}()\)</span>, so <span class="math inline">\(y_i - \hat{f}(x_i)\)</span> is the residual (termed error more often).</p>
<p>When you get the MSE of a trained model for the very data that is used to train the model, then we may call it <strong>training</strong> MSE.</p>
<p>However, we are typically interested in how the trained model performs for the data that we have not seen. Let <span class="math inline">\(D^{test} = \{X^{test}_1, y^{test}_1\}, \{X^{test}_2, y^{test}_2\}, \dots, \{X^{test}_M, y^{test}_M\}\)</span> denote new data set with <span class="math inline">\(M\)</span> data points. Then the test MSE would be:</p>
<p><span class="math display">\[
MSE_{test} = \frac{1}{M} \sum_{i=1}^M (y^{test}_{i} - \hat{f}(x^{test}_{i}))^2
\]</span></p>
<p>Typically, we try different ML approaches (Random Forest, Support Vector Machine, Causal Forest, Boosted Regression Forest, Neural Network, etc). We also try different values of hyper-parameters for the same approach (e.g., tree depth and minimum observations per leaf for RF). Ideally, we would like to pick the model that has the smallest test <span class="math inline">\(MSE\)</span> among all the models.</p>
<p>Suppose you do not have a sufficiently large dataset to split to train and test datasets (often the case). So, you used all the available observations to train a model. That means you can get only training <span class="math inline">\(MSE\)</span>.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In this case, can we trust the model that has the lowest training <span class="math inline">\(MSE\)</span>?</p>
</div>
</div>
<p>The quick answer is no. The problem is that the model with the lowest training <span class="math inline">\(MSE\)</span> does not necessarily achieve the lowest test <span class="math inline">\(MSE\)</span>.</p>
<p>Let’s run some simulations to see this. The data generating process is as follows:</p>
<p><span class="math display">\[
y  = (x - 2.5)^3 + \mu
\]</span></p>
<p>where <span class="math inline">\(\mu\)</span> is the error term.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">943843</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># define the data generating process</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># x fixed</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>gen_data <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  ey <span class="ot">&lt;-</span> (x <span class="sc">-</span> <span class="fl">2.5</span>)<span class="sc">^</span><span class="dv">3</span> <span class="co"># E[y|x]</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> ey <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x)) <span class="co"># y = E[y|x] + u</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">ey =</span> ey)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="do">## generate train data</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="do">## generate test data</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># test data is large to stabilize test MSE </span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">10000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Visually, here is the relationship between <span class="math inline">\(E[y]\)</span> and <span class="math inline">\(x\)</span>:</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> train_data) <span class="sc">+</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> ey, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="480"></p>
</div>
</div>
<p>Now, let’s define a function that runs regression with different levels of flexibility using a generalized additive model from the <code>mgcv</code> package, predict <span class="math inline">\(y\)</span> for both the train and test datasets, and find train and test MSEs. Specifically, we vary the value of <code>k</code> (the number of knots) in <code>gam()</code> while intentionally setting <code>sp</code> to <span class="math inline">\(0\)</span> so that the wiggliness of the fitted curve is not punished.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>A very brief introduction of generalized additive mode is available in <a href="B01-nonlinear.html"><span>Chapter&nbsp;1</span></a></p>
</div></div><div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>est_gam <span class="ot">&lt;-</span> <span class="cf">function</span>(k, train_data, test_data) </span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define train and test data</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(train_data)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_data)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- train a model ---#  </span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>  trained_model <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> k), <span class="at">sp =</span> <span class="dv">0</span>, <span class="at">data =</span> train_data)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- predict y for the train and test datasets ---#</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>  train_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> train_data)] </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  train_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Train"</span>]</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  test_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> test_data)] </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>  test_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Test"</span>]</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- combine before returning ---#</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> </span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(train_data, test_data) <span class="sc">%&gt;%</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    .[, num_knots <span class="sc">:</span><span class="er">=</span> k]</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now loop over the number of knots (<code>num_knots</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>sim_results <span class="ot">&lt;-</span> </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, <span class="cf">function</span>(x) <span class="fu">est_gam</span>(x, train_data, test_data)) <span class="sc">%&gt;%</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-indiv-fit-gam">Figure&nbsp;<span>2.1</span></a> presents the fitted regression lines for <code>num_knots</code> <span class="math inline">\(= 1, 4, 5, 15, 25\)</span>, and <span class="math inline">\(50\)</span>, along with the observed data points in the train dataset.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_results[num_knots  <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), ]) <span class="sc">+</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> train_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x, <span class="at">color =</span> <span class="fu">factor</span>(num_knots))) <span class="sc">+</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-indiv-fit-gam" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-indiv-fit-gam-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.1: Fitted curves by gam() with different numbers of knots</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>When the number of knots is <span class="math inline">\(1\)</span>, gam is not flexible enough to capture the underlying cubic function. However, once the number of knots becomes <span class="math inline">\(4\)</span>, it is capable of capturing the underlying non-linearity. However, when you increase the number of knots to 15, you see that the fitted curve is very wiggly (sudden and large changes in <span class="math inline">\(y\)</span> when <span class="math inline">\(x\)</span> is changed slighly). When <code>num_knots</code> <span class="math inline">\(= 50\)</span>, the fitted curve looks crazy and does not resemble the underlying smooth cubic curve.</p>
<p>Now, let’s check how train and test MSEs change as k changes. As you can see in <a href="#fig-train-test-mse">Figure&nbsp;<span>2.2</span></a> below, train MSE goes down as k increases (the more complex the model is, the better fit you will get for the train data). However, test MSE is the lowest when <code>num_knots</code> <span class="math inline">\(= 4\)</span>, and it goes up afterward instead of going down. As we saw earlier, when model is made too flexible, it is trained to fit the trained data too well and lose generalizability (predict well for the dataset that has not been seen). This phenomenon is called over-fitting.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--- get train and test MSEs by k ---#</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>summary <span class="ot">&lt;-</span> </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  sim_results[, .(<span class="at">mse =</span> <span class="fu">mean</span>((y_hat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(num_knots, type)]</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(summary) <span class="sc">+</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of knots"</span>) <span class="sc">+</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"MSE"</span>) <span class="sc">+</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-train-test-mse" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-train-test-mse-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.2: Train and test MSEs as a function of the number of knots</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>If we were to trust train MSE in picking the model, we would pick the model with <code>k</code> <span class="math inline">\(= 50\)</span> in this particular instance. This clearly tells us that we should <span style="color:blue"> NOT </span> use training MSE to pick the best model.</p>
</section>
<section id="bias-variance-trade-off" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="bias-variance-trade-off"><span class="header-section-number">2.2</span> Bias-variance trade-off</h2>
<p>Expected test MSE at <span class="math inline">\(x = x_0\)</span> can be written in general (no matter what the trained model is) as follows:</p>
<p><span class="math display">\[
E[(y_0 - \hat{f}(x_0))^2] = Var(\hat{f}(x_0)) + Bias(\hat{x}_0)^2 + Var(\mu)
\]</span></p>
<ul>
<li><span class="math inline">\(Bias(\hat{x}_0) = E[\hat{f}(x_0)]-y_0\)</span></li>
<li><span class="math inline">\(Var(\hat{f}(x_0)) = E[(E[\hat{f}(x_0)]-\hat{f}(x_0))^2]\)</span></li>
</ul>
<p>The first term is the variance of predicted value at <span class="math inline">\(x_0\)</span>, the second term is the squared bias of <span class="math inline">\(\hat{f}(x_0)\)</span> (how much <span class="math inline">\(\hat{f}(x_0)\)</span> differs from <span class="math inline">\(E[y_0]\)</span> on average), and <span class="math inline">\(Var(\mu)\)</span> is the variance of the error term.</p>
<p>To illustrate this trade-off, we will run Monte Carlo simulations. We repeat the following steps 500 times.</p>
<ul>
<li>step 1: generate train and test datasets</li>
<li>step 2: train gam with different values of <span class="math inline">\(k\)</span> <span class="math inline">\((1, 5, 15, 25, 50)\)</span> using the train dataset</li>
<li>step 3: predict <span class="math inline">\(y\)</span> using the test dataset</li>
</ul>
<p>Once all the iterations are completed, simulation results are summarized to estimate <span class="math inline">\(Var(\hat{f}(x_0))\)</span> and <span class="math inline">\(E[y - \hat{f}(x_0)]^2\)</span> for all the values of <span class="math inline">\(x_0\)</span> (all the <span class="math inline">\(x\)</span> values observed in the test dataset) by <span class="math inline">\(k\)</span>. We then average them to find the overall <span class="math inline">\(Var(\hat{f}(x_0))\)</span> and <span class="math inline">\(E[y - \hat{f}(x_0)]^2\)</span> by <span class="math inline">\(k\)</span>.</p>
<div class="cell" data-hash="B02-bias-variance-tradeoff_cache/html/unnamed-chunk-9_af141e319cc44613dc34927c25d3be7a">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># x_test is fixed to make it easier to get average conditonal on a given value of x later  </span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># function that performs steps 1 ~ 3 (a single iteration) </span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>run_mc <span class="ot">&lt;-</span> <span class="cf">function</span>(i, x_train, x_test)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i) <span class="co"># track progress</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(x_train) <span class="co"># generate data</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(x_test) <span class="co"># generate data</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run gam for K = 1, ..., 50</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  sim_results <span class="ot">&lt;-</span> </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(x) <span class="fu">est_gam</span>(x, train_data, test_data)</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbindlist</span>()</span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim_results)</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co"># runs run_mc 500 times</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>mc_results <span class="ot">&lt;-</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_mc</span>(x, x_train, x_test),</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim_id"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-bias-variance-1">Figure&nbsp;<span>2.3</span></a> shows plots fitted curves for all the 500 simulations by <span class="math inline">\(k\)</span> (grey lines). The blue line is the true <span class="math inline">\(E[y|x]\)</span>. The red line is <span class="math inline">\(E[\hat{f}(x)]\)</span><a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. Figure <a href="#fig-bias-variance-summary">Figure&nbsp;<span>2.4</span></a> plots the average<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span class="math inline">\(Var(\hat{f}(x))\)</span> (red), <span class="math inline">\(E[y - \hat{f}(x)]^2\)</span> (blue), and test MSE (darkgreen) from the test datasets for different values of <span class="math inline">\(k\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>mc_results_sum <span class="ot">&lt;-</span> </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>    mc_results <span class="sc">%&gt;%</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    .[type <span class="sc">==</span> <span class="st">"Test"</span>, ] <span class="sc">%&gt;%</span> </span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">mean_y_hat =</span> <span class="fu">mean</span>(y_hat)), by <span class="ot">=</span> .(x, ey, num_knots)]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results[type <span class="sc">==</span> <span class="st">"Test"</span>, ], <span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x, <span class="at">group =</span> sim_id), <span class="at">color =</span> <span class="st">"gray"</span>) <span class="sc">+</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results_sum, <span class="fu">aes</span>(<span class="at">y =</span> mean_y_hat, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results_sum, <span class="fu">aes</span>(<span class="at">y =</span> ey, <span class="at">x=</span> x), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(. <span class="sc">~</span> num_knots, <span class="at">ncol =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-bias-variance-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-bias-variance-1-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.3: Bias-variance trade-off of GAM models with differing number of knots</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As you can see in <a href="#fig-bias-variance-1">Figure&nbsp;<span>2.3</span></a>, when <span class="math inline">\(k = 1\)</span>, it clearly has a significant bias in estimating <span class="math inline">\(E[y|x]\)</span> except for several values of <span class="math inline">\(x\)</span> at which <span class="math inline">\(E[\hat{f}(x)]\)</span> only <strong>happens</strong> to be unbiased. The model is simply too restrictive and suffers significant bias. However, the variance of <span class="math inline">\(\hat{f}(x)\)</span> is the smallest as shown in <a href="#fig-bias-variance-summary">Figure&nbsp;<span>2.4</span></a>. As we increase the value of <span class="math inline">\(k\)</span> (making the model more flexible), bias dramatically reduces. However, the variance of <span class="math inline">\(\hat{f}(x)\)</span> slightly increases. Going from <span class="math inline">\(k = 5\)</span> to <span class="math inline">\(k = 15\)</span> further reduces bias. That is, even though individual fitted curves may look very bad, on average they perform well (as you know that what bias measures). However, the variance of <span class="math inline">\(\hat{f}(x)\)</span> dramatically increases (this is why individual fitted curves look terrible). Moving to a even higher value of <span class="math inline">\(k\)</span> does not reduce bias, but increases the variance of <span class="math inline">\(\hat{f}(x)\)</span> even further. That is, increasing <span class="math inline">\(k\)</span> from 15 to a higher value of <span class="math inline">\(k\)</span> increases the variance of <span class="math inline">\(\hat{f}(x)\)</span> while not reducing bias at all.</p>
<p>According to MSE presented in <a href="#fig-bias-variance-summary">Figure&nbsp;<span>2.4</span></a>, <span class="math inline">\(k = 5\)</span> is the best model among all the models tried in this experiment. In this experiment, we had test datasets available. However, in practice, we need to pick the best model when test datasets are not available most of the time. For such a case, we would like a clever way to estimate <em>test</em> MSE even when test datasets are not available. We will later talk about cross-validation as a means to do so.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>sum_stat <span class="ot">&lt;-</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  mc_results <span class="sc">%&gt;%</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>  .[type <span class="sc">==</span> <span class="st">"Test"</span>, ] <span class="sc">%&gt;%</span> </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>  .[</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    , </span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>    .(</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">var_hat =</span> <span class="fu">var</span>(y_hat), <span class="co"># varianc of y_hat</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">bias_sq =</span> <span class="fu">mean</span>(y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>, <span class="co"># squared bias</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">mse =</span> <span class="fu">mean</span>((y <span class="sc">-</span> y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    by <span class="ot">=</span> .(x, num_knots)</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  ] <span class="sc">%&gt;%</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  .[</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    ,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    .(</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_var_hat =</span> <span class="fu">mean</span>(var_hat),</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_bias_sq =</span> <span class="fu">mean</span>(bias_sq),</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_mse =</span> <span class="fu">mean</span>(mse)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>    by <span class="ot">=</span> .(num_knots)</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> sum_stat) <span class="sc">+</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_var_hat, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Variance"</span>)) <span class="sc">+</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_var_hat, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Variance"</span>)) <span class="sc">+</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_bias_sq, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Bias"</span>)) <span class="sc">+</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_bias_sq, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Bias"</span>)) <span class="sc">+</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"test MSE"</span>)) <span class="sc">+</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"test MSE"</span>)) <span class="sc">+</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Variance"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Bias"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"test MSE"</span> <span class="ot">=</span> <span class="st">"darkgreen"</span>),</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of knots"</span>) <span class="sc">+</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-bias-variance-summary" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-bias-variance-summary-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.4: Expected variance of predicted values, bias, and test ME</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="additional-example-k-nearest-neighbor-regression" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="additional-example-k-nearest-neighbor-regression"><span class="header-section-number">2.3</span> Additional Example (K-nearest neighbor regression)</h2>
<p>Another example of bias-variance trade-off is presented using KNN as the regression method. Its hyper-parameter - the number of neighbors (<code>k</code>) - is varied to see its effect.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>fit_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(k, train_data, test_data) </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define train and test data</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(train_data)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_data)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- train a model ---#  </span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  trained_model <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(y <span class="sc">~</span> x, <span class="at">k =</span> k, <span class="at">data =</span> train_data)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- predict y for the train and test datasets ---#</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  train_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> train_data)] </span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  train_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Train"</span>]</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>  test_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> test_data)] </span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  test_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Test"</span>]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- combine before returning ---#</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> </span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(train_data, test_data) <span class="sc">%&gt;%</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    .[, num_nbs <span class="sc">:</span><span class="er">=</span> k]</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now loop over the number of neighbors (<code>k</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="do">## generate train data</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">1000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="do">## generate test data</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">1000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>sim_results <span class="ot">&lt;-</span> </span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, <span class="cf">function</span>(x) <span class="fu">fit_knn</span>(x, train_data, test_data)) <span class="sc">%&gt;%</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-indiv-fit-knn">Figure&nbsp;<span>2.5</span></a> presents the fitted regression lines for <span class="math inline">\(k = 1, 5, 15, 25\)</span>, and <span class="math inline">\(50\)</span> using <code>knnreg()</code>, along with the observed data points in the train dataset.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_results[num_nbs  <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), ]) <span class="sc">+</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> train_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"gray"</span>) <span class="sc">+</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(num_nbs <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-indiv-fit-knn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-indiv-fit-knn-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.5: Fitted curves by knnreg() with different numbers of neighbors</figcaption><p></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--- get train and test MSEs by k ---#</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>summary <span class="ot">&lt;-</span> </span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  sim_results[, .(<span class="at">mse =</span> <span class="fu">mean</span>((y_hat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(num_nbs, type)]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(summary) <span class="sc">+</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_nbs, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_nbs, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of neighbors"</span>) <span class="sc">+</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"MSE"</span>) <span class="sc">+</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-train-test-mse-knn" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="B02-bias-variance-tradeoff_files/figure-html/fig-train-test-mse-knn-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 2.6: Train and test MSEs as a function of the number of knots</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<div id="refs" role="doc-bibliography">

</div>


<!-- -->

</section>
<section class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>This figure is a collection of individual fitted curve just like the ones shown in <a href="#fig-indiv-fit-gam">Figure&nbsp;<span>2.1</span></a>.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>averaged over <span class="math inline">\(x\)</span>, and then averaged over iterations<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./B01-nonlinear.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./B03-cross-validation.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb15" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Bias-variance Trade-off</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!--</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="co">#==========================================</span></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co"># General MC application steps </span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#==========================================</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">--&gt;</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training and Test MSE </span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>Suppose you have a dataset: $D = <span class="sc">\{</span>X_1, y_1<span class="sc">\}</span>, <span class="sc">\{</span>X_2, y_2<span class="sc">\}</span>, </span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>\dots, <span class="sc">\{</span>X_N, y_N<span class="sc">\}</span>$, where $X_i$ is a collection of features and $y_i$ is the dependent variable for $i$th observation. Further, suppose you use $D$ for training ML models and $\hat{f}()$ is a trained model. </span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>A most common measure of how good a model is *mean squared error* (MSE) defined as below:</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>MSE = \frac{1}{N} \sum_{i=1}^N (y_i - \hat{f}(x_i))^2</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>$\hat{f}(x_i)$ is the value of $y$ predicted by the trained model $\hat{f}()$, so $y_i - \hat{f}(x_i)$ is the residual (termed error more often). </span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>When you get the MSE of a trained model for the very data that is used to train the model, then we may call it **training** MSE.  </span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>However, we are typically interested in how the trained model performs for the data that we have not seen. Let $D^{test} = <span class="sc">\{</span>X^{test}_1, y^{test}_1\}, \{X^{test}_2, y^{test}_2\}, \dots, \{X^{test}_M, y^{test}_M<span class="sc">\}</span>$ denote new data set with $M$ data points. Then the test MSE would be:</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>MSE_{test} = \frac{1}{M} \sum_{i=1}^M (y^{test}_{i} - \hat{f}(x^{test}_{i}))^2</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>Typically, we try different ML approaches (Random Forest, Support Vector Machine, Causal Forest, Boosted Regression Forest, Neural Network, etc). We also try different values of hyper-parameters for the same approach (e.g., tree depth and minimum observations per leaf for RF). Ideally, we would like to pick the model that has the smallest test $MSE$ among all the models. </span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>Suppose you do not have a sufficiently large dataset to split to train and test datasets (often the case). So, you used all the available observations to train a model. That means you can get only training $MSE$. </span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>In this case, can we trust the model that has the lowest training $MSE$?</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>The quick answer is no. The problem is that the model with the lowest training $MSE$ does not necessarily achieve the lowest test $MSE$. </span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a>Let's run some simulations to see this. The data generating process is as follows:</span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a>y  = (x - 2.5)^3 + \mu</span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a>where $\mu$ is the error term. </span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">943843</span>)</span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a><span class="co"># define the data generating process</span></span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a><span class="co"># x fixed</span></span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>gen_data <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>  ey <span class="ot">&lt;-</span> (x <span class="sc">-</span> <span class="fl">2.5</span>)<span class="sc">^</span><span class="dv">3</span> <span class="co"># E[y|x]</span></span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> ey <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="fu">length</span>(x)) <span class="co"># y = E[y|x] + u</span></span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">ey =</span> ey)</span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb15-91"><a href="#cb15-91" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-92"><a href="#cb15-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-93"><a href="#cb15-93" aria-hidden="true" tabindex="-1"></a><span class="do">## generate train data</span></span>
<span id="cb15-94"><a href="#cb15-94" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb15-95"><a href="#cb15-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-96"><a href="#cb15-96" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-97"><a href="#cb15-97" aria-hidden="true" tabindex="-1"></a><span class="do">## generate test data</span></span>
<span id="cb15-98"><a href="#cb15-98" aria-hidden="true" tabindex="-1"></a><span class="co"># test data is large to stabilize test MSE </span></span>
<span id="cb15-99"><a href="#cb15-99" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">10000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb15-100"><a href="#cb15-100" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-101"><a href="#cb15-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-102"><a href="#cb15-102" aria-hidden="true" tabindex="-1"></a>Visually, here is the relationship between $E<span class="co">[</span><span class="ot">y</span><span class="co">]</span>$ and $x$:</span>
<span id="cb15-103"><a href="#cb15-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-106"><a href="#cb15-106" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-107"><a href="#cb15-107" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-108"><a href="#cb15-108" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 3 </span></span>
<span id="cb15-109"><a href="#cb15-109" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 5 </span></span>
<span id="cb15-110"><a href="#cb15-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-111"><a href="#cb15-111" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> train_data) <span class="sc">+</span></span>
<span id="cb15-112"><a href="#cb15-112" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> ey, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb15-113"><a href="#cb15-113" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-114"><a href="#cb15-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-115"><a href="#cb15-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-116"><a href="#cb15-116" aria-hidden="true" tabindex="-1"></a>Now, let's define a function that runs regression with different levels of flexibility using a generalized additive model from the <span class="in">`mgcv`</span> package, predict $y$ for both the train and test datasets, and find train and test MSEs. Specifically, we vary the value of <span class="in">`k`</span> (the number of knots) in <span class="in">`gam()`</span> while intentionally setting <span class="in">`sp`</span> to $0$ so that the wiggliness of the fitted curve is not punished.</span>
<span id="cb15-117"><a href="#cb15-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-118"><a href="#cb15-118" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb15-119"><a href="#cb15-119" aria-hidden="true" tabindex="-1"></a>A very brief introduction of generalized additive mode is available in @sec-nonlinear</span>
<span id="cb15-120"><a href="#cb15-120" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb15-121"><a href="#cb15-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-124"><a href="#cb15-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-125"><a href="#cb15-125" aria-hidden="true" tabindex="-1"></a>est_gam <span class="ot">&lt;-</span> <span class="cf">function</span>(k, train_data, test_data) </span>
<span id="cb15-126"><a href="#cb15-126" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb15-127"><a href="#cb15-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-128"><a href="#cb15-128" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define train and test data</span></span>
<span id="cb15-129"><a href="#cb15-129" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(train_data)</span>
<span id="cb15-130"><a href="#cb15-130" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_data)</span>
<span id="cb15-131"><a href="#cb15-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-132"><a href="#cb15-132" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- train a model ---#  </span></span>
<span id="cb15-133"><a href="#cb15-133" aria-hidden="true" tabindex="-1"></a>  trained_model <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> k), <span class="at">sp =</span> <span class="dv">0</span>, <span class="at">data =</span> train_data)</span>
<span id="cb15-134"><a href="#cb15-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-135"><a href="#cb15-135" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- predict y for the train and test datasets ---#</span></span>
<span id="cb15-136"><a href="#cb15-136" aria-hidden="true" tabindex="-1"></a>  train_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> train_data)] </span>
<span id="cb15-137"><a href="#cb15-137" aria-hidden="true" tabindex="-1"></a>  train_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Train"</span>]</span>
<span id="cb15-138"><a href="#cb15-138" aria-hidden="true" tabindex="-1"></a>  test_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> test_data)] </span>
<span id="cb15-139"><a href="#cb15-139" aria-hidden="true" tabindex="-1"></a>  test_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Test"</span>]</span>
<span id="cb15-140"><a href="#cb15-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-141"><a href="#cb15-141" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- combine before returning ---#</span></span>
<span id="cb15-142"><a href="#cb15-142" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> </span>
<span id="cb15-143"><a href="#cb15-143" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(train_data, test_data) <span class="sc">%&gt;%</span></span>
<span id="cb15-144"><a href="#cb15-144" aria-hidden="true" tabindex="-1"></a>    .[, num_knots <span class="sc">:</span><span class="er">=</span> k]</span>
<span id="cb15-145"><a href="#cb15-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-146"><a href="#cb15-146" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb15-147"><a href="#cb15-147" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-148"><a href="#cb15-148" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-149"><a href="#cb15-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-150"><a href="#cb15-150" aria-hidden="true" tabindex="-1"></a>We now loop over the number of knots (<span class="in">`num_knots`</span>). </span>
<span id="cb15-151"><a href="#cb15-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-154"><a href="#cb15-154" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-155"><a href="#cb15-155" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb15-156"><a href="#cb15-156" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb15-157"><a href="#cb15-157" aria-hidden="true" tabindex="-1"></a>sim_results <span class="ot">&lt;-</span> </span>
<span id="cb15-158"><a href="#cb15-158" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, <span class="cf">function</span>(x) <span class="fu">est_gam</span>(x, train_data, test_data)) <span class="sc">%&gt;%</span></span>
<span id="cb15-159"><a href="#cb15-159" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb15-160"><a href="#cb15-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-161"><a href="#cb15-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-162"><a href="#cb15-162" aria-hidden="true" tabindex="-1"></a>@fig-indiv-fit-gam presents the fitted regression lines for <span class="in">`num_knots`</span> $= 1, 4, 5, 15, 25$, and $50$, along with the observed data points in the train dataset.</span>
<span id="cb15-163"><a href="#cb15-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-166"><a href="#cb15-166" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-167"><a href="#cb15-167" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-indiv-fit-gam</span></span>
<span id="cb15-168"><a href="#cb15-168" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-169"><a href="#cb15-169" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Fitted curves by gam() with different numbers of knots</span></span>
<span id="cb15-170"><a href="#cb15-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-171"><a href="#cb15-171" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_results[num_knots  <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), ]) <span class="sc">+</span></span>
<span id="cb15-172"><a href="#cb15-172" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> train_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"grey"</span>) <span class="sc">+</span></span>
<span id="cb15-173"><a href="#cb15-173" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x, <span class="at">color =</span> <span class="fu">factor</span>(num_knots))) <span class="sc">+</span></span>
<span id="cb15-174"><a href="#cb15-174" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-175"><a href="#cb15-175" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-176"><a href="#cb15-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-177"><a href="#cb15-177" aria-hidden="true" tabindex="-1"></a>When the number of knots is $1$, gam is not flexible enough to capture the underlying cubic function. However, once the number of knots becomes $4$, it is capable of capturing the underlying non-linearity. However, when you increase the number of knots to 15, you see that the fitted curve is very wiggly (sudden and large changes in $y$ when $x$ is changed slighly). When <span class="in">`num_knots`</span> $= 50$, the fitted curve looks crazy and does not resemble the underlying smooth cubic curve. </span>
<span id="cb15-178"><a href="#cb15-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-179"><a href="#cb15-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-180"><a href="#cb15-180" aria-hidden="true" tabindex="-1"></a>Now, let's check how train and test MSEs change as k changes. As you can see in @fig-train-test-mse below, train MSE goes down as k increases (the more complex the model is, the better fit you will get for the train data). However, test MSE is the lowest when <span class="in">`num_knots`</span> $= 4$, and it goes up afterward instead of going down. As we saw earlier, when model is made too flexible, it is trained to fit the trained data too well and lose generalizability (predict well for the dataset that has not been seen). This phenomenon is called over-fitting.  </span>
<span id="cb15-181"><a href="#cb15-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-184"><a href="#cb15-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-185"><a href="#cb15-185" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-train-test-mse</span></span>
<span id="cb15-186"><a href="#cb15-186" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-187"><a href="#cb15-187" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Train and test MSEs as a function of the number of knots </span></span>
<span id="cb15-188"><a href="#cb15-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-189"><a href="#cb15-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-190"><a href="#cb15-190" aria-hidden="true" tabindex="-1"></a><span class="co">#--- get train and test MSEs by k ---#</span></span>
<span id="cb15-191"><a href="#cb15-191" aria-hidden="true" tabindex="-1"></a>summary <span class="ot">&lt;-</span> </span>
<span id="cb15-192"><a href="#cb15-192" aria-hidden="true" tabindex="-1"></a>  sim_results[, .(<span class="at">mse =</span> <span class="fu">mean</span>((y_hat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(num_knots, type)]</span>
<span id="cb15-193"><a href="#cb15-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-194"><a href="#cb15-194" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(summary) <span class="sc">+</span></span>
<span id="cb15-195"><a href="#cb15-195" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb15-196"><a href="#cb15-196" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb15-197"><a href="#cb15-197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of knots"</span>) <span class="sc">+</span></span>
<span id="cb15-198"><a href="#cb15-198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"MSE"</span>) <span class="sc">+</span></span>
<span id="cb15-199"><a href="#cb15-199" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb15-200"><a href="#cb15-200" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-201"><a href="#cb15-201" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-202"><a href="#cb15-202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-203"><a href="#cb15-203" aria-hidden="true" tabindex="-1"></a>If we were to trust train MSE in picking the model, we would pick the model with <span class="in">`k`</span> $= 50$ in this particular instance. This clearly tells us that we should <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> NOT <span class="kw">&lt;/span&gt;</span> use training MSE to pick the best model. </span>
<span id="cb15-204"><a href="#cb15-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-205"><a href="#cb15-205" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bias-variance trade-off</span></span>
<span id="cb15-206"><a href="#cb15-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-207"><a href="#cb15-207" aria-hidden="true" tabindex="-1"></a>Expected test MSE at $x = x_0$ can be written in general (no matter what the trained model is) as follows:</span>
<span id="cb15-208"><a href="#cb15-208" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-209"><a href="#cb15-209" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">(y_0 - \hat{f}(x_0))^2</span><span class="co">]</span> = Var(\hat{f}(x_0)) + Bias(\hat{x}_0)^2 + Var(\mu)</span>
<span id="cb15-210"><a href="#cb15-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb15-211"><a href="#cb15-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-212"><a href="#cb15-212" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$Bias(\hat{x}_0) = E<span class="co">[</span><span class="ot">\hat{f}(x_0)</span><span class="co">]</span>-y_0$</span>
<span id="cb15-213"><a href="#cb15-213" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$Var(\hat{f}(x_0)) = E<span class="co">[</span><span class="ot">(E[\hat{f}(x_0)]-\hat{f}(x_0))^2</span><span class="co">]</span>$</span>
<span id="cb15-214"><a href="#cb15-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-215"><a href="#cb15-215" aria-hidden="true" tabindex="-1"></a>The first term is the variance of predicted value at $x_0$, the second term is the squared bias of $\hat{f}(x_0)$ (how much $\hat{f}(x_0)$ differs from $E<span class="co">[</span><span class="ot">y_0</span><span class="co">]</span>$ on average), and $Var(\mu)$ is the variance of the error term. </span>
<span id="cb15-216"><a href="#cb15-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-217"><a href="#cb15-217" aria-hidden="true" tabindex="-1"></a>To illustrate this trade-off, we will run Monte Carlo simulations. We repeat the following steps 500 times.</span>
<span id="cb15-218"><a href="#cb15-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-219"><a href="#cb15-219" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>step 1: generate train and test datasets</span>
<span id="cb15-220"><a href="#cb15-220" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>step 2: train gam with different values of $k$ $(1, 5, 15, 25, 50)$ using the train dataset</span>
<span id="cb15-221"><a href="#cb15-221" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>step 3: predict $y$ using the test dataset</span>
<span id="cb15-222"><a href="#cb15-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-223"><a href="#cb15-223" aria-hidden="true" tabindex="-1"></a>Once all the iterations are completed, simulation results are summarized to estimate $Var(\hat{f}(x_0))$ and $E<span class="co">[</span><span class="ot">y - \hat{f}(x_0)</span><span class="co">]</span>^2$ for all the values of $x_0$ (all the $x$ values observed in the test dataset) by $k$. We then average them to find the overall $Var(\hat{f}(x_0))$ and $E<span class="co">[</span><span class="ot">y - \hat{f}(x_0)</span><span class="co">]</span>^2$ by $k$.</span>
<span id="cb15-224"><a href="#cb15-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-225"><a href="#cb15-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-228"><a href="#cb15-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-229"><a href="#cb15-229" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true</span></span>
<span id="cb15-230"><a href="#cb15-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-231"><a href="#cb15-231" aria-hidden="true" tabindex="-1"></a>x_train <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb15-232"><a href="#cb15-232" aria-hidden="true" tabindex="-1"></a><span class="co"># x_test is fixed to make it easier to get average conditonal on a given value of x later  </span></span>
<span id="cb15-233"><a href="#cb15-233" aria-hidden="true" tabindex="-1"></a>x_test <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">100</span>) <span class="sc">*</span> <span class="dv">5</span></span>
<span id="cb15-234"><a href="#cb15-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-235"><a href="#cb15-235" aria-hidden="true" tabindex="-1"></a><span class="co"># function that performs steps 1 ~ 3 (a single iteration) </span></span>
<span id="cb15-236"><a href="#cb15-236" aria-hidden="true" tabindex="-1"></a>run_mc <span class="ot">&lt;-</span> <span class="cf">function</span>(i, x_train, x_test)</span>
<span id="cb15-237"><a href="#cb15-237" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb15-238"><a href="#cb15-238" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i) <span class="co"># track progress</span></span>
<span id="cb15-239"><a href="#cb15-239" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(x_train) <span class="co"># generate data</span></span>
<span id="cb15-240"><a href="#cb15-240" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(x_test) <span class="co"># generate data</span></span>
<span id="cb15-241"><a href="#cb15-241" aria-hidden="true" tabindex="-1"></a>  <span class="co"># run gam for K = 1, ..., 50</span></span>
<span id="cb15-242"><a href="#cb15-242" aria-hidden="true" tabindex="-1"></a>  sim_results <span class="ot">&lt;-</span> </span>
<span id="cb15-243"><a href="#cb15-243" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb15-244"><a href="#cb15-244" aria-hidden="true" tabindex="-1"></a>      <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), </span>
<span id="cb15-245"><a href="#cb15-245" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(x) <span class="fu">est_gam</span>(x, train_data, test_data)</span>
<span id="cb15-246"><a href="#cb15-246" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span></span>
<span id="cb15-247"><a href="#cb15-247" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbindlist</span>()</span>
<span id="cb15-248"><a href="#cb15-248" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-249"><a href="#cb15-249" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(sim_results)</span>
<span id="cb15-250"><a href="#cb15-250" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-251"><a href="#cb15-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-252"><a href="#cb15-252" aria-hidden="true" tabindex="-1"></a><span class="co"># runs run_mc 500 times</span></span>
<span id="cb15-253"><a href="#cb15-253" aria-hidden="true" tabindex="-1"></a>mc_results <span class="ot">&lt;-</span></span>
<span id="cb15-254"><a href="#cb15-254" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb15-255"><a href="#cb15-255" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb15-256"><a href="#cb15-256" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_mc</span>(x, x_train, x_test),</span>
<span id="cb15-257"><a href="#cb15-257" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb15-258"><a href="#cb15-258" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb15-259"><a href="#cb15-259" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim_id"</span>) </span>
<span id="cb15-260"><a href="#cb15-260" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-261"><a href="#cb15-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-262"><a href="#cb15-262" aria-hidden="true" tabindex="-1"></a>@fig-bias-variance-1 shows plots fitted curves for all the 500 simulations by $k$ (grey lines). The blue line is the true $E<span class="co">[</span><span class="ot">y|x</span><span class="co">]</span>$. The red line is $E<span class="co">[</span><span class="ot">\hat{f}(x)</span><span class="co">]</span>$^<span class="co">[</span><span class="ot">This figure is a collection of individual fitted curve just like the ones shown in @fig-indiv-fit-gam.</span><span class="co">]</span>. Figure @fig-bias-variance-summary plots the average^<span class="co">[</span><span class="ot">averaged over $x$, and then averaged over iterations</span><span class="co">]</span> $Var(\hat{f}(x))$ (red), $E<span class="co">[</span><span class="ot">y - \hat{f}(x)</span><span class="co">]</span>^2$ (blue), and test MSE (darkgreen) from the test datasets for different values of $k$. </span>
<span id="cb15-263"><a href="#cb15-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-266"><a href="#cb15-266" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-267"><a href="#cb15-267" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-bias-variance-1</span></span>
<span id="cb15-268"><a href="#cb15-268" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-269"><a href="#cb15-269" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Bias-variance trade-off of GAM models with differing number of knots</span></span>
<span id="cb15-270"><a href="#cb15-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-271"><a href="#cb15-271" aria-hidden="true" tabindex="-1"></a>mc_results_sum <span class="ot">&lt;-</span> </span>
<span id="cb15-272"><a href="#cb15-272" aria-hidden="true" tabindex="-1"></a>    mc_results <span class="sc">%&gt;%</span></span>
<span id="cb15-273"><a href="#cb15-273" aria-hidden="true" tabindex="-1"></a>    .[type <span class="sc">==</span> <span class="st">"Test"</span>, ] <span class="sc">%&gt;%</span> </span>
<span id="cb15-274"><a href="#cb15-274" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">mean_y_hat =</span> <span class="fu">mean</span>(y_hat)), by <span class="ot">=</span> .(x, ey, num_knots)]</span>
<span id="cb15-275"><a href="#cb15-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-276"><a href="#cb15-276" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb15-277"><a href="#cb15-277" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results[type <span class="sc">==</span> <span class="st">"Test"</span>, ], <span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x, <span class="at">group =</span> sim_id), <span class="at">color =</span> <span class="st">"gray"</span>) <span class="sc">+</span></span>
<span id="cb15-278"><a href="#cb15-278" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results_sum, <span class="fu">aes</span>(<span class="at">y =</span> mean_y_hat, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb15-279"><a href="#cb15-279" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">data =</span> mc_results_sum, <span class="fu">aes</span>(<span class="at">y =</span> ey, <span class="at">x=</span> x), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb15-280"><a href="#cb15-280" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(. <span class="sc">~</span> num_knots, <span class="at">ncol =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb15-281"><a href="#cb15-281" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()</span>
<span id="cb15-282"><a href="#cb15-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-283"><a href="#cb15-283" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-284"><a href="#cb15-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-285"><a href="#cb15-285" aria-hidden="true" tabindex="-1"></a>As you can see in @fig-bias-variance-1, when $k = 1$, it clearly has a significant bias in estimating $E<span class="co">[</span><span class="ot">y|x</span><span class="co">]</span>$ except for several values of $x$ at which $E<span class="co">[</span><span class="ot">\hat{f}(x)</span><span class="co">]</span>$ only **happens** to be unbiased. The model is simply too restrictive and suffers significant bias. However, the variance of $\hat{f}(x)$ is the smallest as shown in @fig-bias-variance-summary. As we increase the value of $k$ (making the model more flexible), bias dramatically reduces. However, the variance of $\hat{f}(x)$ slightly increases. Going from $k = 5$ to $k = 15$ further reduces bias. That is, even though individual fitted curves may look very bad, on average they perform well (as you know that what bias measures). However, the variance of $\hat{f}(x)$ dramatically increases (this is why individual fitted curves look terrible). Moving to a even higher value of $k$ does not reduce bias, but increases the variance of $\hat{f}(x)$ even further. That is, increasing $k$ from 15 to a higher value of $k$ increases the variance of $\hat{f}(x)$ while not reducing bias at all. </span>
<span id="cb15-286"><a href="#cb15-286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-287"><a href="#cb15-287" aria-hidden="true" tabindex="-1"></a>According to MSE presented in @fig-bias-variance-summary, $k = 5$ is the best model among all the models tried in this experiment. In this experiment, we had test datasets available. However, in practice, we need to pick the best model when test datasets are not available most of the time. For such a case, we would like a clever way to estimate *test* MSE even when test datasets are not available. We will later talk about cross-validation as a means to do so.</span>
<span id="cb15-288"><a href="#cb15-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-289"><a href="#cb15-289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-292"><a href="#cb15-292" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-293"><a href="#cb15-293" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-bias-variance-summary</span></span>
<span id="cb15-294"><a href="#cb15-294" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-295"><a href="#cb15-295" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Expected variance of predicted values, bias, and test ME</span></span>
<span id="cb15-296"><a href="#cb15-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-297"><a href="#cb15-297" aria-hidden="true" tabindex="-1"></a>sum_stat <span class="ot">&lt;-</span> </span>
<span id="cb15-298"><a href="#cb15-298" aria-hidden="true" tabindex="-1"></a>  mc_results <span class="sc">%&gt;%</span></span>
<span id="cb15-299"><a href="#cb15-299" aria-hidden="true" tabindex="-1"></a>  .[type <span class="sc">==</span> <span class="st">"Test"</span>, ] <span class="sc">%&gt;%</span> </span>
<span id="cb15-300"><a href="#cb15-300" aria-hidden="true" tabindex="-1"></a>  .[</span>
<span id="cb15-301"><a href="#cb15-301" aria-hidden="true" tabindex="-1"></a>    , </span>
<span id="cb15-302"><a href="#cb15-302" aria-hidden="true" tabindex="-1"></a>    .(</span>
<span id="cb15-303"><a href="#cb15-303" aria-hidden="true" tabindex="-1"></a>      <span class="at">var_hat =</span> <span class="fu">var</span>(y_hat), <span class="co"># varianc of y_hat</span></span>
<span id="cb15-304"><a href="#cb15-304" aria-hidden="true" tabindex="-1"></a>      <span class="at">bias_sq =</span> <span class="fu">mean</span>(y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>, <span class="co"># squared bias</span></span>
<span id="cb15-305"><a href="#cb15-305" aria-hidden="true" tabindex="-1"></a>      <span class="at">mse =</span> <span class="fu">mean</span>((y <span class="sc">-</span> y_hat)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb15-306"><a href="#cb15-306" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb15-307"><a href="#cb15-307" aria-hidden="true" tabindex="-1"></a>    by <span class="ot">=</span> .(x, num_knots)</span>
<span id="cb15-308"><a href="#cb15-308" aria-hidden="true" tabindex="-1"></a>  ] <span class="sc">%&gt;%</span></span>
<span id="cb15-309"><a href="#cb15-309" aria-hidden="true" tabindex="-1"></a>  .[</span>
<span id="cb15-310"><a href="#cb15-310" aria-hidden="true" tabindex="-1"></a>    ,</span>
<span id="cb15-311"><a href="#cb15-311" aria-hidden="true" tabindex="-1"></a>    .(</span>
<span id="cb15-312"><a href="#cb15-312" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_var_hat =</span> <span class="fu">mean</span>(var_hat),</span>
<span id="cb15-313"><a href="#cb15-313" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_bias_sq =</span> <span class="fu">mean</span>(bias_sq),</span>
<span id="cb15-314"><a href="#cb15-314" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_mse =</span> <span class="fu">mean</span>(mse)</span>
<span id="cb15-315"><a href="#cb15-315" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb15-316"><a href="#cb15-316" aria-hidden="true" tabindex="-1"></a>    by <span class="ot">=</span> .(num_knots)</span>
<span id="cb15-317"><a href="#cb15-317" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb15-318"><a href="#cb15-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-319"><a href="#cb15-319" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> sum_stat) <span class="sc">+</span></span>
<span id="cb15-320"><a href="#cb15-320" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_var_hat, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Variance"</span>)) <span class="sc">+</span></span>
<span id="cb15-321"><a href="#cb15-321" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_var_hat, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Variance"</span>)) <span class="sc">+</span></span>
<span id="cb15-322"><a href="#cb15-322" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_bias_sq, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Bias"</span>)) <span class="sc">+</span></span>
<span id="cb15-323"><a href="#cb15-323" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_bias_sq, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"Bias"</span>)) <span class="sc">+</span></span>
<span id="cb15-324"><a href="#cb15-324" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"test MSE"</span>)) <span class="sc">+</span></span>
<span id="cb15-325"><a href="#cb15-325" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mean_mse, <span class="at">x =</span> num_knots, <span class="at">color =</span> <span class="st">"test MSE"</span>)) <span class="sc">+</span></span>
<span id="cb15-326"><a href="#cb15-326" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb15-327"><a href="#cb15-327" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Variance"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Bias"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"test MSE"</span> <span class="ot">=</span> <span class="st">"darkgreen"</span>),</span>
<span id="cb15-328"><a href="#cb15-328" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb15-329"><a href="#cb15-329" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb15-330"><a href="#cb15-330" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb15-331"><a href="#cb15-331" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of knots"</span>) <span class="sc">+</span></span>
<span id="cb15-332"><a href="#cb15-332" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-333"><a href="#cb15-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-334"><a href="#cb15-334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-335"><a href="#cb15-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-336"><a href="#cb15-336" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb15-337"><a href="#cb15-337" aria-hidden="true" tabindex="-1"></a><span class="fu">## Additional Example (K-nearest neighbor regression)</span></span>
<span id="cb15-338"><a href="#cb15-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-339"><a href="#cb15-339" aria-hidden="true" tabindex="-1"></a>Another example of bias-variance trade-off is presented using KNN as the regression method. Its hyper-parameter - the number of neighbors (<span class="in">`k`</span>) - is varied to see its effect. </span>
<span id="cb15-340"><a href="#cb15-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-343"><a href="#cb15-343" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-344"><a href="#cb15-344" aria-hidden="true" tabindex="-1"></a>fit_knn <span class="ot">&lt;-</span> <span class="cf">function</span>(k, train_data, test_data) </span>
<span id="cb15-345"><a href="#cb15-345" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb15-346"><a href="#cb15-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-347"><a href="#cb15-347" aria-hidden="true" tabindex="-1"></a>  <span class="co"># define train and test data</span></span>
<span id="cb15-348"><a href="#cb15-348" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(train_data)</span>
<span id="cb15-349"><a href="#cb15-349" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_data)</span>
<span id="cb15-350"><a href="#cb15-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-351"><a href="#cb15-351" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- train a model ---#  </span></span>
<span id="cb15-352"><a href="#cb15-352" aria-hidden="true" tabindex="-1"></a>  trained_model <span class="ot">&lt;-</span> <span class="fu">knnreg</span>(y <span class="sc">~</span> x, <span class="at">k =</span> k, <span class="at">data =</span> train_data)</span>
<span id="cb15-353"><a href="#cb15-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-354"><a href="#cb15-354" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- predict y for the train and test datasets ---#</span></span>
<span id="cb15-355"><a href="#cb15-355" aria-hidden="true" tabindex="-1"></a>  train_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> train_data)] </span>
<span id="cb15-356"><a href="#cb15-356" aria-hidden="true" tabindex="-1"></a>  train_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Train"</span>]</span>
<span id="cb15-357"><a href="#cb15-357" aria-hidden="true" tabindex="-1"></a>  test_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(trained_model, <span class="at">newdata =</span> test_data)] </span>
<span id="cb15-358"><a href="#cb15-358" aria-hidden="true" tabindex="-1"></a>  test_data[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Test"</span>]</span>
<span id="cb15-359"><a href="#cb15-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-360"><a href="#cb15-360" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--- combine before returning ---#</span></span>
<span id="cb15-361"><a href="#cb15-361" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> </span>
<span id="cb15-362"><a href="#cb15-362" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(train_data, test_data) <span class="sc">%&gt;%</span></span>
<span id="cb15-363"><a href="#cb15-363" aria-hidden="true" tabindex="-1"></a>    .[, num_nbs <span class="sc">:</span><span class="er">=</span> k]</span>
<span id="cb15-364"><a href="#cb15-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-365"><a href="#cb15-365" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(return_data)</span>
<span id="cb15-366"><a href="#cb15-366" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-367"><a href="#cb15-367" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-368"><a href="#cb15-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-369"><a href="#cb15-369" aria-hidden="true" tabindex="-1"></a>We now loop over the number of neighbors (<span class="in">`k`</span>). </span>
<span id="cb15-370"><a href="#cb15-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-373"><a href="#cb15-373" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-374"><a href="#cb15-374" aria-hidden="true" tabindex="-1"></a><span class="co">#| message: false</span></span>
<span id="cb15-375"><a href="#cb15-375" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb15-376"><a href="#cb15-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-377"><a href="#cb15-377" aria-hidden="true" tabindex="-1"></a><span class="do">## generate train data</span></span>
<span id="cb15-378"><a href="#cb15-378" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">1000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb15-379"><a href="#cb15-379" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb15-380"><a href="#cb15-380" aria-hidden="true" tabindex="-1"></a><span class="do">## generate test data</span></span>
<span id="cb15-381"><a href="#cb15-381" aria-hidden="true" tabindex="-1"></a>test_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>(<span class="at">x =</span> <span class="fu">runif</span>(<span class="dv">1000</span>) <span class="sc">*</span> <span class="dv">5</span>)</span>
<span id="cb15-382"><a href="#cb15-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-383"><a href="#cb15-383" aria-hidden="true" tabindex="-1"></a>sim_results <span class="ot">&lt;-</span> </span>
<span id="cb15-384"><a href="#cb15-384" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>, <span class="cf">function</span>(x) <span class="fu">fit_knn</span>(x, train_data, test_data)) <span class="sc">%&gt;%</span></span>
<span id="cb15-385"><a href="#cb15-385" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb15-386"><a href="#cb15-386" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-387"><a href="#cb15-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-388"><a href="#cb15-388" aria-hidden="true" tabindex="-1"></a>@fig-indiv-fit-knn presents the fitted regression lines for $k = 1, 5, 15, 25$, and $50$ using <span class="in">`knnreg()`</span>, along with the observed data points in the train dataset.</span>
<span id="cb15-389"><a href="#cb15-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-392"><a href="#cb15-392" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-393"><a href="#cb15-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-indiv-fit-knn</span></span>
<span id="cb15-394"><a href="#cb15-394" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-395"><a href="#cb15-395" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Fitted curves by knnreg() with different numbers of neighbors</span></span>
<span id="cb15-396"><a href="#cb15-396" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-height: 9</span></span>
<span id="cb15-397"><a href="#cb15-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-398"><a href="#cb15-398" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(sim_results[num_nbs  <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">25</span>, <span class="dv">50</span>), ]) <span class="sc">+</span></span>
<span id="cb15-399"><a href="#cb15-399" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> train_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"gray"</span>) <span class="sc">+</span></span>
<span id="cb15-400"><a href="#cb15-400" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb15-401"><a href="#cb15-401" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(num_nbs <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb15-402"><a href="#cb15-402" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-403"><a href="#cb15-403" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-404"><a href="#cb15-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-407"><a href="#cb15-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb15-408"><a href="#cb15-408" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-train-test-mse-knn</span></span>
<span id="cb15-409"><a href="#cb15-409" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb15-410"><a href="#cb15-410" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Train and test MSEs as a function of the number of knots </span></span>
<span id="cb15-411"><a href="#cb15-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-412"><a href="#cb15-412" aria-hidden="true" tabindex="-1"></a><span class="co">#--- get train and test MSEs by k ---#</span></span>
<span id="cb15-413"><a href="#cb15-413" aria-hidden="true" tabindex="-1"></a>summary <span class="ot">&lt;-</span> </span>
<span id="cb15-414"><a href="#cb15-414" aria-hidden="true" tabindex="-1"></a>  sim_results[, .(<span class="at">mse =</span> <span class="fu">mean</span>((y_hat <span class="sc">-</span> y)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(num_nbs, type)]</span>
<span id="cb15-415"><a href="#cb15-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-416"><a href="#cb15-416" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(summary) <span class="sc">+</span></span>
<span id="cb15-417"><a href="#cb15-417" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_nbs, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb15-418"><a href="#cb15-418" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> mse, <span class="at">x =</span> num_nbs, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb15-419"><a href="#cb15-419" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Number of neighbors"</span>) <span class="sc">+</span></span>
<span id="cb15-420"><a href="#cb15-420" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"MSE"</span>) <span class="sc">+</span></span>
<span id="cb15-421"><a href="#cb15-421" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb15-422"><a href="#cb15-422" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb15-423"><a href="#cb15-423" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb15-424"><a href="#cb15-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-425"><a href="#cb15-425" aria-hidden="true" tabindex="-1"></a><span class="fu">## References {.unnumbered}</span></span>
<span id="cb15-426"><a href="#cb15-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-427"><a href="#cb15-427" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">"refs"</span><span class="kw">&gt;&lt;/div&gt;</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>