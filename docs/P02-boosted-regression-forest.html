<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 7&nbsp; Boosted Regression Forest</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./P03-xgb.html" rel="next">
<link href="./P01-random-forest.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C04-cf-extension.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Extensions of Causal Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C05-causal-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Model Selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Programming Guide: R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code> in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Programming Guide: Python</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-01-scikitlearn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction using <code>scikitlearn</code></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-02-CATE-econml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">CATE estimation using <code>econml</code></span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#gradient-boosting" id="toc-gradient-boosting" class="nav-link active" data-scroll-target="#gradient-boosting"> <span class="header-section-number">7.1</span> Gradient Boosting</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation"> <span class="header-section-number">7.2</span> Implementation</a></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources"> <span class="header-section-number">7.3</span> Resources</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/P02-boosted-regression-forest.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-brf" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="gradient-boosting" class="level2 page-columns page-full" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="gradient-boosting"><span class="header-section-number">7.1</span> Gradient Boosting</h2>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rattle)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(wooldridge)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Dataset for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get data ===#</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mlb1)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>mlb1_dt <span class="ot">&lt;-</span> </span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  mlb1 <span class="sc">%&gt;%</span> </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> <span class="co"># turn into data.table </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  .[, salary <span class="sc">:</span><span class="er">=</span> <span class="cn">NULL</span>] <span class="sc">%&gt;%</span> <span class="co"># remove salary (use lsalary instead)</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>() <span class="co"># remove observations with NA in any of the variables</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p>In training RF that uses the idea of bagging, the original data is used to generate many bootstrapped datasets, a regression tree is trained on each of them <span style="color:blue"> independently </span>, and then they are averaged when prediction. Boosting is similar to bagging (bootstrap aggregation) in that it trains many statistical models and then combine them. However, instead of training models independently, it trains models <span style="color:blue"> sequentially </span> in a manner that improves prediction step by step.</p>
<p>While there are many variants of boosting methods (see Chapter 10 of <span class="citation" data-cites="hastie2009elements">Hastie et al. (<a href="#ref-hastie2009elements" role="doc-biblioref">2009</a>)</span>), we will look at gradient boosting using trees for regression in particular (Algorithm 10.3 in <span class="citation" data-cites="hastie2009elements">Hastie et al. (<a href="#ref-hastie2009elements" role="doc-biblioref">2009</a>)</span> presents the generic gradient tree boosting algorithm), where squared error is used as the loss function.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><span style="color:blue"> Algorithm: Gradient Boosting Regression Forest </span></p>
<ol type="1">
<li>Set <span class="math inline">\(f_0(X_i) = \frac{\sum_{i=1}^N y_i}{N}\)</span> for all <span class="math inline">\(i = 1, \dots, N\)</span></li>
<li>For b = 1 to B,</li>
</ol>
<ol type="i">
<li>For <span class="math inline">\(i = 1, \dots, N\)</span>, calculate <span class="math display">\[
    r_{i,b} =  (y_i - f_{b-1}(X_i))
    \]</span></li>
<li>Fit a regression tree to <span class="math inline">\(r_{i, b}\)</span>, which generates terminal regions <span class="math inline">\(R_{j,b}\)</span>, <span class="math inline">\(j = 1, \dots, J\)</span>, and denote the predicted value of region <span class="math inline">\(R_{j,b}\)</span> as <span class="math inline">\(\gamma_{j,b}\)</span>.</li>
<li>Set <span class="math inline">\(f_b(X_i) = f_{b-1}(X_i) + \lambda \cdot \sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})\)</span></li>
</ol>
<ol start="3" type="1">
<li>Finally, <span class="math inline">\(\hat{f}(X_i) = f_B(X_i)\)</span></li>
</ol>
</div>
</div>
<p>Let’s try to go through this algorithm a bit to have it sink in for you.</p>
<hr>
<p><span style="color:blue"> <strong>Step 1</strong> </span></p>
<p>Step 1 finds the mean of the dependent variable. This quantity is used as the starting estimate for the dependent variable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>f_0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(mlb1_dt<span class="sc">$</span>lsalary)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 13.51172</code></pre>
</div>
</div>
<hr>
<p><span style="color:blue"> <strong>Step 2</strong></span></p>
<p><strong><span class="math inline">\(b = 1\)</span></strong></p>
<p>Now, we get residuals:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>mlb1_dt[, resid_1 <span class="sc">:</span><span class="er">=</span> lsalary <span class="sc">-</span> f_0]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The residuals contain information in <code>lsalary</code> that was left unexplained by simply using the mean of <code>lsalary</code>. By training a regression tree using the residuals as the dependent variable, we are finding a tree that can explain the unexplained parts of <code>lsalary</code> using the explanatory variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>tree_fit_b1 <span class="ot">&lt;-</span> </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart</span>(</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    resid_1 <span class="sc">~</span> ., <span class="co"># . means all variables</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is the fitted value of the residuals (<span class="math inline">\(\sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})\)</span>)</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>resid_1_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_fit_b1, <span class="at">newdata =</span> mlb1_dt)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(resid_1_hat)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>         1          2          3          4          5          6 
 1.7134881  1.7134881  1.2414996  1.2414996  0.5054178 -0.1851016 </code></pre>
</div>
</div>
<p>Now, we update our prediction according to <span class="math inline">\(f_b(X_i) = f_{b-1}(X_i) + \lambda \cdot \sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})\)</span>. We set <span class="math inline">\(\lambda\)</span> to be <span class="math inline">\(0.2\)</span> in this illustration.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>f_1 <span class="ot">&lt;-</span> f_0 <span class="sc">+</span> lambda <span class="sc">*</span> resid_1_hat</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(f_1)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       1        2        3        4        5        6 
13.85441 13.85441 13.76002 13.76002 13.61280 13.47470 </code></pre>
</div>
</div>
<p>Did we actually improve prediction accuracy? Let’s compare <code>f_0</code> and <code>f_1</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_0)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 445.0615</code></pre>
</div>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_1)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 288.3205</code></pre>
</div>
</div>
<p>Great. Let’s move on to <strong><span class="math inline">\(b = 2\)</span></strong>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get negative of the residuals ===#</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>mlb1_dt[, resid_2 <span class="sc">:</span><span class="er">=</span> lsalary <span class="sc">-</span> f_1]</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit a regression tree ===#</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>tree_fit_b2 <span class="ot">&lt;-</span> </span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart</span>(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    resid_2 <span class="sc">~</span> ., <span class="co"># . means all variables</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get predicted values ===#</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>resid_2_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_fit_b2, <span class="at">newdata =</span> mlb1_dt)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== update ===#</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>f_2 <span class="ot">&lt;-</span> f_1 <span class="sc">+</span> lambda <span class="sc">*</span> resid_2_hat</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_1)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 288.3205</code></pre>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_2)<span class="sc">^</span><span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 186.9229</code></pre>
</div>
</div>
<p>We further improved our predictions. We repeat this process until certain user-specified stopping criteria is met.</p>
<p>As you probably have noticed, there are several key parameters in the process above that controls the performance of gradient boosting forest. <span class="math inline">\(\lambda\)</span> controls the speed of learning. The lower <span class="math inline">\(\lambda\)</span> is, slower the learning speed is. <span class="math inline">\(B\)</span> (the number of trees) determines how many times we want to make small improvements to the original prediction. When you increase the value of <span class="math inline">\(\lambda\)</span>, you should decrease the value of <span class="math inline">\(B\)</span>. Too high values of <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(B\)</span> can lead to over-fitting.</p>
<p>You may have been wondering why this algorithm is called <code>Gradient</code> boosting. Gradient boosting is much more general than the one described here particularly for gradient tree boosting for regression. It can be applied to both regression and classification<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. In general, Step 2.a can be written as follows:</p>
<p><span class="math display">\[
r_{i,b} = - \huge[\normalsize\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\huge]\normalsize_{f = f_{b-1}}
\]</span></p>
<p>where <span class="math inline">\(L(y_i, f(x_i))\)</span> is the loss function. For regression, the loss function is almost always squared error: <span class="math inline">\((y_i - f(x_i))^2\)</span>. For, <span class="math inline">\(L(y_i, f(x_i)) = (y_i - f(x_i))^2\)</span>, the negative of the derivative of the loss function with respect to <span class="math inline">\(f(x_i)\)</span> is</p>
<p><span class="math display">\[
- \huge[\normalsize\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\huge]\normalsize_{f = f_{b-1}} = - (- 2 (y_i - f(x_i))) = 2 (y_i - f(x_i))
\]</span></p>
<p>This is why we have <span class="math inline">\(r_{i,b} = (y_i - f_{b-1}(X_i))\)</span> at Step 2.a. And, as you just saw, we are using the gradient of the loss function for model updating, which is why it is called <span style="color:blue"> gradient </span> boosting. Note that it does not really matter whether you have <span class="math inline">\(2\)</span> in front of the residuals or not the fitted residuals is multiplied (scaled) by <span class="math inline">\(\lambda\)</span> to when updating the model. You can always find the same <span class="math inline">\(\lambda\)</span> that would result in the same results as when just non-scaled residuals are used.</p>
<p>Most R and python packages allow you to use a fraction of the train sample that are randomly selected and/or to use a subset of the included variables in building a tree within Step 2. This generate randomness in the algorithm and they are referred to as <span style="color:blue"> stochastic </span>gradient boosting.</p>
</section>
<section id="implementation" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="implementation"><span class="header-section-number">7.2</span> Implementation</h2>
<p>We can use the <code>gbm</code> package to train a gradient boosting regression. Just like <code>ranger()</code>, <code>gbm</code> takes formula and data like below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit a gbm model ===#</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>gbm_fit <span class="ot">&lt;-</span> </span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gbm</span>(</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    lsalary <span class="sc">~</span> hruns <span class="sc">+</span> years <span class="sc">+</span> rbisyr <span class="sc">+</span> allstar <span class="sc">+</span> runsyr <span class="sc">+</span> hits <span class="sc">+</span> bavg, </span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming gaussian ...</code></pre>
</div>
</div>
<p>Here is the list of some parameters to be aware of:</p>
<ul>
<li><code>n.trees</code>: Number of trees (<span class="math inline">\(B\)</span>). Default is <span class="math inline">\(100\)</span>.</li>
<li><code>interaction.depth</code>: 1 implies an additive model without interactions between included variables<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, 2 implies a model with 2-way interactions. Default is 1.</li>
<li><code>n.minobsinnode</code>: Minimum number of observations in a terminal node (leaf).</li>
<li><code>shrinkage</code>: Learning rate (<span class="math inline">\(\lambda\)</span>). Default is 0.1.</li>
<li><code>bag.fraction</code>: The fraction of the train data observations that are select randomly in building a tree. Default is 0.5.</li>
<li><code>cv.folds</code>: The number of folds in conducting KCV</li>
</ul>
<p>By specifying <code>cv.folds</code>, <code>gbm()</code> automatically conducts cross-validation for you.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== gbm fit with CV ===#</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>gbm_fit <span class="ot">&lt;-</span> </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gbm</span>(</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    lsalary <span class="sc">~</span> hruns <span class="sc">+</span> years <span class="sc">+</span> rbisyr <span class="sc">+</span> allstar <span class="sc">+</span> runsyr <span class="sc">+</span> hits <span class="sc">+</span> bavg, <span class="co"># . means all variables</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">cv.folds =</span> <span class="dv">5</span>,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Distribution not specified, assuming gaussian ...</code></pre>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the MSE history ===#  </span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>gbm_fit<span class="sc">$</span>cv.error</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  [1] 1.2254388 1.1096572 1.0188836 0.9451484 0.8764874 0.8154053 0.7681966
  [8] 0.7227889 0.6831316 0.6492878 0.6202762 0.5942215 0.5693241 0.5485684
 [15] 0.5278321 0.5131015 0.4985837 0.4880802 0.4767910 0.4656425 0.4571257
 [22] 0.4502539 0.4448326 0.4411768 0.4368799 0.4285447 0.4250382 0.4184043
 [29] 0.4146997 0.4104091 0.4078917 0.4036995 0.4012386 0.3984762 0.3968246
 [36] 0.3954408 0.3936881 0.3922179 0.3898391 0.3877176 0.3873386 0.3871197
 [43] 0.3873842 0.3861886 0.3850445 0.3845866 0.3848790 0.3838000 0.3833878
 [50] 0.3825944 0.3808730 0.3806207 0.3792785 0.3791392 0.3784091 0.3779299
 [57] 0.3749792 0.3753697 0.3748035 0.3749157 0.3728077 0.3721398 0.3735805
 [64] 0.3730954 0.3716606 0.3712136 0.3698348 0.3701441 0.3688050 0.3696563
 [71] 0.3695531 0.3678965 0.3692444 0.3697791 0.3704924 0.3694109 0.3688957
 [78] 0.3671964 0.3673546 0.3681492 0.3679176 0.3677911 0.3675692 0.3677197
 [85] 0.3676185 0.3677390 0.3673854 0.3660198 0.3673235 0.3675350 0.3685687
 [92] 0.3678714 0.3666266 0.3676465 0.3671833 0.3661709 0.3652917 0.3647139
 [99] 0.3644427 0.3651259</code></pre>
</div>
</div>
<p>You can visualize the CV results using <code>gbm.perf()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">gbm.perf</span>(gbm_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="P02-boosted-regression-forest_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid" width="672"></p>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 99</code></pre>
</div>
</div>
<p>Note that it will tell you what the optimal number of trees is <span style="color:blue"> given </span> the values of the other hyper-parameters (here default values). If you want to tune other parameters as well, you need to program it yourself.</p>
</section>
<section id="resources" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="resources"><span class="header-section-number">7.3</span> Resources</h2>
<ul>
<li><a href="https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/">Gradient Boosting with Scikit-Learn, XGBoost, LightGBM, and CatBoost</a> by Jason Brownlee</li>
</ul>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-hastie2009elements" class="csl-entry" role="doc-biblioentry">
Hastie, Trevor, Robert Tibshirani, Jerome H Friedman, and Jerome H Friedman. 2009. <em>The Elements of Statistical Learning: Data Mining, Inference, and Prediction</em>. Vol. 2. Springer.
</div>
</div>
</section>
<section class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr>
<ol>
<li id="fn1" role="doc-endnote"><p>Indeed, all the algorithms and models we have talked about can be applied to classification problems with some small changes.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2" role="doc-endnote"><p>You can of course create interactions terms yourself in the data, which would allow simple linear 2-way interactions.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./P01-random-forest.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./P03-xgb.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb28" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Boosted Regression Forest {#sec-brf}</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">## Gradient Boosting</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rattle)</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(wooldridge)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rattle)</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(wooldridge)</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>**Dataset for replication**</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a><span class="in">```{r set-up-data}</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get data ===#</span></span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(mlb1)</span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>mlb1_dt <span class="ot">&lt;-</span> </span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>  mlb1 <span class="sc">%&gt;%</span> </span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> <span class="co"># turn into data.table </span></span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a>  .[, salary <span class="sc">:</span><span class="er">=</span> <span class="cn">NULL</span>] <span class="sc">%&gt;%</span> <span class="co"># remove salary (use lsalary instead)</span></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">na.omit</span>() <span class="co"># remove observations with NA in any of the variables</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>In training RF that uses the idea of bagging, the original data is used to generate many bootstrapped datasets, a regression tree is trained on each of them <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> independently <span class="kw">&lt;/span&gt;</span>, and then they are averaged when prediction. Boosting is similar to bagging (bootstrap aggregation) in that it trains many statistical models and then combine them. However, instead of training models independently, it trains models <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> sequentially <span class="kw">&lt;/span&gt;</span> in a manner that improves prediction step by step.</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a>While there are many variants of boosting methods (see Chapter 10 of @hastie2009elements), we will look at gradient boosting using trees for regression in particular (Algorithm 10.3 in @hastie2009elements presents the generic gradient tree boosting algorithm), where squared error is used as the loss function.  </span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-52"><a href="#cb28-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-53"><a href="#cb28-53" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb28-54"><a href="#cb28-54" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Algorithm: Gradient Boosting Regression Forest <span class="kw">&lt;/span&gt;</span></span>
<span id="cb28-55"><a href="#cb28-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-56"><a href="#cb28-56" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Set $f_0(X_i)  = \frac{\sum_{i=1}^N y_i}{N}$ for all $i = 1, \dots, N$</span>
<span id="cb28-57"><a href="#cb28-57" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>For b = 1 to B,</span>
<span id="cb28-58"><a href="#cb28-58" aria-hidden="true" tabindex="-1"></a>  i. For $i = 1, \dots, N$, calculate</span>
<span id="cb28-59"><a href="#cb28-59" aria-hidden="true" tabindex="-1"></a>    $$</span>
<span id="cb28-60"><a href="#cb28-60" aria-hidden="true" tabindex="-1"></a>    r_{i,b} =  (y_i - f_{b-1}(X_i))</span>
<span id="cb28-61"><a href="#cb28-61" aria-hidden="true" tabindex="-1"></a>    $$</span>
<span id="cb28-62"><a href="#cb28-62" aria-hidden="true" tabindex="-1"></a>  ii. Fit a regression tree to $r_{i, b}$, which generates terminal regions $R_{j,b}$, $j = 1, \dots, J$, and denote the predicted value of region $R_{j,b}$ as $\gamma_{j,b}$.</span>
<span id="cb28-63"><a href="#cb28-63" aria-hidden="true" tabindex="-1"></a>  iii. Set $f_b(X_i) = f_{b-1}(X_i) + \lambda \cdot \sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})$</span>
<span id="cb28-64"><a href="#cb28-64" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Finally, $\hat{f}(X_i) = f_B(X_i)$</span>
<span id="cb28-65"><a href="#cb28-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-66"><a href="#cb28-66" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb28-67"><a href="#cb28-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-68"><a href="#cb28-68" aria-hidden="true" tabindex="-1"></a>Let's try to go through this algorithm a bit to have it sink in for you.</span>
<span id="cb28-69"><a href="#cb28-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-70"><a href="#cb28-70" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb28-71"><a href="#cb28-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-72"><a href="#cb28-72" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> **Step 1** <span class="kw">&lt;/span&gt;</span></span>
<span id="cb28-73"><a href="#cb28-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-74"><a href="#cb28-74" aria-hidden="true" tabindex="-1"></a>Step 1 finds the mean of the dependent variable. This quantity is used as the starting estimate for the dependent variable. </span>
<span id="cb28-75"><a href="#cb28-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-78"><a href="#cb28-78" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-79"><a href="#cb28-79" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb28-80"><a href="#cb28-80" aria-hidden="true" tabindex="-1"></a>f_0 <span class="ot">&lt;-</span> <span class="fu">mean</span>(mlb1_dt<span class="sc">$</span>lsalary)</span>
<span id="cb28-81"><a href="#cb28-81" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb28-82"><a href="#cb28-82" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-83"><a href="#cb28-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-84"><a href="#cb28-84" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb28-85"><a href="#cb28-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-86"><a href="#cb28-86" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> **Step 2**<span class="kw">&lt;/span&gt;</span></span>
<span id="cb28-87"><a href="#cb28-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-88"><a href="#cb28-88" aria-hidden="true" tabindex="-1"></a>**$b = 1$**</span>
<span id="cb28-89"><a href="#cb28-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-90"><a href="#cb28-90" aria-hidden="true" tabindex="-1"></a>Now, we get residuals:</span>
<span id="cb28-91"><a href="#cb28-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-94"><a href="#cb28-94" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-95"><a href="#cb28-95" aria-hidden="true" tabindex="-1"></a>mlb1_dt[, resid_1 <span class="sc">:</span><span class="er">=</span> lsalary <span class="sc">-</span> f_0]</span>
<span id="cb28-96"><a href="#cb28-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-97"><a href="#cb28-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-98"><a href="#cb28-98" aria-hidden="true" tabindex="-1"></a>The residuals contain information in <span class="in">`lsalary`</span> that was left unexplained by simply using the mean of <span class="in">`lsalary`</span>. By training a regression tree using the residuals as the dependent variable, we are finding a tree that can explain the unexplained parts of <span class="in">`lsalary`</span> using the explanatory variables. </span>
<span id="cb28-99"><a href="#cb28-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-102"><a href="#cb28-102" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-103"><a href="#cb28-103" aria-hidden="true" tabindex="-1"></a>tree_fit_b1 <span class="ot">&lt;-</span> </span>
<span id="cb28-104"><a href="#cb28-104" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart</span>(</span>
<span id="cb28-105"><a href="#cb28-105" aria-hidden="true" tabindex="-1"></a>    resid_1 <span class="sc">~</span> ., <span class="co"># . means all variables</span></span>
<span id="cb28-106"><a href="#cb28-106" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb28-107"><a href="#cb28-107" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb28-108"><a href="#cb28-108" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-109"><a href="#cb28-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-110"><a href="#cb28-110" aria-hidden="true" tabindex="-1"></a>Here is the fitted value of the residuals ($\sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})$)</span>
<span id="cb28-111"><a href="#cb28-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-114"><a href="#cb28-114" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-115"><a href="#cb28-115" aria-hidden="true" tabindex="-1"></a>resid_1_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_fit_b1, <span class="at">newdata =</span> mlb1_dt)</span>
<span id="cb28-116"><a href="#cb28-116" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(resid_1_hat)</span>
<span id="cb28-117"><a href="#cb28-117" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-118"><a href="#cb28-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-119"><a href="#cb28-119" aria-hidden="true" tabindex="-1"></a>Now, we update our prediction according to $f_b(X_i) = f_{b-1}(X_i) + \lambda \cdot \sum_{j=1}^J\gamma_{j, b}\cdot I(X_i \in R_{j,b})$. We set $\lambda$ to be $0.2$ in this illustration.</span>
<span id="cb28-120"><a href="#cb28-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-123"><a href="#cb28-123" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-124"><a href="#cb28-124" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb28-125"><a href="#cb28-125" aria-hidden="true" tabindex="-1"></a>f_1 <span class="ot">&lt;-</span> f_0 <span class="sc">+</span> lambda <span class="sc">*</span> resid_1_hat</span>
<span id="cb28-126"><a href="#cb28-126" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(f_1)</span>
<span id="cb28-127"><a href="#cb28-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-128"><a href="#cb28-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-129"><a href="#cb28-129" aria-hidden="true" tabindex="-1"></a>Did we actually improve prediction accuracy? Let's compare <span class="in">`f_0`</span> and <span class="in">`f_1`</span>.</span>
<span id="cb28-130"><a href="#cb28-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-133"><a href="#cb28-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-134"><a href="#cb28-134" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_0)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-135"><a href="#cb28-135" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-136"><a href="#cb28-136" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-137"><a href="#cb28-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-138"><a href="#cb28-138" aria-hidden="true" tabindex="-1"></a>Great. Let's move on to **$b = 2$**.</span>
<span id="cb28-139"><a href="#cb28-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-142"><a href="#cb28-142" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-143"><a href="#cb28-143" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get negative of the residuals ===#</span></span>
<span id="cb28-144"><a href="#cb28-144" aria-hidden="true" tabindex="-1"></a>mlb1_dt[, resid_2 <span class="sc">:</span><span class="er">=</span> lsalary <span class="sc">-</span> f_1]</span>
<span id="cb28-145"><a href="#cb28-145" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-146"><a href="#cb28-146" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit a regression tree ===#</span></span>
<span id="cb28-147"><a href="#cb28-147" aria-hidden="true" tabindex="-1"></a>tree_fit_b2 <span class="ot">&lt;-</span> </span>
<span id="cb28-148"><a href="#cb28-148" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rpart</span>(</span>
<span id="cb28-149"><a href="#cb28-149" aria-hidden="true" tabindex="-1"></a>    resid_2 <span class="sc">~</span> ., <span class="co"># . means all variables</span></span>
<span id="cb28-150"><a href="#cb28-150" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb28-151"><a href="#cb28-151" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb28-152"><a href="#cb28-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-153"><a href="#cb28-153" aria-hidden="true" tabindex="-1"></a><span class="co">#=== get predicted values ===#</span></span>
<span id="cb28-154"><a href="#cb28-154" aria-hidden="true" tabindex="-1"></a>resid_2_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(tree_fit_b2, <span class="at">newdata =</span> mlb1_dt)</span>
<span id="cb28-155"><a href="#cb28-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-156"><a href="#cb28-156" aria-hidden="true" tabindex="-1"></a><span class="co">#=== update ===#</span></span>
<span id="cb28-157"><a href="#cb28-157" aria-hidden="true" tabindex="-1"></a>f_2 <span class="ot">&lt;-</span> f_1 <span class="sc">+</span> lambda <span class="sc">*</span> resid_2_hat</span>
<span id="cb28-158"><a href="#cb28-158" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-159"><a href="#cb28-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-162"><a href="#cb28-162" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-163"><a href="#cb28-163" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_1)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-164"><a href="#cb28-164" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((mlb1_dt<span class="sc">$</span>lsalary <span class="sc">-</span> f_2)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb28-165"><a href="#cb28-165" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-166"><a href="#cb28-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-167"><a href="#cb28-167" aria-hidden="true" tabindex="-1"></a>We further improved our predictions. We repeat this process until certain user-specified stopping criteria is met. </span>
<span id="cb28-168"><a href="#cb28-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-169"><a href="#cb28-169" aria-hidden="true" tabindex="-1"></a>As you probably have noticed, there are several key parameters in the process above that controls the performance of gradient boosting forest. $\lambda$ controls the speed of learning. The lower $\lambda$ is, slower the learning speed is. $B$ (the number of trees) determines how many times we want to make small improvements to the original prediction. When you increase the value of $\lambda$, you should decrease the value of $B$. Too high values of $\lambda$ and $B$ can lead to over-fitting. </span>
<span id="cb28-170"><a href="#cb28-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-171"><a href="#cb28-171" aria-hidden="true" tabindex="-1"></a>You may have been wondering why this algorithm is called <span class="in">`Gradient`</span> boosting. Gradient boosting is much more general than the one described here particularly for gradient tree boosting for regression. It can be applied to both regression and classification^<span class="co">[</span><span class="ot">Indeed, all the algorithms and models we have talked about can be applied to classification problems with some small changes.</span><span class="co">]</span>. In general, Step 2.a can be written as follows:</span>
<span id="cb28-172"><a href="#cb28-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-173"><a href="#cb28-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb28-174"><a href="#cb28-174" aria-hidden="true" tabindex="-1"></a>r_{i,b} = - \huge<span class="co">[</span><span class="ot">\normalsize\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\huge</span><span class="co">]</span>\normalsize_{f = f_{b-1}}</span>
<span id="cb28-175"><a href="#cb28-175" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb28-176"><a href="#cb28-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-177"><a href="#cb28-177" aria-hidden="true" tabindex="-1"></a>where $L(y_i, f(x_i))$ is the loss function. For regression, the loss function is almost always squared error: $(y_i - f(x_i))^2$. For, $L(y_i, f(x_i)) = (y_i - f(x_i))^2$, the negative of the derivative of the loss function with respect to $f(x_i)$ is </span>
<span id="cb28-178"><a href="#cb28-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-179"><a href="#cb28-179" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb28-180"><a href="#cb28-180" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\huge<span class="co">[</span><span class="ot">\normalsize\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)}\huge</span><span class="co">]</span>\normalsize_{f = f_{b-1}} = - (- 2 (y_i - f(x_i))) = 2 (y_i - f(x_i)) </span>
<span id="cb28-181"><a href="#cb28-181" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb28-182"><a href="#cb28-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-183"><a href="#cb28-183" aria-hidden="true" tabindex="-1"></a>This is why we have $r_{i,b} = (y_i - f_{b-1}(X_i))$ at Step 2.a. And, as you just saw, we are using the gradient of the loss function for model updating, which is why it is called <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> gradient <span class="kw">&lt;/span&gt;</span> boosting. Note that it does not really matter whether you have $2$ in front of the residuals or not the fitted residuals is multiplied (scaled) by $\lambda$ to when updating the model. You can always find the same $\lambda$ that would result in the same results as when just non-scaled residuals are used.</span>
<span id="cb28-184"><a href="#cb28-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-185"><a href="#cb28-185" aria-hidden="true" tabindex="-1"></a>Most R and python packages allow you to use a fraction of the train sample that are randomly selected and/or to use a subset of the included variables in building a tree within Step 2. This generate randomness in the algorithm and they are referred to as <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> stochastic <span class="kw">&lt;/span&gt;</span>gradient boosting.</span>
<span id="cb28-186"><a href="#cb28-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-187"><a href="#cb28-187" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implementation</span></span>
<span id="cb28-188"><a href="#cb28-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-189"><a href="#cb28-189" aria-hidden="true" tabindex="-1"></a>We can use the <span class="in">`gbm`</span> package to train a gradient boosting regression. Just like <span class="in">`ranger()`</span>, <span class="in">`gbm`</span> takes formula and data like below.</span>
<span id="cb28-190"><a href="#cb28-190" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-193"><a href="#cb28-193" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-194"><a href="#cb28-194" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb28-195"><a href="#cb28-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-196"><a href="#cb28-196" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit a gbm model ===#</span></span>
<span id="cb28-197"><a href="#cb28-197" aria-hidden="true" tabindex="-1"></a>gbm_fit <span class="ot">&lt;-</span> </span>
<span id="cb28-198"><a href="#cb28-198" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gbm</span>(</span>
<span id="cb28-199"><a href="#cb28-199" aria-hidden="true" tabindex="-1"></a>    lsalary <span class="sc">~</span> hruns <span class="sc">+</span> years <span class="sc">+</span> rbisyr <span class="sc">+</span> allstar <span class="sc">+</span> runsyr <span class="sc">+</span> hits <span class="sc">+</span> bavg, </span>
<span id="cb28-200"><a href="#cb28-200" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt </span>
<span id="cb28-201"><a href="#cb28-201" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb28-202"><a href="#cb28-202" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-203"><a href="#cb28-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-204"><a href="#cb28-204" aria-hidden="true" tabindex="-1"></a>Here is the list of some parameters to be aware of:</span>
<span id="cb28-205"><a href="#cb28-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-206"><a href="#cb28-206" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`n.trees`</span>: Number of trees ($B$). Default is $100$.</span>
<span id="cb28-207"><a href="#cb28-207" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`interaction.depth`</span>: 1 implies an additive model without interactions between included variables^<span class="co">[</span><span class="ot">You can of course create interactions terms yourself in the data, which would allow simple linear 2-way interactions.</span><span class="co">]</span>, 2 implies a model with 2-way interactions. Default is 1.</span>
<span id="cb28-208"><a href="#cb28-208" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`n.minobsinnode`</span>: Minimum number of observations in a terminal node (leaf). </span>
<span id="cb28-209"><a href="#cb28-209" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`shrinkage`</span>: Learning rate ($\lambda$). Default is 0.1.</span>
<span id="cb28-210"><a href="#cb28-210" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`bag.fraction`</span>: The fraction of the train data observations that are select randomly in building a tree. Default is 0.5.</span>
<span id="cb28-211"><a href="#cb28-211" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`cv.folds`</span>: The number of folds in conducting KCV</span>
<span id="cb28-212"><a href="#cb28-212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-213"><a href="#cb28-213" aria-hidden="true" tabindex="-1"></a>By specifying <span class="in">`cv.folds`</span>, <span class="in">`gbm()`</span> automatically conducts cross-validation for you. </span>
<span id="cb28-214"><a href="#cb28-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-217"><a href="#cb28-217" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-218"><a href="#cb28-218" aria-hidden="true" tabindex="-1"></a><span class="co">#=== gbm fit with CV ===#</span></span>
<span id="cb28-219"><a href="#cb28-219" aria-hidden="true" tabindex="-1"></a>gbm_fit <span class="ot">&lt;-</span> </span>
<span id="cb28-220"><a href="#cb28-220" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gbm</span>(</span>
<span id="cb28-221"><a href="#cb28-221" aria-hidden="true" tabindex="-1"></a>    lsalary <span class="sc">~</span> hruns <span class="sc">+</span> years <span class="sc">+</span> rbisyr <span class="sc">+</span> allstar <span class="sc">+</span> runsyr <span class="sc">+</span> hits <span class="sc">+</span> bavg, <span class="co"># . means all variables</span></span>
<span id="cb28-222"><a href="#cb28-222" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> mlb1_dt,</span>
<span id="cb28-223"><a href="#cb28-223" aria-hidden="true" tabindex="-1"></a>    <span class="at">cv.folds =</span> <span class="dv">5</span>,</span>
<span id="cb28-224"><a href="#cb28-224" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb28-225"><a href="#cb28-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-226"><a href="#cb28-226" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the MSE history ===#  </span></span>
<span id="cb28-227"><a href="#cb28-227" aria-hidden="true" tabindex="-1"></a>gbm_fit<span class="sc">$</span>cv.error</span>
<span id="cb28-228"><a href="#cb28-228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-229"><a href="#cb28-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-230"><a href="#cb28-230" aria-hidden="true" tabindex="-1"></a>You can visualize the CV results using <span class="in">`gbm.perf()`</span>.</span>
<span id="cb28-231"><a href="#cb28-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-234"><a href="#cb28-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb28-235"><a href="#cb28-235" aria-hidden="true" tabindex="-1"></a><span class="fu">gbm.perf</span>(gbm_fit)</span>
<span id="cb28-236"><a href="#cb28-236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb28-237"><a href="#cb28-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-238"><a href="#cb28-238" aria-hidden="true" tabindex="-1"></a>Note that it will tell you what the optimal number of trees is <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> given <span class="kw">&lt;/span&gt;</span> the values of the other hyper-parameters (here default values). If you want to tune other parameters as well, you need to program it yourself.</span>
<span id="cb28-239"><a href="#cb28-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-240"><a href="#cb28-240" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resources</span></span>
<span id="cb28-241"><a href="#cb28-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-242"><a href="#cb28-242" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="co">[</span><span class="ot">Gradient Boosting with Scikit-Learn, XGBoost, LightGBM, and CatBoost</span><span class="co">](https://machinelearningmastery.com/gradient-boosting-with-scikit-learn-xgboost-lightgbm-and-catboost/)</span> by Jason Brownlee</span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>