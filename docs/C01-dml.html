<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 11&nbsp; Double Machine Learning</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C02-xstr-learner.html" rel="next">
<link href="./C00-why-not-this.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>
<script src="site_libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="site_libs/viz-1.8.2/viz.js"></script>
<link href="site_libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet">
<script src="site_libs/grViz-binding-1.0.9/grViz.js"></script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./PROG-00-programming.html" class="sidebar-item-text sidebar-link">Programming Guide</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code> in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#dml-the-basic-idea" id="toc-dml-the-basic-idea" class="nav-link active" data-scroll-target="#dml-the-basic-idea"> <span class="header-section-number">11.1</span> DML: the basic idea</a>
  <ul class="collapse">
  <li><a href="#problem-setting" id="toc-problem-setting" class="nav-link" data-scroll-target="#problem-setting"> <span class="header-section-number">11.1.1</span> Problem Setting</a></li>
  <li><a href="#sec-dml-naive" id="toc-sec-dml-naive" class="nav-link" data-scroll-target="#sec-dml-naive"> <span class="header-section-number">11.1.2</span> An intuitive, yet naive approach</a></li>
  <li><a href="#overcoming-the-regularization-bias" id="toc-overcoming-the-regularization-bias" class="nav-link" data-scroll-target="#overcoming-the-regularization-bias"> <span class="header-section-number">11.1.3</span> Overcoming the regularization bias</a></li>
  <li><a href="#sec-cf" id="toc-sec-cf" class="nav-link" data-scroll-target="#sec-cf"> <span class="header-section-number">11.1.4</span> Overcoming the over-fitting bias</a></li>
  </ul></li>
  <li><a href="#models-and-implementation-by-doubleml" id="toc-models-and-implementation-by-doubleml" class="nav-link" data-scroll-target="#models-and-implementation-by-doubleml"> <span class="header-section-number">11.2</span> Models and implementation by <code>DoubleML</code></a>
  <ul class="collapse">
  <li><a href="#partially-linear-model" id="toc-partially-linear-model" class="nav-link" data-scroll-target="#partially-linear-model"> <span class="header-section-number">11.2.1</span> Partially linear model</a></li>
  <li><a href="#partially-linear-iv-model" id="toc-partially-linear-iv-model" class="nav-link" data-scroll-target="#partially-linear-iv-model"> <span class="header-section-number">11.2.2</span> Partially linear IV model</a></li>
  </ul></li>
  <li><a href="#suggested-exercises" id="toc-suggested-exercises" class="nav-link" data-scroll-target="#suggested-exercises"> <span class="header-section-number">11.3</span> Suggested Exercises</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/C01-dml.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-dml" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>One of the most important ideas of the recent development of causal machine learning (CML) methods originate from <span class="citation" data-cites="Chernozhukov2018">Chernozhukov et al. (<a href="#ref-Chernozhukov2018" role="doc-biblioref">2018</a>)</span>, which proposed Double/Debiased ML methods. In this section, we go over those key ideas that are at the heart of many other important CML methods we will learn later. We then learn various models you can estimate using the R and Python <code>DoubleML</code> package <span class="citation" data-cites="DoubleML2021R DoubleML2022Python">(<a href="#ref-DoubleML2021R" role="doc-biblioref">P. Bach et al. 2021</a>; <a href="#ref-DoubleML2022Python" role="doc-biblioref">Philipp Bach et al. 2022</a>)</span>.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What you will learn
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>How double/debiased machine learning works
<ul>
<li>avoiding regularlization bias through orthogonalization</li>
<li>avoiding over-fitting bias through cross-fitting</li>
</ul></li>
<li>Mechanics of DML
<ul>
<li>method of moment</li>
<li>score function</li>
<li>cross-fitting</li>
</ul></li>
<li>How to estimate ATE under conditional unconfoundedness using <code>DoubleMLPLR()</code> and under confoundedness using <code>DoubleMLPLIV()</code>.</li>
</ul>
</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Preferable background knowledge
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>how to use <code>mlr3</code> (see <a href="PROG-01-mlr3.html"><span>Chapter&nbsp;16</span></a>)</li>
<li>idea of method of moment</li>
<li>causal diagram</li>
</ul>
</div>
</div>
<section id="dml-the-basic-idea" class="level2 page-columns page-full" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="dml-the-basic-idea"><span class="header-section-number">11.1</span> DML: the basic idea</h2>
<section id="problem-setting" class="level3 page-columns page-full" data-number="11.1.1">
<h3 data-number="11.1.1" class="anchored" data-anchor-id="problem-setting"><span class="header-section-number">11.1.1</span> Problem Setting</h3>
<p>Throughout this section, we are interested in estimating the following econometric model , which is called a partially linear regression model (PLR).</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>We try to follow the notations of <span class="citation" data-cites="Chernozhukov2018">Chernozhukov et al. (<a href="#ref-Chernozhukov2018" role="doc-biblioref">2018</a>)</span> as much as possible.</p>
</div></div><p><span class="math display">\[
\begin{aligned}
y = \theta d + g_0(X) + \mu \\
d = m_0(X) + \eta
\end{aligned}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Partially linear regression model is a class of models where some of the variables are linear in parameter (here, <span class="math inline">\(\theta d\)</span>) and the rest of the variables are modeled non-parametrically (here, <span class="math inline">\(g_0(X)\)</span>).</p>
</div></div><p>Your sole interest is in estimating <span class="math inline">\(\theta\)</span>: the impact of the treatment (<span class="math inline">\(d\)</span>). <span class="math inline">\(g_0(X)\)</span> is the impact of a collection of variables <span class="math inline">\(X\)</span>. <span class="math inline">\(m_0(X)\)</span> expresses how <span class="math inline">\(X\)</span> affects the treatment status, <span class="math inline">\(d\)</span>. <span class="math inline">\(d\)</span> may be binary or continuous. $</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Assumptions on the error terms
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><span class="math inline">\(E[\mu|D,X] = 0\)</span></li>
<li><span class="math inline">\(E[\eta|X] = 0\)</span></li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The treatment effect is assumed to be constant irrespective of the value of <span class="math inline">\(X\)</span>. So, the treatment effect is not heterogeneous. We will cover heterogeneous treatment effect estimation later.</p>
</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Terminology alert
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math inline">\(g_0(X)\)</span> and <span class="math inline">\(m_0(X)\)</span> are called <span style="color:blue"> nuisance functions </span>because knowing them is not the ultimate goal. We are only interested in <strong>controlling for</strong> them to estimate <span class="math inline">\(\theta\)</span> accurately.</p>
</div>
</div>
</section>
<section id="sec-dml-naive" class="level3 page-columns page-full" data-number="11.1.2">
<h3 data-number="11.1.2" class="anchored" data-anchor-id="sec-dml-naive"><span class="header-section-number">11.1.2</span> An intuitive, yet naive approach</h3>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggbrace)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p>Consider the estimating equation of interest below.</p>
<p><span id="eq-model-naive"><span class="math display">\[
\begin{aligned}
y = \theta d + g_0(X) + \mu
\end{aligned}
\tag{11.1}\]</span></span></p>
<p>Subtracting <span class="math inline">\(g_0(x)\)</span> from both sides,</p>
<p><span class="math display">\[
\begin{aligned}
y - g_0(x) = \theta d + \mu
\end{aligned}
\]</span></p>
<p>So, if we know <span class="math inline">\(g_0(X)\)</span>, then we can simply regress <span class="math inline">\(y - g_0(x)\)</span> on <span class="math inline">\(d\)</span>. Of course, we do not know <span class="math inline">\(g_0(X)\)</span>, so we need to estimate <span class="math inline">\(g_0(x)\)</span>. Let <span class="math inline">\(\hat{g}_0(x)\)</span> denote <span class="math inline">\(g_0(x)\)</span> estimated by any appropriate machine learning method. Then, we can regress <span class="math inline">\(y - \hat{g}_0(x)\)</span> on <span class="math inline">\(d\)</span> to estimate <span class="math inline">\(\theta\)</span> using OLS. Mathematically, it can be written as follows:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{g}_0(X_i))
\end{aligned}
\]</span></p>
<p>Now, subtracting <span class="math inline">\(\hat{g}_0(x)\)</span> from both sides of <a href="#eq-model-naive">Equation&nbsp;<span>11.1</span></a>,</p>
<p><span class="math display">\[
\begin{aligned}
y - \hat{g}_0(x) = \theta d + (g_0(x) - \hat{g}_0(x) + \mu)
\end{aligned}
\]</span></p>
<p>So, as long as <span class="math inline">\(d\)</span> is not correlated with <span class="math inline">\(g_0(x) - \hat{g}_0(x) + \mu\)</span>, then the regression of <span class="math inline">\(y - \hat{g}_0(x)\)</span> on <span class="math inline">\(d\)</span> should work. Unfortunately, this approach turns out to be naive and suffer from bias in general <span class="citation" data-cites="Chernozhukov2018">(<a href="#ref-Chernozhukov2018" role="doc-biblioref">Chernozhukov et al. 2018</a>)</span>.</p>
<p>As a way to implement this naive approach, consider the following procedures.</p>
<ul>
<li>Step 1: Estimate <span class="math inline">\(g_0(X)\)</span> and then subtract the fitted value of <span class="math inline">\(g_0(X)\)</span> from <span class="math inline">\(y\)</span>.
<ul>
<li>Step 1.1: Regress <span class="math inline">\(y\)</span> on <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(E[y|X]\)</span> and call it <span class="math inline">\(\hat{l}_0(x)\)</span></li>
<li>Step 1.2: Regress <span class="math inline">\(d\)</span> on <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(E[d|X]\)</span> (<span class="math inline">\(m_0(X)\)</span>), call it <span class="math inline">\(\hat{m}_0(x)\)</span>, and calculate <span class="math inline">\(\tilde{d} = d - \hat{m}_0(X)\)</span>.</li>
<li>Step 1.3: Get an initial estimate of <span class="math inline">\(\theta\)</span> using <span id="eq-partial-out"><span class="math display">\[
\begin{aligned}
\hat{\theta}_{init} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i \tilde{d}_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{l}_0(X_i))
\end{aligned}
\tag{11.2}\]</span></span></li>
<li>Step 1.4: Regress <span class="math inline">\(y_i - \hat{\theta}_{init}d\)</span> on <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(g_0(X)\)</span> and call it <span class="math inline">\(\hat{g}_0(X)\)</span>.</li>
</ul></li>
<li>Step 2: Regress <span class="math inline">\(y - \hat{g}_0(X)\)</span> on <span class="math inline">\(d\)</span> using OLS. Or equivalently, use the following formula <span id="eq-theta-partial"><span class="math display">\[
\begin{aligned}
  \hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{g}_0(X_i))
\end{aligned}
\tag{11.3}\]</span></span></li>
</ul>
<p>To demonstrate the bias problem, we work on the following data generating process used in <a href="https://docs.doubleml.org/stable/guide/basics.html">the user guide for the DoubleML package</a>.</p>
<p><span id="eq-simple-synthetic"><span class="math display">\[
\begin{aligned}
y_i = 0.5 d_i  + \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3} + \mu_i \\
d_i = x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} \eta_i
\end{aligned}
\tag{11.4}\]</span></span></p>
<p>where <span class="math inline">\(\mu_i \sim N(0, 1)\)</span> and <span class="math inline">\(\eta_i \sim N(0, 1)\)</span>. The error terms (<span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\eta_i\)</span>) are independent. In this data generating process, <span class="math inline">\(d\)</span> is continuous (not binary) and its effect on <span class="math inline">\(y\)</span> is assumed to be linear.</p>
<p>We use the <code>gen_data()</code> function (defined on the right), which is a slightly generalized version of the <code>make_plr_CCDDHNR2018()</code> function from the <code>DoubleML</code> package.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><code>gen_data()</code> allows you to specify <span class="math inline">\(g_0(X)\)</span> and <span class="math inline">\(m_0(X)\)</span> unlike <code>make_plr_CCDDHNR2018()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>gen_data <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">g_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(x1))) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">/</span><span class="dv">4</span>)), <span class="co"># formula that defines m(x)</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">m_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> x1 <span class="sc">+</span> <span class="fu">I</span>(<span class="fu">exp</span>(x3)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(x3))<span class="sc">/</span><span class="dv">4</span>)), <span class="co"># formula that defines g(x)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fl">0.5</span><span class="sc">*</span>d)), <span class="co"># formula that defines theta(x) * t</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_obs =</span> <span class="dv">500</span>, </span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_vars =</span> <span class="dv">20</span>, </span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_x =</span> <span class="dv">0</span>, </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">vcov_x =</span> <span class="cn">NULL</span>,</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span> <span class="co"># sd of the error term in the y equation</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.null</span>(vcov_x)) {</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    vcov_x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rep</span>(<span class="dv">0</span>, n_vars<span class="sc">^</span><span class="dv">2</span>), <span class="at">nrow =</span> n_vars)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_vars)) {</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>      vcov_x[i, ] <span class="ot">&lt;-</span> <span class="fl">0.7</span><span class="sc">^</span><span class="fu">abs</span>(i <span class="sc">-</span> <span class="fu">seq_len</span>(n_vars)) </span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== draw from multivariate normal ===#</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> </span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mvrnorm</span>(n_obs, <span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, n_vars), <span class="at">Sigma =</span> vcov_x) <span class="sc">%&gt;%</span> </span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">paste0</span>(<span class="st">"x"</span>, <span class="dv">1</span><span class="sc">:</span>n_vars))  </span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate d ===#</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (m_formula <span class="sc">==</span> <span class="st">"independent"</span>) {</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    data[, d <span class="sc">:</span><span class="er">=</span> <span class="fu">rnorm</span>(n_obs)]</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    data[, d <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(m_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>() <span class="sc">+</span> <span class="fu">rnorm</span>(n_obs)]</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate y ===#</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>  data[, g <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(g_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>()]</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate treatment effect ===#</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>  data[, te <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(te_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>()]</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate y ===#</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>  data[, y <span class="sc">:</span><span class="er">=</span> te <span class="sc">+</span> g <span class="sc">+</span> <span class="fu">rnorm</span>(n_obs, <span class="at">sd =</span> sigma)]</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data[])</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">782394</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>It has 20 <code>x</code> variables (for <span class="math inline">\(X\)</span>) along with <code>d</code> (treatment) and <code>y</code> (dependent variable). Only <code>x1</code> and <code>x3</code> are the relevant variables. The rest of <span class="math inline">\(X\)</span> do not play any role in explaining either <span class="math inline">\(Y\)</span> or <span class="math inline">\(d\)</span>. However, they are correlated with <code>x1</code> and <code>x3</code> and interfere with estimating the nuisance functions.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(training_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Classes 'data.table' and 'data.frame':  500 obs. of  24 variables:
 $ x1 : num  -0.364 1.115 0.733 1.882 0.479 ...
 $ x2 : num  -0.5296 0.1056 -0.0411 1.0817 0.6851 ...
 $ x3 : num  -0.6156 1.0599 0.0799 0.4634 0.1374 ...
 $ x4 : num  -0.352 0.987 0.805 1.24 1.404 ...
 $ x5 : num  -0.723 0.547 1.85 0.574 0.501 ...
 $ x6 : num  -1.366 1.275 2.695 0.526 1.395 ...
 $ x7 : num  -0.9908 0.7295 1.1006 0.0523 0.3603 ...
 $ x8 : num  -0.3203 0.4991 0.7414 -0.0727 -0.4202 ...
 $ x9 : num  0.313 0.347 0.796 -1.268 -0.128 ...
 $ x10: num  0.2812 -0.6702 0.9771 0.0751 0.2713 ...
 $ x11: num  0.0656 -0.6435 1.5061 -0.8429 1.4138 ...
 $ x12: num  -0.383 0.825 2.299 -0.642 0.859 ...
 $ x13: num  0.7852 -0.0489 0.3969 0.1613 0.299 ...
 $ x14: num  -0.869 -0.27 0.264 0.787 -0.44 ...
 $ x15: num  -0.92172 0.00569 0.04343 0.7545 0.20734 ...
 $ x16: num  -2.062 -0.898 0.655 0.995 1.561 ...
 $ x17: num  -2.325 0.187 -0.114 0.89 0.947 ...
 $ x18: num  -1.1131 -0.3046 -0.0297 0.1187 0.2166 ...
 $ x19: num  -0.83 -0.7797 -0.2592 0.9764 -0.0221 ...
 $ x20: num  -0.577 -1.162 1.126 0.693 1.119 ...
 $ d  : num  -0.683 0.622 -1.909 -0.517 0.816 ...
 $ g  : num  0.256 1.018 0.695 0.984 0.652 ...
 $ te : num  -0.342 0.311 -0.955 -0.259 0.408 ...
 $ y  : num  -0.0511 0.4342 0.7377 1.5015 1.5488 ...
 - attr(*, ".internal.selfref")=&lt;externalptr&gt; </code></pre>
</div>
</div>
<section id="step-1" class="level4 page-columns page-full" data-number="11.1.2.1">
<h4 data-number="11.1.2.1" class="anchored" data-anchor-id="step-1"><span class="header-section-number">11.1.2.1</span> Step 1</h4>
<p>Let’s now work on Step 1. We estimate <span class="math inline">\(g_0(X)\)</span> using random forest (RF). As described above, this is a four-step process.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>It does not have to be RF. Indeed, you can use any statistical methods in this step.</p>
</div></div><p><strong>Step 1.1</strong>: Estimate <span class="math inline">\(l_0(X)\)</span> by regressing <span class="math inline">\(y\)</span> on <span class="math inline">\(X\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.1</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>rf_fitted_l0 <span class="ot">&lt;-</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    y <span class="sc">~</span> .,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">132</span>,</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">1</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>l0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_l0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - l0_hat ===#</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_l <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> l0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Step 1.2</strong>: Estimate <span class="math inline">\(m_0(X)\)</span> by regressing <span class="math inline">\(d\)</span> on <span class="math inline">\(X\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.2</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>rf_fitted_m0 <span class="ot">&lt;-</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    d <span class="sc">~</span> .,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"d"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">378</span>,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">3</span>,</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">6</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - m0_hat ===#</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>Figure of <code>d</code> (treatment variable) plotted against <code>m0_hat</code> (<span class="math inline">\(\hat{m}_0(X)\)</span>).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(training_data) <span class="sc">+</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> d, <span class="at">x =</span> m0_hat)) <span class="sc">+</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C01-dml_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</div></div><p><strong>Step 1.3</strong>: Get an initial estimate of <span class="math inline">\(\theta\)</span> using <a href="#eq-partial-out">Equation&nbsp;<span>11.2</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.2</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>theta_init <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_l) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d_less_m) ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Step 1.4</strong>: Regress <span class="math inline">\(y - \theta_{init}d\)</span> on <span class="math inline">\(X\)</span> to fit <span class="math inline">\(g_0(X)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.3</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== define y - treatment effect ===#</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_te <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> theta_init <span class="sc">*</span> d]</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit rf ===#</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>rf_fitted_g0 <span class="ot">&lt;-</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    y_less_te <span class="sc">~</span> .,</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y_less_te"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">132</span>,</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">1</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - g0 ===#</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-g0-ghat">Figure&nbsp;<span>11.1</span></a> plots true <span class="math inline">\(g_0(X)\)</span> (<code>g</code>) against <span class="math inline">\(\hat{g}_0(X)\)</span> (<code>g0_hat</code>). As you can see, <span class="math inline">\(\hat{g}_0(X)\)</span> is a bit biased.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(training_data) <span class="sc">+</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> g, <span class="at">x =</span> g0_hat)) <span class="sc">+</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-g0-ghat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C01-dml_files/figure-html/fig-g0-ghat-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 11.1: <strong>?(caption)</strong></figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="step-2" class="level4" data-number="11.1.2.2">
<h4 data-number="11.1.2.2" class="anchored" data-anchor-id="step-2"><span class="header-section-number">11.1.2.2</span> Step 2</h4>
<p>Finally, we regress <span class="math inline">\(y - \hat{g}_0(X)\)</span> on <span class="math inline">\(d\)</span> (or equivalently using <a href="#eq-theta-partial">Equation&nbsp;<span>11.3</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_less_g <span class="sc">~</span> d, <span class="at">data =</span> training_data)<span class="sc">$</span>coefficient[<span class="st">"d"</span>]</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        d 
0.5372165 </code></pre>
</div>
</div>
<p>So, in this instance, we get an estimate of <span class="math inline">\(\theta\)</span> that is a bit lower than the true value of <span class="math inline">\(\theta\)</span>. Let’s repeat this process many times to see how this procedure performs on average.</p>
<div class="cell" data-hash="C01-dml_cache/html/fig-naive_129ccc14135cfc04346125fa35e06c36">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>fit_m0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, <span class="at">mtry =</span> <span class="dv">10</span>) {</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>      d <span class="sc">~</span> .,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"d"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>      <span class="co"># mtry = 5,</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry,</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 378,</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">3</span>,</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 6</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_m0)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>fit_l0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, <span class="at">mtry =</span> <span class="dv">12</span>)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  rf_fitted_l0 <span class="ot">&lt;-</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>      y <span class="sc">~</span> .,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry,</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 132,</span></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 1</span></span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_l0)</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function that will get you g0_hat</span></span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="co"># this function will be used later</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>fit_g0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, rf_fitted_m0, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>) {</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.1</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>  rf_fitted_l0 <span class="ot">&lt;-</span> <span class="fu">fit_l0</span>(training_data, mtry_l)</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fitted values ===#</span></span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a>  l0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_l0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - l0_hat ===#</span></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_l <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> l0_hat]</span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.2</span></span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fitted values ===#</span></span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a>  m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - m0_hat ===#</span></span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a>  training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span>
<span id="cb14-62"><a href="#cb14-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-63"><a href="#cb14-63" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-64"><a href="#cb14-64" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.2</span></span>
<span id="cb14-65"><a href="#cb14-65" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-66"><a href="#cb14-66" aria-hidden="true" tabindex="-1"></a>  theta_init <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_l) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d_less_m)]</span>
<span id="cb14-67"><a href="#cb14-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-68"><a href="#cb14-68" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-69"><a href="#cb14-69" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.3</span></span>
<span id="cb14-70"><a href="#cb14-70" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb14-71"><a href="#cb14-71" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== define y - treatment effect ===#</span></span>
<span id="cb14-72"><a href="#cb14-72" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_te <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> theta_init <span class="sc">*</span> d]</span>
<span id="cb14-73"><a href="#cb14-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-74"><a href="#cb14-74" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit rf ===#</span></span>
<span id="cb14-75"><a href="#cb14-75" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span></span>
<span id="cb14-76"><a href="#cb14-76" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb14-77"><a href="#cb14-77" aria-hidden="true" tabindex="-1"></a>      y_less_te <span class="sc">~</span> .,</span>
<span id="cb14-78"><a href="#cb14-78" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y_less_te"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb14-79"><a href="#cb14-79" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry_g,</span>
<span id="cb14-80"><a href="#cb14-80" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 132,</span></span>
<span id="cb14-81"><a href="#cb14-81" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb14-82"><a href="#cb14-82" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb14-83"><a href="#cb14-83" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 1</span></span>
<span id="cb14-84"><a href="#cb14-84" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb14-85"><a href="#cb14-85" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb14-86"><a href="#cb14-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-87"><a href="#cb14-87" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_g0)</span>
<span id="cb14-88"><a href="#cb14-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-89"><a href="#cb14-89" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-90"><a href="#cb14-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-91"><a href="#cb14-91" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-92"><a href="#cb14-92" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function that runs a single simulation and gets you theta_hat</span></span>
<span id="cb14-93"><a href="#cb14-93" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-94"><a href="#cb14-94" aria-hidden="true" tabindex="-1"></a>run_sim_naive <span class="ot">&lt;-</span> <span class="cf">function</span>(i){</span>
<span id="cb14-95"><a href="#cb14-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-96"><a href="#cb14-96" aria-hidden="true" tabindex="-1"></a>  <span class="co"># training_data &lt;- data[[i]] %&gt;% data.table()</span></span>
<span id="cb14-97"><a href="#cb14-97" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb14-98"><a href="#cb14-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-99"><a href="#cb14-99" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(training_data)</span>
<span id="cb14-100"><a href="#cb14-100" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(training_data, rf_fitted_m0)</span>
<span id="cb14-101"><a href="#cb14-101" aria-hidden="true" tabindex="-1"></a>  g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb14-102"><a href="#cb14-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-103"><a href="#cb14-103" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - g0 ===#</span></span>
<span id="cb14-104"><a href="#cb14-104" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span>
<span id="cb14-105"><a href="#cb14-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-106"><a href="#cb14-106" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_less_g <span class="sc">~</span> d, <span class="at">data =</span> training_data)<span class="sc">$</span>coefficient[<span class="st">"d"</span>]</span>
<span id="cb14-107"><a href="#cb14-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-108"><a href="#cb14-108" aria-hidden="true" tabindex="-1"></a>  <span class="co"># theta_hat &lt;- training_data[, sum(d * y_less_g) / sum(d * d)]</span></span>
<span id="cb14-109"><a href="#cb14-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-110"><a href="#cb14-110" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb14-111"><a href="#cb14-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-112"><a href="#cb14-112" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-113"><a href="#cb14-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-114"><a href="#cb14-114" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-115"><a href="#cb14-115" aria-hidden="true" tabindex="-1"></a><span class="co"># Repeat MC simulations 500 times</span></span>
<span id="cb14-116"><a href="#cb14-116" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-117"><a href="#cb14-117" aria-hidden="true" tabindex="-1"></a>theta_hats_apr1 <span class="ot">&lt;-</span></span>
<span id="cb14-118"><a href="#cb14-118" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb14-119"><a href="#cb14-119" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb14-120"><a href="#cb14-120" aria-hidden="true" tabindex="-1"></a>    run_sim_naive,</span>
<span id="cb14-121"><a href="#cb14-121" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">/</span> <span class="dv">4</span> <span class="sc">*</span> <span class="dv">3</span></span>
<span id="cb14-122"><a href="#cb14-122" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb14-123"><a href="#cb14-123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb14-124"><a href="#cb14-124" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">theta =</span> .)</span>
<span id="cb14-125"><a href="#cb14-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-126"><a href="#cb14-126" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-127"><a href="#cb14-127" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb14-128"><a href="#cb14-128" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb14-129"><a href="#cb14-129" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_hats_apr1) <span class="sc">+</span></span>
<span id="cb14-130"><a href="#cb14-130" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb14-131"><a href="#cb14-131" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb14-132"><a href="#cb14-132" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb14-133"><a href="#cb14-133" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> theta_hats_apr1[, <span class="fu">mean</span>(theta)], <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb14-134"><a href="#cb14-134" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb14-135"><a href="#cb14-135" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb14-136"><a href="#cb14-136" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb14-137"><a href="#cb14-137" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb14-138"><a href="#cb14-138" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb14-139"><a href="#cb14-139" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-naive" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C01-dml_files/figure-html/fig-naive-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 11.2: Simulation results of the naive procedure</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-naive">Figure&nbsp;<span>11.2</span></a> shows the histogram of <span class="math inline">\(\hat{\theta}\)</span> from 500 simulations. You can see that this procedure has led to consistent underestimation of the treatment effect (mean value of <span class="math inline">\(\hat{\theta}\)</span> is 0.468). There are two sources of bias in this approach: regularization and over-fitting bias.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>Regularization bias: the bias coming from bias in estimating <span class="math inline">\(g_0(X)\)</span></li>
<li>Over-fitting bias: the bias coming from over-fitting <span class="math inline">\(g_0(X)\)</span> and <span class="math inline">\(m_0(X)\)</span> due to the fact that the same sample is used for <span class="math inline">\(g_0(X)\)</span> and <span class="math inline">\(m_0(X)\)</span> estimation and <span class="math inline">\(\theta\)</span> estimation</li>
</ul>
</div>
</div>
<p>Regularization bias is termed so because bias in estimating <span class="math inline">\(g_0(X)\)</span> can occur when some form of regularization is implemented (e.g., lasso).</p>
<!-- However, its name is slightly misleading because $g_0(X)$ cannot be estimated without bias even without any regularization in general. This is because the estimation of initial $\theta$ (in Step 1.3) is biased, which comes from the fact that $m_0(X)$ is correlated with $g_0(X)$ through $X$.  -->
<!-- ::: {.column-margin}
Another (unofficial) implementation of $g_0(X)$ estimation is to just use $\hat{l}_0(X_i)$ as $\hat{g}_0(X_i)$ ([a blog post](https://www.r-bloggers.com/2017/06/cross-fitting-double-machine-learning-estimator/)) and then use the following formula.



$$
\begin{aligned}
  \hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{l}_0(X_i))
\end{aligned}
$$



$\hat{\theta}$ is biased because $\hat{l}_0(X_i)$ is a biased estimator of $\hat{g}_0(X_i)$ when $m_0(X)$ and $g_0(X)$ are correlated. The point here is that, $g_0(X)$ is hard to estimate without bias irrespective of whether any regularization happens or not.
::: -->
<!-- However, if the treatment is independent, then, $g_0(X)$ can be estimated well and this approach works well except it still suffers from over-fitting bias. @fig-apr1-indep shows that the distribution of $\hat{\theta}$ when $m_0(X)$ is independent of $g_0(X)$ and the RF with the same hyper-parameters are used. While regularization can lead to bias in the estimation of $g_0(X)$, regularization is not the only source of bias.  -->

<!-- ```{r}
#| fig-cap: Performance of approach 1 when the treatment status is independent
#| label: fig-apr1-indep
#| code-fold: true
#| warning: false
#| cache: true 

run_sim_naive <- function(i){

  training_data <- gen_data(m_formula = "independent")

  rf_fitted_m0 <- fit_m0(training_data)
  rf_fitted_g0 <- fit_g0(training_data, rf_fitted_m0)
  # rf_fitted_g0 <- fit_l0(training_data)

  g0_hat <- predict(rf_fitted_g0, data = training_data)$predictions

  #=== create y - g0 ===#
  training_data[, y_less_g := y - g0_hat]

  theta_hat <- lm(y_less_g ~ d, data = training_data)$coefficient["d"]

  # theta_hat <- training_data[, sum(d * y_less_g) / sum(d * d)]

  return(theta_hat)

}

#===================================
# Repeat MC simulations 500 times
#===================================
theta_hats_apr1_indep <-
  mclapply(
    1:500,
    run_sim_naive,
    mc.cores = detectCores() / 4 * 3
  ) %>% 
  unlist() %>% 
  data.table(theta = .)

#===================================
# Plot the results
#===================================
ggplot(theta_hats_apr1_indep) +
  geom_histogram(aes(x = theta), color = "grey", fill = "white") +
  theme_bw() + 
  geom_vline(aes(xintercept = 0.5,color = "True Value")) +
  geom_vline(aes(xintercept = theta_hats_apr1_indep[, mean(theta)], color = "Mean of the Estimates")) +
  scale_color_manual(
    values = c("True Value" = "red", "Mean of the Estimates" = "blue"),
    name = ""
  ) +
  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +
  theme(legend.position = "bottom")
``` -->
</section>
</section>
<section id="overcoming-the-regularization-bias" class="level3 page-columns page-full" data-number="11.1.3">
<h3 data-number="11.1.3" class="anchored" data-anchor-id="overcoming-the-regularization-bias"><span class="header-section-number">11.1.3</span> Overcoming the regularization bias</h3>
<p>Regularization bias can be overcome by double-debiasing (orthogonalizing both <span class="math inline">\(d\)</span> and <span class="math inline">\(y\)</span>). Specifically,</p>
<ul>
<li>Step 1: Estimate <span class="math inline">\(g_0(X)\)</span> and then subtract the fitted value of <span class="math inline">\(g_0(X)\)</span> from <span class="math inline">\(y\)</span></li>
<li>Step 2: Subtract <span class="math inline">\(\hat{m}_0(X)\)</span> from <span class="math inline">\(d\)</span> (<span class="math inline">\(\tilde{d} = d - \hat{m}_0(x)\)</span>)</li>
<li>Step 3: Calculate <span class="math inline">\(\hat{\theta}\)</span> based on the following formula</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{g}_0(X_i))
\end{aligned}
\]</span></p>
<p>The key difference from the previous approach is that this approach uses <strong>IV-like</strong> formula, where <span class="math inline">\(\tilde{d}\)</span> is acting like an instrument.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>For <span class="math inline">\(y = X\beta + \mu\)</span> with instruments <span class="math inline">\(Z\)</span>, the IV estimator is <span class="math display">\[
\begin{aligned}
\hat{\beta} = (Z'X)^{-1}Z'y
\end{aligned}
\]</span></p>
</div></div><p>We have done Steps 1 and 2 already in the previous approach. So,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_g) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d)]</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5325107</code></pre>
</div>
</div>
<p>Now, let’s repeat this 500 times.</p>
<div class="cell" data-hash="C01-dml_cache/html/fig-dd_2945fcf559fd312ad8ebcee214a75904">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>run_sim_dereg <span class="ot">&lt;-</span> <span class="cf">function</span>(i)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="co"># training_data &lt;- data[[i]] %&gt;% data.table</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(training_data)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>  m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create d - m0_hat ===#</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>  training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== get g0_hat ===#</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(training_data, rf_fitted_m0)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - g0 ===#</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_g) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d)]</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>theta_hats_apr2 <span class="ot">&lt;-</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_sim_dereg</span>(x),</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">/</span> <span class="dv">4</span> <span class="sc">*</span> <span class="dv">3</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">theta =</span> .)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_hats_apr2) <span class="sc">+</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> theta_hats_apr2[, <span class="fu">mean</span>(theta)], <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dd" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C01-dml_files/figure-html/fig-dd-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 11.3: Simulation results of double-debiased approach</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-dd">Figure&nbsp;<span>11.3</span></a> shows the distribution of <span class="math inline">\(\hat{\theta}\)</span>, which is centered about <span class="math inline">\(0.478\)</span>. The current approach still suffers from the so-called over-fitting bias<span class="citation" data-cites="Chernozhukov2018">(<a href="#ref-Chernozhukov2018" role="doc-biblioref">Chernozhukov et al. 2018</a>)</span>. Let’s look at how we can overcome this bias next.</p>
</section>
<section id="sec-cf" class="level3 page-columns page-full" data-number="11.1.4">
<h3 data-number="11.1.4" class="anchored" data-anchor-id="sec-cf"><span class="header-section-number">11.1.4</span> Overcoming the over-fitting bias</h3>
<p>Over-fitting bias can be overcome by cross-fitting. First, the training data is split into <span class="math inline">\(K\)</span>-folds just like K-fold cross-validation. Let’s denote them as <span class="math inline">\(I_1, \dots, I_k\)</span>. For example, for <span class="math inline">\(I_1\)</span>, the following steps are taken (<a href="#fig-cross-fitting">Figure&nbsp;<span>11.4</span></a> provides a visual illustration):</p>
<ul>
<li>Step 1: Estimate <span class="math inline">\(\hat{g}_0(x)\)</span> and <span class="math inline">\(\hat{m}_0(x)\)</span> using the data from the other folds (<span class="math inline">\(I_2, \dots, I_K\)</span>).</li>
<li>Step 2: Estimate <span class="math inline">\(\hat{g}_0(x_i)\)</span> and <span class="math inline">\(\hat{m}_0(x_i)\)</span> for each <span class="math inline">\(i \in I_1\)</span> and calculate <span class="math inline">\(\tilde{y}_i = y_i - \hat{g}_0(x_i)\)</span> and <span class="math inline">\(\tilde{d}_i = d_i - \hat{m}_0(x_i)\)</span>.</li>
<li>Step 3: Use the following formula to obtain <span class="math inline">\(\hat{\theta}\)</span>.</li>
</ul>
<p><span id="eq-iv-score"><span class="math display">\[
\begin{aligned}
\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{g}_0(X_i))
\end{aligned}
\tag{11.5}\]</span></span></p>
<p>This process is repeated for all the <span class="math inline">\(K\)</span> folds, and then the the final estimate of <span class="math inline">\(\hat{\theta}\)</span> is obtained as the average of <span class="math inline">\(\hat{\theta}\)</span>s.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>You can implement repeated K-fold cross-fitting using the <code>DoublML</code> package, which is not demonstrated here as it is very much similar in concept to repeated K-fold CV explained in <a href="B03-cross-validation.html"><span>Chapter&nbsp;3</span></a>.</p>
</div></div><p><span style="color:blue"> talk about <code>algorithm_2</code> </span></p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 1 ===#</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> <span class="dv">2</span>),</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="fl">2.5</span>, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> <span class="dv">2</span>),</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 2 ===#</span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">2.2</span>, <span class="at">ymax =</span> <span class="fl">4.2</span>),</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="fl">2.5</span>, <span class="at">xmax =</span> <span class="dv">5</span>, <span class="at">ymin =</span> <span class="fl">2.2</span>, <span class="at">ymax =</span> <span class="fl">4.2</span>),</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 3 ===#</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">4.4</span>, <span class="at">ymax =</span> <span class="fl">6.4</span>),</span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">5</span>, <span class="at">xmax =</span> <span class="fl">7.5</span>, <span class="at">ymin =</span> <span class="fl">4.4</span>, <span class="at">ymax =</span> <span class="fl">6.4</span>),</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 4 ===#</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">6.6</span>, <span class="at">ymax =</span> <span class="fl">8.6</span>),</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="fl">7.5</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">6.6</span>, <span class="at">ymax =</span> <span class="fl">8.6</span>),</span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_brace</span>(<span class="fu">aes</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">7.4</span>), <span class="fu">c</span>(<span class="fl">8.7</span>, <span class="fl">9.2</span>)), <span class="at">inherit.data=</span>F) <span class="sc">+</span></span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">3.5</span>, <span class="at">y =</span> <span class="fl">9.7</span>, <span class="at">parse =</span> <span class="cn">TRUE</span>,</span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> <span class="st">"'Find ' * hat(g)[0](x) * ' and ' * hat(m)[0](x) * ' from this data.'"</span>,</span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">6</span></span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-52"><a href="#cb18-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_curve</span>(</span>
<span id="cb18-53"><a href="#cb18-53" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">2.2</span>, <span class="at">xend =</span> <span class="fl">8.5</span>, <span class="at">y =</span> <span class="fl">10.3</span>, <span class="at">yend =</span> <span class="fl">8.8</span>),</span>
<span id="cb18-54"><a href="#cb18-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.03</span>, <span class="st">"npc"</span>)),</span>
<span id="cb18-55"><a href="#cb18-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">curvature =</span> <span class="sc">-</span><span class="fl">0.3</span></span>
<span id="cb18-56"><a href="#cb18-56" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-57"><a href="#cb18-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_curve</span>(</span>
<span id="cb18-58"><a href="#cb18-58" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">3.4</span>, <span class="at">xend =</span> <span class="dv">8</span>, <span class="at">y =</span> <span class="fl">10.3</span>, <span class="at">yend =</span> <span class="fl">8.8</span>),</span>
<span id="cb18-59"><a href="#cb18-59" aria-hidden="true" tabindex="-1"></a>    <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.03</span>, <span class="st">"npc"</span>)),</span>
<span id="cb18-60"><a href="#cb18-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">curvature =</span> <span class="sc">-</span><span class="fl">0.3</span></span>
<span id="cb18-61"><a href="#cb18-61" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb18-62"><a href="#cb18-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="cn">NA</span>, <span class="dv">11</span>) <span class="sc">+</span></span>
<span id="cb18-63"><a href="#cb18-63" aria-hidden="true" tabindex="-1"></a>  <span class="co"># coord_equal() +</span></span>
<span id="cb18-64"><a href="#cb18-64" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_void</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cross-fitting" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C01-dml_files/figure-html/fig-cross-fitting-1.png" class="img-fluid figure-img" width="864"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 11.4: Illustration of cross-fitting</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Let’s code the cross-fitting procedure. We first split the data into 2 folds (<span class="math inline">\(K = 2\)</span>).</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span class="math inline">\(K\)</span> does not have to be 2.</p>
</div></div><div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(training_data, <span class="at">v =</span> <span class="dv">2</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#  2-fold cross-validation 
# A tibble: 2 × 2
  splits            id   
  &lt;list&gt;            &lt;chr&gt;
1 &lt;split [250/250]&gt; Fold1
2 &lt;split [250/250]&gt; Fold2</code></pre>
</div>
</div>
<p>Let’s cross-fit for fold 1.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>split_1 <span class="ot">&lt;-</span> data_folds[<span class="dv">1</span>, ]</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for estimating g_0  and m_0 ===#</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>data_train <span class="ot">&lt;-</span> <span class="fu">analysis</span>(split_1<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for which g_0(x_i) and m_0(x_i) are calculated ===#</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>data_target <span class="ot">&lt;-</span> <span class="fu">assessment</span>(split_1<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>First, we fit <span class="math inline">\(\hat{g}_0(x)\)</span> and <span class="math inline">\(\hat{m}_0(x)\)</span> using the data from the other folds.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== m0 ===#</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>m_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(data_train)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== g0 ===#</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>g_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(data_train, m_rf_fit)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we predict <span class="math inline">\(\hat{g}_0(x_i)\)</span> and <span class="math inline">\(\hat{m}_0(x_i)\)</span> for each <span class="math inline">\(i\)</span> of fold 1 (the target dataset) and calculate <span class="math inline">\(\tilde{y}_i = y_i - \hat{g}_0(x_i)\)</span> and <span class="math inline">\(\tilde{d}_i = d_i - \hat{m}_0(x_i)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>data_orth <span class="ot">&lt;-</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  data_target <span class="sc">%&gt;%</span> </span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== prediction of g_0(x_i) ===#</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  .[, g_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(g_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== orthogonalize y ===#</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>  .[, y_tilde <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== prediction of m_0(x_i) ===#</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  .[, m_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(m_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== orthogonalize d ===#</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  .[, d_tilde <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m_0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Then, <span class="math inline">\(\hat{\theta}\)</span> is obtained for this fold using <a href="#eq-iv-score">Equation&nbsp;<span>11.5</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> data_orth[, <span class="fu">sum</span>(d_tilde <span class="sc">*</span> y_tilde) <span class="sc">/</span> <span class="fu">sum</span>(d_tilde <span class="sc">*</span> d)]</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5486855</code></pre>
</div>
</div>
<p>We can repeat this for all the folds (<code>cross_fit()</code> which finds <span class="math inline">\(\hat{\theta}\)</span> for a particular fold is defined on the side).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(i, data_folds, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_m =</span> <span class="dv">10</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>)</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prepare data</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== ith split ===#</span></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  working_split <span class="ot">&lt;-</span> data_folds[i, ]</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== data for estimating g_0  and m_0 ===#</span></span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>  data_train <span class="ot">&lt;-</span> <span class="fu">analysis</span>(working_split<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== data for which g_0(x_i) and m_0(x_i) are calculated ===#</span></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  data_target <span class="ot">&lt;-</span> <span class="fu">assessment</span>(working_split<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Fit g0 and m0</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== m0 ===#</span></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>  m_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(data_train, mtry_m)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== g0 ===#</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>  g_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(data_train, m_rf_fit, mtry_l, mtry_g)</span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get y_tilde and d_tilde</span></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a>  data_orth <span class="ot">&lt;-</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>    data_target <span class="sc">%&gt;%</span> </span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== prediction of g_0(x_i) ===#</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    .[, g_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(g_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== orthogonalize y ===#</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    .[, y_tilde <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== prediction of m_0(x_i) ===#</span></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>    .[, m_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(m_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== orthogonalize d ===#</span></span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    .[, d_tilde <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>    .[, .(y_tilde, d_tilde, d)]</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>  theta_cf <span class="ot">&lt;-</span> data_orth[, <span class="fu">sum</span>(d_tilde <span class="sc">*</span> y_tilde) <span class="sc">/</span> <span class="fu">sum</span>(d_tilde <span class="sc">*</span> d)]</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_cf)</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> </span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)), <span class="co"># loop over folds</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds) <span class="co"># get theta_hat</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>() <span class="co"># average them</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.5247844</code></pre>
</div>
</div>
<p>Okay, now that we understand the steps of this approach, let’s repeat this many times (<code>get_theta_cf()</code> that finds <span class="math inline">\(\hat{\theta}\)</span> by cross-fitting is defined on the side).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>get_theta_cf <span class="ot">&lt;-</span> <span class="cf">function</span>(data_folds, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_m =</span> <span class="dv">10</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>){</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> </span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds, mtry_l, mtry_m, mtry_g)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>()</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><div class="cell" data-hash="C01-dml_cache/html/fig-cf-debiased_80e2bdd7dd7f0848047825d099f877ad">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>theta_hats_cf <span class="ot">&lt;-</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) {</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>      <span class="fu">print</span>(x)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>      training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>      data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(training_data, <span class="at">v =</span> <span class="dv">2</span>)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>      theta_hat <span class="ot">&lt;-</span>  <span class="fu">get_theta_cf</span>(data_folds)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(theta_hat)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">*</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span></span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>()</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a><span class="co">#=== visualize the results ===#</span></span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta_hats_cf), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(theta_hats_cf), <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-cf-debiased" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C01-dml_files/figure-html/fig-cf-debiased-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 11.5: The distribution of treatment effect estimated by the double-debiased approach with cross-fitting</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-cf-debiased">Figure&nbsp;<span>11.5</span></a> shows the distribution of <span class="math inline">\(\hat{\theta}\)</span> with double-debiasing and cross-fitting. It is slightly biased in this instance (mean is 0.502), but the average <span class="math inline">\(\hat{\theta}\)</span> is very close to the true parameter.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><p>Double/debiased (double orthogonalization) can help overcome the bias in <span class="math inline">\(\hat{\theta}\)</span> that comes from the bias in estimating <span class="math inline">\(g_0(X)\)</span>.</p></li>
<li><p>Cross-fitting can help overcome the bias from estimating <span class="math inline">\(g_0(X)\)</span>, <span class="math inline">\(m_0(X)\)</span>, and <span class="math inline">\(\theta\)</span> using the same data.</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="models-and-implementation-by-doubleml" class="level2 page-columns page-full" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="models-and-implementation-by-doubleml"><span class="header-section-number">11.2</span> Models and implementation by <code>DoubleML</code></h2>
<p>In R, <code>DoubleML</code> is built on top of <code>mlr3</code>, which uses <code>R6</code> classes provided by the <code>R6</code> package. Since <code>R6</code> implements encapsulated object-oriented programming like Python, <code>DoubleML</code> in R and Python work in a very similar manner. Here, we will use R for demonstrations.</p>
<section id="partially-linear-model" class="level3 page-columns page-full" data-number="11.2.1">
<h3 data-number="11.2.1" class="anchored" data-anchor-id="partially-linear-model"><span class="header-section-number">11.2.1</span> Partially linear model</h3>
<p><span id="eq-plr"><span class="math display">\[
\begin{aligned}
y = \theta d + g_0(X) + \mu \\
d = m_0(X) + \eta
\end{aligned}
\tag{11.6}\]</span></span></p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Assumptions on the error terms</strong></p>
<ul>
<li><span class="math inline">\(E[\mu|D,X] = 0\)</span></li>
<li><span class="math inline">\(E[\eta|X] = 0\)</span></li>
<li><span class="math inline">\(E[\eta\cdot \mu|D, X] = 0\)</span></li>
</ul>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>DiagrammeR<span class="sc">::</span><span class="fu">grViz</span>(</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a><span class="st">  digraph {</span></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a><span class="st">    graph [layout = circo, ranksep = 0.5]</span></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a><span class="st">      Y [label = 'Y']</span></span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a><span class="st">      u [label = '\U03BC']</span></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="st">      X [label = 'X']</span></span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a><span class="st">      T [label = 'T']</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="st">      v [label = '\U03B7']</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="st">    edge [minlen = 2]</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="st">      {v, X}-&gt;T</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a><span class="st">      {X, T}-&gt;Y</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a><span class="st">      u-&gt;Y</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="htmlwidget-6513000584a4d02624c3" style="width:100%;height:464px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-6513000584a4d02624c3">{"x":{"diagram":"\n  digraph {\n    graph [layout = circo, ranksep = 0.5]\n\n    node [shape = box]\n      Y [label = \"Y\"]\n      u [label = \"μ\"]\n\n    node [shape = box]\n      X [label = \"X\"]\n      T [label = \"T\"]\n      v [label = \"η\"]\n\n    edge [minlen = 2]\n      {v, X}->T\n      {X, T}->Y\n      u->Y\n  }\n  ","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>There are two ways to estimate <span class="math inline">\(\theta\)</span> using <code>DoublMLPLR()</code>. They differ in how their score functions are defined. You pick either one of the two:</p>
<ul>
<li><code>partialling-out</code>: <span class="math inline">\([Y - l(X) - \theta(D-m(X))][D-m(X)]\)</span></li>
<li><code>IV-type</code>: <span class="math inline">\([Y - \theta D - g(X)][D-m(X)]\)</span></li>
</ul>
<p>Since <span class="math inline">\(g(X)\)</span> and <span class="math inline">\(m(X)\)</span> themselves appear in the data generating process (<a href="#eq-plr">Equation&nbsp;<span>11.7</span></a>), it is clear what they are. However, it is not immediately clear what <span class="math inline">\(l(X)\)</span> represents. <span class="math inline">\(l(X)\)</span> refers to <span class="math inline">\(E[Y|X]\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
l(X) = E[Y|X] &amp; = E[\theta d + g_0(X) + \mu] \\
              &amp; = \theta E[d|X] + E[g_0(X)] + E[\mu|X] \\
              &amp; = \theta m_0(X) + g_0(X) \;\; \mbox{(by the assumptions on the error terms)}\\
\end{aligned}
\]</span></p>
<p>Given this, the scores functions can be rewritten as:</p>
<ul>
<li><code>partialling-out</code>: <span class="math inline">\(\mu\cdot \eta\)</span></li>
<li><code>IV-type</code>: <span class="math inline">\(\mu\cdot \eta\)</span></li>
</ul>
<p>Therefore, the two score functions are actually identical in meaning, but represented by different terms, which result in different equations to calculate <span class="math inline">\(\hat{\theta}\)</span>. Here are how <span class="math inline">\(\theta\)</span> is identified for the two scores functions:</p>
<p><strong><code>partialling-out</code></strong></p>
<p><span class="math display">\[
\begin{aligned}
E\large(\normalsize[Y - l(X) - \theta(D-m(X))][D-m(X)]\large)\normalsize = 0 \\
\theta = \frac{E[(Y - l(X))(D-m(X))]}{E[(D-m(X))(D-m(X))]}
\end{aligned}
\]</span></p>
<p>The empirical analog of this moment condition is</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta} = \frac{\sum_{i=1}^N (Y_i - l(X_i))(D_i-m(X_i))}{\sum_{i=1}^N (D_i-m(X_i))(D_i-m(X_i))}
\end{aligned}
\]</span></p>
<p><strong><code>IV-type</code></strong></p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta} = \frac{\sum_{i=1}^N (Y_i - g(X_i))(D_i-m(X_i))}{\sum_{i=1}^N D_i(D_i-m(X_i))}
\end{aligned}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span class="math inline">\(D_i-m(X_i)\)</span> is acting like an instrument.</p>
</div></div><p>The choice of the score function results in different steps to estimate <span class="math inline">\(\theta\)</span> and what you need to supply to <code>DoublMLPLR()</code>. <span class="math inline">\(g_0(X)\)</span> is estimated in several steps (see <a href="#sec-dml-naive"><span>Section&nbsp;11.1.2</span></a>) as it needs to remove the effect of <span class="math inline">\(\theta D\)</span> before estimating only <span class="math inline">\(g_0(X)\)</span>. <span class="math inline">\(l_0(X)\)</span>, however, is estimated by simply regressing <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span>. In running <code>DoublMLPLR()</code>, there are three key options:</p>
<ul>
<li><code>ml_l</code>: ML method to use to estimate <span class="math inline">\(l(X)\)</span></li>
<li><code>ml_m</code>: ML method to use to estimate <span class="math inline">\(m(X)\)</span></li>
<li><code>ml_g</code>: ML method to use to estimate <span class="math inline">\(g(X)\)</span></li>
</ul>
<p>When <code>partialling-out</code> is selected, you need to specify <code>ml_l</code> and <code>ml_m</code>. However, you do not need to specify the <code>ml_g</code>. When <code>IV-type</code> is used you need to specify all three. This is because estimating <code>g(X)</code> involves first estimating <code>l(X)</code> (see <a href="#sec-dml-naive"><span>Section&nbsp;11.1.2</span></a>). So, the <code>partialling-out</code> option requires a smaller number of steps and easier to specify for the user.</p>
<p>Let’s implement <code>DoublMLPLR()</code> using a synthetic dataset that follows the DGP represented by <a href="#eq-simple-synthetic">Equation&nbsp;<span>11.4</span></a>. We can use <code>make_plr_CCDDHNR2018()</code> to create such a dataset.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">make_plr_CCDDHNR2018</span>(</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>, </span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> <span class="dv">500</span>, </span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">dim_x =</span> <span class="dv">20</span>, </span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">return_type =</span> <span class="st">'data.table'</span></span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>             X1          X2          X3         X4           X5         X6
  1:  1.2440476  1.64639297  0.71131792  0.4783044  0.008239645  0.4533324
  2:  0.9023502  0.15267901  0.01064853  0.2088653 -0.305263506  0.7158397
  3: -1.9637574 -1.87906651 -0.67356583 -0.5550050  0.029957814  0.5359109
  4: -1.9718906 -0.82930335 -1.11817257 -1.6561757 -1.853304959 -0.5511951
  5: -1.0273249 -0.69520796 -1.62652575 -0.8325634 -0.769455086  0.7121183
 ---                                                                      
496: -0.5828880  0.03691634 -0.09796938 -0.2660888  0.256374614  0.8409559
497:  0.1310249 -0.04537018 -0.63309501 -1.9887410 -0.511560500 -0.6410372
498:  0.6988148  1.18801352  1.40573962  1.7227378  0.135727751 -0.9089638
499:  0.9334815  0.53835718  0.63176578  0.6217877  0.949987407  1.3972804
500: -1.8301636 -0.48985250  0.28928829  0.2081408  0.289517934  0.1162203
             X7          X8         X9         X10        X11        X12
  1:  0.2998599  0.08169994 -0.3034012 -0.41817280 -0.1684357 -0.5818317
  2:  0.4535326  0.39097316 -0.1131795 -0.32836997 -0.4328069  0.3964901
  3:  1.9876844  0.32706905 -0.3247179 -0.95800870 -0.6582622 -0.8564451
  4: -1.1271986  0.01316699 -0.6730823 -0.27714289 -0.4080058  0.2292704
  5:  0.9164861  0.25645093  0.8497441  1.43501126  1.0167186 -0.1490919
 ---                                                                    
496:  1.9224220 -0.36454764  0.5100894  0.56865912  1.2143600  1.4910141
497: -0.3887281  0.19720732 -0.2633226 -0.36455774 -0.6915640  0.1428711
498: -0.4677247  0.09132417  1.3396831  0.12893152  0.5207629  0.3854993
499:  1.4887376  1.83162991  1.0472136  1.52179830  1.8261050  2.2777564
500:  1.2296010  0.99825727  1.2843710 -0.08255473 -0.2282313 -0.4273543
            X13        X14        X15        X16        X17        X18
  1:  0.6359233  0.6519038  0.8225963  1.4501328  1.3638703  2.3590094
  2:  0.4119444  0.8873855  0.4601086  0.8426136  1.1745062  1.0474801
  3: -1.7953205 -2.7288900 -1.8070682 -2.3540323 -1.0996324 -0.4669641
  4:  0.6332562 -1.5151797 -0.5069169 -0.3316435 -0.5820351 -1.1698090
  5:  0.3762819  0.2109936  1.5015694  0.7507966  0.4815073  0.4143088
 ---                                                                  
496:  0.7537537  0.5242330  1.0652588  2.2025996  1.3431624  0.4493184
497: -0.5253672  0.1851662  0.1890410 -1.1936561 -2.0104705 -1.6484655
498:  0.3943351 -1.0036494  0.2384225 -0.1725888  0.8901573  0.3837909
499:  3.3185716  1.9115865  1.6692008  0.3438597 -0.1976231  0.3944083
500:  0.5623116  0.8880912  1.5738437  1.2236440  1.8337886  2.8762545
             X19        X20          y          d
  1:  2.15034400  1.9143797  1.8599237  1.2501768
  2:  0.94456253 -0.4795718  2.3923080  2.1841305
  3: -0.06033539  0.5126436 -0.9123374 -1.4574737
  4: -1.12264600 -0.3507258 -1.7675132 -2.9801900
  5:  0.08113000 -1.6986236 -1.7201920 -0.8987789
 ---                                             
496: -0.17389979  0.7992646  0.2055072 -1.3320553
497: -2.00535182 -0.9286602 -0.2724589 -1.6061591
498:  1.25943944  0.5382165  0.4598890  0.4722447
499: -0.67025460 -0.4495312  0.4208797  0.4633706
500:  1.44951329  0.3391455 -1.7206897 -3.5137542</code></pre>
</div>
</div>
<p>Note that the treatment variable is continuous in this dataset.</p>
<p>We first need to create a <code>DoubleMLData</code> object from the train data using <code>DoubleMLData$new()</code>. Specify the dependent variable using the <code>y_col</code> option and the treatment variable(s) by <code>d_cols</code>. The rest of the variables in the dataset provided will be regarded as covariates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>obj_dml_data <span class="ot">&lt;-</span> </span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>  DoubleMLData<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    data, </span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_col =</span> <span class="st">"y"</span>, </span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">d_cols =</span> <span class="st">"d"</span></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= DoubleMLData Object ==================


------------------ Data summary      ------------------
Outcome variable: y
Treatment variable(s): d
Covariates: X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20
Instrument(s): 
No. Observations: 500</code></pre>
</div>
</div>
<p>Now, let’s specify <code>ml_l</code>, <code>ml_m</code>, and <code>ml_g</code>. The <code>DoubleML</code> follows <code>mlr3</code> (see <a href="PROG-01-mlr3.html"><span>Chapter&nbsp;16</span></a> for how to use <code>mlr3</code>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>ml_l <span class="ot">&lt;-</span> </span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">"regr.ranger"</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">500</span>, </span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">15</span>, </span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">5</span></span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;LearnerRegrRanger:regr.ranger&gt;
* Model: -
* Parameters: num.threads=1, num.trees=500, mtry=15, min.node.size=5
* Packages: mlr3, mlr3learners, ranger
* Predict Type: response
* Feature types: logical, integer, numeric, character, factor, ordered
* Properties: hotstart_backward, importance, oob_error, weights</code></pre>
</div>
</div>
<p>Let’s use the same ML method for <code>ml_m</code> and <code>ml_g</code> (you can use any appropriate ML methods). We can simply use the <code>clone()</code> method to replicate <code>ml_l</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>ml_m <span class="ot">&lt;-</span> ml_l<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>ml_g <span class="ot">&lt;-</span> ml_l<span class="sc">$</span><span class="fu">clone</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now set up the <code>DoubleMLPLR</code> estimator by providing a <code>DoubleMLData</code> and ML methods. By default, <code>score</code> is set to <code>"partialling out"</code>, so we do not need to provide <code>ml_g</code>. The <code>apply_cross_fitting</code> option is set to <code>TRUE</code> by default.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>dml_plr_obj <span class="ot">&lt;-</span> DoubleMLPLR<span class="sc">$</span><span class="fu">new</span>(obj_dml_data, ml_l, ml_m)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can fit the model by invoking <code>fit()</code> on <code>dml_plr_obj</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>dml_plr_obj<span class="sc">$</span><span class="fu">fit</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO  [09:54:55.571] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 5/5) 
INFO  [09:54:56.047] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 3/5) 
INFO  [09:54:56.507] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 1/5) 
INFO  [09:54:56.954] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 2/5) 
INFO  [09:54:57.409] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 4/5) 
INFO  [09:54:58.185] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 1/5) 
INFO  [09:54:58.658] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 4/5) 
INFO  [09:54:59.121] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 3/5) 
INFO  [09:54:59.589] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 5/5) 
INFO  [09:55:00.056] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 2/5) </code></pre>
</div>
</div>
<p>See the results with <code>print()</code>. You can see <span class="math inline">\(\hat{\theta}\)</span> at the bottom.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dml_plr_obj)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= DoubleMLPLR Object ==================


------------------ Data summary      ------------------
Outcome variable: y
Treatment variable(s): d
Covariates: X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20
Instrument(s): 
No. Observations: 500

------------------ Score &amp; algorithm ------------------
Score function: partialling out
DML algorithm: dml2

------------------ Machine learner   ------------------
ml_l: regr.ranger
ml_m: regr.ranger

------------------ Resampling        ------------------
No. folds: 5
No. repeated sample splits: 1
Apply cross-fitting: TRUE

------------------ Fit summary       ------------------
 Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.52331    0.04536   11.54   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
<p>If you are using <code>IV-type</code>, then you need to provide <code>ml_g</code> as well like below.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up ===#</span></span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a>dml_plr_obj_iv <span class="ot">&lt;-</span> </span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>  DoubleMLPLR<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb44-4"><a href="#cb44-4" aria-hidden="true" tabindex="-1"></a>    obj_dml_data, </span>
<span id="cb44-5"><a href="#cb44-5" aria-hidden="true" tabindex="-1"></a>    ml_l, </span>
<span id="cb44-6"><a href="#cb44-6" aria-hidden="true" tabindex="-1"></a>    ml_m, </span>
<span id="cb44-7"><a href="#cb44-7" aria-hidden="true" tabindex="-1"></a>    ml_g,</span>
<span id="cb44-8"><a href="#cb44-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">score =</span> <span class="st">"IV-type"</span></span>
<span id="cb44-9"><a href="#cb44-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb44-10"><a href="#cb44-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-11"><a href="#cb44-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit ===#</span></span>
<span id="cb44-12"><a href="#cb44-12" aria-hidden="true" tabindex="-1"></a>dml_plr_obj_iv<span class="sc">$</span><span class="fu">fit</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>INFO  [09:55:00.693] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 2/5) 
INFO  [09:55:01.165] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 4/5) 
INFO  [09:55:01.639] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 1/5) 
INFO  [09:55:02.111] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 3/5) 
INFO  [09:55:02.589] [mlr3] Applying learner 'regr.ranger' on task 'nuis_l' (iter 5/5) 
INFO  [09:55:03.203] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 1/5) 
INFO  [09:55:03.662] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 5/5) 
INFO  [09:55:04.123] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 4/5) 
INFO  [09:55:04.586] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 2/5) 
INFO  [09:55:05.052] [mlr3] Applying learner 'regr.ranger' on task 'nuis_m' (iter 3/5) 
INFO  [09:55:05.676] [mlr3] Applying learner 'regr.ranger' on task 'nuis_g' (iter 5/5) 
INFO  [09:55:06.140] [mlr3] Applying learner 'regr.ranger' on task 'nuis_g' (iter 4/5) 
INFO  [09:55:06.609] [mlr3] Applying learner 'regr.ranger' on task 'nuis_g' (iter 3/5) 
INFO  [09:55:07.077] [mlr3] Applying learner 'regr.ranger' on task 'nuis_g' (iter 2/5) 
INFO  [09:55:07.542] [mlr3] Applying learner 'regr.ranger' on task 'nuis_g' (iter 1/5) </code></pre>
</div>
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== print the results ===#</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dml_plr_obj_iv)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>================= DoubleMLPLR Object ==================


------------------ Data summary      ------------------
Outcome variable: y
Treatment variable(s): d
Covariates: X1, X2, X3, X4, X5, X6, X7, X8, X9, X10, X11, X12, X13, X14, X15, X16, X17, X18, X19, X20
Instrument(s): 
No. Observations: 500

------------------ Score &amp; algorithm ------------------
Score function: IV-type
DML algorithm: dml2

------------------ Machine learner   ------------------
ml_l: regr.ranger
ml_m: regr.ranger
ml_g: regr.ranger

------------------ Resampling        ------------------
No. folds: 5
No. repeated sample splits: 1
Apply cross-fitting: TRUE

------------------ Fit summary       ------------------
 Estimates and significance testing of the effect of target variables
  Estimate. Std. Error t value Pr(&gt;|t|)    
d   0.54946    0.04565   12.04   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
</div>
</section>
<section id="partially-linear-iv-model" class="level3" data-number="11.2.2">
<h3 data-number="11.2.2" class="anchored" data-anchor-id="partially-linear-iv-model"><span class="header-section-number">11.2.2</span> Partially linear IV model</h3>
<p>When using observational data, it is rarely the case that conditional unconfoundedness of the treatment is satisfied. In such a case, you may want to consider a DML-IV approach implemented by <code>DoubleMLPLIV()</code>. Just like IV for linear models, finding the right instrument is critical for the DML-IV approach to be consistent.</p>
<p><span id="eq-plr"><span class="math display">\[
\begin{aligned}
y = \theta d + g_0(X) + \mu \\
Z = m_0(X) + \varepsilon \\
d = r_0(X) + \eta
\end{aligned}
\tag{11.7}\]</span></span></p>
<p>When <span class="math inline">\(\varspsilon\)</span> and <span class="math inline">\(\mu\)</span> are correlated, <code>DoubleMLPLR()</code> is inconsistent. However, as long as the following assumptions are satisfied, <code>DoubleMLPLIV()</code> is consistent.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Assumptions on the error terms</strong></p>
<ul>
<li><span class="math inline">\(E[\mu|Z,X] = 0\)</span></li>
<li><span class="math inline">\(E[\varepsilon|X] = 0\)</span></li>
<li><span class="math inline">\(E[\varepsilon\cdot \mu|Z, X] = 0\)</span></li>
</ul>
</div>
</div>
<p>Here is the causal diagram for the partially linear model of interest. As you can see, the treatment variable <span class="math inline">\(T\)</span> is confounded as <span class="math inline">\(\mu\)</span> affects both <span class="math inline">\(Y\)</span> and <span class="math inline">\(T\)</span> (through <span class="math inline">\(\eta\)</span>).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>DiagrammeR<span class="sc">::</span><span class="fu">grViz</span>(</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="st">  digraph {</span></span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="st">    graph [ranksep = 0.6]</span></span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a><span class="st">      Y [label = 'Y']</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a><span class="st">      X [label = 'X']</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a><span class="st">      T [label = 'T']</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a><span class="st">      Z [label = 'Z']</span></span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a><span class="st">      varep [label = '\U03B5']</span></span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a><span class="st">      mu [label = '\U03BC']</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a><span class="st">      eta [label = '\U03B7']</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a><span class="st">    edge [minlen = 2]</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;Y</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a><span class="st">      T-&gt;Y</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a><span class="st">      Z-&gt;T</span></span>
<span id="cb48-18"><a href="#cb48-18" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;T</span></span>
<span id="cb48-19"><a href="#cb48-19" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;Z</span></span>
<span id="cb48-20"><a href="#cb48-20" aria-hidden="true" tabindex="-1"></a><span class="st">      varep-&gt;Z</span></span>
<span id="cb48-21"><a href="#cb48-21" aria-hidden="true" tabindex="-1"></a><span class="st">      mu-&gt;{Y, eta}</span></span>
<span id="cb48-22"><a href="#cb48-22" aria-hidden="true" tabindex="-1"></a><span class="st">      eta-&gt;{T, mu}</span></span>
<span id="cb48-23"><a href="#cb48-23" aria-hidden="true" tabindex="-1"></a><span class="st">    { rank = same; Y; Z; varep}</span></span>
<span id="cb48-24"><a href="#cb48-24" aria-hidden="true" tabindex="-1"></a><span class="st">    { rank = same; X; T; mu}</span></span>
<span id="cb48-25"><a href="#cb48-25" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb48-26"><a href="#cb48-26" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb48-27"><a href="#cb48-27" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb48-28"><a href="#cb48-28" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="htmlwidget-1c291c2394a95241a846" style="width:100%;height:464px;" class="grViz html-widget"></div>
<script type="application/json" data-for="htmlwidget-1c291c2394a95241a846">{"x":{"diagram":"\n  digraph {\n    graph [ranksep = 0.6]\n    node [shape = box]\n      Y [label = \"Y\"]\n      X [label = \"X\"]\n      T [label = \"T\"]\n      Z [label = \"Z\"]\n      varep [label = \"ε\"]\n      mu [label = \"μ\"]\n      eta [label = \"η\"]\n    edge [minlen = 2]\n      X->Y\n      T->Y\n      Z->T\n      X->T\n      X->Z\n      varep->Z\n      mu->{Y, eta}\n      eta->{T, mu}\n    { rank = same; Y; Z; varep}\n    { rank = same; X; T; mu}\n  }\n  ","config":{"engine":"dot","options":null}},"evals":[],"jsHooks":[]}</script>
</div>
</div>
<p>Just like <code>DoublMLPLR()</code>, there are two ways to estimate <span class="math inline">\(\theta\)</span> using <code>DoublMLPLIV()</code>. The two score functions are:</p>
<ul>
<li><code>partialling-out</code>: <span class="math inline">\([Y - l(X) - \theta(D-r(X))][Z-m(X)]\)</span></li>
<li><code>IV-type</code>: <span class="math inline">\([Y - \theta D - g(X)][Z-m(X)]\)</span></li>
</ul>
<p>, where <span class="math inline">\(r(X) = E[D|X]\)</span>. So, <span class="math inline">\(r(X)\)</span> is the same as <span class="math inline">\(m(X)\)</span> in the partially line model case. <span class="math inline">\(m(X)\)</span> represents <span class="math inline">\(E[Z|X]\)</span> in the IV model.</p>
<p>Let <span class="math inline">\(\tilde{Z}\)</span>, <span class="math inline">\(\tilde{D}\)</span>, <span class="math inline">\(\tilde{Y}_l\)</span>, and <span class="math inline">\(\tilde{Y}_g\)</span> denote <span class="math inline">\(Z-m(X)\)</span>, <span class="math inline">\(D-r(X)\)</span>, <span class="math inline">\(Y-l(X)\)</span>, and <span class="math inline">\(Y-g(X)\)</span>, respectively.</p>
<ul>
<li><p><code>partialling-out</code>: <span class="math inline">\(\theta = (\tilde{Z}'\tilde{D})^{-1}\tilde{Z}\tilde{Y}_l\)</span></p></li>
<li><p><code>IV-type</code>: <span class="math inline">\(\theta = (\tilde{Z}'D)^{-1}\tilde{Z}\tilde{Y}_g\)</span></p></li>
</ul>
</section>
</section>
<section id="suggested-exercises" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="suggested-exercises"><span class="header-section-number">11.3</span> Suggested Exercises</h2>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-DoubleML2021R" class="csl-entry" role="doc-biblioentry">
Bach, P., V. Chernozhukov, M. S. Kurz, and M. Spindler. 2021. <span>“<span>DoubleML</span> – <span>A</span>n Object-Oriented Implementation of Double Machine Learning in <span>R</span>.”</span> <a href="https://arxiv.org/abs/2103.09603">https://arxiv.org/abs/2103.09603</a>.
</div>
<div id="ref-DoubleML2022Python" class="csl-entry" role="doc-biblioentry">
Bach, Philipp, Victor Chernozhukov, Malte S. Kurz, and Martin Spindler. 2022. <span>“<span>DoubleML</span> – <span>A</span>n Object-Oriented Implementation of Double Machine Learning in <span>P</span>ython.”</span> <em>Journal of Machine Learning Research</em> 23 (53): 1–6. <a href="http://jmlr.org/papers/v23/21-0862.html">http://jmlr.org/papers/v23/21-0862.html</a>.
</div>
<div id="ref-Chernozhukov2018" class="csl-entry" role="doc-biblioentry">
Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. <span>“<span class="nocase">Double/debiased machine learning for treatment and structural parameters</span>.”</span> <em>The Econometrics Journal</em> 21 (1): C1–68. <a href="https://doi.org/10.1111/ectj.12097">https://doi.org/10.1111/ectj.12097</a>.
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C00-why-not-this.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C02-xstr-learner.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb49" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Double Machine Learning {#sec-dml}</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>One of the most important ideas of the recent development of causal machine learning (CML) methods originate from @Chernozhukov2018, which proposed Double/Debiased ML methods. In this section, we go over those key ideas that are at the heart of many other important CML methods we will learn later. We then learn various models you can estimate using the R and Python <span class="in">`DoubleML`</span> package <span class="co">[</span><span class="ot">@DoubleML2021R; @DoubleML2022Python</span><span class="co">]</span>.</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## What you will learn</span></span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How double/debiased machine learning works </span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>avoiding regularlization bias through orthogonalization</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>avoiding over-fitting bias through cross-fitting</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Mechanics of DML</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>method of moment</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>score function</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>cross-fitting</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How to estimate ATE under conditional unconfoundedness using <span class="in">`DoubleMLPLR()`</span> and under confoundedness using <span class="in">`DoubleMLPLIV()`</span>.</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a><span class="fu">## Preferable background knowledge</span></span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>how to use <span class="in">`mlr3`</span> (see @sec-mlr3)</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>idea of method of moment</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>causal diagram </span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a><span class="fu">## DML: the basic idea</span></span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a><span class="fu">### Problem Setting</span></span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a>Throughout this section, we are interested in estimating the following econometric model</span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>, which is called a partially linear regression model (PLR).</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>:::{.column-margin}</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>We try to follow the notations of @Chernozhukov2018 as much as possible.</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a>y = \theta d + g_0(X) + \mu <span class="sc">\\</span></span>
<span id="cb49-44"><a href="#cb49-44" aria-hidden="true" tabindex="-1"></a>d = m_0(X) + \eta</span>
<span id="cb49-45"><a href="#cb49-45" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-46"><a href="#cb49-46" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb49-47"><a href="#cb49-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-48"><a href="#cb49-48" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-49"><a href="#cb49-49" aria-hidden="true" tabindex="-1"></a>Partially linear regression model is a class of models where some of the variables are linear in parameter (here, $\theta d$) and the rest of the variables are modeled non-parametrically (here, $g_0(X)$).</span>
<span id="cb49-50"><a href="#cb49-50" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-51"><a href="#cb49-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-52"><a href="#cb49-52" aria-hidden="true" tabindex="-1"></a>Your sole interest is in estimating $\theta$: the impact of the treatment ($d$). $g_0(X)$ is the impact of a collection of variables $X$. $m_0(X)$ expresses how $X$ affects the treatment status, $d$. $d$ may be binary or continuous. $</span>
<span id="cb49-53"><a href="#cb49-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-54"><a href="#cb49-54" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb49-55"><a href="#cb49-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-56"><a href="#cb49-56" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assumptions on the error terms</span></span>
<span id="cb49-57"><a href="#cb49-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-58"><a href="#cb49-58" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\mu|D,X</span><span class="co">]</span> = 0$</span>
<span id="cb49-59"><a href="#cb49-59" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta|X</span><span class="co">]</span> = 0$</span>
<span id="cb49-60"><a href="#cb49-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-61"><a href="#cb49-61" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-62"><a href="#cb49-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-63"><a href="#cb49-63" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb49-64"><a href="#cb49-64" aria-hidden="true" tabindex="-1"></a>The treatment effect is assumed to be constant irrespective of the value of $X$. So, the treatment effect is not heterogeneous. We will cover heterogeneous treatment effect estimation later.</span>
<span id="cb49-65"><a href="#cb49-65" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-66"><a href="#cb49-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-67"><a href="#cb49-67" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb49-68"><a href="#cb49-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-69"><a href="#cb49-69" aria-hidden="true" tabindex="-1"></a><span class="fu">## Terminology alert</span></span>
<span id="cb49-70"><a href="#cb49-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-71"><a href="#cb49-71" aria-hidden="true" tabindex="-1"></a>$g_0(X)$ and $m_0(X)$ are called <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> nuisance functions <span class="kw">&lt;/span&gt;</span>because knowing them is not the ultimate goal. We are only interested in **controlling for** them to estimate $\theta$ accurately. </span>
<span id="cb49-72"><a href="#cb49-72" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-73"><a href="#cb49-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-74"><a href="#cb49-74" aria-hidden="true" tabindex="-1"></a><span class="fu">### An intuitive, yet naive approach {#sec-dml-naive}</span></span>
<span id="cb49-75"><a href="#cb49-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-76"><a href="#cb49-76" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-77"><a href="#cb49-77" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb49-78"><a href="#cb49-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-81"><a href="#cb49-81" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-82"><a href="#cb49-82" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb49-83"><a href="#cb49-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-84"><a href="#cb49-84" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb49-85"><a href="#cb49-85" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb49-86"><a href="#cb49-86" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb49-87"><a href="#cb49-87" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb49-88"><a href="#cb49-88" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb49-89"><a href="#cb49-89" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb49-90"><a href="#cb49-90" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb49-91"><a href="#cb49-91" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb49-92"><a href="#cb49-92" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggbrace)</span>
<span id="cb49-93"><a href="#cb49-93" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb49-94"><a href="#cb49-94" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb49-95"><a href="#cb49-95" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb49-96"><a href="#cb49-96" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-97"><a href="#cb49-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-100"><a href="#cb49-100" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-101"><a href="#cb49-101" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-102"><a href="#cb49-102" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb49-103"><a href="#cb49-103" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb49-104"><a href="#cb49-104" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb49-105"><a href="#cb49-105" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb49-106"><a href="#cb49-106" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb49-107"><a href="#cb49-107" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3)</span>
<span id="cb49-108"><a href="#cb49-108" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb49-109"><a href="#cb49-109" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mlr3learners)</span>
<span id="cb49-110"><a href="#cb49-110" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggbrace)</span>
<span id="cb49-111"><a href="#cb49-111" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb49-112"><a href="#cb49-112" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb49-113"><a href="#cb49-113" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb49-114"><a href="#cb49-114" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-115"><a href="#cb49-115" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-116"><a href="#cb49-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-117"><a href="#cb49-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-118"><a href="#cb49-118" aria-hidden="true" tabindex="-1"></a>Consider the estimating equation of interest below.</span>
<span id="cb49-119"><a href="#cb49-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-120"><a href="#cb49-120" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-121"><a href="#cb49-121" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-122"><a href="#cb49-122" aria-hidden="true" tabindex="-1"></a>y = \theta d + g_0(X) + \mu</span>
<span id="cb49-123"><a href="#cb49-123" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-124"><a href="#cb49-124" aria-hidden="true" tabindex="-1"></a>$$ {#eq-model-naive}</span>
<span id="cb49-125"><a href="#cb49-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-126"><a href="#cb49-126" aria-hidden="true" tabindex="-1"></a>Subtracting $g_0(x)$ from both sides,</span>
<span id="cb49-127"><a href="#cb49-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-128"><a href="#cb49-128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-129"><a href="#cb49-129" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-130"><a href="#cb49-130" aria-hidden="true" tabindex="-1"></a>y - g_0(x) = \theta d + \mu</span>
<span id="cb49-131"><a href="#cb49-131" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-132"><a href="#cb49-132" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-133"><a href="#cb49-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-134"><a href="#cb49-134" aria-hidden="true" tabindex="-1"></a>So, if we know $g_0(X)$, then we can simply regress $y - g_0(x)$ on $d$. Of course, we do not know $g_0(X)$, so we need to estimate $g_0(x)$. Let $\hat{g}_0(x)$ denote $g_0(x)$ estimated by any appropriate machine learning method. Then, we can regress $y - \hat{g}_0(x)$ on $d$ to estimate $\theta$ using OLS. Mathematically, it can be written as follows:</span>
<span id="cb49-135"><a href="#cb49-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-136"><a href="#cb49-136" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-137"><a href="#cb49-137" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-138"><a href="#cb49-138" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{g}_0(X_i))</span>
<span id="cb49-139"><a href="#cb49-139" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-140"><a href="#cb49-140" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-141"><a href="#cb49-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-142"><a href="#cb49-142" aria-hidden="true" tabindex="-1"></a>Now, subtracting $\hat{g}_0(x)$ from both sides of @eq-model-naive,</span>
<span id="cb49-143"><a href="#cb49-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-144"><a href="#cb49-144" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-145"><a href="#cb49-145" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-146"><a href="#cb49-146" aria-hidden="true" tabindex="-1"></a>y - \hat{g}_0(x) = \theta d + (g_0(x) - \hat{g}_0(x) + \mu)</span>
<span id="cb49-147"><a href="#cb49-147" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-148"><a href="#cb49-148" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-149"><a href="#cb49-149" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-150"><a href="#cb49-150" aria-hidden="true" tabindex="-1"></a>So, as long as $d$ is not correlated with $g_0(x) - \hat{g}_0(x) + \mu$, then the regression of $y - \hat{g}_0(x)$ on $d$ should work. Unfortunately, this approach turns out to be naive and suffer from bias in general <span class="co">[</span><span class="ot">@Chernozhukov2018</span><span class="co">]</span>.</span>
<span id="cb49-151"><a href="#cb49-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-152"><a href="#cb49-152" aria-hidden="true" tabindex="-1"></a>As a way to implement this naive approach, consider the following procedures.</span>
<span id="cb49-153"><a href="#cb49-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-154"><a href="#cb49-154" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 1: Estimate $g_0(X)$ and then subtract the fitted value of $g_0(X)$ from $y$.</span>
<span id="cb49-155"><a href="#cb49-155" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Step 1.1: Regress $y$ on $X$ to estimate $E<span class="co">[</span><span class="ot">y|X</span><span class="co">]</span>$ and call it $\hat{l}_0(x)$ </span>
<span id="cb49-156"><a href="#cb49-156" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Step 1.2: Regress $d$ on $X$ to estimate $E<span class="co">[</span><span class="ot">d|X</span><span class="co">]</span>$ ($m_0(X)$), call it $\hat{m}_0(x)$, and calculate $\tilde{d} = d - \hat{m}_0(X)$.</span>
<span id="cb49-157"><a href="#cb49-157" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Step 1.3: Get an initial estimate of $\theta$ using</span>
<span id="cb49-158"><a href="#cb49-158" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb49-159"><a href="#cb49-159" aria-hidden="true" tabindex="-1"></a>  \begin{aligned}</span>
<span id="cb49-160"><a href="#cb49-160" aria-hidden="true" tabindex="-1"></a>    \hat{\theta}_{init} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i \tilde{d}_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{l}_0(X_i))</span>
<span id="cb49-161"><a href="#cb49-161" aria-hidden="true" tabindex="-1"></a>  \end{aligned} </span>
<span id="cb49-162"><a href="#cb49-162" aria-hidden="true" tabindex="-1"></a>  $$ {#eq-partial-out}</span>
<span id="cb49-163"><a href="#cb49-163" aria-hidden="true" tabindex="-1"></a><span class="ss">  * </span>Step 1.4: Regress $y_i - \hat{\theta}_{init}d$ on $X$ to estimate $g_0(X)$ and call it $\hat{g}_0(X)$.</span>
<span id="cb49-164"><a href="#cb49-164" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 2: Regress $y - \hat{g}_0(X)$ on $d$ using OLS. Or equivalently, use the following formula </span>
<span id="cb49-165"><a href="#cb49-165" aria-hidden="true" tabindex="-1"></a>  $$</span>
<span id="cb49-166"><a href="#cb49-166" aria-hidden="true" tabindex="-1"></a>  \begin{aligned}</span>
<span id="cb49-167"><a href="#cb49-167" aria-hidden="true" tabindex="-1"></a>    \hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{g}_0(X_i))</span>
<span id="cb49-168"><a href="#cb49-168" aria-hidden="true" tabindex="-1"></a>  \end{aligned}</span>
<span id="cb49-169"><a href="#cb49-169" aria-hidden="true" tabindex="-1"></a>  $$ {#eq-theta-partial}</span>
<span id="cb49-170"><a href="#cb49-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-171"><a href="#cb49-171" aria-hidden="true" tabindex="-1"></a>To demonstrate the bias problem, we work on the following data generating process used in <span class="co">[</span><span class="ot">the user guide for the DoubleML package</span><span class="co">](https://docs.doubleml.org/stable/guide/basics.html)</span>.</span>
<span id="cb49-172"><a href="#cb49-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-173"><a href="#cb49-173" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-174"><a href="#cb49-174" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-175"><a href="#cb49-175" aria-hidden="true" tabindex="-1"></a>y_i = 0.5 d_i  + \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3} + \mu_i <span class="sc">\\</span></span>
<span id="cb49-176"><a href="#cb49-176" aria-hidden="true" tabindex="-1"></a>d_i = x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} \eta_i</span>
<span id="cb49-177"><a href="#cb49-177" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-178"><a href="#cb49-178" aria-hidden="true" tabindex="-1"></a>$$ {#eq-simple-synthetic}</span>
<span id="cb49-179"><a href="#cb49-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-180"><a href="#cb49-180" aria-hidden="true" tabindex="-1"></a>where $\mu_i \sim N(0, 1)$ and $\eta_i \sim N(0, 1)$. The error terms ($\mu_i$ and $\eta_i$) are independent. In this data generating process, $d$ is continuous (not binary) and its effect on $y$ is assumed to be linear. </span>
<span id="cb49-181"><a href="#cb49-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-182"><a href="#cb49-182" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`gen_data()`</span> function (defined on the right), which is a slightly generalized version of the <span class="in">`make_plr_CCDDHNR2018()`</span> function from the <span class="in">`DoubleML`</span> package.</span>
<span id="cb49-183"><a href="#cb49-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-184"><a href="#cb49-184" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-185"><a href="#cb49-185" aria-hidden="true" tabindex="-1"></a><span class="in">`gen_data()`</span> allows you to specify $g_0(X)$ and $m_0(X)$ unlike <span class="in">`make_plr_CCDDHNR2018()`</span>.</span>
<span id="cb49-186"><a href="#cb49-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-189"><a href="#cb49-189" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-190"><a href="#cb49-190" aria-hidden="true" tabindex="-1"></a>gen_data <span class="ot">&lt;-</span> <span class="cf">function</span>(</span>
<span id="cb49-191"><a href="#cb49-191" aria-hidden="true" tabindex="-1"></a>  <span class="at">g_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(x1))) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">/</span><span class="dv">4</span>)), <span class="co"># formula that defines m(x)</span></span>
<span id="cb49-192"><a href="#cb49-192" aria-hidden="true" tabindex="-1"></a>  <span class="at">m_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> x1 <span class="sc">+</span> <span class="fu">I</span>(<span class="fu">exp</span>(x3)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(x3))<span class="sc">/</span><span class="dv">4</span>)), <span class="co"># formula that defines g(x)</span></span>
<span id="cb49-193"><a href="#cb49-193" aria-hidden="true" tabindex="-1"></a>  <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fl">0.5</span><span class="sc">*</span>d)), <span class="co"># formula that defines theta(x) * t</span></span>
<span id="cb49-194"><a href="#cb49-194" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_obs =</span> <span class="dv">500</span>, </span>
<span id="cb49-195"><a href="#cb49-195" aria-hidden="true" tabindex="-1"></a>  <span class="at">n_vars =</span> <span class="dv">20</span>, </span>
<span id="cb49-196"><a href="#cb49-196" aria-hidden="true" tabindex="-1"></a>  <span class="at">mu_x =</span> <span class="dv">0</span>, </span>
<span id="cb49-197"><a href="#cb49-197" aria-hidden="true" tabindex="-1"></a>  <span class="at">vcov_x =</span> <span class="cn">NULL</span>,</span>
<span id="cb49-198"><a href="#cb49-198" aria-hidden="true" tabindex="-1"></a>  <span class="at">sigma =</span> <span class="dv">1</span> <span class="co"># sd of the error term in the y equation</span></span>
<span id="cb49-199"><a href="#cb49-199" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-200"><a href="#cb49-200" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb49-201"><a href="#cb49-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-202"><a href="#cb49-202" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (<span class="fu">is.null</span>(vcov_x)) {</span>
<span id="cb49-203"><a href="#cb49-203" aria-hidden="true" tabindex="-1"></a>    vcov_x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rep</span>(<span class="dv">0</span>, n_vars<span class="sc">^</span><span class="dv">2</span>), <span class="at">nrow =</span> n_vars)</span>
<span id="cb49-204"><a href="#cb49-204" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="fu">seq_len</span>(n_vars)) {</span>
<span id="cb49-205"><a href="#cb49-205" aria-hidden="true" tabindex="-1"></a>      vcov_x[i, ] <span class="ot">&lt;-</span> <span class="fl">0.7</span><span class="sc">^</span><span class="fu">abs</span>(i <span class="sc">-</span> <span class="fu">seq_len</span>(n_vars)) </span>
<span id="cb49-206"><a href="#cb49-206" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb49-207"><a href="#cb49-207" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-208"><a href="#cb49-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-209"><a href="#cb49-209" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== draw from multivariate normal ===#</span></span>
<span id="cb49-210"><a href="#cb49-210" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span> </span>
<span id="cb49-211"><a href="#cb49-211" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mvrnorm</span>(n_obs, <span class="at">mu =</span> <span class="fu">rep</span>(<span class="dv">0</span>, n_vars), <span class="at">Sigma =</span> vcov_x) <span class="sc">%&gt;%</span> </span>
<span id="cb49-212"><a href="#cb49-212" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-213"><a href="#cb49-213" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">paste0</span>(<span class="st">"x"</span>, <span class="dv">1</span><span class="sc">:</span>n_vars))  </span>
<span id="cb49-214"><a href="#cb49-214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-215"><a href="#cb49-215" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate d ===#</span></span>
<span id="cb49-216"><a href="#cb49-216" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (m_formula <span class="sc">==</span> <span class="st">"independent"</span>) {</span>
<span id="cb49-217"><a href="#cb49-217" aria-hidden="true" tabindex="-1"></a>    data[, d <span class="sc">:</span><span class="er">=</span> <span class="fu">rnorm</span>(n_obs)]</span>
<span id="cb49-218"><a href="#cb49-218" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> {</span>
<span id="cb49-219"><a href="#cb49-219" aria-hidden="true" tabindex="-1"></a>    data[, d <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(m_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>() <span class="sc">+</span> <span class="fu">rnorm</span>(n_obs)]</span>
<span id="cb49-220"><a href="#cb49-220" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb49-221"><a href="#cb49-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-222"><a href="#cb49-222" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate y ===#</span></span>
<span id="cb49-223"><a href="#cb49-223" aria-hidden="true" tabindex="-1"></a>  data[, g <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(g_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>()]</span>
<span id="cb49-224"><a href="#cb49-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-225"><a href="#cb49-225" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate treatment effect ===#</span></span>
<span id="cb49-226"><a href="#cb49-226" aria-hidden="true" tabindex="-1"></a>  data[, te <span class="sc">:</span><span class="er">=</span> <span class="fu">model.frame</span>(te_formula, <span class="at">data =</span> data) <span class="sc">%&gt;%</span> <span class="fu">rowSums</span>()]</span>
<span id="cb49-227"><a href="#cb49-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-228"><a href="#cb49-228" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== generate y ===#</span></span>
<span id="cb49-229"><a href="#cb49-229" aria-hidden="true" tabindex="-1"></a>  data[, y <span class="sc">:</span><span class="er">=</span> te <span class="sc">+</span> g <span class="sc">+</span> <span class="fu">rnorm</span>(n_obs, <span class="at">sd =</span> sigma)]</span>
<span id="cb49-230"><a href="#cb49-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-231"><a href="#cb49-231" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data[])</span>
<span id="cb49-232"><a href="#cb49-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-233"><a href="#cb49-233" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-234"><a href="#cb49-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-235"><a href="#cb49-235" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-236"><a href="#cb49-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-237"><a href="#cb49-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-240"><a href="#cb49-240" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-241"><a href="#cb49-241" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">782394</span>)</span>
<span id="cb49-242"><a href="#cb49-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-243"><a href="#cb49-243" aria-hidden="true" tabindex="-1"></a>training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb49-244"><a href="#cb49-244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-245"><a href="#cb49-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-248"><a href="#cb49-248" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-249"><a href="#cb49-249" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb49-250"><a href="#cb49-250" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb49-251"><a href="#cb49-251" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">19343</span>)</span>
<span id="cb49-252"><a href="#cb49-252" aria-hidden="true" tabindex="-1"></a>n_rep <span class="ot">=</span> <span class="dv">1000</span></span>
<span id="cb49-253"><a href="#cb49-253" aria-hidden="true" tabindex="-1"></a>n_obs <span class="ot">=</span> <span class="dv">500</span></span>
<span id="cb49-254"><a href="#cb49-254" aria-hidden="true" tabindex="-1"></a>n_vars <span class="ot">=</span> <span class="dv">20</span></span>
<span id="cb49-255"><a href="#cb49-255" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">=</span> <span class="fl">0.5</span></span>
<span id="cb49-256"><a href="#cb49-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-257"><a href="#cb49-257" aria-hidden="true" tabindex="-1"></a>data <span class="ot">=</span> <span class="fu">list</span>()</span>
<span id="cb49-258"><a href="#cb49-258" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i_rep <span class="cf">in</span> <span class="fu">seq_len</span>(n_rep)) {</span>
<span id="cb49-259"><a href="#cb49-259" aria-hidden="true" tabindex="-1"></a>    data[[i_rep]] <span class="ot">=</span> <span class="fu">make_plr_CCDDHNR2018</span>(<span class="at">alpha=</span>alpha, <span class="at">n_obs=</span>n_obs, <span class="at">dim_x=</span>n_vars,</span>
<span id="cb49-260"><a href="#cb49-260" aria-hidden="true" tabindex="-1"></a>                                          <span class="at">return_type=</span><span class="st">"data.frame"</span>)</span>
<span id="cb49-261"><a href="#cb49-261" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-262"><a href="#cb49-262" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-263"><a href="#cb49-263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-264"><a href="#cb49-264" aria-hidden="true" tabindex="-1"></a>It has 20 <span class="in">`x`</span> variables (for $X$) along with <span class="in">`d`</span> (treatment) and <span class="in">`y`</span> (dependent variable). Only <span class="in">`x1`</span> and <span class="in">`x3`</span> are the relevant variables. The rest of $X$ do not play any role in explaining either $Y$ or $d$. However, they are correlated with <span class="in">`x1`</span> and <span class="in">`x3`</span> and interfere with estimating the nuisance functions.</span>
<span id="cb49-265"><a href="#cb49-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-268"><a href="#cb49-268" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-269"><a href="#cb49-269" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(training_data)</span>
<span id="cb49-270"><a href="#cb49-270" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-271"><a href="#cb49-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-272"><a href="#cb49-272" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Step 1</span></span>
<span id="cb49-273"><a href="#cb49-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-274"><a href="#cb49-274" aria-hidden="true" tabindex="-1"></a>Let's now work on Step 1. We estimate $g_0(X)$ using random forest (RF). As described above, this is a four-step process.</span>
<span id="cb49-275"><a href="#cb49-275" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-276"><a href="#cb49-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-277"><a href="#cb49-277" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-278"><a href="#cb49-278" aria-hidden="true" tabindex="-1"></a>It does not have to be RF. Indeed, you can use any statistical methods in this step.</span>
<span id="cb49-279"><a href="#cb49-279" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-280"><a href="#cb49-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-281"><a href="#cb49-281" aria-hidden="true" tabindex="-1"></a>**Step 1.1**: Estimate $l_0(X)$ by regressing $y$ on $X$.</span>
<span id="cb49-282"><a href="#cb49-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-285"><a href="#cb49-285" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-286"><a href="#cb49-286" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-287"><a href="#cb49-287" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.1</span></span>
<span id="cb49-288"><a href="#cb49-288" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-289"><a href="#cb49-289" aria-hidden="true" tabindex="-1"></a>rf_fitted_l0 <span class="ot">&lt;-</span></span>
<span id="cb49-290"><a href="#cb49-290" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb49-291"><a href="#cb49-291" aria-hidden="true" tabindex="-1"></a>    y <span class="sc">~</span> .,</span>
<span id="cb49-292"><a href="#cb49-292" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-293"><a href="#cb49-293" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb49-294"><a href="#cb49-294" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">132</span>,</span>
<span id="cb49-295"><a href="#cb49-295" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb49-296"><a href="#cb49-296" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">1</span></span>
<span id="cb49-297"><a href="#cb49-297" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-298"><a href="#cb49-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-299"><a href="#cb49-299" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb49-300"><a href="#cb49-300" aria-hidden="true" tabindex="-1"></a>l0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_l0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-301"><a href="#cb49-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-302"><a href="#cb49-302" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - l0_hat ===#</span></span>
<span id="cb49-303"><a href="#cb49-303" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_l <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> l0_hat]</span>
<span id="cb49-304"><a href="#cb49-304" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-305"><a href="#cb49-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-306"><a href="#cb49-306" aria-hidden="true" tabindex="-1"></a>**Step 1.2**: Estimate $m_0(X)$ by regressing $d$ on $X$.</span>
<span id="cb49-307"><a href="#cb49-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-310"><a href="#cb49-310" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-311"><a href="#cb49-311" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-312"><a href="#cb49-312" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.2</span></span>
<span id="cb49-313"><a href="#cb49-313" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-314"><a href="#cb49-314" aria-hidden="true" tabindex="-1"></a>rf_fitted_m0 <span class="ot">&lt;-</span></span>
<span id="cb49-315"><a href="#cb49-315" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb49-316"><a href="#cb49-316" aria-hidden="true" tabindex="-1"></a>    d <span class="sc">~</span> .,</span>
<span id="cb49-317"><a href="#cb49-317" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"d"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-318"><a href="#cb49-318" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb49-319"><a href="#cb49-319" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">378</span>,</span>
<span id="cb49-320"><a href="#cb49-320" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">3</span>,</span>
<span id="cb49-321"><a href="#cb49-321" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">6</span></span>
<span id="cb49-322"><a href="#cb49-322" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-323"><a href="#cb49-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-324"><a href="#cb49-324" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb49-325"><a href="#cb49-325" aria-hidden="true" tabindex="-1"></a>m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-326"><a href="#cb49-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-327"><a href="#cb49-327" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - m0_hat ===#</span></span>
<span id="cb49-328"><a href="#cb49-328" aria-hidden="true" tabindex="-1"></a>training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span>
<span id="cb49-329"><a href="#cb49-329" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-330"><a href="#cb49-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-331"><a href="#cb49-331" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-332"><a href="#cb49-332" aria-hidden="true" tabindex="-1"></a>Figure of <span class="in">`d`</span> (treatment variable) plotted against <span class="in">`m0_hat`</span> ($\hat{m}_0(X)$).</span>
<span id="cb49-333"><a href="#cb49-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-336"><a href="#cb49-336" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-337"><a href="#cb49-337" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-338"><a href="#cb49-338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-339"><a href="#cb49-339" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(training_data) <span class="sc">+</span></span>
<span id="cb49-340"><a href="#cb49-340" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> d, <span class="at">x =</span> m0_hat)) <span class="sc">+</span></span>
<span id="cb49-341"><a href="#cb49-341" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-342"><a href="#cb49-342" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb49-343"><a href="#cb49-343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-344"><a href="#cb49-344" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-345"><a href="#cb49-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-346"><a href="#cb49-346" aria-hidden="true" tabindex="-1"></a>**Step 1.3**: Get an initial estimate of $\theta$ using @eq-partial-out.</span>
<span id="cb49-347"><a href="#cb49-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-350"><a href="#cb49-350" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-351"><a href="#cb49-351" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-352"><a href="#cb49-352" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.2</span></span>
<span id="cb49-353"><a href="#cb49-353" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-354"><a href="#cb49-354" aria-hidden="true" tabindex="-1"></a>theta_init <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_l) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d_less_m) ]</span>
<span id="cb49-355"><a href="#cb49-355" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-356"><a href="#cb49-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-357"><a href="#cb49-357" aria-hidden="true" tabindex="-1"></a>**Step 1.4**: Regress $y - \theta_{init}d$ on $X$ to fit $g_0(X)$.</span>
<span id="cb49-358"><a href="#cb49-358" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-361"><a href="#cb49-361" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-362"><a href="#cb49-362" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-363"><a href="#cb49-363" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1.3</span></span>
<span id="cb49-364"><a href="#cb49-364" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-365"><a href="#cb49-365" aria-hidden="true" tabindex="-1"></a><span class="co">#=== define y - treatment effect ===#</span></span>
<span id="cb49-366"><a href="#cb49-366" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_te <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> theta_init <span class="sc">*</span> d]</span>
<span id="cb49-367"><a href="#cb49-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-368"><a href="#cb49-368" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit rf ===#</span></span>
<span id="cb49-369"><a href="#cb49-369" aria-hidden="true" tabindex="-1"></a>rf_fitted_g0 <span class="ot">&lt;-</span></span>
<span id="cb49-370"><a href="#cb49-370" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb49-371"><a href="#cb49-371" aria-hidden="true" tabindex="-1"></a>    y_less_te <span class="sc">~</span> .,</span>
<span id="cb49-372"><a href="#cb49-372" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y_less_te"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-373"><a href="#cb49-373" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">5</span>,</span>
<span id="cb49-374"><a href="#cb49-374" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">132</span>,</span>
<span id="cb49-375"><a href="#cb49-375" aria-hidden="true" tabindex="-1"></a>    <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb49-376"><a href="#cb49-376" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">1</span></span>
<span id="cb49-377"><a href="#cb49-377" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-378"><a href="#cb49-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-379"><a href="#cb49-379" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fitted values ===#</span></span>
<span id="cb49-380"><a href="#cb49-380" aria-hidden="true" tabindex="-1"></a>g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-381"><a href="#cb49-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-382"><a href="#cb49-382" aria-hidden="true" tabindex="-1"></a><span class="co">#=== create y - g0 ===#</span></span>
<span id="cb49-383"><a href="#cb49-383" aria-hidden="true" tabindex="-1"></a>training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span>
<span id="cb49-384"><a href="#cb49-384" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-385"><a href="#cb49-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-386"><a href="#cb49-386" aria-hidden="true" tabindex="-1"></a>@fig-g0-ghat plots true $g_0(X)$ (<span class="in">`g`</span>) against $\hat{g}_0(X)$ (`g0_hat`). As you can see, $\hat{g}_0(X)$ is a bit biased.</span>
<span id="cb49-387"><a href="#cb49-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-390"><a href="#cb49-390" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-391"><a href="#cb49-391" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: ""</span></span>
<span id="cb49-392"><a href="#cb49-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-g0-ghat</span></span>
<span id="cb49-393"><a href="#cb49-393" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-394"><a href="#cb49-394" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(training_data) <span class="sc">+</span></span>
<span id="cb49-395"><a href="#cb49-395" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> g, <span class="at">x =</span> g0_hat)) <span class="sc">+</span></span>
<span id="cb49-396"><a href="#cb49-396" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb49-397"><a href="#cb49-397" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb49-398"><a href="#cb49-398" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_equal</span>()</span>
<span id="cb49-399"><a href="#cb49-399" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-400"><a href="#cb49-400" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-401"><a href="#cb49-401" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Step 2</span></span>
<span id="cb49-402"><a href="#cb49-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-403"><a href="#cb49-403" aria-hidden="true" tabindex="-1"></a>Finally, we regress $y - \hat{g}_0(X)$ on $d$ (or equivalently using @eq-theta-partial).</span>
<span id="cb49-404"><a href="#cb49-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-407"><a href="#cb49-407" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-408"><a href="#cb49-408" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-409"><a href="#cb49-409" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_less_g <span class="sc">~</span> d, <span class="at">data =</span> training_data)<span class="sc">$</span>coefficient[<span class="st">"d"</span>]</span>
<span id="cb49-410"><a href="#cb49-410" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-411"><a href="#cb49-411" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-412"><a href="#cb49-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-413"><a href="#cb49-413" aria-hidden="true" tabindex="-1"></a>So, in this instance, we get an estimate of $\theta$ that is a bit lower than the true value of $\theta$. Let's repeat this process many times to see how this procedure performs on average. </span>
<span id="cb49-414"><a href="#cb49-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-417"><a href="#cb49-417" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-418"><a href="#cb49-418" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true </span></span>
<span id="cb49-419"><a href="#cb49-419" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Simulation results of the naive procedure</span></span>
<span id="cb49-420"><a href="#cb49-420" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-naive</span></span>
<span id="cb49-421"><a href="#cb49-421" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-422"><a href="#cb49-422" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true </span></span>
<span id="cb49-423"><a href="#cb49-423" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-424"><a href="#cb49-424" aria-hidden="true" tabindex="-1"></a>fit_m0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, <span class="at">mtry =</span> <span class="dv">10</span>) {</span>
<span id="cb49-425"><a href="#cb49-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-426"><a href="#cb49-426" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span></span>
<span id="cb49-427"><a href="#cb49-427" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb49-428"><a href="#cb49-428" aria-hidden="true" tabindex="-1"></a>      d <span class="sc">~</span> .,</span>
<span id="cb49-429"><a href="#cb49-429" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"d"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-430"><a href="#cb49-430" aria-hidden="true" tabindex="-1"></a>      <span class="co"># mtry = 5,</span></span>
<span id="cb49-431"><a href="#cb49-431" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry,</span>
<span id="cb49-432"><a href="#cb49-432" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 378,</span></span>
<span id="cb49-433"><a href="#cb49-433" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb49-434"><a href="#cb49-434" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">3</span>,</span>
<span id="cb49-435"><a href="#cb49-435" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 6</span></span>
<span id="cb49-436"><a href="#cb49-436" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb49-437"><a href="#cb49-437" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-438"><a href="#cb49-438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-439"><a href="#cb49-439" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_m0)</span>
<span id="cb49-440"><a href="#cb49-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-441"><a href="#cb49-441" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-442"><a href="#cb49-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-443"><a href="#cb49-443" aria-hidden="true" tabindex="-1"></a>fit_l0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, <span class="at">mtry =</span> <span class="dv">12</span>)</span>
<span id="cb49-444"><a href="#cb49-444" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb49-445"><a href="#cb49-445" aria-hidden="true" tabindex="-1"></a>  rf_fitted_l0 <span class="ot">&lt;-</span></span>
<span id="cb49-446"><a href="#cb49-446" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb49-447"><a href="#cb49-447" aria-hidden="true" tabindex="-1"></a>      y <span class="sc">~</span> .,</span>
<span id="cb49-448"><a href="#cb49-448" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-449"><a href="#cb49-449" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry,</span>
<span id="cb49-450"><a href="#cb49-450" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 132,</span></span>
<span id="cb49-451"><a href="#cb49-451" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb49-452"><a href="#cb49-452" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb49-453"><a href="#cb49-453" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 1</span></span>
<span id="cb49-454"><a href="#cb49-454" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb49-455"><a href="#cb49-455" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-456"><a href="#cb49-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-457"><a href="#cb49-457" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_l0)</span>
<span id="cb49-458"><a href="#cb49-458" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-459"><a href="#cb49-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-460"><a href="#cb49-460" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-461"><a href="#cb49-461" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function that will get you g0_hat</span></span>
<span id="cb49-462"><a href="#cb49-462" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-463"><a href="#cb49-463" aria-hidden="true" tabindex="-1"></a><span class="co"># this function will be used later</span></span>
<span id="cb49-464"><a href="#cb49-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-465"><a href="#cb49-465" aria-hidden="true" tabindex="-1"></a>fit_g0 <span class="ot">&lt;-</span> <span class="cf">function</span>(training_data, rf_fitted_m0, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>) {</span>
<span id="cb49-466"><a href="#cb49-466" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-467"><a href="#cb49-467" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.1</span></span>
<span id="cb49-468"><a href="#cb49-468" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-469"><a href="#cb49-469" aria-hidden="true" tabindex="-1"></a>  rf_fitted_l0 <span class="ot">&lt;-</span> <span class="fu">fit_l0</span>(training_data, mtry_l)</span>
<span id="cb49-470"><a href="#cb49-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-471"><a href="#cb49-471" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fitted values ===#</span></span>
<span id="cb49-472"><a href="#cb49-472" aria-hidden="true" tabindex="-1"></a>  l0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_l0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-473"><a href="#cb49-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-474"><a href="#cb49-474" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - l0_hat ===#</span></span>
<span id="cb49-475"><a href="#cb49-475" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_l <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> l0_hat]</span>
<span id="cb49-476"><a href="#cb49-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-477"><a href="#cb49-477" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-478"><a href="#cb49-478" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.2</span></span>
<span id="cb49-479"><a href="#cb49-479" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-480"><a href="#cb49-480" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fitted values ===#</span></span>
<span id="cb49-481"><a href="#cb49-481" aria-hidden="true" tabindex="-1"></a>  m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-482"><a href="#cb49-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-483"><a href="#cb49-483" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - m0_hat ===#</span></span>
<span id="cb49-484"><a href="#cb49-484" aria-hidden="true" tabindex="-1"></a>  training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span>
<span id="cb49-485"><a href="#cb49-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-486"><a href="#cb49-486" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-487"><a href="#cb49-487" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.2</span></span>
<span id="cb49-488"><a href="#cb49-488" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-489"><a href="#cb49-489" aria-hidden="true" tabindex="-1"></a>  theta_init <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_l) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d_less_m)]</span>
<span id="cb49-490"><a href="#cb49-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-491"><a href="#cb49-491" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-492"><a href="#cb49-492" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Step 1.3</span></span>
<span id="cb49-493"><a href="#cb49-493" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-494"><a href="#cb49-494" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== define y - treatment effect ===#</span></span>
<span id="cb49-495"><a href="#cb49-495" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_te <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> theta_init <span class="sc">*</span> d]</span>
<span id="cb49-496"><a href="#cb49-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-497"><a href="#cb49-497" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit rf ===#</span></span>
<span id="cb49-498"><a href="#cb49-498" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span></span>
<span id="cb49-499"><a href="#cb49-499" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb49-500"><a href="#cb49-500" aria-hidden="true" tabindex="-1"></a>      y_less_te <span class="sc">~</span> .,</span>
<span id="cb49-501"><a href="#cb49-501" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> dplyr<span class="sc">::</span><span class="fu">select</span>(training_data, <span class="fu">c</span>(<span class="st">"y_less_te"</span>, <span class="fu">starts_with</span>(<span class="st">"x"</span>))),</span>
<span id="cb49-502"><a href="#cb49-502" aria-hidden="true" tabindex="-1"></a>      <span class="at">mtry =</span> mtry_g,</span>
<span id="cb49-503"><a href="#cb49-503" aria-hidden="true" tabindex="-1"></a>      <span class="co"># num.trees = 132,</span></span>
<span id="cb49-504"><a href="#cb49-504" aria-hidden="true" tabindex="-1"></a>      <span class="at">num.trees =</span> <span class="dv">500</span>,</span>
<span id="cb49-505"><a href="#cb49-505" aria-hidden="true" tabindex="-1"></a>      <span class="at">max.depth =</span> <span class="dv">5</span>,</span>
<span id="cb49-506"><a href="#cb49-506" aria-hidden="true" tabindex="-1"></a>      <span class="co"># min.node.size = 1</span></span>
<span id="cb49-507"><a href="#cb49-507" aria-hidden="true" tabindex="-1"></a>      <span class="at">min.node.size =</span> <span class="dv">10</span></span>
<span id="cb49-508"><a href="#cb49-508" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb49-509"><a href="#cb49-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-510"><a href="#cb49-510" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(rf_fitted_g0)</span>
<span id="cb49-511"><a href="#cb49-511" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-512"><a href="#cb49-512" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-513"><a href="#cb49-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-514"><a href="#cb49-514" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-515"><a href="#cb49-515" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a function that runs a single simulation and gets you theta_hat</span></span>
<span id="cb49-516"><a href="#cb49-516" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-517"><a href="#cb49-517" aria-hidden="true" tabindex="-1"></a>run_sim_naive <span class="ot">&lt;-</span> <span class="cf">function</span>(i){</span>
<span id="cb49-518"><a href="#cb49-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-519"><a href="#cb49-519" aria-hidden="true" tabindex="-1"></a>  <span class="co"># training_data &lt;- data[[i]] %&gt;% data.table()</span></span>
<span id="cb49-520"><a href="#cb49-520" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb49-521"><a href="#cb49-521" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-522"><a href="#cb49-522" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(training_data)</span>
<span id="cb49-523"><a href="#cb49-523" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(training_data, rf_fitted_m0)</span>
<span id="cb49-524"><a href="#cb49-524" aria-hidden="true" tabindex="-1"></a>  g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-525"><a href="#cb49-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-526"><a href="#cb49-526" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - g0 ===#</span></span>
<span id="cb49-527"><a href="#cb49-527" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span>
<span id="cb49-528"><a href="#cb49-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-529"><a href="#cb49-529" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_less_g <span class="sc">~</span> d, <span class="at">data =</span> training_data)<span class="sc">$</span>coefficient[<span class="st">"d"</span>]</span>
<span id="cb49-530"><a href="#cb49-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-531"><a href="#cb49-531" aria-hidden="true" tabindex="-1"></a>  <span class="co"># theta_hat &lt;- training_data[, sum(d * y_less_g) / sum(d * d)]</span></span>
<span id="cb49-532"><a href="#cb49-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-533"><a href="#cb49-533" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb49-534"><a href="#cb49-534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-535"><a href="#cb49-535" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-536"><a href="#cb49-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-537"><a href="#cb49-537" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-538"><a href="#cb49-538" aria-hidden="true" tabindex="-1"></a><span class="co"># Repeat MC simulations 500 times</span></span>
<span id="cb49-539"><a href="#cb49-539" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-540"><a href="#cb49-540" aria-hidden="true" tabindex="-1"></a>theta_hats_apr1 <span class="ot">&lt;-</span></span>
<span id="cb49-541"><a href="#cb49-541" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb49-542"><a href="#cb49-542" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb49-543"><a href="#cb49-543" aria-hidden="true" tabindex="-1"></a>    run_sim_naive,</span>
<span id="cb49-544"><a href="#cb49-544" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">/</span> <span class="dv">4</span> <span class="sc">*</span> <span class="dv">3</span></span>
<span id="cb49-545"><a href="#cb49-545" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-546"><a href="#cb49-546" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-547"><a href="#cb49-547" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">theta =</span> .)</span>
<span id="cb49-548"><a href="#cb49-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-549"><a href="#cb49-549" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-550"><a href="#cb49-550" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb49-551"><a href="#cb49-551" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-552"><a href="#cb49-552" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_hats_apr1) <span class="sc">+</span></span>
<span id="cb49-553"><a href="#cb49-553" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb49-554"><a href="#cb49-554" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb49-555"><a href="#cb49-555" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb49-556"><a href="#cb49-556" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> theta_hats_apr1[, <span class="fu">mean</span>(theta)], <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb49-557"><a href="#cb49-557" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb49-558"><a href="#cb49-558" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb49-559"><a href="#cb49-559" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb49-560"><a href="#cb49-560" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-561"><a href="#cb49-561" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb49-562"><a href="#cb49-562" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-563"><a href="#cb49-563" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-564"><a href="#cb49-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-565"><a href="#cb49-565" aria-hidden="true" tabindex="-1"></a>@fig-naive shows the histogram of $\hat{\theta}$ from 500 simulations. You can see that this procedure has led to consistent underestimation of the treatment effect (mean value of $\hat{\theta}$ is <span class="in">`r theta_hats_apr1[, round(mean(theta), digits = 3)]`</span>). There are two sources of bias in this approach: regularization and over-fitting bias. </span>
<span id="cb49-566"><a href="#cb49-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-567"><a href="#cb49-567" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb49-568"><a href="#cb49-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-569"><a href="#cb49-569" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Regularization bias: the bias coming from bias in estimating $g_0(X)$</span>
<span id="cb49-570"><a href="#cb49-570" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Over-fitting bias: the bias coming from over-fitting $g_0(X)$ and $m_0(X)$ due to the fact that the same sample is used for $g_0(X)$ and $m_0(X)$ estimation and $\theta$ estimation</span>
<span id="cb49-571"><a href="#cb49-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-572"><a href="#cb49-572" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-573"><a href="#cb49-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-574"><a href="#cb49-574" aria-hidden="true" tabindex="-1"></a>Regularization bias is termed so because bias in estimating $g_0(X)$ can occur when some form of regularization is implemented (e.g., lasso). </span>
<span id="cb49-575"><a href="#cb49-575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-576"><a href="#cb49-576" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- However, its name is slightly misleading because $g_0(X)$ cannot be estimated without bias even without any regularization in general. This is because the estimation of initial $\theta$ (in Step 1.3) is biased, which comes from the fact that $m_0(X)$ is correlated with $g_0(X)$ through $X$.  --&gt;</span></span>
<span id="cb49-577"><a href="#cb49-577" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-578"><a href="#cb49-578" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ::: {.column-margin}</span></span>
<span id="cb49-579"><a href="#cb49-579" aria-hidden="true" tabindex="-1"></a><span class="co">Another (unofficial) implementation of $g_0(X)$ estimation is to just use $\hat{l}_0(X_i)$ as $\hat{g}_0(X_i)$ ([a blog post](https://www.r-bloggers.com/2017/06/cross-fitting-double-machine-learning-estimator/)) and then use the following formula.</span></span>
<span id="cb49-580"><a href="#cb49-580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-581"><a href="#cb49-581" aria-hidden="true" tabindex="-1"></a><span class="co">$$</span></span>
<span id="cb49-582"><a href="#cb49-582" aria-hidden="true" tabindex="-1"></a><span class="co">\begin{aligned}</span></span>
<span id="cb49-583"><a href="#cb49-583" aria-hidden="true" tabindex="-1"></a><span class="co">  \hat{\theta} = (\frac{1}{n}\sum_{i=1}^N d_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N d_i (y_i - \hat{l}_0(X_i))</span></span>
<span id="cb49-584"><a href="#cb49-584" aria-hidden="true" tabindex="-1"></a><span class="co">\end{aligned}</span></span>
<span id="cb49-585"><a href="#cb49-585" aria-hidden="true" tabindex="-1"></a><span class="co">$$</span></span>
<span id="cb49-586"><a href="#cb49-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-587"><a href="#cb49-587" aria-hidden="true" tabindex="-1"></a><span class="co">$\hat{\theta}$ is biased because $\hat{l}_0(X_i)$ is a biased estimator of $\hat{g}_0(X_i)$ when $m_0(X)$ and $g_0(X)$ are correlated. The point here is that, $g_0(X)$ is hard to estimate without bias irrespective of whether any regularization happens or not.</span></span>
<span id="cb49-588"><a href="#cb49-588" aria-hidden="true" tabindex="-1"></a><span class="co">::: --&gt;</span></span>
<span id="cb49-589"><a href="#cb49-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-590"><a href="#cb49-590" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- However, if the treatment is independent, then, $g_0(X)$ can be estimated well and this approach works well except it still suffers from over-fitting bias. @fig-apr1-indep shows that the distribution of $\hat{\theta}$ when $m_0(X)$ is independent of $g_0(X)$ and the RF with the same hyper-parameters are used. While regularization can lead to bias in the estimation of $g_0(X)$, regularization is not the only source of bias.  --&gt;</span></span>
<span id="cb49-591"><a href="#cb49-591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-592"><a href="#cb49-592" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ```{r}</span></span>
<span id="cb49-593"><a href="#cb49-593" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Performance of approach 1 when the treatment status is independent</span></span>
<span id="cb49-594"><a href="#cb49-594" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-apr1-indep</span></span>
<span id="cb49-595"><a href="#cb49-595" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-596"><a href="#cb49-596" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-597"><a href="#cb49-597" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true </span></span>
<span id="cb49-598"><a href="#cb49-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-599"><a href="#cb49-599" aria-hidden="true" tabindex="-1"></a><span class="co">run_sim_naive &lt;- function(i){</span></span>
<span id="cb49-600"><a href="#cb49-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-601"><a href="#cb49-601" aria-hidden="true" tabindex="-1"></a><span class="co">  training_data &lt;- gen_data(m_formula = "independent")</span></span>
<span id="cb49-602"><a href="#cb49-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-603"><a href="#cb49-603" aria-hidden="true" tabindex="-1"></a><span class="co">  rf_fitted_m0 &lt;- fit_m0(training_data)</span></span>
<span id="cb49-604"><a href="#cb49-604" aria-hidden="true" tabindex="-1"></a><span class="co">  rf_fitted_g0 &lt;- fit_g0(training_data, rf_fitted_m0)</span></span>
<span id="cb49-605"><a href="#cb49-605" aria-hidden="true" tabindex="-1"></a><span class="co">  # rf_fitted_g0 &lt;- fit_l0(training_data)</span></span>
<span id="cb49-606"><a href="#cb49-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-607"><a href="#cb49-607" aria-hidden="true" tabindex="-1"></a><span class="co">  g0_hat &lt;- predict(rf_fitted_g0, data = training_data)$predictions</span></span>
<span id="cb49-608"><a href="#cb49-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-609"><a href="#cb49-609" aria-hidden="true" tabindex="-1"></a><span class="co">  #=== create y - g0 ===#</span></span>
<span id="cb49-610"><a href="#cb49-610" aria-hidden="true" tabindex="-1"></a><span class="co">  training_data[, y_less_g := y - g0_hat]</span></span>
<span id="cb49-611"><a href="#cb49-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-612"><a href="#cb49-612" aria-hidden="true" tabindex="-1"></a><span class="co">  theta_hat &lt;- lm(y_less_g ~ d, data = training_data)$coefficient["d"]</span></span>
<span id="cb49-613"><a href="#cb49-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-614"><a href="#cb49-614" aria-hidden="true" tabindex="-1"></a><span class="co">  # theta_hat &lt;- training_data[, sum(d * y_less_g) / sum(d * d)]</span></span>
<span id="cb49-615"><a href="#cb49-615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-616"><a href="#cb49-616" aria-hidden="true" tabindex="-1"></a><span class="co">  return(theta_hat)</span></span>
<span id="cb49-617"><a href="#cb49-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-618"><a href="#cb49-618" aria-hidden="true" tabindex="-1"></a><span class="co">}</span></span>
<span id="cb49-619"><a href="#cb49-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-620"><a href="#cb49-620" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-621"><a href="#cb49-621" aria-hidden="true" tabindex="-1"></a><span class="co"># Repeat MC simulations 500 times</span></span>
<span id="cb49-622"><a href="#cb49-622" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-623"><a href="#cb49-623" aria-hidden="true" tabindex="-1"></a><span class="co">theta_hats_apr1_indep &lt;-</span></span>
<span id="cb49-624"><a href="#cb49-624" aria-hidden="true" tabindex="-1"></a><span class="co">  mclapply(</span></span>
<span id="cb49-625"><a href="#cb49-625" aria-hidden="true" tabindex="-1"></a><span class="co">    1:500,</span></span>
<span id="cb49-626"><a href="#cb49-626" aria-hidden="true" tabindex="-1"></a><span class="co">    run_sim_naive,</span></span>
<span id="cb49-627"><a href="#cb49-627" aria-hidden="true" tabindex="-1"></a><span class="co">    mc.cores = detectCores() / 4 * 3</span></span>
<span id="cb49-628"><a href="#cb49-628" aria-hidden="true" tabindex="-1"></a><span class="co">  ) %&gt;% </span></span>
<span id="cb49-629"><a href="#cb49-629" aria-hidden="true" tabindex="-1"></a><span class="co">  unlist() %&gt;% </span></span>
<span id="cb49-630"><a href="#cb49-630" aria-hidden="true" tabindex="-1"></a><span class="co">  data.table(theta = .)</span></span>
<span id="cb49-631"><a href="#cb49-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-632"><a href="#cb49-632" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-633"><a href="#cb49-633" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the results</span></span>
<span id="cb49-634"><a href="#cb49-634" aria-hidden="true" tabindex="-1"></a><span class="co">#===================================</span></span>
<span id="cb49-635"><a href="#cb49-635" aria-hidden="true" tabindex="-1"></a><span class="co">ggplot(theta_hats_apr1_indep) +</span></span>
<span id="cb49-636"><a href="#cb49-636" aria-hidden="true" tabindex="-1"></a><span class="co">  geom_histogram(aes(x = theta), color = "grey", fill = "white") +</span></span>
<span id="cb49-637"><a href="#cb49-637" aria-hidden="true" tabindex="-1"></a><span class="co">  theme_bw() + </span></span>
<span id="cb49-638"><a href="#cb49-638" aria-hidden="true" tabindex="-1"></a><span class="co">  geom_vline(aes(xintercept = 0.5,color = "True Value")) +</span></span>
<span id="cb49-639"><a href="#cb49-639" aria-hidden="true" tabindex="-1"></a><span class="co">  geom_vline(aes(xintercept = theta_hats_apr1_indep[, mean(theta)], color = "Mean of the Estimates")) +</span></span>
<span id="cb49-640"><a href="#cb49-640" aria-hidden="true" tabindex="-1"></a><span class="co">  scale_color_manual(</span></span>
<span id="cb49-641"><a href="#cb49-641" aria-hidden="true" tabindex="-1"></a><span class="co">    values = c("True Value" = "red", "Mean of the Estimates" = "blue"),</span></span>
<span id="cb49-642"><a href="#cb49-642" aria-hidden="true" tabindex="-1"></a><span class="co">    name = ""</span></span>
<span id="cb49-643"><a href="#cb49-643" aria-hidden="true" tabindex="-1"></a><span class="co">  ) +</span></span>
<span id="cb49-644"><a href="#cb49-644" aria-hidden="true" tabindex="-1"></a><span class="co">  guides(color = guide_legend(nrow = 1, byrow = TRUE)) +</span></span>
<span id="cb49-645"><a href="#cb49-645" aria-hidden="true" tabindex="-1"></a><span class="co">  theme(legend.position = "bottom")</span></span>
<span id="cb49-646"><a href="#cb49-646" aria-hidden="true" tabindex="-1"></a><span class="co">``` --&gt;</span></span>
<span id="cb49-647"><a href="#cb49-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-648"><a href="#cb49-648" aria-hidden="true" tabindex="-1"></a><span class="fu">### Overcoming the regularization bias</span></span>
<span id="cb49-649"><a href="#cb49-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-650"><a href="#cb49-650" aria-hidden="true" tabindex="-1"></a>Regularization bias can be overcome by double-debiasing (orthogonalizing both $d$ and $y$). Specifically, </span>
<span id="cb49-651"><a href="#cb49-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-652"><a href="#cb49-652" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 1: Estimate $g_0(X)$ and then subtract the fitted value of $g_0(X)$ from $y$ </span>
<span id="cb49-653"><a href="#cb49-653" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 2: Subtract $\hat{m}_0(X)$ from $d$ ($\tilde{d} = d - \hat{m}_0(x)$)</span>
<span id="cb49-654"><a href="#cb49-654" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 3: Calculate $\hat{\theta}$ based on the following formula</span>
<span id="cb49-655"><a href="#cb49-655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-656"><a href="#cb49-656" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-657"><a href="#cb49-657" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-658"><a href="#cb49-658" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{g}_0(X_i))</span>
<span id="cb49-659"><a href="#cb49-659" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-660"><a href="#cb49-660" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-661"><a href="#cb49-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-662"><a href="#cb49-662" aria-hidden="true" tabindex="-1"></a>The key difference from the previous approach is that this approach uses **IV-like** formula, where $\tilde{d}$ is acting like an instrument. </span>
<span id="cb49-663"><a href="#cb49-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-664"><a href="#cb49-664" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-665"><a href="#cb49-665" aria-hidden="true" tabindex="-1"></a>For $y = X\beta + \mu$ with instruments $Z$, the IV estimator is</span>
<span id="cb49-666"><a href="#cb49-666" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-667"><a href="#cb49-667" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-668"><a href="#cb49-668" aria-hidden="true" tabindex="-1"></a>\hat{\beta} = (Z'X)^{-1}Z'y</span>
<span id="cb49-669"><a href="#cb49-669" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-670"><a href="#cb49-670" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-671"><a href="#cb49-671" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb49-672"><a href="#cb49-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-673"><a href="#cb49-673" aria-hidden="true" tabindex="-1"></a>We have done Steps 1 and 2 already in the previous approach. So,</span>
<span id="cb49-674"><a href="#cb49-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-677"><a href="#cb49-677" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-678"><a href="#cb49-678" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-679"><a href="#cb49-679" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 3</span></span>
<span id="cb49-680"><a href="#cb49-680" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb49-681"><a href="#cb49-681" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-682"><a href="#cb49-682" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_g) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d)]</span>
<span id="cb49-683"><a href="#cb49-683" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-684"><a href="#cb49-684" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-685"><a href="#cb49-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-686"><a href="#cb49-686" aria-hidden="true" tabindex="-1"></a>Now, let's repeat this 500 times. </span>
<span id="cb49-687"><a href="#cb49-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-690"><a href="#cb49-690" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-691"><a href="#cb49-691" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-692"><a href="#cb49-692" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Simulation results of double-debiased approach</span></span>
<span id="cb49-693"><a href="#cb49-693" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dd</span></span>
<span id="cb49-694"><a href="#cb49-694" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-695"><a href="#cb49-695" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true </span></span>
<span id="cb49-696"><a href="#cb49-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-697"><a href="#cb49-697" aria-hidden="true" tabindex="-1"></a>run_sim_dereg <span class="ot">&lt;-</span> <span class="cf">function</span>(i)</span>
<span id="cb49-698"><a href="#cb49-698" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb49-699"><a href="#cb49-699" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb49-700"><a href="#cb49-700" aria-hidden="true" tabindex="-1"></a>  <span class="co"># training_data &lt;- data[[i]] %&gt;% data.table</span></span>
<span id="cb49-701"><a href="#cb49-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-702"><a href="#cb49-702" aria-hidden="true" tabindex="-1"></a>  rf_fitted_m0 <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(training_data)</span>
<span id="cb49-703"><a href="#cb49-703" aria-hidden="true" tabindex="-1"></a>  m0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_m0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-704"><a href="#cb49-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-705"><a href="#cb49-705" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create d - m0_hat ===#</span></span>
<span id="cb49-706"><a href="#cb49-706" aria-hidden="true" tabindex="-1"></a>  training_data[, d_less_m <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m0_hat]</span>
<span id="cb49-707"><a href="#cb49-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-708"><a href="#cb49-708" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== get g0_hat ===#</span></span>
<span id="cb49-709"><a href="#cb49-709" aria-hidden="true" tabindex="-1"></a>  rf_fitted_g0 <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(training_data, rf_fitted_m0)</span>
<span id="cb49-710"><a href="#cb49-710" aria-hidden="true" tabindex="-1"></a>  g0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_fitted_g0, <span class="at">data =</span> training_data)<span class="sc">$</span>predictions</span>
<span id="cb49-711"><a href="#cb49-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-712"><a href="#cb49-712" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== create y - g0 ===#</span></span>
<span id="cb49-713"><a href="#cb49-713" aria-hidden="true" tabindex="-1"></a>  training_data[, y_less_g <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g0_hat]</span>
<span id="cb49-714"><a href="#cb49-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-715"><a href="#cb49-715" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> training_data[, <span class="fu">sum</span>(d_less_m <span class="sc">*</span> y_less_g) <span class="sc">/</span> <span class="fu">sum</span>(d_less_m <span class="sc">*</span> d)]</span>
<span id="cb49-716"><a href="#cb49-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-717"><a href="#cb49-717" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb49-718"><a href="#cb49-718" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-719"><a href="#cb49-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-720"><a href="#cb49-720" aria-hidden="true" tabindex="-1"></a>theta_hats_apr2 <span class="ot">&lt;-</span></span>
<span id="cb49-721"><a href="#cb49-721" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb49-722"><a href="#cb49-722" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb49-723"><a href="#cb49-723" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_sim_dereg</span>(x),</span>
<span id="cb49-724"><a href="#cb49-724" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">/</span> <span class="dv">4</span> <span class="sc">*</span> <span class="dv">3</span></span>
<span id="cb49-725"><a href="#cb49-725" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-726"><a href="#cb49-726" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-727"><a href="#cb49-727" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">theta =</span> .)</span>
<span id="cb49-728"><a href="#cb49-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-729"><a href="#cb49-729" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(theta_hats_apr2) <span class="sc">+</span></span>
<span id="cb49-730"><a href="#cb49-730" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb49-731"><a href="#cb49-731" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb49-732"><a href="#cb49-732" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb49-733"><a href="#cb49-733" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> theta_hats_apr2[, <span class="fu">mean</span>(theta)], <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb49-734"><a href="#cb49-734" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb49-735"><a href="#cb49-735" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb49-736"><a href="#cb49-736" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb49-737"><a href="#cb49-737" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-738"><a href="#cb49-738" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb49-739"><a href="#cb49-739" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-740"><a href="#cb49-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-741"><a href="#cb49-741" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-742"><a href="#cb49-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-743"><a href="#cb49-743" aria-hidden="true" tabindex="-1"></a>@fig-dd shows the distribution of $\hat{\theta}$, which is centered about $<span class="in">`r round(theta_hats_apr2[, mean(theta)], digits = 3)`</span>$. The current approach still suffers from the so-called over-fitting bias<span class="co">[</span><span class="ot">@Chernozhukov2018</span><span class="co">]</span>. Let's look at how we can overcome this bias next.</span>
<span id="cb49-744"><a href="#cb49-744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-745"><a href="#cb49-745" aria-hidden="true" tabindex="-1"></a><span class="fu">### Overcoming the over-fitting bias {#sec-cf}</span></span>
<span id="cb49-746"><a href="#cb49-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-747"><a href="#cb49-747" aria-hidden="true" tabindex="-1"></a>Over-fitting bias can be overcome by cross-fitting. First, the training data is split into $K$-folds just like K-fold cross-validation. Let's denote them as $I_1, \dots, I_k$. For example, for $I_1$, the following steps are taken (@fig-cross-fitting provides a visual illustration):</span>
<span id="cb49-748"><a href="#cb49-748" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-749"><a href="#cb49-749" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 1: Estimate $\hat{g}_0(x)$ and $\hat{m}_0(x)$ using the data from the other folds ($I_2, \dots, I_K$).</span>
<span id="cb49-750"><a href="#cb49-750" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 2: Estimate $\hat{g}_0(x_i)$ and $\hat{m}_0(x_i)$ for each $i \in I_1$ and calculate $\tilde{y}_i = y_i - \hat{g}_0(x_i)$ and $\tilde{d}_i = d_i - \hat{m}_0(x_i)$.</span>
<span id="cb49-751"><a href="#cb49-751" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Step 3: Use the following formula to obtain $\hat{\theta}$.</span>
<span id="cb49-752"><a href="#cb49-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-753"><a href="#cb49-753" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-754"><a href="#cb49-754" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-755"><a href="#cb49-755" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = (\frac{1}{n}\sum_{i=1}^N \tilde{d}_i d_i)^{-1}\frac{1}{n}\sum_{i=1}^N \tilde{d}_i (y_i - \hat{g}_0(X_i))</span>
<span id="cb49-756"><a href="#cb49-756" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-757"><a href="#cb49-757" aria-hidden="true" tabindex="-1"></a>$$ {#eq-iv-score}</span>
<span id="cb49-758"><a href="#cb49-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-759"><a href="#cb49-759" aria-hidden="true" tabindex="-1"></a>This process is repeated for all the $K$ folds, and then the the final estimate of $\hat{\theta}$ is obtained as the average of $\hat{\theta}$s.</span>
<span id="cb49-760"><a href="#cb49-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-761"><a href="#cb49-761" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-762"><a href="#cb49-762" aria-hidden="true" tabindex="-1"></a>You can implement repeated K-fold cross-fitting using the <span class="in">`DoublML`</span> package, which is not demonstrated here as it is very much similar in concept to repeated K-fold CV explained in @sec-cross-validation.</span>
<span id="cb49-763"><a href="#cb49-763" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-764"><a href="#cb49-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-765"><a href="#cb49-765" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> talk about <span class="in">`algorithm_2`</span> <span class="kw">&lt;/span&gt;</span></span>
<span id="cb49-766"><a href="#cb49-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-769"><a href="#cb49-769" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-770"><a href="#cb49-770" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-771"><a href="#cb49-771" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-width: 9</span></span>
<span id="cb49-772"><a href="#cb49-772" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Illustration of cross-fitting</span></span>
<span id="cb49-773"><a href="#cb49-773" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cross-fitting</span></span>
<span id="cb49-774"><a href="#cb49-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-775"><a href="#cb49-775" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb49-776"><a href="#cb49-776" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 1 ===#</span></span>
<span id="cb49-777"><a href="#cb49-777" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-778"><a href="#cb49-778" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> <span class="dv">2</span>),</span>
<span id="cb49-779"><a href="#cb49-779" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb49-780"><a href="#cb49-780" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb49-781"><a href="#cb49-781" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb49-782"><a href="#cb49-782" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-783"><a href="#cb49-783" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-784"><a href="#cb49-784" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="fl">2.5</span>, <span class="at">ymin =</span> <span class="dv">0</span>, <span class="at">ymax =</span> <span class="dv">2</span>),</span>
<span id="cb49-785"><a href="#cb49-785" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb49-786"><a href="#cb49-786" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-787"><a href="#cb49-787" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 2 ===#</span></span>
<span id="cb49-788"><a href="#cb49-788" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-789"><a href="#cb49-789" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">2.2</span>, <span class="at">ymax =</span> <span class="fl">4.2</span>),</span>
<span id="cb49-790"><a href="#cb49-790" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb49-791"><a href="#cb49-791" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb49-792"><a href="#cb49-792" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb49-793"><a href="#cb49-793" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-794"><a href="#cb49-794" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-795"><a href="#cb49-795" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="fl">2.5</span>, <span class="at">xmax =</span> <span class="dv">5</span>, <span class="at">ymin =</span> <span class="fl">2.2</span>, <span class="at">ymax =</span> <span class="fl">4.2</span>),</span>
<span id="cb49-796"><a href="#cb49-796" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb49-797"><a href="#cb49-797" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-798"><a href="#cb49-798" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 3 ===#</span></span>
<span id="cb49-799"><a href="#cb49-799" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-800"><a href="#cb49-800" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">4.4</span>, <span class="at">ymax =</span> <span class="fl">6.4</span>),</span>
<span id="cb49-801"><a href="#cb49-801" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb49-802"><a href="#cb49-802" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb49-803"><a href="#cb49-803" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb49-804"><a href="#cb49-804" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-805"><a href="#cb49-805" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-806"><a href="#cb49-806" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">5</span>, <span class="at">xmax =</span> <span class="fl">7.5</span>, <span class="at">ymin =</span> <span class="fl">4.4</span>, <span class="at">ymax =</span> <span class="fl">6.4</span>),</span>
<span id="cb49-807"><a href="#cb49-807" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb49-808"><a href="#cb49-808" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-809"><a href="#cb49-809" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fold 4 ===#</span></span>
<span id="cb49-810"><a href="#cb49-810" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-811"><a href="#cb49-811" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="dv">0</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">6.6</span>, <span class="at">ymax =</span> <span class="fl">8.6</span>),</span>
<span id="cb49-812"><a href="#cb49-812" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"grey"</span>,</span>
<span id="cb49-813"><a href="#cb49-813" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb49-814"><a href="#cb49-814" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="fl">1.2</span></span>
<span id="cb49-815"><a href="#cb49-815" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-816"><a href="#cb49-816" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_rect</span>(</span>
<span id="cb49-817"><a href="#cb49-817" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">xmin =</span> <span class="fl">7.5</span>, <span class="at">xmax =</span> <span class="dv">10</span>, <span class="at">ymin =</span> <span class="fl">6.6</span>, <span class="at">ymax =</span> <span class="fl">8.6</span>),</span>
<span id="cb49-818"><a href="#cb49-818" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"black"</span></span>
<span id="cb49-819"><a href="#cb49-819" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-820"><a href="#cb49-820" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_brace</span>(<span class="fu">aes</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">7.4</span>), <span class="fu">c</span>(<span class="fl">8.7</span>, <span class="fl">9.2</span>)), <span class="at">inherit.data=</span>F) <span class="sc">+</span></span>
<span id="cb49-821"><a href="#cb49-821" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(</span>
<span id="cb49-822"><a href="#cb49-822" aria-hidden="true" tabindex="-1"></a>    <span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">3.5</span>, <span class="at">y =</span> <span class="fl">9.7</span>, <span class="at">parse =</span> <span class="cn">TRUE</span>,</span>
<span id="cb49-823"><a href="#cb49-823" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> <span class="st">"'Find ' * hat(g)[0](x) * ' and ' * hat(m)[0](x) * ' from this data.'"</span>,</span>
<span id="cb49-824"><a href="#cb49-824" aria-hidden="true" tabindex="-1"></a>    <span class="at">size =</span> <span class="dv">6</span></span>
<span id="cb49-825"><a href="#cb49-825" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-826"><a href="#cb49-826" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_curve</span>(</span>
<span id="cb49-827"><a href="#cb49-827" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">2.2</span>, <span class="at">xend =</span> <span class="fl">8.5</span>, <span class="at">y =</span> <span class="fl">10.3</span>, <span class="at">yend =</span> <span class="fl">8.8</span>),</span>
<span id="cb49-828"><a href="#cb49-828" aria-hidden="true" tabindex="-1"></a>    <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.03</span>, <span class="st">"npc"</span>)),</span>
<span id="cb49-829"><a href="#cb49-829" aria-hidden="true" tabindex="-1"></a>    <span class="at">curvature =</span> <span class="sc">-</span><span class="fl">0.3</span></span>
<span id="cb49-830"><a href="#cb49-830" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-831"><a href="#cb49-831" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_curve</span>(</span>
<span id="cb49-832"><a href="#cb49-832" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> <span class="fl">3.4</span>, <span class="at">xend =</span> <span class="dv">8</span>, <span class="at">y =</span> <span class="fl">10.3</span>, <span class="at">yend =</span> <span class="fl">8.8</span>),</span>
<span id="cb49-833"><a href="#cb49-833" aria-hidden="true" tabindex="-1"></a>    <span class="at">arrow =</span> <span class="fu">arrow</span>(<span class="at">length =</span> <span class="fu">unit</span>(<span class="fl">0.03</span>, <span class="st">"npc"</span>)),</span>
<span id="cb49-834"><a href="#cb49-834" aria-hidden="true" tabindex="-1"></a>    <span class="at">curvature =</span> <span class="sc">-</span><span class="fl">0.3</span></span>
<span id="cb49-835"><a href="#cb49-835" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-836"><a href="#cb49-836" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylim</span>(<span class="cn">NA</span>, <span class="dv">11</span>) <span class="sc">+</span></span>
<span id="cb49-837"><a href="#cb49-837" aria-hidden="true" tabindex="-1"></a>  <span class="co"># coord_equal() +</span></span>
<span id="cb49-838"><a href="#cb49-838" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_void</span>()</span>
<span id="cb49-839"><a href="#cb49-839" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-840"><a href="#cb49-840" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-841"><a href="#cb49-841" aria-hidden="true" tabindex="-1"></a>Let's code the cross-fitting procedure. We first split the data into 2 folds ($K = 2$).</span>
<span id="cb49-842"><a href="#cb49-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-843"><a href="#cb49-843" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-844"><a href="#cb49-844" aria-hidden="true" tabindex="-1"></a>$K$ does not have to be 2.</span>
<span id="cb49-845"><a href="#cb49-845" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-846"><a href="#cb49-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-849"><a href="#cb49-849" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-850"><a href="#cb49-850" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-851"><a href="#cb49-851" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(training_data, <span class="at">v =</span> <span class="dv">2</span>)</span>
<span id="cb49-852"><a href="#cb49-852" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-853"><a href="#cb49-853" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-854"><a href="#cb49-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-855"><a href="#cb49-855" aria-hidden="true" tabindex="-1"></a>Let's cross-fit for fold 1.</span>
<span id="cb49-856"><a href="#cb49-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-859"><a href="#cb49-859" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-860"><a href="#cb49-860" aria-hidden="true" tabindex="-1"></a>split_1 <span class="ot">&lt;-</span> data_folds[<span class="dv">1</span>, ]</span>
<span id="cb49-861"><a href="#cb49-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-862"><a href="#cb49-862" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for estimating g_0  and m_0 ===#</span></span>
<span id="cb49-863"><a href="#cb49-863" aria-hidden="true" tabindex="-1"></a>data_train <span class="ot">&lt;-</span> <span class="fu">analysis</span>(split_1<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb49-864"><a href="#cb49-864" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-865"><a href="#cb49-865" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for which g_0(x_i) and m_0(x_i) are calculated ===#</span></span>
<span id="cb49-866"><a href="#cb49-866" aria-hidden="true" tabindex="-1"></a>data_target <span class="ot">&lt;-</span> <span class="fu">assessment</span>(split_1<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb49-867"><a href="#cb49-867" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-868"><a href="#cb49-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-869"><a href="#cb49-869" aria-hidden="true" tabindex="-1"></a>First, we fit $\hat{g}_0(x)$ and $\hat{m}_0(x)$ using the data from the other folds.</span>
<span id="cb49-870"><a href="#cb49-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-873"><a href="#cb49-873" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-874"><a href="#cb49-874" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-875"><a href="#cb49-875" aria-hidden="true" tabindex="-1"></a><span class="co">#=== m0 ===#</span></span>
<span id="cb49-876"><a href="#cb49-876" aria-hidden="true" tabindex="-1"></a>m_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(data_train)</span>
<span id="cb49-877"><a href="#cb49-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-878"><a href="#cb49-878" aria-hidden="true" tabindex="-1"></a><span class="co">#=== g0 ===#</span></span>
<span id="cb49-879"><a href="#cb49-879" aria-hidden="true" tabindex="-1"></a>g_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(data_train, m_rf_fit)</span>
<span id="cb49-880"><a href="#cb49-880" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-881"><a href="#cb49-881" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-882"><a href="#cb49-882" aria-hidden="true" tabindex="-1"></a>Next, we predict $\hat{g}_0(x_i)$ and $\hat{m}_0(x_i)$ for each $i$ of fold 1 (the target dataset) and calculate $\tilde{y}_i = y_i - \hat{g}_0(x_i)$ and $\tilde{d}_i = d_i - \hat{m}_0(x_i)$.</span>
<span id="cb49-883"><a href="#cb49-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-886"><a href="#cb49-886" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-887"><a href="#cb49-887" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-888"><a href="#cb49-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-889"><a href="#cb49-889" aria-hidden="true" tabindex="-1"></a>data_orth <span class="ot">&lt;-</span></span>
<span id="cb49-890"><a href="#cb49-890" aria-hidden="true" tabindex="-1"></a>  data_target <span class="sc">%&gt;%</span> </span>
<span id="cb49-891"><a href="#cb49-891" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== prediction of g_0(x_i) ===#</span></span>
<span id="cb49-892"><a href="#cb49-892" aria-hidden="true" tabindex="-1"></a>  .[, g_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(g_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb49-893"><a href="#cb49-893" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== orthogonalize y ===#</span></span>
<span id="cb49-894"><a href="#cb49-894" aria-hidden="true" tabindex="-1"></a>  .[, y_tilde <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb49-895"><a href="#cb49-895" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== prediction of m_0(x_i) ===#</span></span>
<span id="cb49-896"><a href="#cb49-896" aria-hidden="true" tabindex="-1"></a>  .[, m_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(m_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb49-897"><a href="#cb49-897" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== orthogonalize d ===#</span></span>
<span id="cb49-898"><a href="#cb49-898" aria-hidden="true" tabindex="-1"></a>  .[, d_tilde <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m_0_hat]</span>
<span id="cb49-899"><a href="#cb49-899" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-900"><a href="#cb49-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-901"><a href="#cb49-901" aria-hidden="true" tabindex="-1"></a>Then, $\hat{\theta}$ is obtained for this fold using @eq-iv-score.</span>
<span id="cb49-902"><a href="#cb49-902" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-905"><a href="#cb49-905" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-906"><a href="#cb49-906" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-907"><a href="#cb49-907" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> data_orth[, <span class="fu">sum</span>(d_tilde <span class="sc">*</span> y_tilde) <span class="sc">/</span> <span class="fu">sum</span>(d_tilde <span class="sc">*</span> d)]</span>
<span id="cb49-908"><a href="#cb49-908" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-909"><a href="#cb49-909" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-910"><a href="#cb49-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-911"><a href="#cb49-911" aria-hidden="true" tabindex="-1"></a>We can repeat this for all the folds (<span class="in">`cross_fit()`</span> which finds $\hat{\theta}$ for a particular fold is defined on the side).</span>
<span id="cb49-912"><a href="#cb49-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-913"><a href="#cb49-913" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-914"><a href="#cb49-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-917"><a href="#cb49-917" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-918"><a href="#cb49-918" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(i, data_folds, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_m =</span> <span class="dv">10</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>)</span>
<span id="cb49-919"><a href="#cb49-919" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb49-920"><a href="#cb49-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-921"><a href="#cb49-921" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-922"><a href="#cb49-922" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prepare data</span></span>
<span id="cb49-923"><a href="#cb49-923" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-924"><a href="#cb49-924" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== ith split ===#</span></span>
<span id="cb49-925"><a href="#cb49-925" aria-hidden="true" tabindex="-1"></a>  working_split <span class="ot">&lt;-</span> data_folds[i, ]</span>
<span id="cb49-926"><a href="#cb49-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-927"><a href="#cb49-927" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== data for estimating g_0  and m_0 ===#</span></span>
<span id="cb49-928"><a href="#cb49-928" aria-hidden="true" tabindex="-1"></a>  data_train <span class="ot">&lt;-</span> <span class="fu">analysis</span>(working_split<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb49-929"><a href="#cb49-929" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-930"><a href="#cb49-930" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== data for which g_0(x_i) and m_0(x_i) are calculated ===#</span></span>
<span id="cb49-931"><a href="#cb49-931" aria-hidden="true" tabindex="-1"></a>  data_target <span class="ot">&lt;-</span> <span class="fu">assessment</span>(working_split<span class="sc">$</span>splits[[<span class="dv">1</span>]]) </span>
<span id="cb49-932"><a href="#cb49-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-933"><a href="#cb49-933" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-934"><a href="#cb49-934" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Fit g0 and m0</span></span>
<span id="cb49-935"><a href="#cb49-935" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-936"><a href="#cb49-936" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== m0 ===#</span></span>
<span id="cb49-937"><a href="#cb49-937" aria-hidden="true" tabindex="-1"></a>  m_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_m0</span>(data_train, mtry_m)</span>
<span id="cb49-938"><a href="#cb49-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-939"><a href="#cb49-939" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== g0 ===#</span></span>
<span id="cb49-940"><a href="#cb49-940" aria-hidden="true" tabindex="-1"></a>  g_rf_fit <span class="ot">&lt;-</span> <span class="fu">fit_g0</span>(data_train, m_rf_fit, mtry_l, mtry_g)</span>
<span id="cb49-941"><a href="#cb49-941" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-942"><a href="#cb49-942" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-943"><a href="#cb49-943" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Get y_tilde and d_tilde</span></span>
<span id="cb49-944"><a href="#cb49-944" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb49-945"><a href="#cb49-945" aria-hidden="true" tabindex="-1"></a>  data_orth <span class="ot">&lt;-</span></span>
<span id="cb49-946"><a href="#cb49-946" aria-hidden="true" tabindex="-1"></a>    data_target <span class="sc">%&gt;%</span> </span>
<span id="cb49-947"><a href="#cb49-947" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== prediction of g_0(x_i) ===#</span></span>
<span id="cb49-948"><a href="#cb49-948" aria-hidden="true" tabindex="-1"></a>    .[, g_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(g_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb49-949"><a href="#cb49-949" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== orthogonalize y ===#</span></span>
<span id="cb49-950"><a href="#cb49-950" aria-hidden="true" tabindex="-1"></a>    .[, y_tilde <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> g_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb49-951"><a href="#cb49-951" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== prediction of m_0(x_i) ===#</span></span>
<span id="cb49-952"><a href="#cb49-952" aria-hidden="true" tabindex="-1"></a>    .[, m_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(m_rf_fit, <span class="at">data =</span> .)<span class="sc">$</span>predictions] <span class="sc">%&gt;%</span> </span>
<span id="cb49-953"><a href="#cb49-953" aria-hidden="true" tabindex="-1"></a>    <span class="co">#=== orthogonalize d ===#</span></span>
<span id="cb49-954"><a href="#cb49-954" aria-hidden="true" tabindex="-1"></a>    .[, d_tilde <span class="sc">:</span><span class="er">=</span> d <span class="sc">-</span> m_0_hat] <span class="sc">%&gt;%</span> </span>
<span id="cb49-955"><a href="#cb49-955" aria-hidden="true" tabindex="-1"></a>    .[, .(y_tilde, d_tilde, d)]</span>
<span id="cb49-956"><a href="#cb49-956" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-957"><a href="#cb49-957" aria-hidden="true" tabindex="-1"></a>  theta_cf <span class="ot">&lt;-</span> data_orth[, <span class="fu">sum</span>(d_tilde <span class="sc">*</span> y_tilde) <span class="sc">/</span> <span class="fu">sum</span>(d_tilde <span class="sc">*</span> d)]</span>
<span id="cb49-958"><a href="#cb49-958" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-959"><a href="#cb49-959" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_cf)</span>
<span id="cb49-960"><a href="#cb49-960" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-961"><a href="#cb49-961" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-962"><a href="#cb49-962" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-963"><a href="#cb49-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-964"><a href="#cb49-964" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-967"><a href="#cb49-967" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-968"><a href="#cb49-968" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-969"><a href="#cb49-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-970"><a href="#cb49-970" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-971"><a href="#cb49-971" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> </span>
<span id="cb49-972"><a href="#cb49-972" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb49-973"><a href="#cb49-973" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)), <span class="co"># loop over folds</span></span>
<span id="cb49-974"><a href="#cb49-974" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds) <span class="co"># get theta_hat</span></span>
<span id="cb49-975"><a href="#cb49-975" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-976"><a href="#cb49-976" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>() <span class="sc">%&gt;%</span></span>
<span id="cb49-977"><a href="#cb49-977" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>() <span class="co"># average them</span></span>
<span id="cb49-978"><a href="#cb49-978" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-979"><a href="#cb49-979" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-980"><a href="#cb49-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-981"><a href="#cb49-981" aria-hidden="true" tabindex="-1"></a>Okay, now that we understand the steps of this approach, let's repeat this many times (<span class="in">`get_theta_cf()`</span> that finds $\hat{\theta}$ by cross-fitting is defined on the side). </span>
<span id="cb49-982"><a href="#cb49-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-983"><a href="#cb49-983" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-986"><a href="#cb49-986" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-987"><a href="#cb49-987" aria-hidden="true" tabindex="-1"></a>get_theta_cf <span class="ot">&lt;-</span> <span class="cf">function</span>(data_folds, <span class="at">mtry_l =</span> <span class="dv">12</span>, <span class="at">mtry_m =</span> <span class="dv">10</span>, <span class="at">mtry_g =</span> <span class="dv">12</span>){</span>
<span id="cb49-988"><a href="#cb49-988" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-989"><a href="#cb49-989" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> </span>
<span id="cb49-990"><a href="#cb49-990" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb49-991"><a href="#cb49-991" aria-hidden="true" tabindex="-1"></a>      <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb49-992"><a href="#cb49-992" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds, mtry_l, mtry_m, mtry_g)</span>
<span id="cb49-993"><a href="#cb49-993" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-994"><a href="#cb49-994" aria-hidden="true" tabindex="-1"></a>    <span class="fu">unlist</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb49-995"><a href="#cb49-995" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>()</span>
<span id="cb49-996"><a href="#cb49-996" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-997"><a href="#cb49-997" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(theta_hat)</span>
<span id="cb49-998"><a href="#cb49-998" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb49-999"><a href="#cb49-999" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1000"><a href="#cb49-1000" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1001"><a href="#cb49-1001" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1002"><a href="#cb49-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1005"><a href="#cb49-1005" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1006"><a href="#cb49-1006" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: The distribution of treatment effect estimated by the double-debiased approach with cross-fitting</span></span>
<span id="cb49-1007"><a href="#cb49-1007" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-cf-debiased</span></span>
<span id="cb49-1008"><a href="#cb49-1008" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1009"><a href="#cb49-1009" aria-hidden="true" tabindex="-1"></a><span class="co">#| warning: false</span></span>
<span id="cb49-1010"><a href="#cb49-1010" aria-hidden="true" tabindex="-1"></a><span class="co">#| cache: true </span></span>
<span id="cb49-1011"><a href="#cb49-1011" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1012"><a href="#cb49-1012" aria-hidden="true" tabindex="-1"></a>theta_hats_cf <span class="ot">&lt;-</span></span>
<span id="cb49-1013"><a href="#cb49-1013" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb49-1014"><a href="#cb49-1014" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>,</span>
<span id="cb49-1015"><a href="#cb49-1015" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) {</span>
<span id="cb49-1016"><a href="#cb49-1016" aria-hidden="true" tabindex="-1"></a>      <span class="fu">print</span>(x)</span>
<span id="cb49-1017"><a href="#cb49-1017" aria-hidden="true" tabindex="-1"></a>      training_data <span class="ot">&lt;-</span> <span class="fu">gen_data</span>()</span>
<span id="cb49-1018"><a href="#cb49-1018" aria-hidden="true" tabindex="-1"></a>      data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(training_data, <span class="at">v =</span> <span class="dv">2</span>)</span>
<span id="cb49-1019"><a href="#cb49-1019" aria-hidden="true" tabindex="-1"></a>      theta_hat <span class="ot">&lt;-</span>  <span class="fu">get_theta_cf</span>(data_folds)</span>
<span id="cb49-1020"><a href="#cb49-1020" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(theta_hat)</span>
<span id="cb49-1021"><a href="#cb49-1021" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb49-1022"><a href="#cb49-1022" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="fu">detectCores</span>() <span class="sc">*</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span></span>
<span id="cb49-1023"><a href="#cb49-1023" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb49-1024"><a href="#cb49-1024" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unlist</span>()</span>
<span id="cb49-1025"><a href="#cb49-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1026"><a href="#cb49-1026" aria-hidden="true" tabindex="-1"></a><span class="co">#=== visualize the results ===#</span></span>
<span id="cb49-1027"><a href="#cb49-1027" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span></span>
<span id="cb49-1028"><a href="#cb49-1028" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> theta_hats_cf), <span class="at">color =</span> <span class="st">"grey"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb49-1029"><a href="#cb49-1029" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb49-1030"><a href="#cb49-1030" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fl">0.5</span>,<span class="at">color =</span> <span class="st">"True Value"</span>)) <span class="sc">+</span></span>
<span id="cb49-1031"><a href="#cb49-1031" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="fu">aes</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(theta_hats_cf), <span class="at">color =</span> <span class="st">"Mean of the Estimates"</span>)) <span class="sc">+</span></span>
<span id="cb49-1032"><a href="#cb49-1032" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb49-1033"><a href="#cb49-1033" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"True Value"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"Mean of the Estimates"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb49-1034"><a href="#cb49-1034" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb49-1035"><a href="#cb49-1035" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb49-1036"><a href="#cb49-1036" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">color =</span> <span class="fu">guide_legend</span>(<span class="at">nrow =</span> <span class="dv">1</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb49-1037"><a href="#cb49-1037" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb49-1038"><a href="#cb49-1038" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1039"><a href="#cb49-1039" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1040"><a href="#cb49-1040" aria-hidden="true" tabindex="-1"></a>@fig-cf-debiased shows the distribution of $\hat{\theta}$ with double-debiasing and cross-fitting. It is slightly biased in this instance (mean is <span class="in">`r round(mean(theta_hats_cf), digits = 3)`</span>), but the average $\hat{\theta}$ is very close to the true parameter. </span>
<span id="cb49-1041"><a href="#cb49-1041" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1042"><a href="#cb49-1042" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb49-1043"><a href="#cb49-1043" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1044"><a href="#cb49-1044" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Double/debiased (double orthogonalization) can help overcome the bias in $\hat{\theta}$ that comes from the bias in estimating $g_0(X)$.</span>
<span id="cb49-1045"><a href="#cb49-1045" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1046"><a href="#cb49-1046" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Cross-fitting can help overcome the bias from estimating $g_0(X)$, $m_0(X)$, and $\theta$ using the same data.</span>
<span id="cb49-1047"><a href="#cb49-1047" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1048"><a href="#cb49-1048" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1049"><a href="#cb49-1049" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1050"><a href="#cb49-1050" aria-hidden="true" tabindex="-1"></a><span class="fu">## Models and implementation by `DoubleML`</span></span>
<span id="cb49-1051"><a href="#cb49-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1052"><a href="#cb49-1052" aria-hidden="true" tabindex="-1"></a>In R, <span class="in">`DoubleML`</span> is built on top of <span class="in">`mlr3`</span>, which uses <span class="in">`R6`</span> classes provided by the <span class="in">`R6`</span> package. Since <span class="in">`R6`</span> implements encapsulated object-oriented programming like Python, <span class="in">`DoubleML`</span> in R and Python work in a very similar manner. Here, we will use R for demonstrations. </span>
<span id="cb49-1053"><a href="#cb49-1053" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1054"><a href="#cb49-1054" aria-hidden="true" tabindex="-1"></a><span class="fu">### Partially linear model</span></span>
<span id="cb49-1055"><a href="#cb49-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1056"><a href="#cb49-1056" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1057"><a href="#cb49-1057" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1058"><a href="#cb49-1058" aria-hidden="true" tabindex="-1"></a>y = \theta d + g_0(X) + \mu <span class="sc">\\</span></span>
<span id="cb49-1059"><a href="#cb49-1059" aria-hidden="true" tabindex="-1"></a>d = m_0(X) + \eta</span>
<span id="cb49-1060"><a href="#cb49-1060" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1061"><a href="#cb49-1061" aria-hidden="true" tabindex="-1"></a>$$ {#eq-plr}</span>
<span id="cb49-1062"><a href="#cb49-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1063"><a href="#cb49-1063" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb49-1064"><a href="#cb49-1064" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1065"><a href="#cb49-1065" aria-hidden="true" tabindex="-1"></a>**Assumptions on the error terms**</span>
<span id="cb49-1066"><a href="#cb49-1066" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1067"><a href="#cb49-1067" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\mu|D,X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1068"><a href="#cb49-1068" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta|X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1069"><a href="#cb49-1069" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta\cdot \mu|D, X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1070"><a href="#cb49-1070" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1071"><a href="#cb49-1071" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1072"><a href="#cb49-1072" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1075"><a href="#cb49-1075" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1076"><a href="#cb49-1076" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1077"><a href="#cb49-1077" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1078"><a href="#cb49-1078" aria-hidden="true" tabindex="-1"></a>DiagrammeR<span class="sc">::</span><span class="fu">grViz</span>(</span>
<span id="cb49-1079"><a href="#cb49-1079" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(</span>
<span id="cb49-1080"><a href="#cb49-1080" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb49-1081"><a href="#cb49-1081" aria-hidden="true" tabindex="-1"></a><span class="st">  digraph {</span></span>
<span id="cb49-1082"><a href="#cb49-1082" aria-hidden="true" tabindex="-1"></a><span class="st">    graph [layout = circo, ranksep = 0.5]</span></span>
<span id="cb49-1083"><a href="#cb49-1083" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1084"><a href="#cb49-1084" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb49-1085"><a href="#cb49-1085" aria-hidden="true" tabindex="-1"></a><span class="st">      Y [label = 'Y']</span></span>
<span id="cb49-1086"><a href="#cb49-1086" aria-hidden="true" tabindex="-1"></a><span class="st">      u [label = '\U03BC']</span></span>
<span id="cb49-1087"><a href="#cb49-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1088"><a href="#cb49-1088" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb49-1089"><a href="#cb49-1089" aria-hidden="true" tabindex="-1"></a><span class="st">      X [label = 'X']</span></span>
<span id="cb49-1090"><a href="#cb49-1090" aria-hidden="true" tabindex="-1"></a><span class="st">      T [label = 'T']</span></span>
<span id="cb49-1091"><a href="#cb49-1091" aria-hidden="true" tabindex="-1"></a><span class="st">      v [label = '\U03B7']</span></span>
<span id="cb49-1092"><a href="#cb49-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1093"><a href="#cb49-1093" aria-hidden="true" tabindex="-1"></a><span class="st">    edge [minlen = 2]</span></span>
<span id="cb49-1094"><a href="#cb49-1094" aria-hidden="true" tabindex="-1"></a><span class="st">      {v, X}-&gt;T</span></span>
<span id="cb49-1095"><a href="#cb49-1095" aria-hidden="true" tabindex="-1"></a><span class="st">      {X, T}-&gt;Y</span></span>
<span id="cb49-1096"><a href="#cb49-1096" aria-hidden="true" tabindex="-1"></a><span class="st">      u-&gt;Y</span></span>
<span id="cb49-1097"><a href="#cb49-1097" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb49-1098"><a href="#cb49-1098" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb49-1099"><a href="#cb49-1099" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1100"><a href="#cb49-1100" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1101"><a href="#cb49-1101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1102"><a href="#cb49-1102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1103"><a href="#cb49-1103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1104"><a href="#cb49-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1105"><a href="#cb49-1105" aria-hidden="true" tabindex="-1"></a>There are two ways to estimate $\theta$ using <span class="in">`DoublMLPLR()`</span>. They differ in how their score functions are defined. You pick either one of the two:</span>
<span id="cb49-1106"><a href="#cb49-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1107"><a href="#cb49-1107" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`partialling-out`</span>: $<span class="co">[</span><span class="ot">Y - l(X) - \theta(D-m(X))</span><span class="co">][D-m(X)]</span>$</span>
<span id="cb49-1108"><a href="#cb49-1108" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`IV-type`</span>: $<span class="co">[</span><span class="ot">Y - \theta D - g(X)</span><span class="co">][D-m(X)]</span>$</span>
<span id="cb49-1109"><a href="#cb49-1109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1110"><a href="#cb49-1110" aria-hidden="true" tabindex="-1"></a>Since $g(X)$ and $m(X)$ themselves appear in the data generating process (@eq-plr), it is clear what  they are. However, it is not immediately clear what $l(X)$ represents. $l(X)$ refers to $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$.</span>
<span id="cb49-1111"><a href="#cb49-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1112"><a href="#cb49-1112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1113"><a href="#cb49-1113" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1114"><a href="#cb49-1114" aria-hidden="true" tabindex="-1"></a>l(X) = E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span> &amp; = E<span class="co">[</span><span class="ot">\theta d + g_0(X) + \mu</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb49-1115"><a href="#cb49-1115" aria-hidden="true" tabindex="-1"></a>              &amp; = \theta E<span class="co">[</span><span class="ot">d|X</span><span class="co">]</span> + E<span class="co">[</span><span class="ot">g_0(X)</span><span class="co">]</span> + E<span class="co">[</span><span class="ot">\mu|X</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb49-1116"><a href="#cb49-1116" aria-hidden="true" tabindex="-1"></a>              &amp; = \theta m_0(X) + g_0(X) \;\; \mbox{(by the assumptions on the error terms)}<span class="sc">\\</span></span>
<span id="cb49-1117"><a href="#cb49-1117" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1118"><a href="#cb49-1118" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1119"><a href="#cb49-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1120"><a href="#cb49-1120" aria-hidden="true" tabindex="-1"></a>Given this, the scores functions can be rewritten as:</span>
<span id="cb49-1121"><a href="#cb49-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1122"><a href="#cb49-1122" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`partialling-out`</span>: $\mu\cdot \eta$</span>
<span id="cb49-1123"><a href="#cb49-1123" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`IV-type`</span>: $\mu\cdot \eta$</span>
<span id="cb49-1124"><a href="#cb49-1124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1125"><a href="#cb49-1125" aria-hidden="true" tabindex="-1"></a>Therefore, the two score functions are actually identical in meaning, but represented by different terms, which result in different equations to calculate $\hat{\theta}$. Here are how $\theta$ is identified for the two scores functions:</span>
<span id="cb49-1126"><a href="#cb49-1126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1127"><a href="#cb49-1127" aria-hidden="true" tabindex="-1"></a>**`partialling-out`**</span>
<span id="cb49-1128"><a href="#cb49-1128" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1129"><a href="#cb49-1129" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1130"><a href="#cb49-1130" aria-hidden="true" tabindex="-1"></a>E\large(\normalsize<span class="co">[</span><span class="ot">Y - l(X) - \theta(D-m(X))</span><span class="co">][D-m(X)]</span>\large)\normalsize = 0 <span class="sc">\\</span></span>
<span id="cb49-1131"><a href="#cb49-1131" aria-hidden="true" tabindex="-1"></a>\theta = \frac{E<span class="co">[</span><span class="ot">(Y - l(X))(D-m(X))</span><span class="co">]</span>}{E<span class="co">[</span><span class="ot">(D-m(X))(D-m(X))</span><span class="co">]</span>}</span>
<span id="cb49-1132"><a href="#cb49-1132" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1133"><a href="#cb49-1133" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1134"><a href="#cb49-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1135"><a href="#cb49-1135" aria-hidden="true" tabindex="-1"></a>The empirical analog of this moment condition is</span>
<span id="cb49-1136"><a href="#cb49-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1137"><a href="#cb49-1137" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1138"><a href="#cb49-1138" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1139"><a href="#cb49-1139" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = \frac{\sum_{i=1}^N (Y_i - l(X_i))(D_i-m(X_i))}{\sum_{i=1}^N (D_i-m(X_i))(D_i-m(X_i))}</span>
<span id="cb49-1140"><a href="#cb49-1140" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1141"><a href="#cb49-1141" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1142"><a href="#cb49-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1143"><a href="#cb49-1143" aria-hidden="true" tabindex="-1"></a>**`IV-type`**</span>
<span id="cb49-1144"><a href="#cb49-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1145"><a href="#cb49-1145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1146"><a href="#cb49-1146" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1147"><a href="#cb49-1147" aria-hidden="true" tabindex="-1"></a>\hat{\theta} = \frac{\sum_{i=1}^N (Y_i - g(X_i))(D_i-m(X_i))}{\sum_{i=1}^N D_i(D_i-m(X_i))}</span>
<span id="cb49-1148"><a href="#cb49-1148" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1149"><a href="#cb49-1149" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1150"><a href="#cb49-1150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1151"><a href="#cb49-1151" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb49-1152"><a href="#cb49-1152" aria-hidden="true" tabindex="-1"></a>$D_i-m(X_i)$ is acting like an instrument.</span>
<span id="cb49-1153"><a href="#cb49-1153" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1154"><a href="#cb49-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1155"><a href="#cb49-1155" aria-hidden="true" tabindex="-1"></a>The choice of the score function results in different steps to estimate $\theta$ and what you need to supply to <span class="in">`DoublMLPLR()`</span>. $g_0(X)$ is estimated in several steps (see @sec-dml-naive) as it needs to remove the effect of $\theta D$ before estimating only $g_0(X)$. $l_0(X)$, however, is estimated by simply regressing $Y$ on $X$. In running <span class="in">`DoublMLPLR()`</span>, there are three key options:</span>
<span id="cb49-1156"><a href="#cb49-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1157"><a href="#cb49-1157" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`ml_l`</span>: ML method to use to estimate $l(X)$</span>
<span id="cb49-1158"><a href="#cb49-1158" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`ml_m`</span>: ML method to use to estimate $m(X)$</span>
<span id="cb49-1159"><a href="#cb49-1159" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`ml_g`</span>: ML method to use to estimate $g(X)$</span>
<span id="cb49-1160"><a href="#cb49-1160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1161"><a href="#cb49-1161" aria-hidden="true" tabindex="-1"></a>When <span class="in">`partialling-out`</span> is selected, you need to specify <span class="in">`ml_l`</span>  and <span class="in">`ml_m`</span>. However, you do not need to specify the <span class="in">`ml_g`</span>. When <span class="in">`IV-type`</span> is used you need to specify all three. This is because estimating <span class="in">`g(X)`</span> involves first estimating <span class="in">`l(X)`</span> (see @sec-dml-naive). So, the <span class="in">`partialling-out`</span> option requires a smaller number of steps and easier to specify for the user. </span>
<span id="cb49-1162"><a href="#cb49-1162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1163"><a href="#cb49-1163" aria-hidden="true" tabindex="-1"></a>Let's implement <span class="in">`DoublMLPLR()`</span> using a synthetic dataset that follows the DGP represented by @eq-simple-synthetic. We can use <span class="in">`make_plr_CCDDHNR2018()`</span> to create such a dataset.</span>
<span id="cb49-1164"><a href="#cb49-1164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1167"><a href="#cb49-1167" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1168"><a href="#cb49-1168" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-1169"><a href="#cb49-1169" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb49-1170"><a href="#cb49-1170" aria-hidden="true" tabindex="-1"></a>  <span class="fu">make_plr_CCDDHNR2018</span>(</span>
<span id="cb49-1171"><a href="#cb49-1171" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>, </span>
<span id="cb49-1172"><a href="#cb49-1172" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> <span class="dv">500</span>, </span>
<span id="cb49-1173"><a href="#cb49-1173" aria-hidden="true" tabindex="-1"></a>    <span class="at">dim_x =</span> <span class="dv">20</span>, </span>
<span id="cb49-1174"><a href="#cb49-1174" aria-hidden="true" tabindex="-1"></a>    <span class="at">return_type =</span> <span class="st">'data.table'</span></span>
<span id="cb49-1175"><a href="#cb49-1175" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1176"><a href="#cb49-1176" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1177"><a href="#cb49-1177" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1178"><a href="#cb49-1178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1179"><a href="#cb49-1179" aria-hidden="true" tabindex="-1"></a>Note that the treatment variable is continuous in this dataset.</span>
<span id="cb49-1180"><a href="#cb49-1180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1181"><a href="#cb49-1181" aria-hidden="true" tabindex="-1"></a>We first need to create a <span class="in">`DoubleMLData`</span> object from the train data using <span class="in">`DoubleMLData$new()`</span>. Specify the dependent variable using the <span class="in">`y_col`</span> option and the treatment variable(s) by <span class="in">`d_cols`</span>. The rest of the variables in the dataset provided will be regarded as covariates.</span>
<span id="cb49-1182"><a href="#cb49-1182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1185"><a href="#cb49-1185" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1186"><a href="#cb49-1186" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-1187"><a href="#cb49-1187" aria-hidden="true" tabindex="-1"></a>obj_dml_data <span class="ot">&lt;-</span> </span>
<span id="cb49-1188"><a href="#cb49-1188" aria-hidden="true" tabindex="-1"></a>  DoubleMLData<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb49-1189"><a href="#cb49-1189" aria-hidden="true" tabindex="-1"></a>    data, </span>
<span id="cb49-1190"><a href="#cb49-1190" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_col =</span> <span class="st">"y"</span>, </span>
<span id="cb49-1191"><a href="#cb49-1191" aria-hidden="true" tabindex="-1"></a>    <span class="at">d_cols =</span> <span class="st">"d"</span></span>
<span id="cb49-1192"><a href="#cb49-1192" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1193"><a href="#cb49-1193" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1194"><a href="#cb49-1194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1195"><a href="#cb49-1195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1196"><a href="#cb49-1196" aria-hidden="true" tabindex="-1"></a>Now, let's specify <span class="in">`ml_l`</span>, <span class="in">`ml_m`</span>, and <span class="in">`ml_g`</span>. The <span class="in">`DoubleML`</span> follows <span class="in">`mlr3`</span> (see @sec-mlr3 for how to use <span class="in">`mlr3`</span>).</span>
<span id="cb49-1197"><a href="#cb49-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1200"><a href="#cb49-1200" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1201"><a href="#cb49-1201" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb49-1202"><a href="#cb49-1202" aria-hidden="true" tabindex="-1"></a>ml_l <span class="ot">&lt;-</span> </span>
<span id="cb49-1203"><a href="#cb49-1203" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lrn</span>(</span>
<span id="cb49-1204"><a href="#cb49-1204" aria-hidden="true" tabindex="-1"></a>    <span class="st">"regr.ranger"</span>,</span>
<span id="cb49-1205"><a href="#cb49-1205" aria-hidden="true" tabindex="-1"></a>    <span class="at">num.trees =</span> <span class="dv">500</span>, </span>
<span id="cb49-1206"><a href="#cb49-1206" aria-hidden="true" tabindex="-1"></a>    <span class="at">mtry =</span> <span class="dv">15</span>, </span>
<span id="cb49-1207"><a href="#cb49-1207" aria-hidden="true" tabindex="-1"></a>    <span class="at">min.node.size =</span> <span class="dv">5</span></span>
<span id="cb49-1208"><a href="#cb49-1208" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1209"><a href="#cb49-1209" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1210"><a href="#cb49-1210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1211"><a href="#cb49-1211" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1212"><a href="#cb49-1212" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1213"><a href="#cb49-1213" aria-hidden="true" tabindex="-1"></a>Let's use the same ML method for <span class="in">`ml_m`</span> and <span class="in">`ml_g`</span> (you can use any appropriate ML methods). We can simply use the <span class="in">`clone()`</span> method to replicate <span class="in">`ml_l`</span>.</span>
<span id="cb49-1214"><a href="#cb49-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1217"><a href="#cb49-1217" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1218"><a href="#cb49-1218" aria-hidden="true" tabindex="-1"></a>ml_m <span class="ot">&lt;-</span> ml_l<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb49-1219"><a href="#cb49-1219" aria-hidden="true" tabindex="-1"></a>ml_g <span class="ot">&lt;-</span> ml_l<span class="sc">$</span><span class="fu">clone</span>()</span>
<span id="cb49-1220"><a href="#cb49-1220" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1221"><a href="#cb49-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1222"><a href="#cb49-1222" aria-hidden="true" tabindex="-1"></a>We now set up the <span class="in">`DoubleMLPLR`</span> estimator by providing a <span class="in">`DoubleMLData`</span> and ML methods. By default, <span class="in">`score`</span> is set to <span class="in">`"partialling out"`</span>, so we do not need to provide <span class="in">`ml_g`</span>. The <span class="in">`apply_cross_fitting`</span> option is set to <span class="in">`TRUE`</span> by default.</span>
<span id="cb49-1223"><a href="#cb49-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1226"><a href="#cb49-1226" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1227"><a href="#cb49-1227" aria-hidden="true" tabindex="-1"></a>dml_plr_obj <span class="ot">&lt;-</span> DoubleMLPLR<span class="sc">$</span><span class="fu">new</span>(obj_dml_data, ml_l, ml_m)</span>
<span id="cb49-1228"><a href="#cb49-1228" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1229"><a href="#cb49-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1230"><a href="#cb49-1230" aria-hidden="true" tabindex="-1"></a>We can fit the model by invoking <span class="in">`fit()`</span> on <span class="in">`dml_plr_obj`</span>.</span>
<span id="cb49-1231"><a href="#cb49-1231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1234"><a href="#cb49-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1235"><a href="#cb49-1235" aria-hidden="true" tabindex="-1"></a>dml_plr_obj<span class="sc">$</span><span class="fu">fit</span>()</span>
<span id="cb49-1236"><a href="#cb49-1236" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1237"><a href="#cb49-1237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1238"><a href="#cb49-1238" aria-hidden="true" tabindex="-1"></a>See the results with <span class="in">`print()`</span>. You can see $\hat{\theta}$ at the bottom.</span>
<span id="cb49-1239"><a href="#cb49-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1242"><a href="#cb49-1242" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1243"><a href="#cb49-1243" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dml_plr_obj)</span>
<span id="cb49-1244"><a href="#cb49-1244" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1245"><a href="#cb49-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1246"><a href="#cb49-1246" aria-hidden="true" tabindex="-1"></a>If you are using <span class="in">`IV-type`</span>, then you need to provide <span class="in">`ml_g`</span> as well like below.</span>
<span id="cb49-1247"><a href="#cb49-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1250"><a href="#cb49-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1251"><a href="#cb49-1251" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up ===#</span></span>
<span id="cb49-1252"><a href="#cb49-1252" aria-hidden="true" tabindex="-1"></a>dml_plr_obj_iv <span class="ot">&lt;-</span> </span>
<span id="cb49-1253"><a href="#cb49-1253" aria-hidden="true" tabindex="-1"></a>  DoubleMLPLR<span class="sc">$</span><span class="fu">new</span>(</span>
<span id="cb49-1254"><a href="#cb49-1254" aria-hidden="true" tabindex="-1"></a>    obj_dml_data, </span>
<span id="cb49-1255"><a href="#cb49-1255" aria-hidden="true" tabindex="-1"></a>    ml_l, </span>
<span id="cb49-1256"><a href="#cb49-1256" aria-hidden="true" tabindex="-1"></a>    ml_m, </span>
<span id="cb49-1257"><a href="#cb49-1257" aria-hidden="true" tabindex="-1"></a>    ml_g,</span>
<span id="cb49-1258"><a href="#cb49-1258" aria-hidden="true" tabindex="-1"></a>    <span class="at">score =</span> <span class="st">"IV-type"</span></span>
<span id="cb49-1259"><a href="#cb49-1259" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1260"><a href="#cb49-1260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1261"><a href="#cb49-1261" aria-hidden="true" tabindex="-1"></a><span class="co">#=== fit ===#</span></span>
<span id="cb49-1262"><a href="#cb49-1262" aria-hidden="true" tabindex="-1"></a>dml_plr_obj_iv<span class="sc">$</span><span class="fu">fit</span>()</span>
<span id="cb49-1263"><a href="#cb49-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1264"><a href="#cb49-1264" aria-hidden="true" tabindex="-1"></a><span class="co">#=== print the results ===#</span></span>
<span id="cb49-1265"><a href="#cb49-1265" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(dml_plr_obj_iv)</span>
<span id="cb49-1266"><a href="#cb49-1266" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1267"><a href="#cb49-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1268"><a href="#cb49-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1269"><a href="#cb49-1269" aria-hidden="true" tabindex="-1"></a><span class="fu">### Partially linear IV model</span></span>
<span id="cb49-1270"><a href="#cb49-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1271"><a href="#cb49-1271" aria-hidden="true" tabindex="-1"></a>When using observational data, it is rarely the case that conditional unconfoundedness of the treatment is satisfied. In such a case, you may want to consider a DML-IV approach implemented by <span class="in">`DoubleMLPLIV()`</span>. Just like IV for linear models, finding the right instrument is critical for the DML-IV approach to be consistent.</span>
<span id="cb49-1272"><a href="#cb49-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1273"><a href="#cb49-1273" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb49-1274"><a href="#cb49-1274" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb49-1275"><a href="#cb49-1275" aria-hidden="true" tabindex="-1"></a>y = \theta d + g_0(X) + \mu <span class="sc">\\</span></span>
<span id="cb49-1276"><a href="#cb49-1276" aria-hidden="true" tabindex="-1"></a>Z = m_0(X) + \varepsilon <span class="sc">\\</span></span>
<span id="cb49-1277"><a href="#cb49-1277" aria-hidden="true" tabindex="-1"></a>d = r_0(X) + \eta</span>
<span id="cb49-1278"><a href="#cb49-1278" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb49-1279"><a href="#cb49-1279" aria-hidden="true" tabindex="-1"></a>$$ {#eq-plr}</span>
<span id="cb49-1280"><a href="#cb49-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1281"><a href="#cb49-1281" aria-hidden="true" tabindex="-1"></a>When $\varspsilon$ and $\mu$ are correlated, <span class="in">`DoubleMLPLR()`</span> is inconsistent. However, as long as the following assumptions are satisfied, <span class="in">`DoubleMLPLIV()`</span> is consistent.</span>
<span id="cb49-1282"><a href="#cb49-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1283"><a href="#cb49-1283" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb49-1284"><a href="#cb49-1284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1285"><a href="#cb49-1285" aria-hidden="true" tabindex="-1"></a>**Assumptions on the error terms**</span>
<span id="cb49-1286"><a href="#cb49-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1287"><a href="#cb49-1287" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\mu|Z,X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1288"><a href="#cb49-1288" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\varepsilon|X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1289"><a href="#cb49-1289" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\varepsilon\cdot \mu|Z, X</span><span class="co">]</span> = 0$</span>
<span id="cb49-1290"><a href="#cb49-1290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1291"><a href="#cb49-1291" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb49-1292"><a href="#cb49-1292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1293"><a href="#cb49-1293" aria-hidden="true" tabindex="-1"></a>Here is the causal diagram for the partially linear model of interest. As you can see, the treatment variable $T$ is confounded as $\mu$ affects both $Y$ and $T$ (through $\eta$). </span>
<span id="cb49-1294"><a href="#cb49-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1297"><a href="#cb49-1297" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb49-1298"><a href="#cb49-1298" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb49-1299"><a href="#cb49-1299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1300"><a href="#cb49-1300" aria-hidden="true" tabindex="-1"></a>DiagrammeR<span class="sc">::</span><span class="fu">grViz</span>(</span>
<span id="cb49-1301"><a href="#cb49-1301" aria-hidden="true" tabindex="-1"></a>  <span class="fu">paste0</span>(</span>
<span id="cb49-1302"><a href="#cb49-1302" aria-hidden="true" tabindex="-1"></a>  <span class="st">"</span></span>
<span id="cb49-1303"><a href="#cb49-1303" aria-hidden="true" tabindex="-1"></a><span class="st">  digraph {</span></span>
<span id="cb49-1304"><a href="#cb49-1304" aria-hidden="true" tabindex="-1"></a><span class="st">    graph [ranksep = 0.6]</span></span>
<span id="cb49-1305"><a href="#cb49-1305" aria-hidden="true" tabindex="-1"></a><span class="st">    node [shape = box]</span></span>
<span id="cb49-1306"><a href="#cb49-1306" aria-hidden="true" tabindex="-1"></a><span class="st">      Y [label = 'Y']</span></span>
<span id="cb49-1307"><a href="#cb49-1307" aria-hidden="true" tabindex="-1"></a><span class="st">      X [label = 'X']</span></span>
<span id="cb49-1308"><a href="#cb49-1308" aria-hidden="true" tabindex="-1"></a><span class="st">      T [label = 'T']</span></span>
<span id="cb49-1309"><a href="#cb49-1309" aria-hidden="true" tabindex="-1"></a><span class="st">      Z [label = 'Z']</span></span>
<span id="cb49-1310"><a href="#cb49-1310" aria-hidden="true" tabindex="-1"></a><span class="st">      varep [label = '\U03B5']</span></span>
<span id="cb49-1311"><a href="#cb49-1311" aria-hidden="true" tabindex="-1"></a><span class="st">      mu [label = '\U03BC']</span></span>
<span id="cb49-1312"><a href="#cb49-1312" aria-hidden="true" tabindex="-1"></a><span class="st">      eta [label = '\U03B7']</span></span>
<span id="cb49-1313"><a href="#cb49-1313" aria-hidden="true" tabindex="-1"></a><span class="st">    edge [minlen = 2]</span></span>
<span id="cb49-1314"><a href="#cb49-1314" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;Y</span></span>
<span id="cb49-1315"><a href="#cb49-1315" aria-hidden="true" tabindex="-1"></a><span class="st">      T-&gt;Y</span></span>
<span id="cb49-1316"><a href="#cb49-1316" aria-hidden="true" tabindex="-1"></a><span class="st">      Z-&gt;T</span></span>
<span id="cb49-1317"><a href="#cb49-1317" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;T</span></span>
<span id="cb49-1318"><a href="#cb49-1318" aria-hidden="true" tabindex="-1"></a><span class="st">      X-&gt;Z</span></span>
<span id="cb49-1319"><a href="#cb49-1319" aria-hidden="true" tabindex="-1"></a><span class="st">      varep-&gt;Z</span></span>
<span id="cb49-1320"><a href="#cb49-1320" aria-hidden="true" tabindex="-1"></a><span class="st">      mu-&gt;{Y, eta}</span></span>
<span id="cb49-1321"><a href="#cb49-1321" aria-hidden="true" tabindex="-1"></a><span class="st">      eta-&gt;{T, mu}</span></span>
<span id="cb49-1322"><a href="#cb49-1322" aria-hidden="true" tabindex="-1"></a><span class="st">    { rank = same; Y; Z; varep}</span></span>
<span id="cb49-1323"><a href="#cb49-1323" aria-hidden="true" tabindex="-1"></a><span class="st">    { rank = same; X; T; mu}</span></span>
<span id="cb49-1324"><a href="#cb49-1324" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb49-1325"><a href="#cb49-1325" aria-hidden="true" tabindex="-1"></a><span class="st">  "</span></span>
<span id="cb49-1326"><a href="#cb49-1326" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb49-1327"><a href="#cb49-1327" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb49-1328"><a href="#cb49-1328" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb49-1329"><a href="#cb49-1329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1330"><a href="#cb49-1330" aria-hidden="true" tabindex="-1"></a>Just like <span class="in">`DoublMLPLR()`</span>, there are two ways to estimate $\theta$ using <span class="in">`DoublMLPLIV()`</span>. The two score functions are:</span>
<span id="cb49-1331"><a href="#cb49-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1332"><a href="#cb49-1332" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`partialling-out`</span>: $<span class="co">[</span><span class="ot">Y - l(X) - \theta(D-r(X))</span><span class="co">][Z-m(X)]</span>$</span>
<span id="cb49-1333"><a href="#cb49-1333" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`IV-type`</span>: $<span class="co">[</span><span class="ot">Y - \theta D - g(X)</span><span class="co">][Z-m(X)]</span>$</span>
<span id="cb49-1334"><a href="#cb49-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1335"><a href="#cb49-1335" aria-hidden="true" tabindex="-1"></a>, where $r(X) = E<span class="co">[</span><span class="ot">D|X</span><span class="co">]</span>$. So, $r(X)$ is the same as $m(X)$ in the partially line model case. $m(X)$ represents $E<span class="co">[</span><span class="ot">Z|X</span><span class="co">]</span>$ in the IV model.</span>
<span id="cb49-1336"><a href="#cb49-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1337"><a href="#cb49-1337" aria-hidden="true" tabindex="-1"></a>Let $\tilde{Z}$, $\tilde{D}$, $\tilde{Y}_l$, and $\tilde{Y}_g$ denote $Z-m(X)$, $D-r(X)$, $Y-l(X)$, and $Y-g(X)$, respectively.</span>
<span id="cb49-1338"><a href="#cb49-1338" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1339"><a href="#cb49-1339" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`partialling-out`</span>: $\theta = (\tilde{Z}'\tilde{D})^{-1}\tilde{Z}\tilde{Y}_l$</span>
<span id="cb49-1340"><a href="#cb49-1340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1341"><a href="#cb49-1341" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`IV-type`</span>: $\theta = (\tilde{Z}'D)^{-1}\tilde{Z}\tilde{Y}_g$</span>
<span id="cb49-1342"><a href="#cb49-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1343"><a href="#cb49-1343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1344"><a href="#cb49-1344" aria-hidden="true" tabindex="-1"></a><span class="fu">## Suggested Exercises</span></span>
<span id="cb49-1345"><a href="#cb49-1345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1346"><a href="#cb49-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1347"><a href="#cb49-1347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1348"><a href="#cb49-1348" aria-hidden="true" tabindex="-1"></a><span class="fu">## References {.unnumbered}</span></span>
<span id="cb49-1349"><a href="#cb49-1349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1350"><a href="#cb49-1350" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">"refs"</span><span class="kw">&gt;&lt;/div&gt;</span></span>
<span id="cb49-1351"><a href="#cb49-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1352"><a href="#cb49-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-1353"><a href="#cb49-1353" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>