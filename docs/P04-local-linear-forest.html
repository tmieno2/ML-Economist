<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 9&nbsp; Local Linear Forest</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C0P-causal-ml.html" rel="next">
<link href="./P03-xgb.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C04-cf-extension.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Extensions of Causal Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C05-causal-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Model Selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Programming Guide: R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code> in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Programming Guide: Python</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-01-scikitlearn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction using <code>scikitlearn</code></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-02-CATE-econml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">CATE estimation using <code>econml</code></span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link active" data-scroll-target="#theoretical-background"> <span class="header-section-number">9.1</span> Theoretical background</a></li>
  <li><a href="#performance-comparison-llf-v.s.-rf" id="toc-performance-comparison-llf-v.s.-rf" class="nav-link" data-scroll-target="#performance-comparison-llf-v.s.-rf"> <span class="header-section-number">9.2</span> Performance comparison: LLF v.s. RF</a>
  <ul class="collapse">
  <li><a href="#dgp-1" id="toc-dgp-1" class="nav-link" data-scroll-target="#dgp-1"> <span class="header-section-number">9.2.1</span> DGP 1</a></li>
  <li><a href="#dgp-2" id="toc-dgp-2" class="nav-link" data-scroll-target="#dgp-2"> <span class="header-section-number">9.2.2</span> DGP 2</a></li>
  </ul></li>
  <li><a href="#extension-to-other-grf-methods" id="toc-extension-to-other-grf-methods" class="nav-link" data-scroll-target="#extension-to-other-grf-methods"> <span class="header-section-number">9.3</span> Extension to other GRF methods</a></li>
  <li><a href="#implementation" id="toc-implementation" class="nav-link" data-scroll-target="#implementation"> <span class="header-section-number">9.4</span> Implementation</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/P04-local-linear-forest.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>Local linear forest (LLF) is an extension of random forest (RF) and also a generalized random forest (GRF) <span class="citation" data-cites="friedberg2020local">(<a href="#ref-friedberg2020local" role="doc-biblioref">Friedberg et al. 2020</a>)</span>. We first see that RF is actually a special case of local constant regression. We will then see how LLF builds on RF from the view point of a local regression method.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What you will learn
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>How LLF works in relation to RF and local regression</li>
<li>How LLF performs compared to RF</li>
<li>How the idea of LLF can be applied to other GRF methods</li>
<li>How to train LLF using R and Python</li>
</ul>
</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Background knowledge
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>(necessary) random forest (<a href="P01-random-forest.html#sec-rf"><span>Section&nbsp;6.2</span></a>)</li>
<li>(necessary) local regression (<a href="B01-nonlinear.html#sec-local"><span>Section&nbsp;1.3</span></a>)</li>
<li>(preferred) generalized random forest (<a href="E02-grf.html"><span>Chapter&nbsp;17</span></a>)</li>
<li>(preferred) ridge regression (<a href="B04-regularization.html#sec-ridge-en"><span>Section&nbsp;4.3</span></a>)</li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Packages to load for replication
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grf)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="theoretical-background" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="theoretical-background"><span class="header-section-number">9.1</span> Theoretical background</h2>
<p>Suppose <span class="math inline">\(T\)</span> tress have been built after a random forest model is trained on a dataset. Now, let <span class="math inline">\(\eta_{i,t}(X)\)</span> takes <span class="math inline">\(1\)</span> if observation <span class="math inline">\(i\)</span> belongs to the same leaf as <span class="math inline">\(X\)</span> in tree <span class="math inline">\(t\)</span>, where <span class="math inline">\(X\)</span> is a vector of covariates (<span class="math inline">\(K\)</span> variables). Then, the RF’s predicted value of <span class="math inline">\(y\)</span> conditional on a particular value of <span class="math inline">\(X\)</span> (say, <span class="math inline">\(X_0\)</span>) can be written as follows:</p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}(X_0) = \frac{1}{T} \cdot\sum_{t=1}^T\sum_{i=1}^N \frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i
\end{aligned}
\]</span></p>
<p>Note that <span class="math inline">\(\sum_{i=1}^N\eta_{i,t}(X_0)\)</span> represents the number of observations in the same leaf as <span class="math inline">\(X_0\)</span>. Therefore, <span class="math inline">\(\sum_{i=1}^N \frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i\)</span> is the average value of <span class="math inline">\(y\)</span> of the leaf that <span class="math inline">\(X_0\)</span> belongs to. So, while looking slightly complicated, it is the average value of <span class="math inline">\(y\)</span> of the tree <span class="math inline">\(X_0\)</span> belongs to averaged across the trees.</p>
<p>We can switch the summations like this,</p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}(X_0) = \sum_{i=1}^N \cdot\frac{1}{T}\sum_{t=1}^T\frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\alpha(X_i, X_0)\)</span> denote <span class="math inline">\(\frac{1}{T}\sum_{t=1}^T\frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\)</span>. Then, we can rewrite the above equation as</p>
<p><span class="math display">\[
\begin{aligned}
\hat{y}(X_0) = \sum_{i=1}^N \alpha(X_i,X_0) \cdot y_i
\end{aligned}
\]</span></p>
<p>It is easy to show that <span class="math inline">\(\hat{y}(X_0)\)</span> is a solution to the following minimization problem.</p>
<p><span id="eq-ll-constant"><span class="math display">\[
\begin{aligned}
Min_{\theta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot[y_i -\theta]^2
\end{aligned}
\tag{9.1}\]</span></span></p>
<p>In this formulation of the problem, <span class="math inline">\(\alpha(X_i,X_0)\)</span> can be considered the weight given to observation <span class="math inline">\(i\)</span>. By definition,</p>
<ul>
<li><span class="math inline">\(0 \leq \alpha(X_i,X_0) \leq 1\)</span></li>
<li><span class="math inline">\(\sum_{i=1}^N \alpha(X_i,X_0) = 1\)</span></li>
</ul>
<p>You may notice that <a href="E02-grf.html#eq-ll-constant">Equation&nbsp;<span>17.1</span></a> is actually a special case of local constant regression where the individual weights are <span class="math inline">\(\alpha(X_i, X_0)\)</span>. Roughly speaking, <span class="math inline">\(\alpha(X_i, X_0)\)</span> measures how often observation <span class="math inline">\(i\)</span> share the same leaves as the evaluation point (<span class="math inline">\(X_0\)</span>) across <span class="math inline">\(T\)</span> trees. So, it measures how similar <span class="math inline">\(X_i\)</span> is to <span class="math inline">\(X_0\)</span> in the RF way, but not based on euclidean distance (which is subject to curse of dimensionality). So, RF is actually a local <span style="color:blue">constant</span> regression with a special way of distributing weights to the individual observations. This interpretation leads to a natural extension. Why don’t we solve local <span style="color:blue">linear</span> regression problem instead, which would be more appropriate if <span class="math inline">\(y\)</span> is a smooth function of <span class="math inline">\(X\)</span>?</p>
<p>Rewriting <a href="E02-grf.html#eq-ll-constant">Equation&nbsp;<span>17.1</span></a> as a local linear regression problem.</p>
<p><span id="eq-ll"><span class="math display">\[
\begin{aligned}
Min_{\mu, \beta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot[y_i -\mu - (X_i - X_0)\beta]^2
\end{aligned}
\tag{9.2}\]</span></span></p>
<p>where <span class="math inline">\(\mu\)</span> is a scalar (intercept) and <span class="math inline">\(\beta\)</span> is a vector of parameters (<span class="math inline">\(K \times 1\)</span>).</p>
<p>This approach was proposed by <span class="citation" data-cites="Bloniarz2016">Bloniarz et al. (<a href="#ref-Bloniarz2016" role="doc-biblioref">2016</a>)</span> and they showed modest improvement over RF. LLF by <span class="citation" data-cites="friedberg2020local">Friedberg et al. (<a href="#ref-friedberg2020local" role="doc-biblioref">2020</a>)</span> differ from this approach in two important ways.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
LLF
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>Modify the splitting process in a way that the resulting splitting rules (and thus weights) are more suitable to the second stage local linear regression<br>
</li>
<li>At the local linear regression stage, use ridge regularization</li>
</ol>
</div>
</div>
<p>Let’s look at the first modification. In RF, when deciding how to split a node (parent node), we choose a split that solves the following problem:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{1}{N_1}\sum_{i\in C_1}(Y_i - \bar{Y_1}) + \frac{1}{N_2}\sum_{i\in C_2}(Y_i - \bar{Y_2})
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span> are child nodes, and <span class="math inline">\(\bar{Y_1}\)</span> and <span class="math inline">\(\bar{Y_2}\)</span> are the mean value of the outcome for <span class="math inline">\(C_1\)</span> and <span class="math inline">\(C_2\)</span>, respectively. Instead, LLF by <span class="citation" data-cites="friedberg2020local">Friedberg et al. (<a href="#ref-friedberg2020local" role="doc-biblioref">2020</a>)</span> first regresses <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> using ridge regression using the observations in the parent node, finds the residuals, and then uses the residuals in place of <span class="math inline">\(Y\)</span> itself.</p>
<p>Now, let’s look at the second modification. LLF implemented by the <code>grf</code> package adds the ridge penalty to avoid over-fitting and solve the following problem:</p>
<p><span id="eq-ll-ridge"><span class="math display">\[
\begin{aligned}
Min_{\mu, \beta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot[y_i -\mu - (X_i - X_0)\beta]^2 + \lambda||\beta||^2_2
\end{aligned}
\tag{9.3}\]</span></span></p>
<p>where <span class="math inline">\(\lambda\)</span> is the regularization parameter. LLF estimator is a weighted ridge regression, and it has a nice analytical solution (just like a regular ridge regression). With the following notations,</p>
<ul>
<li><span class="math inline">\(A\)</span>: the diagonal matrix where its diagonal element at <span class="math inline">\(\{i, i\}\)</span> is the weight for observation <span class="math inline">\(i\)</span>, (<span class="math inline">\(\alpha(X_i,X_0)\)</span>, obtained based on the trees grown using the modified splitting process.</li>
<li><span class="math inline">\(\Delta\)</span>: the <span class="math inline">\(N \times K\)</span> (the intercept plus <span class="math inline">\(K-1\)</span> covariates) matrix where <span class="math inline">\(\Delta_{i,1} = 1\)</span> and <span class="math inline">\(\Delta_{i,j} = x_{i,j} - x_{0,j}\)</span>.</li>
<li><span class="math inline">\(J\)</span>: <span class="math inline">\((K+1) \times (K+1)\)</span> diagonal matrix where its diagonal elements are all <span class="math inline">\(1\)</span> except <span class="math inline">\(J_{1,1}\)</span>, which is 0 to not penalize the intercept.</li>
<li><span class="math inline">\(\theta\)</span>: <span class="math inline">\(\{\mu, \beta\}\)</span></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}_{llf} = (\Delta'A\Delta + \lambda J)^{-1}\Delta'AY
\end{aligned}
\]</span></p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Terminology alert
</div>
</div>
<div class="callout-body-container callout-body">
<p>Using local linear regression at the time of prediction is termed <span style="color:blue"> local linear correction </span>by the authors of the <code>grf</code> package.</p>
</div>
</div>
<!-- ## Implementation: Training and Prediction

LLF can be implemented using `ll_linear_forest()` from the `grf` package. 


::: {.cell}

```{.r .cell-code}
ll_linear_forest()
```
:::

 -->
</section>
<section id="performance-comparison-llf-v.s.-rf" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="performance-comparison-llf-v.s.-rf"><span class="header-section-number">9.2</span> Performance comparison: LLF v.s. RF</h2>
<p>First, let’s consider the following DGP that is used in <span class="citation" data-cites="friedberg2020local">Friedberg et al. (<a href="#ref-friedberg2020local" role="doc-biblioref">2020</a>)</span>.</p>
<section id="dgp-1" class="level3" data-number="9.2.1">
<h3 data-number="9.2.1" class="anchored" data-anchor-id="dgp-1"><span class="header-section-number">9.2.1</span> DGP 1</h3>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DGP 1
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
y_i = log(1+exp(6x)) + \varepsilon
\end{aligned}
\]</span></p>
<ul>
<li><span class="math inline">\(\{X_1, \dots, X_10\} \sim U[-1, 1]^{10}\)</span></li>
<li><span class="math inline">\(\varepsilon \sim N(0, 20)\)</span></li>
</ul>
</div>
</div>
<p>We consider the following four methods presented in <span class="citation" data-cites="tab-methods">(<a href="#ref-tab-methods" role="doc-biblioref"><strong>tab-methods?</strong></a>)</span>.</p>
<div class="cell" data-tab-cap="Four methods of prediction">
<div class="cell-output-display">

<div id="ivkusuuonq" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#ivkusuuonq .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#ivkusuuonq .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ivkusuuonq .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#ivkusuuonq .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#ivkusuuonq .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ivkusuuonq .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#ivkusuuonq .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#ivkusuuonq .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#ivkusuuonq .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#ivkusuuonq .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#ivkusuuonq .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#ivkusuuonq .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#ivkusuuonq .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#ivkusuuonq .gt_from_md > :first-child {
  margin-top: 0;
}

#ivkusuuonq .gt_from_md > :last-child {
  margin-bottom: 0;
}

#ivkusuuonq .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#ivkusuuonq .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#ivkusuuonq .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#ivkusuuonq .gt_row_group_first td {
  border-top-width: 2px;
}

#ivkusuuonq .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ivkusuuonq .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#ivkusuuonq .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#ivkusuuonq .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ivkusuuonq .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#ivkusuuonq .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#ivkusuuonq .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#ivkusuuonq .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#ivkusuuonq .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ivkusuuonq .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ivkusuuonq .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#ivkusuuonq .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#ivkusuuonq .gt_left {
  text-align: left;
}

#ivkusuuonq .gt_center {
  text-align: center;
}

#ivkusuuonq .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#ivkusuuonq .gt_font_normal {
  font-weight: normal;
}

#ivkusuuonq .gt_font_bold {
  font-weight: bold;
}

#ivkusuuonq .gt_font_italic {
  font-style: italic;
}

#ivkusuuonq .gt_super {
  font-size: 65%;
}

#ivkusuuonq .gt_two_val_uncert {
  display: inline-block;
  line-height: 1em;
  text-align: right;
  font-size: 60%;
  vertical-align: -0.25em;
  margin-left: 0.1em;
}

#ivkusuuonq .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#ivkusuuonq .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#ivkusuuonq .gt_slash_mark {
  font-size: 0.7em;
  line-height: 0.7em;
  vertical-align: 0.15em;
}

#ivkusuuonq .gt_fraction_numerator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: 0.45em;
}

#ivkusuuonq .gt_fraction_denominator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: -0.05em;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Method</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Split on outcome</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1">Linear Correction</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_center">1</td>
<td class="gt_row gt_center">No</td>
<td class="gt_row gt_center">No</td></tr>
    <tr><td class="gt_row gt_center">2</td>
<td class="gt_row gt_center">No</td>
<td class="gt_row gt_center">X1</td></tr>
    <tr><td class="gt_row gt_center">3</td>
<td class="gt_row gt_center">Yes</td>
<td class="gt_row gt_center">All</td></tr>
    <tr><td class="gt_row gt_center">4</td>
<td class="gt_row gt_center">Yes</td>
<td class="gt_row gt_center">X1</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<p>Method 1 is equivalent to a standard RF estimation. Method 2 grows trees like RF, but make local linear corrections on <span class="math inline">\(X_1\)</span> at the time of prediction. This means that at the prediction stage, only <span class="math inline">\(X_1\)</span> is used in <a href="#eq-ll">Equation&nbsp;<span>9.2</span></a> instead of using all of <span class="math inline">\(10\)</span> variables in <span class="math inline">\(X\)</span>. Since we know <span class="math inline">\(X_1\)</span> is the only variable that affects <span class="math inline">\(y\)</span> in DGP 1, this way of linear correction should perform better than using all of the <span class="math inline">\(10\)</span> variables in <span class="math inline">\(X\)</span>. Of course, in practice, you do not get to do this. Method 3 splits on the residuals from ridge regression, and uses all of the <span class="math inline">\(10\)</span> variables in <span class="math inline">\(X\)</span> for linear correction. Method 4 splits on the residuals from ridge regression and uses only <span class="math inline">\(X1\)</span> for local linear correction.</p>
<p><a href="#fig-comp-rf-llf">Figure&nbsp;<span>9.1</span></a> presents how <span class="math inline">\(\hat{y}(X)\)</span> for the test data (black dots) changes according to the value of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(E[y|X]\)</span> (red line). Note that heterogeneity in <span class="math inline">\(\hat{y}(X)\)</span> at the same value of <span class="math inline">\(X_1\)</span> occurs dues to modeling error: the trained model attributed some of the variations in observed <span class="math inline">\(y\)</span> to other variables than <span class="math inline">\(X_1\)</span> even though <span class="math inline">\(X_1\)</span> is the only variable that is actually affecting <span class="math inline">\(y\)</span> as you can see in DGP 1. <a href="#fig-comp-rf-llf">Figure&nbsp;<span>9.1</span></a> indicates that irrespective of whether you split on <span class="math inline">\(y\)</span> or residuals from ridge regression, linear correction on <span class="math inline">\(X1\)</span> can substantially reduce bias. Method 4 seems to perform slightly better than Method 2 in this instance. However, when all the variables in <span class="math inline">\(X\)</span> (that include many irrelevant variables) are used for linear correction (Method 3), its benefit disappears, performing about the same as Method 1. Comparing Methods 2 and 4, the benefit of split on residual is not clear at least in this instance. Let’s run MC simulations to have a better picture of the relative performance of the four methods. In each iteration, we calculate RMSE of <span class="math inline">\(y\)</span> prediction for each method.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">78234</span>)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> X[, <span class="dv">1</span>])) <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">20</span>) <span class="sc">*</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> N)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">1</span>] <span class="ot">&lt;-</span> x_seq</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>ey <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> x_seq))</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>true_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> x_seq, <span class="at">y =</span> ey)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on outcome and ridge residuals </span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>llf_trained <span class="ot">&lt;-</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> X,</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> y,</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> X,</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> y</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions with and without linear correction</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>rf_results <span class="ot">&lt;-</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>        rf_trained, </span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 1: Split on outcome </span><span class="sc">\n</span><span class="st"> without linear correction"</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>rf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>        rf_trained, </span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test, </span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>        <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 2: Split on outcome </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span></span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a>llf_results_nlc <span class="ot">&lt;-</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>        llf_trained, </span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test</span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 3: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on all X"</span></span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>llf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a>        llf_trained, </span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test, </span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>        <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 4: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span></span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the results and plot</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a>all_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(rf_results, rf_results_lc, llf_results_nlc, llf_results_lc)</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> all_results, <span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x), <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(type <span class="sc">~</span> ., <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted Value"</span>) <span class="sc">+</span></span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"X1"</span>) <span class="sc">+</span></span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-comp-rf-llf" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="P04-local-linear-forest_files/figure-html/fig-comp-rf-llf-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 9.1: Comparison of predicted values</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-mc-four-methods">Figure&nbsp;<span>9.2</span></a> presents the distribution of RMSE for each method over <span class="math inline">\(200\)</span> iterations. As you can see, Method 4 works the best under DGP 1. However, Method 2 also works quite well and the benefit of split on residual is rather small. This is actually expected based on how DGP 1 is specified. We now look at a different DGP that illustrates when split on residuals is likely to be beneficial.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This function runs an experiment run above with a different dataset drawn from DGP 1 and returns rmse for each method</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>run_llf_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(i){</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> X[, <span class="dv">1</span>])) <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">20</span>) <span class="sc">*</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>  X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> N)</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  X_test[, <span class="dv">1</span>] <span class="ot">&lt;-</span> x_seq</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>  ey <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> x_seq))</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>  true_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> x_seq, <span class="at">y =</span> ey)</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Train on outcome and ridge residuals </span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  llf_trained <span class="ot">&lt;-</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> X,</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> y,</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>      <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>  rf_trained <span class="ot">&lt;-</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> X,</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> y</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions with and without linear correction</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>  rf_results <span class="ot">&lt;-</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>          rf_trained, </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 1: Split on outcome </span><span class="sc">\n</span><span class="st"> without linear correction"</span>] </span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>  rf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>          rf_trained, </span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test, </span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>          <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span></span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 2: Split on outcome </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span>]</span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>  llf_results_nlc <span class="ot">&lt;-</span></span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>          llf_trained, </span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 3: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on all X"</span>]</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>  llf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>          llf_trained, </span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test, </span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a>          <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 4: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span>]</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine the results and plot</span></span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a>  all_results <span class="ot">&lt;-</span> </span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(rf_results, rf_results_lc, llf_results_nlc, llf_results_lc)</span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(all_results)</span>
<span id="cb3-97"><a href="#cb3-97" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-98"><a href="#cb3-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-99"><a href="#cb3-99" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_1 &lt;-</span></span>
<span id="cb3-100"><a href="#cb3-100" aria-hidden="true" tabindex="-1"></a><span class="co">#   lapply(</span></span>
<span id="cb3-101"><a href="#cb3-101" aria-hidden="true" tabindex="-1"></a><span class="co">#     1:200,</span></span>
<span id="cb3-102"><a href="#cb3-102" aria-hidden="true" tabindex="-1"></a><span class="co">#     function(x) run_llf_sim(x)</span></span>
<span id="cb3-103"><a href="#cb3-103" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;% </span></span>
<span id="cb3-104"><a href="#cb3-104" aria-hidden="true" tabindex="-1"></a><span class="co">#   rbindlist()</span></span>
<span id="cb3-105"><a href="#cb3-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-106"><a href="#cb3-106" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2134</span>)</span>
<span id="cb3-107"><a href="#cb3-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-108"><a href="#cb3-108" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb3-109"><a href="#cb3-109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb3-110"><a href="#cb3-110" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,</span>
<span id="cb3-111"><a href="#cb3-111" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_llf_sim</span>(x),</span>
<span id="cb3-112"><a href="#cb3-112" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb3-113"><a href="#cb3-113" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb3-114"><a href="#cb3-114" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb3-115"><a href="#cb3-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-116"><a href="#cb3-116" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1 <span class="ot">&lt;-</span> </span>
<span id="cb3-117"><a href="#cb3-117" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_1) <span class="sc">+</span> </span>
<span id="cb3-118"><a href="#cb3-118" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> rmse, <span class="at">fill =</span> type), <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb3-119"><a href="#cb3-119" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb3-120"><a href="#cb3-120" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(</span>
<span id="cb3-121"><a href="#cb3-121" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb3-122"><a href="#cb3-122" aria-hidden="true" tabindex="-1"></a>    <span class="at">guide =</span> <span class="fu">guide_legend</span>(</span>
<span id="cb3-123"><a href="#cb3-123" aria-hidden="true" tabindex="-1"></a>      <span class="at">nrow =</span> <span class="dv">2</span></span>
<span id="cb3-124"><a href="#cb3-124" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb3-125"><a href="#cb3-125" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb3-126"><a href="#cb3-126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb3-127"><a href="#cb3-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-128"><a href="#cb3-128" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1</span>
<span id="cb3-129"><a href="#cb3-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-130"><a href="#cb3-130" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(g_mc_llf_1, <span class="st">"LectureNotes/Data/g_mc_llf_1.rds"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mc-four-methods" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="P04-local-linear-forest_files/figure-html/fig-mc-four-methods-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 9.2: MC simulations results</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="dgp-2" class="level3" data-number="9.2.2">
<h3 data-number="9.2.2" class="anchored" data-anchor-id="dgp-2"><span class="header-section-number">9.2.2</span> DGP 2</h3>
<p>In this section, we work on the following DGP.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DGP 2
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
y_i = 10\cdot sin(\pi x_{i,1}x_{i,2}) + 20(x_{i,3}-0.5)^2 + 10 x_{i,4} + 5 C_{i,5} + \varepsilon
\end{aligned}
\]</span></p>
<ul>
<li><span class="math inline">\(\{X_1, \dots, X_5\} \sim U[0, 1]^5\)</span></li>
<li><span class="math inline">\(\varepsilon \sim N(0, \sigma^2)\)</span></li>
</ul>
</div>
</div>
<p>This DGP is helpful in illustrating the power of split on residuals.</p>
<p>We first generate training and test datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>make_data <span class="ot">&lt;-</span> <span class="cf">function</span>(N, sigma, K)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">matrix</span>(<span class="fu">runif</span>(N <span class="sc">*</span> K), <span class="at">nrow =</span> N) <span class="sc">%&gt;%</span> </span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">gsub</span>(<span class="st">"V"</span>, <span class="st">"x"</span>, <span class="fu">names</span>(.))) <span class="sc">%&gt;%</span> </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    .[, ey <span class="sc">:</span><span class="er">=</span> <span class="dv">10</span><span class="sc">*</span><span class="fu">sin</span>(pi<span class="sc">*</span>x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">20</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span>x4 <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span>x5] <span class="sc">%&gt;%</span> </span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> ey <span class="sc">+</span> sigma <span class="sc">*</span> <span class="fu">rnorm</span>(N)]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>data_train <span class="ot">&lt;-</span> <span class="fu">make_data</span>(N, sigma, K)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>data_test <span class="ot">&lt;-</span> <span class="fu">make_data</span>(N, sigma, K)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s train RF and LLF using <code>data_train</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== RF ===#</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> data_train[, .(x1, x2, x3, x4, x5)],</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> data_train[, y]</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="co">#=== LLF ===#</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>llf_traiend <span class="ot">&lt;-</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> data_train[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> data_train[, y],</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">ll.split.weight.penalty =</span> <span class="cn">TRUE</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now predict <span class="math inline">\(y\)</span> on the test data (<code>data_test</code>) based on RF and LLF with linear corrections on all the variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>pred_data <span class="ot">&lt;-</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  data_test <span class="sc">%&gt;%</span> </span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  .[, y_hat_rf <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    rf_trained, </span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> data_test[, .(x1, x2, x3, x4, x5)],</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">linear.correction.variables =</span> <span class="dv">1</span><span class="sc">:</span>K</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  .[, y_hat_llf <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    llf_traiend, </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> data_test[, .(x1, x2, x3, x4, x5)]</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  )<span class="sc">$</span>predictions</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  ] <span class="sc">%&gt;%</span> </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  .[, .(ey, y_hat_rf, y_hat_llf)] <span class="sc">%&gt;%</span> </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"ey"</span>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><span class="citation" data-cites="tab-rf-llf-dgp2">(<a href="#ref-tab-rf-llf-dgp2" role="doc-biblioref"><strong>tab-rf-llf-dgp2?</strong></a>)</span> shows the RMSE values for RF and LLF. Since both methods here use linear correction at the time of prediction, the observed difference in their performance is attributable to the way splitting is done: split on outcome or residuals.</p>
<div class="cell" data-tab-cap="Performance measured by RMSE">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>pred_data <span class="sc">%&gt;%</span> </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>.[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((value <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>))), by <span class="ot">=</span> variable] <span class="sc">%&gt;%</span> </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>.[, variable <span class="sc">:</span><span class="er">=</span> <span class="fu">c</span>(<span class="st">"RF"</span>, <span class="st">"LLF"</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">c</span>(<span class="st">"Method"</span>, <span class="st">"RMSE"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="fu">gt</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">

<div id="cmmkvcldpt" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#cmmkvcldpt .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#cmmkvcldpt .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cmmkvcldpt .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#cmmkvcldpt .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#cmmkvcldpt .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cmmkvcldpt .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cmmkvcldpt .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#cmmkvcldpt .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#cmmkvcldpt .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#cmmkvcldpt .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#cmmkvcldpt .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#cmmkvcldpt .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#cmmkvcldpt .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#cmmkvcldpt .gt_from_md > :first-child {
  margin-top: 0;
}

#cmmkvcldpt .gt_from_md > :last-child {
  margin-bottom: 0;
}

#cmmkvcldpt .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#cmmkvcldpt .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#cmmkvcldpt .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#cmmkvcldpt .gt_row_group_first td {
  border-top-width: 2px;
}

#cmmkvcldpt .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cmmkvcldpt .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#cmmkvcldpt .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#cmmkvcldpt .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cmmkvcldpt .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cmmkvcldpt .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#cmmkvcldpt .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#cmmkvcldpt .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cmmkvcldpt .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cmmkvcldpt .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#cmmkvcldpt .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cmmkvcldpt .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#cmmkvcldpt .gt_left {
  text-align: left;
}

#cmmkvcldpt .gt_center {
  text-align: center;
}

#cmmkvcldpt .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#cmmkvcldpt .gt_font_normal {
  font-weight: normal;
}

#cmmkvcldpt .gt_font_bold {
  font-weight: bold;
}

#cmmkvcldpt .gt_font_italic {
  font-style: italic;
}

#cmmkvcldpt .gt_super {
  font-size: 65%;
}

#cmmkvcldpt .gt_two_val_uncert {
  display: inline-block;
  line-height: 1em;
  text-align: right;
  font-size: 60%;
  vertical-align: -0.25em;
  margin-left: 0.1em;
}

#cmmkvcldpt .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#cmmkvcldpt .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#cmmkvcldpt .gt_slash_mark {
  font-size: 0.7em;
  line-height: 0.7em;
  vertical-align: 0.15em;
}

#cmmkvcldpt .gt_fraction_numerator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: 0.45em;
}

#cmmkvcldpt .gt_fraction_denominator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: -0.05em;
}
</style>
<table class="gt_table">
  
  <thead class="gt_col_headings">
    <tr>
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1">Method</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">RMSE</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td class="gt_row gt_left">RF</td>
<td class="gt_row gt_right">50.45657</td></tr>
    <tr><td class="gt_row gt_left">LLF</td>
<td class="gt_row gt_right">46.29489</td></tr>
  </tbody>
  
  
</table>
</div>
</div>
</div>
<p>Looking at how splits are done is very insightful in understanding what gives the edge to splitting on residuals. <span class="quarto-unresolved-ref">?fig-dif-splits</span> shows what variables are used to split nodes at various depths. When split on outcome, <span class="math inline">\(X_4\)</span> is used most often at the first depth because it is a highly influential variable. On the other hand, when split on residuals, <span class="math inline">\(X_1\)</span> is used most often at the first depth. This is because when ridge regression is run on the parent node, much of the linear signals does not remain in the residuals (signals from <span class="math inline">\(X_4\)</span> and <span class="math inline">\(X_5\)</span>). So, the trees grown focus more on complicated non-linear and interactive signals. Note that signals from <span class="math inline">\(X_4\)</span> and <span class="math inline">\(X_5\)</span> will be caught anyway at the prediction stage because of local linear correction. So, if you are doing linear correction, then you should not “waste” trees on linear signals. This is the motivation of split on residuals.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>rf_split <span class="ot">&lt;-</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">split_frequencies</span>(rf_trained) <span class="sc">%&gt;%</span> </span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>  .[, Depth <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N] <span class="sc">%&gt;%</span> </span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"Depth"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  .[, value <span class="sc">:</span><span class="er">=</span> value <span class="sc">/</span><span class="fu">sum</span>(value), by <span class="ot">=</span> Depth] <span class="sc">%&gt;%</span> </span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Split on Outcome"</span>]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>llf_split <span class="ot">&lt;-</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">split_frequencies</span>(llf_traiend) <span class="sc">%&gt;%</span> </span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  .[, Depth <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N] <span class="sc">%&gt;%</span> </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"Depth"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>  .[, value <span class="sc">:</span><span class="er">=</span> value <span class="sc">/</span><span class="fu">sum</span>(value), by <span class="ot">=</span> Depth] <span class="sc">%&gt;%</span> </span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Split on Residual"</span>]</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(rf_split, llf_split) <span class="sc">%&gt;%</span> </span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  .[, Variable <span class="sc">:</span><span class="er">=</span> <span class="fu">gsub</span>(<span class="st">"V"</span>, <span class="st">"X"</span>, variable)] <span class="sc">%&gt;%</span> </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">data =</span> .) <span class="sc">+</span> </span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">y =</span> Depth, <span class="at">x =</span> Variable, <span class="at">fill =</span> value)) <span class="sc">+</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(type <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-dif-split" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="P04-local-linear-forest_files/figure-html/fig-dif-split-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 9.3: Difference in splitting</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>For more extensive performance comparison via MC simulations, see <span class="citation" data-cites="friedberg2020local">Friedberg et al. (<a href="#ref-friedberg2020local" role="doc-biblioref">2020</a>)</span>.</p>
</section>
</section>
<section id="extension-to-other-grf-methods" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="extension-to-other-grf-methods"><span class="header-section-number">9.3</span> Extension to other GRF methods</h2>
<!-- ## Coding by hand

Let's code the modified process for LLF to aid our understanding of them. 
 -->
</section>
<section id="implementation" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="implementation"><span class="header-section-number">9.4</span> Implementation</h2>
<p>You can use <code>ll_regression_forest()</code> from the <code>grf</code> package to train LLF for R and <code>GRFForestLocalLinearRegressor()</code> from the <code>skgrf</code> package for Python.</p>
</section>
<section id="references" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Bloniarz2016" class="csl-entry" role="doc-biblioentry">
Bloniarz, Adam, Ameet Talwalkar, Bin Yu, and Christopher Wu. 2016. <span>“Supervised Neighborhoods for Distributed Nonparametric Regression.”</span> In <em>Proceedings of the 19th International Conference on Artificial Intelligence and Statistics</em>, edited by Arthur Gretton and Christian C. Robert, 51:1450–59. Proceedings of Machine Learning Research. Cadiz, Spain: PMLR. <a href="https://proceedings.mlr.press/v51/bloniarz16.html">https://proceedings.mlr.press/v51/bloniarz16.html</a>.
</div>
<div id="ref-friedberg2020local" class="csl-entry" role="doc-biblioentry">
Friedberg, Rina, Julie Tibshirani, Susan Athey, and Stefan Wager. 2020. <span>“Local Linear Forests.”</span> <em>Journal of Computational and Graphical Statistics</em> 30 (2): 503–17.
</div>
</div>


<!-- -->

</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./P03-xgb.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C0P-causal-ml.html" class="pagination-link">
        <span class="nav-page-text">Causal Machine Learning (CML) Methods</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb9" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Local Linear Forest</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>Local linear forest (LLF) is an extension of random forest (RF) and also a generalized random forest (GRF) <span class="co">[</span><span class="ot">@friedberg2020local</span><span class="co">]</span>. We first see that RF is actually a special case of local constant regression. We will then see how LLF builds on RF from the view point of a local regression method.</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">## What you will learn</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How LLF works in relation to RF and local regression</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How LLF performs compared to RF</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How the idea of LLF can be applied to other GRF methods</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How to train LLF using R and Python</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="fu">## Background knowledge</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>(necessary) random forest (@sec-rf)</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>(necessary) local regression (@sec-local)</span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>(preferred) generalized random forest (@sec-grf)</span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>(preferred) ridge regression (@sec-ridge-en)</span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Packages to load for replication</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grf)</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grf)</span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(parallel)</span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gt)</span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a><span class="fu">## Theoretical background</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>Suppose $T$ tress have been built after a random forest model is trained on a dataset. Now, let $\eta_{i,t}(X)$ takes $1$ if observation $i$ belongs to the same leaf as $X$ in tree $t$, where $X$ is a vector of covariates ($K$ variables). Then, the RF's predicted value of $y$ conditional on a particular value of $X$ (say, $X_0$) can be written as follows:</span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>\hat{y}(X_0) = \frac{1}{T} \cdot\sum_{t=1}^T\sum_{i=1}^N \frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i</span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>Note that $\sum_{i=1}^N\eta_{i,t}(X_0)$ represents the number of observations in the same leaf as $X_0$. Therefore, $\sum_{i=1}^N \frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i$ is the average value of $y$ of the leaf that $X_0$ belongs to. So, while looking slightly complicated, it is the average value of $y$ of the tree $X_0$ belongs to averaged across the trees. </span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>We can switch the summations like this,</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>\hat{y}(X_0) = \sum_{i=1}^N \cdot\frac{1}{T}\sum_{t=1}^T\frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}\cdot y_i</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>Let $\alpha(X_i, X_0)$ denote $\frac{1}{T}\sum_{t=1}^T\frac{\eta_{i,t}(X_0)}{\sum_{i=1}^N\eta_{i,t}(X_0)}$. Then, we can rewrite the above equation as</span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>\hat{y}(X_0) = \sum_{i=1}^N \alpha(X_i,X_0) \cdot y_i</span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>It is easy to show that $\hat{y}(X_0)$ is a solution to the following minimization problem.</span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>Min_{\theta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot<span class="co">[</span><span class="ot">y_i -\theta</span><span class="co">]</span>^2</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ll-constant}</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>In this formulation of the problem, $\alpha(X_i,X_0)$ can be considered the weight given to observation $i$. By definition,</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$0 \leq \alpha(X_i,X_0) \leq 1$</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\sum_{i=1}^N \alpha(X_i,X_0) = 1$</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>You may notice that @eq-ll-constant is actually a special case of local constant regression where the individual weights are $\alpha(X_i, X_0)$. Roughly speaking, $\alpha(X_i, X_0)$ measures how often observation $i$ share the same leaves as the evaluation point ($X_0$) across $T$ trees. So, it measures how similar $X_i$ is to $X_0$ in the RF way, but not based on euclidean distance (which is subject to curse of dimensionality). So, RF is actually a local <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:blue'</span><span class="kw">&gt;</span>constant<span class="kw">&lt;/span&gt;</span> regression with a special way of distributing weights to the individual observations. This interpretation leads to a natural extension. Why don't we solve local <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:blue'</span><span class="kw">&gt;</span>linear<span class="kw">&lt;/span&gt;</span> regression problem instead, which would be more appropriate if $y$ is a smooth function of $X$? </span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>Rewriting @eq-ll-constant as a local linear regression problem.</span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>Min_{\mu, \beta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot<span class="co">[</span><span class="ot">y_i -\mu - (X_i - X_0)\beta</span><span class="co">]</span>^2 </span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ll}</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>where $\mu$ is a scalar (intercept) and $\beta$ is a vector of parameters ($K \times 1$). </span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>This approach was proposed by @Bloniarz2016 and they showed modest improvement over RF. LLF by @friedberg2020local differ from this approach in two important ways.</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a><span class="fu">## LLF </span></span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Modify the splitting process in a way that the resulting splitting rules (and thus weights) are more suitable to the second stage local linear regression   </span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>At the local linear regression stage, use ridge regularization</span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a>::: </span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>Let's look at the first modification. In RF, when deciding how to split a node (parent node), we choose a split that solves the following problem:</span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a>\frac{1}{N_1}\sum_{i\in C_1}(Y_i - \bar{Y_1}) + \frac{1}{N_2}\sum_{i\in C_2}(Y_i - \bar{Y_2})</span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>where $C_1$ and $C_2$ are child nodes, and $\bar{Y_1}$ and $\bar{Y_2}$ are the mean value of the outcome for $C_1$ and $C_2$, respectively. Instead, LLF by @friedberg2020local first regresses $Y$ on $X$ using ridge regression using the observations in the parent node, finds the residuals, and then uses the residuals in place of $Y$ itself.</span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a>Now, let's look at the second modification. LLF implemented by the <span class="in">`grf`</span> package adds the ridge penalty to avoid over-fitting and solve the following problem:</span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>Min_{\mu, \beta} \sum_{i=1}^N \alpha(X_i,X_0)\cdot<span class="co">[</span><span class="ot">y_i -\mu - (X_i - X_0)\beta</span><span class="co">]</span>^2 + \lambda||\beta||^2_2</span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a>$$ {#eq-ll-ridge}</span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a>where $\lambda$ is the regularization parameter. LLF estimator is a weighted ridge regression, and it has a nice analytical solution (just like a regular ridge regression). With the following notations,</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$A$: the diagonal matrix where its diagonal element at $<span class="sc">\{</span>i, i<span class="sc">\}</span>$ is the weight for observation $i$, ($\alpha(X_i,X_0)$, obtained based on the trees grown using the modified splitting process. </span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\Delta$: the $N \times K$ (the intercept plus $K-1$ covariates) matrix where $\Delta_{i,1} = 1$ and $\Delta_{i,j} = x_{i,j} - x_{0,j}$.</span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$J$: $(K+1) \times (K+1)$ diagonal matrix where its diagonal elements are all $1$ except $J_{1,1}$, which is 0 to not penalize the intercept.</span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\theta$: $<span class="sc">\{</span>\mu, \beta<span class="sc">\}</span>$</span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a>\hat{\theta}_{llf} = (\Delta'A\Delta + \lambda J)^{-1}\Delta'AY</span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a><span class="fu">## Terminology alert</span></span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a>Using local linear regression at the time of prediction is termed <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> local linear correction <span class="kw">&lt;/span&gt;</span>by the authors of the <span class="in">`grf`</span> package.</span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Implementation: Training and Prediction</span></span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a><span class="co">LLF can be implemented using `ll_linear_forest()` from the `grf` package. </span></span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-165"><a href="#cb9-165" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-166"><a href="#cb9-166" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb9-167"><a href="#cb9-167" aria-hidden="true" tabindex="-1"></a><span class="co">ll_linear_forest()</span></span>
<span id="cb9-168"><a href="#cb9-168" aria-hidden="true" tabindex="-1"></a><span class="co">```</span></span>
<span id="cb9-169"><a href="#cb9-169" aria-hidden="true" tabindex="-1"></a><span class="co"> --&gt;</span></span>
<span id="cb9-170"><a href="#cb9-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-171"><a href="#cb9-171" aria-hidden="true" tabindex="-1"></a><span class="fu">## Performance comparison: LLF v.s. RF</span></span>
<span id="cb9-172"><a href="#cb9-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-173"><a href="#cb9-173" aria-hidden="true" tabindex="-1"></a>First, let's consider the following DGP that is used in @friedberg2020local.</span>
<span id="cb9-174"><a href="#cb9-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-175"><a href="#cb9-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### DGP 1</span></span>
<span id="cb9-176"><a href="#cb9-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-177"><a href="#cb9-177" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb9-178"><a href="#cb9-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-179"><a href="#cb9-179" aria-hidden="true" tabindex="-1"></a><span class="fu">## DGP 1</span></span>
<span id="cb9-180"><a href="#cb9-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-181"><a href="#cb9-181" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-182"><a href="#cb9-182" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-183"><a href="#cb9-183" aria-hidden="true" tabindex="-1"></a>y_i = log(1+exp(6x)) + \varepsilon</span>
<span id="cb9-184"><a href="#cb9-184" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-185"><a href="#cb9-185" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-186"><a href="#cb9-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-187"><a href="#cb9-187" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$<span class="sc">\{</span>X_1, \dots, X_10<span class="sc">\}</span> \sim U<span class="co">[</span><span class="ot">-1, 1</span><span class="co">]</span>^{10}$</span>
<span id="cb9-188"><a href="#cb9-188" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\varepsilon \sim N(0, 20)$</span>
<span id="cb9-189"><a href="#cb9-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-190"><a href="#cb9-190" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-191"><a href="#cb9-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-192"><a href="#cb9-192" aria-hidden="true" tabindex="-1"></a>We consider the following four methods presented in @tab-methods.</span>
<span id="cb9-193"><a href="#cb9-193" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-196"><a href="#cb9-196" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-197"><a href="#cb9-197" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb9-198"><a href="#cb9-198" aria-hidden="true" tabindex="-1"></a><span class="co">#| tab-cap: Four methods of prediction</span></span>
<span id="cb9-199"><a href="#cb9-199" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tab-methods</span></span>
<span id="cb9-200"><a href="#cb9-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-201"><a href="#cb9-201" aria-hidden="true" tabindex="-1"></a><span class="fu">tribble</span>(</span>
<span id="cb9-202"><a href="#cb9-202" aria-hidden="true" tabindex="-1"></a>  <span class="sc">~</span> Method, <span class="sc">~</span> <span class="st">`</span><span class="at">Split on outcome</span><span class="st">`</span>, <span class="sc">~</span> <span class="st">`</span><span class="at">Linear Correction</span><span class="st">`</span>,</span>
<span id="cb9-203"><a href="#cb9-203" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span>, <span class="st">"No"</span>, <span class="st">"No"</span>,</span>
<span id="cb9-204"><a href="#cb9-204" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span>, <span class="st">"No"</span>, <span class="st">"X1"</span>,</span>
<span id="cb9-205"><a href="#cb9-205" aria-hidden="true" tabindex="-1"></a>  <span class="dv">3</span>, <span class="st">"Yes"</span>, <span class="st">"All"</span>,</span>
<span id="cb9-206"><a href="#cb9-206" aria-hidden="true" tabindex="-1"></a>  <span class="dv">4</span>, <span class="st">"Yes"</span>, <span class="st">"X1"</span></span>
<span id="cb9-207"><a href="#cb9-207" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-208"><a href="#cb9-208" aria-hidden="true" tabindex="-1"></a><span class="fu">gt</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-209"><a href="#cb9-209" aria-hidden="true" tabindex="-1"></a><span class="fu">cols_align</span>(</span>
<span id="cb9-210"><a href="#cb9-210" aria-hidden="true" tabindex="-1"></a>  <span class="at">align =</span> <span class="st">"center"</span></span>
<span id="cb9-211"><a href="#cb9-211" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-212"><a href="#cb9-212" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-213"><a href="#cb9-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-214"><a href="#cb9-214" aria-hidden="true" tabindex="-1"></a>Method 1 is equivalent to a standard RF estimation. Method 2 grows trees like RF, but make local linear corrections on $X_1$ at the time of prediction. This means that at the prediction stage, only $X_1$ is used in @eq-ll instead of using all of $10$ variables in $X$. Since we know $X_1$ is the only variable that affects $y$ in DGP 1, this way of linear correction should perform better than using all of the $10$ variables in $X$. Of course, in practice, you do not get to do this. Method 3 splits on the residuals from ridge regression, and uses all of the $10$ variables in $X$ for linear correction. Method 4 splits on the residuals from ridge regression and uses only $X1$ for local linear correction. </span>
<span id="cb9-215"><a href="#cb9-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-216"><a href="#cb9-216" aria-hidden="true" tabindex="-1"></a>@fig-comp-rf-llf presents how $\hat{y}(X)$ for the test data (black dots) changes according to the value of $X_1$ and $E<span class="co">[</span><span class="ot">y|X</span><span class="co">]</span>$ (red line). Note that heterogeneity in $\hat{y}(X)$ at the same value of $X_1$ occurs dues to modeling error: the trained model attributed some of the variations in observed $y$ to other variables than $X_1$ even though $X_1$ is the only variable that is actually affecting $y$ as you can see in DGP 1. @fig-comp-rf-llf indicates that irrespective of whether you split on $y$ or residuals from ridge regression, linear correction on $X1$ can substantially reduce bias. Method 4 seems to perform slightly better than Method 2 in this instance. However, when all the variables in $X$ (that include many irrelevant variables) are used for linear correction (Method 3), its benefit disappears, performing about the same as Method 1. Comparing Methods 2 and 4, the benefit of split on residual is not clear at least in this instance. Let's run MC simulations to have a better picture of the relative performance of the four methods. In each iteration, we calculate RMSE of $y$ prediction for each method.</span>
<span id="cb9-217"><a href="#cb9-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-218"><a href="#cb9-218" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb9-219"><a href="#cb9-219" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-220"><a href="#cb9-220" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Comparison of predicted values</span></span>
<span id="cb9-221"><a href="#cb9-221" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-comp-rf-llf</span></span>
<span id="cb9-222"><a href="#cb9-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-223"><a href="#cb9-223" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-224"><a href="#cb9-224" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data</span></span>
<span id="cb9-225"><a href="#cb9-225" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-226"><a href="#cb9-226" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">78234</span>)</span>
<span id="cb9-227"><a href="#cb9-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-228"><a href="#cb9-228" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb9-229"><a href="#cb9-229" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb9-230"><a href="#cb9-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-231"><a href="#cb9-231" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb9-232"><a href="#cb9-232" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> X[, <span class="dv">1</span>])) <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">20</span>) <span class="sc">*</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb9-233"><a href="#cb9-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-234"><a href="#cb9-234" aria-hidden="true" tabindex="-1"></a>X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb9-235"><a href="#cb9-235" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> N)</span>
<span id="cb9-236"><a href="#cb9-236" aria-hidden="true" tabindex="-1"></a>X_test[, <span class="dv">1</span>] <span class="ot">&lt;-</span> x_seq</span>
<span id="cb9-237"><a href="#cb9-237" aria-hidden="true" tabindex="-1"></a>ey <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> x_seq))</span>
<span id="cb9-238"><a href="#cb9-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-239"><a href="#cb9-239" aria-hidden="true" tabindex="-1"></a>true_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> x_seq, <span class="at">y =</span> ey)</span>
<span id="cb9-240"><a href="#cb9-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-241"><a href="#cb9-241" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-242"><a href="#cb9-242" aria-hidden="true" tabindex="-1"></a><span class="co"># Train on outcome and ridge residuals </span></span>
<span id="cb9-243"><a href="#cb9-243" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-244"><a href="#cb9-244" aria-hidden="true" tabindex="-1"></a>llf_trained <span class="ot">&lt;-</span></span>
<span id="cb9-245"><a href="#cb9-245" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb9-246"><a href="#cb9-246" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> X,</span>
<span id="cb9-247"><a href="#cb9-247" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> y,</span>
<span id="cb9-248"><a href="#cb9-248" aria-hidden="true" tabindex="-1"></a>    <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span></span>
<span id="cb9-249"><a href="#cb9-249" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-250"><a href="#cb9-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-251"><a href="#cb9-251" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb9-252"><a href="#cb9-252" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb9-253"><a href="#cb9-253" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> X,</span>
<span id="cb9-254"><a href="#cb9-254" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> y</span>
<span id="cb9-255"><a href="#cb9-255" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-256"><a href="#cb9-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-257"><a href="#cb9-257" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-258"><a href="#cb9-258" aria-hidden="true" tabindex="-1"></a><span class="co"># Predictions with and without linear correction</span></span>
<span id="cb9-259"><a href="#cb9-259" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-260"><a href="#cb9-260" aria-hidden="true" tabindex="-1"></a>rf_results <span class="ot">&lt;-</span></span>
<span id="cb9-261"><a href="#cb9-261" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb9-262"><a href="#cb9-262" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb9-263"><a href="#cb9-263" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb9-264"><a href="#cb9-264" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb9-265"><a href="#cb9-265" aria-hidden="true" tabindex="-1"></a>        rf_trained, </span>
<span id="cb9-266"><a href="#cb9-266" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test</span>
<span id="cb9-267"><a href="#cb9-267" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb9-268"><a href="#cb9-268" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 1: Split on outcome </span><span class="sc">\n</span><span class="st"> without linear correction"</span></span>
<span id="cb9-269"><a href="#cb9-269" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-270"><a href="#cb9-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-271"><a href="#cb9-271" aria-hidden="true" tabindex="-1"></a>rf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb9-272"><a href="#cb9-272" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb9-273"><a href="#cb9-273" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb9-274"><a href="#cb9-274" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb9-275"><a href="#cb9-275" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb9-276"><a href="#cb9-276" aria-hidden="true" tabindex="-1"></a>        rf_trained, </span>
<span id="cb9-277"><a href="#cb9-277" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test, </span>
<span id="cb9-278"><a href="#cb9-278" aria-hidden="true" tabindex="-1"></a>        <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb9-279"><a href="#cb9-279" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb9-280"><a href="#cb9-280" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 2: Split on outcome </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span></span>
<span id="cb9-281"><a href="#cb9-281" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-282"><a href="#cb9-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-283"><a href="#cb9-283" aria-hidden="true" tabindex="-1"></a>llf_results_nlc <span class="ot">&lt;-</span></span>
<span id="cb9-284"><a href="#cb9-284" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb9-285"><a href="#cb9-285" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb9-286"><a href="#cb9-286" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb9-287"><a href="#cb9-287" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb9-288"><a href="#cb9-288" aria-hidden="true" tabindex="-1"></a>        llf_trained, </span>
<span id="cb9-289"><a href="#cb9-289" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test</span>
<span id="cb9-290"><a href="#cb9-290" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb9-291"><a href="#cb9-291" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 3: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on all X"</span></span>
<span id="cb9-292"><a href="#cb9-292" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-293"><a href="#cb9-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-294"><a href="#cb9-294" aria-hidden="true" tabindex="-1"></a>llf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb9-295"><a href="#cb9-295" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb9-296"><a href="#cb9-296" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> x_seq,</span>
<span id="cb9-297"><a href="#cb9-297" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> </span>
<span id="cb9-298"><a href="#cb9-298" aria-hidden="true" tabindex="-1"></a>      <span class="fu">predict</span>(</span>
<span id="cb9-299"><a href="#cb9-299" aria-hidden="true" tabindex="-1"></a>        llf_trained, </span>
<span id="cb9-300"><a href="#cb9-300" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> X_test, </span>
<span id="cb9-301"><a href="#cb9-301" aria-hidden="true" tabindex="-1"></a>        <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb9-302"><a href="#cb9-302" aria-hidden="true" tabindex="-1"></a>      )<span class="sc">$</span>predictions,</span>
<span id="cb9-303"><a href="#cb9-303" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">"Method 4: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span></span>
<span id="cb9-304"><a href="#cb9-304" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-305"><a href="#cb9-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-306"><a href="#cb9-306" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-307"><a href="#cb9-307" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine the results and plot</span></span>
<span id="cb9-308"><a href="#cb9-308" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb9-309"><a href="#cb9-309" aria-hidden="true" tabindex="-1"></a>all_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(rf_results, rf_results_lc, llf_results_nlc, llf_results_lc)</span>
<span id="cb9-310"><a href="#cb9-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-311"><a href="#cb9-311" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>() <span class="sc">+</span> </span>
<span id="cb9-312"><a href="#cb9-312" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data =</span> all_results, <span class="fu">aes</span>(<span class="at">y =</span> y_hat, <span class="at">x =</span> x), <span class="at">size =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb9-313"><a href="#cb9-313" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> true_data, <span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x), <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb9-314"><a href="#cb9-314" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(type <span class="sc">~</span> ., <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb9-315"><a href="#cb9-315" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Predicted Value"</span>) <span class="sc">+</span></span>
<span id="cb9-316"><a href="#cb9-316" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"X1"</span>) <span class="sc">+</span></span>
<span id="cb9-317"><a href="#cb9-317" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() </span>
<span id="cb9-318"><a href="#cb9-318" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-319"><a href="#cb9-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-320"><a href="#cb9-320" aria-hidden="true" tabindex="-1"></a>@fig-mc-four-methods presents the distribution of RMSE for each method over $200$ iterations. As you can see, Method 4 works the best under DGP 1. However, Method 2 also works quite well and the benefit of split on residual is rather small. This is actually expected based on how DGP 1 is specified. We now look at a different DGP that illustrates when split on residuals is likely to be beneficial.</span>
<span id="cb9-321"><a href="#cb9-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-324"><a href="#cb9-324" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-325"><a href="#cb9-325" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb9-326"><a href="#cb9-326" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-327"><a href="#cb9-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-328"><a href="#cb9-328" aria-hidden="true" tabindex="-1"></a><span class="co"># This function runs an experiment run above with a different dataset drawn from DGP 1 and returns rmse for each method</span></span>
<span id="cb9-329"><a href="#cb9-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-330"><a href="#cb9-330" aria-hidden="true" tabindex="-1"></a>run_llf_sim <span class="ot">&lt;-</span> <span class="cf">function</span>(i){</span>
<span id="cb9-331"><a href="#cb9-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-332"><a href="#cb9-332" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i)</span>
<span id="cb9-333"><a href="#cb9-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-334"><a href="#cb9-334" aria-hidden="true" tabindex="-1"></a>  X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb9-335"><a href="#cb9-335" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> X[, <span class="dv">1</span>])) <span class="sc">+</span> <span class="fu">sqrt</span>(<span class="dv">20</span>) <span class="sc">*</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb9-336"><a href="#cb9-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-337"><a href="#cb9-337" aria-hidden="true" tabindex="-1"></a>  X_test <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N<span class="sc">*</span>K, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">nrow =</span> N)</span>
<span id="cb9-338"><a href="#cb9-338" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> N)</span>
<span id="cb9-339"><a href="#cb9-339" aria-hidden="true" tabindex="-1"></a>  X_test[, <span class="dv">1</span>] <span class="ot">&lt;-</span> x_seq</span>
<span id="cb9-340"><a href="#cb9-340" aria-hidden="true" tabindex="-1"></a>  ey <span class="ot">&lt;-</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="dv">6</span> <span class="sc">*</span> x_seq))</span>
<span id="cb9-341"><a href="#cb9-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-342"><a href="#cb9-342" aria-hidden="true" tabindex="-1"></a>  true_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> x_seq, <span class="at">y =</span> ey)</span>
<span id="cb9-343"><a href="#cb9-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-344"><a href="#cb9-344" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-345"><a href="#cb9-345" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Train on outcome and ridge residuals </span></span>
<span id="cb9-346"><a href="#cb9-346" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-347"><a href="#cb9-347" aria-hidden="true" tabindex="-1"></a>  llf_trained <span class="ot">&lt;-</span></span>
<span id="cb9-348"><a href="#cb9-348" aria-hidden="true" tabindex="-1"></a>    grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb9-349"><a href="#cb9-349" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> X,</span>
<span id="cb9-350"><a href="#cb9-350" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> y,</span>
<span id="cb9-351"><a href="#cb9-351" aria-hidden="true" tabindex="-1"></a>      <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span></span>
<span id="cb9-352"><a href="#cb9-352" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-353"><a href="#cb9-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-354"><a href="#cb9-354" aria-hidden="true" tabindex="-1"></a>  rf_trained <span class="ot">&lt;-</span></span>
<span id="cb9-355"><a href="#cb9-355" aria-hidden="true" tabindex="-1"></a>    grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb9-356"><a href="#cb9-356" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> X,</span>
<span id="cb9-357"><a href="#cb9-357" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> y</span>
<span id="cb9-358"><a href="#cb9-358" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-359"><a href="#cb9-359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-360"><a href="#cb9-360" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-361"><a href="#cb9-361" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Predictions with and without linear correction</span></span>
<span id="cb9-362"><a href="#cb9-362" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-363"><a href="#cb9-363" aria-hidden="true" tabindex="-1"></a>  rf_results <span class="ot">&lt;-</span></span>
<span id="cb9-364"><a href="#cb9-364" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb9-365"><a href="#cb9-365" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb9-366"><a href="#cb9-366" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb9-367"><a href="#cb9-367" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb9-368"><a href="#cb9-368" aria-hidden="true" tabindex="-1"></a>          rf_trained, </span>
<span id="cb9-369"><a href="#cb9-369" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test</span>
<span id="cb9-370"><a href="#cb9-370" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb9-371"><a href="#cb9-371" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb9-372"><a href="#cb9-372" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-373"><a href="#cb9-373" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb9-374"><a href="#cb9-374" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 1: Split on outcome </span><span class="sc">\n</span><span class="st"> without linear correction"</span>] </span>
<span id="cb9-375"><a href="#cb9-375" aria-hidden="true" tabindex="-1"></a>      </span>
<span id="cb9-376"><a href="#cb9-376" aria-hidden="true" tabindex="-1"></a>  rf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb9-377"><a href="#cb9-377" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb9-378"><a href="#cb9-378" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb9-379"><a href="#cb9-379" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb9-380"><a href="#cb9-380" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb9-381"><a href="#cb9-381" aria-hidden="true" tabindex="-1"></a>          rf_trained, </span>
<span id="cb9-382"><a href="#cb9-382" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test, </span>
<span id="cb9-383"><a href="#cb9-383" aria-hidden="true" tabindex="-1"></a>          <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb9-384"><a href="#cb9-384" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb9-385"><a href="#cb9-385" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb9-386"><a href="#cb9-386" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-387"><a href="#cb9-387" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span></span>
<span id="cb9-388"><a href="#cb9-388" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 2: Split on outcome </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span>]</span>
<span id="cb9-389"><a href="#cb9-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-390"><a href="#cb9-390" aria-hidden="true" tabindex="-1"></a>  llf_results_nlc <span class="ot">&lt;-</span></span>
<span id="cb9-391"><a href="#cb9-391" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb9-392"><a href="#cb9-392" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb9-393"><a href="#cb9-393" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb9-394"><a href="#cb9-394" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb9-395"><a href="#cb9-395" aria-hidden="true" tabindex="-1"></a>          llf_trained, </span>
<span id="cb9-396"><a href="#cb9-396" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test</span>
<span id="cb9-397"><a href="#cb9-397" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb9-398"><a href="#cb9-398" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb9-399"><a href="#cb9-399" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-400"><a href="#cb9-400" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb9-401"><a href="#cb9-401" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 3: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on all X"</span>]</span>
<span id="cb9-402"><a href="#cb9-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-403"><a href="#cb9-403" aria-hidden="true" tabindex="-1"></a>  llf_results_lc <span class="ot">&lt;-</span></span>
<span id="cb9-404"><a href="#cb9-404" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb9-405"><a href="#cb9-405" aria-hidden="true" tabindex="-1"></a>      <span class="at">x =</span> x_seq,</span>
<span id="cb9-406"><a href="#cb9-406" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_hat =</span> </span>
<span id="cb9-407"><a href="#cb9-407" aria-hidden="true" tabindex="-1"></a>        <span class="fu">predict</span>(</span>
<span id="cb9-408"><a href="#cb9-408" aria-hidden="true" tabindex="-1"></a>          llf_trained, </span>
<span id="cb9-409"><a href="#cb9-409" aria-hidden="true" tabindex="-1"></a>          <span class="at">newdata =</span> X_test, </span>
<span id="cb9-410"><a href="#cb9-410" aria-hidden="true" tabindex="-1"></a>          <span class="at">linear.correction.variables =</span> <span class="dv">1</span></span>
<span id="cb9-411"><a href="#cb9-411" aria-hidden="true" tabindex="-1"></a>        )<span class="sc">$</span>predictions,</span>
<span id="cb9-412"><a href="#cb9-412" aria-hidden="true" tabindex="-1"></a>      <span class="at">ey =</span> ey</span>
<span id="cb9-413"><a href="#cb9-413" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-414"><a href="#cb9-414" aria-hidden="true" tabindex="-1"></a>    .[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">mean</span>((y_hat <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>)))] <span class="sc">%&gt;%</span> </span>
<span id="cb9-415"><a href="#cb9-415" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Method 4: Split on residual </span><span class="sc">\n</span><span class="st"> with linear correction on X1"</span>]</span>
<span id="cb9-416"><a href="#cb9-416" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-417"><a href="#cb9-417" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-418"><a href="#cb9-418" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Combine the results and plot</span></span>
<span id="cb9-419"><a href="#cb9-419" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb9-420"><a href="#cb9-420" aria-hidden="true" tabindex="-1"></a>  all_results <span class="ot">&lt;-</span> </span>
<span id="cb9-421"><a href="#cb9-421" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbind</span>(rf_results, rf_results_lc, llf_results_nlc, llf_results_lc)</span>
<span id="cb9-422"><a href="#cb9-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-423"><a href="#cb9-423" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(all_results)</span>
<span id="cb9-424"><a href="#cb9-424" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-425"><a href="#cb9-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-426"><a href="#cb9-426" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_1 &lt;-</span></span>
<span id="cb9-427"><a href="#cb9-427" aria-hidden="true" tabindex="-1"></a><span class="co">#   lapply(</span></span>
<span id="cb9-428"><a href="#cb9-428" aria-hidden="true" tabindex="-1"></a><span class="co">#     1:200,</span></span>
<span id="cb9-429"><a href="#cb9-429" aria-hidden="true" tabindex="-1"></a><span class="co">#     function(x) run_llf_sim(x)</span></span>
<span id="cb9-430"><a href="#cb9-430" aria-hidden="true" tabindex="-1"></a><span class="co">#   ) %&gt;% </span></span>
<span id="cb9-431"><a href="#cb9-431" aria-hidden="true" tabindex="-1"></a><span class="co">#   rbindlist()</span></span>
<span id="cb9-432"><a href="#cb9-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-433"><a href="#cb9-433" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2134</span>)</span>
<span id="cb9-434"><a href="#cb9-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-435"><a href="#cb9-435" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb9-436"><a href="#cb9-436" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb9-437"><a href="#cb9-437" aria-hidden="true" tabindex="-1"></a>    <span class="dv">1</span><span class="sc">:</span><span class="dv">200</span>,</span>
<span id="cb9-438"><a href="#cb9-438" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">run_llf_sim</span>(x),</span>
<span id="cb9-439"><a href="#cb9-439" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb9-440"><a href="#cb9-440" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb9-441"><a href="#cb9-441" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb9-442"><a href="#cb9-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-443"><a href="#cb9-443" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1 <span class="ot">&lt;-</span> </span>
<span id="cb9-444"><a href="#cb9-444" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_1) <span class="sc">+</span> </span>
<span id="cb9-445"><a href="#cb9-445" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x =</span> rmse, <span class="at">fill =</span> type), <span class="at">alpha =</span> <span class="fl">0.4</span>) <span class="sc">+</span></span>
<span id="cb9-446"><a href="#cb9-446" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb9-447"><a href="#cb9-447" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(</span>
<span id="cb9-448"><a href="#cb9-448" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span>,</span>
<span id="cb9-449"><a href="#cb9-449" aria-hidden="true" tabindex="-1"></a>    <span class="at">guide =</span> <span class="fu">guide_legend</span>(</span>
<span id="cb9-450"><a href="#cb9-450" aria-hidden="true" tabindex="-1"></a>      <span class="at">nrow =</span> <span class="dv">2</span></span>
<span id="cb9-451"><a href="#cb9-451" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-452"><a href="#cb9-452" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb9-453"><a href="#cb9-453" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb9-454"><a href="#cb9-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-455"><a href="#cb9-455" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1</span>
<span id="cb9-456"><a href="#cb9-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-457"><a href="#cb9-457" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(g_mc_llf_1, <span class="st">"LectureNotes/Data/g_mc_llf_1.rds"</span>)</span>
<span id="cb9-458"><a href="#cb9-458" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-459"><a href="#cb9-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-462"><a href="#cb9-462" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-463"><a href="#cb9-463" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb9-464"><a href="#cb9-464" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: MC simulations results</span></span>
<span id="cb9-465"><a href="#cb9-465" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-mc-four-methods</span></span>
<span id="cb9-466"><a href="#cb9-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-467"><a href="#cb9-467" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1 <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"Data/g_mc_llf_1.rds"</span>)</span>
<span id="cb9-468"><a href="#cb9-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-469"><a href="#cb9-469" aria-hidden="true" tabindex="-1"></a>g_mc_llf_1</span>
<span id="cb9-470"><a href="#cb9-470" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-471"><a href="#cb9-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-472"><a href="#cb9-472" aria-hidden="true" tabindex="-1"></a><span class="fu">### DGP 2</span></span>
<span id="cb9-473"><a href="#cb9-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-474"><a href="#cb9-474" aria-hidden="true" tabindex="-1"></a>In this section, we work on the following DGP. </span>
<span id="cb9-475"><a href="#cb9-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-476"><a href="#cb9-476" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb9-477"><a href="#cb9-477" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-478"><a href="#cb9-478" aria-hidden="true" tabindex="-1"></a><span class="fu">## DGP 2</span></span>
<span id="cb9-479"><a href="#cb9-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-480"><a href="#cb9-480" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-481"><a href="#cb9-481" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb9-482"><a href="#cb9-482" aria-hidden="true" tabindex="-1"></a>y_i = 10\cdot sin(\pi x_{i,1}x_{i,2}) + 20(x_{i,3}-0.5)^2 + 10 x_{i,4} + 5 C_{i,5} + \varepsilon</span>
<span id="cb9-483"><a href="#cb9-483" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb9-484"><a href="#cb9-484" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb9-485"><a href="#cb9-485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-486"><a href="#cb9-486" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$<span class="sc">\{</span>X_1, \dots, X_5<span class="sc">\}</span> \sim U<span class="co">[</span><span class="ot">0, 1</span><span class="co">]</span>^5$</span>
<span id="cb9-487"><a href="#cb9-487" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\varepsilon \sim N(0, \sigma^2)$</span>
<span id="cb9-488"><a href="#cb9-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-489"><a href="#cb9-489" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb9-490"><a href="#cb9-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-491"><a href="#cb9-491" aria-hidden="true" tabindex="-1"></a>This DGP is helpful in illustrating the power of split on residuals. </span>
<span id="cb9-492"><a href="#cb9-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-493"><a href="#cb9-493" aria-hidden="true" tabindex="-1"></a>We first generate training and test datasets.</span>
<span id="cb9-494"><a href="#cb9-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-497"><a href="#cb9-497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-498"><a href="#cb9-498" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb9-499"><a href="#cb9-499" aria-hidden="true" tabindex="-1"></a>K <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb9-500"><a href="#cb9-500" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">20</span>)</span>
<span id="cb9-501"><a href="#cb9-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-502"><a href="#cb9-502" aria-hidden="true" tabindex="-1"></a>make_data <span class="ot">&lt;-</span> <span class="cf">function</span>(N, sigma, K)</span>
<span id="cb9-503"><a href="#cb9-503" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb9-504"><a href="#cb9-504" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb9-505"><a href="#cb9-505" aria-hidden="true" tabindex="-1"></a>    <span class="fu">matrix</span>(<span class="fu">runif</span>(N <span class="sc">*</span> K), <span class="at">nrow =</span> N) <span class="sc">%&gt;%</span> </span>
<span id="cb9-506"><a href="#cb9-506" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-507"><a href="#cb9-507" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">gsub</span>(<span class="st">"V"</span>, <span class="st">"x"</span>, <span class="fu">names</span>(.))) <span class="sc">%&gt;%</span> </span>
<span id="cb9-508"><a href="#cb9-508" aria-hidden="true" tabindex="-1"></a>    .[, ey <span class="sc">:</span><span class="er">=</span> <span class="dv">10</span><span class="sc">*</span><span class="fu">sin</span>(pi<span class="sc">*</span>x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">20</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span>x4 <span class="sc">+</span> <span class="dv">5</span><span class="sc">*</span>x5] <span class="sc">%&gt;%</span> </span>
<span id="cb9-509"><a href="#cb9-509" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> ey <span class="sc">+</span> sigma <span class="sc">*</span> <span class="fu">rnorm</span>(N)]</span>
<span id="cb9-510"><a href="#cb9-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-511"><a href="#cb9-511" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb9-512"><a href="#cb9-512" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb9-513"><a href="#cb9-513" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-514"><a href="#cb9-514" aria-hidden="true" tabindex="-1"></a>data_train <span class="ot">&lt;-</span> <span class="fu">make_data</span>(N, sigma, K)</span>
<span id="cb9-515"><a href="#cb9-515" aria-hidden="true" tabindex="-1"></a>data_test <span class="ot">&lt;-</span> <span class="fu">make_data</span>(N, sigma, K)</span>
<span id="cb9-516"><a href="#cb9-516" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-517"><a href="#cb9-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-518"><a href="#cb9-518" aria-hidden="true" tabindex="-1"></a>Let's train RF and LLF using <span class="in">`data_train`</span>.</span>
<span id="cb9-519"><a href="#cb9-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-520"><a href="#cb9-520" aria-hidden="true" tabindex="-1"></a><span class="in">```{r training}</span></span>
<span id="cb9-521"><a href="#cb9-521" aria-hidden="true" tabindex="-1"></a><span class="co">#=== RF ===#</span></span>
<span id="cb9-522"><a href="#cb9-522" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb9-523"><a href="#cb9-523" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">regression_forest</span>(</span>
<span id="cb9-524"><a href="#cb9-524" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> data_train[, .(x1, x2, x3, x4, x5)],</span>
<span id="cb9-525"><a href="#cb9-525" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> data_train[, y]</span>
<span id="cb9-526"><a href="#cb9-526" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-527"><a href="#cb9-527" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-528"><a href="#cb9-528" aria-hidden="true" tabindex="-1"></a><span class="co">#=== LLF ===#</span></span>
<span id="cb9-529"><a href="#cb9-529" aria-hidden="true" tabindex="-1"></a>llf_traiend <span class="ot">&lt;-</span></span>
<span id="cb9-530"><a href="#cb9-530" aria-hidden="true" tabindex="-1"></a>  grf<span class="sc">::</span><span class="fu">ll_regression_forest</span>(</span>
<span id="cb9-531"><a href="#cb9-531" aria-hidden="true" tabindex="-1"></a>    <span class="at">X =</span> data_train[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb9-532"><a href="#cb9-532" aria-hidden="true" tabindex="-1"></a>    <span class="at">Y =</span> data_train[, y],</span>
<span id="cb9-533"><a href="#cb9-533" aria-hidden="true" tabindex="-1"></a>    <span class="at">enable.ll.split =</span> <span class="cn">TRUE</span>,</span>
<span id="cb9-534"><a href="#cb9-534" aria-hidden="true" tabindex="-1"></a>    <span class="at">ll.split.weight.penalty =</span> <span class="cn">TRUE</span></span>
<span id="cb9-535"><a href="#cb9-535" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb9-536"><a href="#cb9-536" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-537"><a href="#cb9-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-538"><a href="#cb9-538" aria-hidden="true" tabindex="-1"></a>We now predict $y$ on the test data (<span class="in">`data_test`</span>) based on RF and LLF with linear corrections on all the variables. </span>
<span id="cb9-539"><a href="#cb9-539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-540"><a href="#cb9-540" aria-hidden="true" tabindex="-1"></a><span class="in">```{r predictions}</span></span>
<span id="cb9-541"><a href="#cb9-541" aria-hidden="true" tabindex="-1"></a>pred_data <span class="ot">&lt;-</span></span>
<span id="cb9-542"><a href="#cb9-542" aria-hidden="true" tabindex="-1"></a>  data_test <span class="sc">%&gt;%</span> </span>
<span id="cb9-543"><a href="#cb9-543" aria-hidden="true" tabindex="-1"></a>  .[, y_hat_rf <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(</span>
<span id="cb9-544"><a href="#cb9-544" aria-hidden="true" tabindex="-1"></a>    rf_trained, </span>
<span id="cb9-545"><a href="#cb9-545" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> data_test[, .(x1, x2, x3, x4, x5)],</span>
<span id="cb9-546"><a href="#cb9-546" aria-hidden="true" tabindex="-1"></a>    <span class="at">linear.correction.variables =</span> <span class="dv">1</span><span class="sc">:</span>K</span>
<span id="cb9-547"><a href="#cb9-547" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb9-548"><a href="#cb9-548" aria-hidden="true" tabindex="-1"></a>  .[, y_hat_llf <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(</span>
<span id="cb9-549"><a href="#cb9-549" aria-hidden="true" tabindex="-1"></a>    llf_traiend, </span>
<span id="cb9-550"><a href="#cb9-550" aria-hidden="true" tabindex="-1"></a>    <span class="at">newdata =</span> data_test[, .(x1, x2, x3, x4, x5)]</span>
<span id="cb9-551"><a href="#cb9-551" aria-hidden="true" tabindex="-1"></a>  )<span class="sc">$</span>predictions</span>
<span id="cb9-552"><a href="#cb9-552" aria-hidden="true" tabindex="-1"></a>  ] <span class="sc">%&gt;%</span> </span>
<span id="cb9-553"><a href="#cb9-553" aria-hidden="true" tabindex="-1"></a>  .[, .(ey, y_hat_rf, y_hat_llf)] <span class="sc">%&gt;%</span> </span>
<span id="cb9-554"><a href="#cb9-554" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"ey"</span>) </span>
<span id="cb9-555"><a href="#cb9-555" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-556"><a href="#cb9-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-557"><a href="#cb9-557" aria-hidden="true" tabindex="-1"></a>@tab-rf-llf-dgp2 shows the RMSE values for RF and LLF. Since both methods here use linear correction at the time of prediction, the observed difference in their performance is attributable to the way splitting is done: split on outcome or residuals.</span>
<span id="cb9-558"><a href="#cb9-558" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-561"><a href="#cb9-561" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb9-562"><a href="#cb9-562" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-563"><a href="#cb9-563" aria-hidden="true" tabindex="-1"></a><span class="co">#| tab-cap: Performance measured by RMSE</span></span>
<span id="cb9-564"><a href="#cb9-564" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: tab-rf-llf-dgp2</span></span>
<span id="cb9-565"><a href="#cb9-565" aria-hidden="true" tabindex="-1"></a>pred_data <span class="sc">%&gt;%</span> </span>
<span id="cb9-566"><a href="#cb9-566" aria-hidden="true" tabindex="-1"></a>.[, .(<span class="at">rmse =</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((value <span class="sc">-</span> ey)<span class="sc">^</span><span class="dv">2</span>))), by <span class="ot">=</span> variable] <span class="sc">%&gt;%</span> </span>
<span id="cb9-567"><a href="#cb9-567" aria-hidden="true" tabindex="-1"></a>.[, variable <span class="sc">:</span><span class="er">=</span> <span class="fu">c</span>(<span class="st">"RF"</span>, <span class="st">"LLF"</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb9-568"><a href="#cb9-568" aria-hidden="true" tabindex="-1"></a><span class="fu">setnames</span>(<span class="fu">names</span>(.), <span class="fu">c</span>(<span class="st">"Method"</span>, <span class="st">"RMSE"</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb9-569"><a href="#cb9-569" aria-hidden="true" tabindex="-1"></a><span class="fu">gt</span>()</span>
<span id="cb9-570"><a href="#cb9-570" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-571"><a href="#cb9-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-572"><a href="#cb9-572" aria-hidden="true" tabindex="-1"></a>Looking at how splits are done is very insightful in understanding what gives the edge to splitting on residuals. @fig-dif-splits shows what variables are used to split nodes at various depths. When split on outcome, $X_4$ is used most often at the first depth because it is a highly influential variable. On the other hand, when split on residuals, $X_1$ is used most often at the first depth. This is because when ridge regression is run on the parent node, much of the linear signals does not remain in the residuals (signals from $X_4$ and $X_5$). So, the trees grown focus more on complicated non-linear and interactive signals. Note that signals from $X_4$ and $X_5$ will be caught anyway at the prediction stage because of local linear correction. So, if you are doing linear correction, then you should not "waste" trees on linear signals. This is the motivation of split on residuals.</span>
<span id="cb9-573"><a href="#cb9-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-574"><a href="#cb9-574" aria-hidden="true" tabindex="-1"></a><span class="in">```{r split-decision}</span></span>
<span id="cb9-575"><a href="#cb9-575" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb9-576"><a href="#cb9-576" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Difference in splitting</span></span>
<span id="cb9-577"><a href="#cb9-577" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dif-split</span></span>
<span id="cb9-578"><a href="#cb9-578" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-579"><a href="#cb9-579" aria-hidden="true" tabindex="-1"></a>rf_split <span class="ot">&lt;-</span></span>
<span id="cb9-580"><a href="#cb9-580" aria-hidden="true" tabindex="-1"></a>  <span class="fu">split_frequencies</span>(rf_trained) <span class="sc">%&gt;%</span> </span>
<span id="cb9-581"><a href="#cb9-581" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-582"><a href="#cb9-582" aria-hidden="true" tabindex="-1"></a>  .[, Depth <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N] <span class="sc">%&gt;%</span> </span>
<span id="cb9-583"><a href="#cb9-583" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"Depth"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-584"><a href="#cb9-584" aria-hidden="true" tabindex="-1"></a>  .[, value <span class="sc">:</span><span class="er">=</span> value <span class="sc">/</span><span class="fu">sum</span>(value), by <span class="ot">=</span> Depth] <span class="sc">%&gt;%</span> </span>
<span id="cb9-585"><a href="#cb9-585" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Split on Outcome"</span>]</span>
<span id="cb9-586"><a href="#cb9-586" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-587"><a href="#cb9-587" aria-hidden="true" tabindex="-1"></a>llf_split <span class="ot">&lt;-</span></span>
<span id="cb9-588"><a href="#cb9-588" aria-hidden="true" tabindex="-1"></a>  <span class="fu">split_frequencies</span>(llf_traiend) <span class="sc">%&gt;%</span> </span>
<span id="cb9-589"><a href="#cb9-589" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb9-590"><a href="#cb9-590" aria-hidden="true" tabindex="-1"></a>  .[, Depth <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N] <span class="sc">%&gt;%</span> </span>
<span id="cb9-591"><a href="#cb9-591" aria-hidden="true" tabindex="-1"></a>  <span class="fu">melt</span>(<span class="at">id.var =</span> <span class="st">"Depth"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb9-592"><a href="#cb9-592" aria-hidden="true" tabindex="-1"></a>  .[, value <span class="sc">:</span><span class="er">=</span> value <span class="sc">/</span><span class="fu">sum</span>(value), by <span class="ot">=</span> Depth] <span class="sc">%&gt;%</span> </span>
<span id="cb9-593"><a href="#cb9-593" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"Split on Residual"</span>]</span>
<span id="cb9-594"><a href="#cb9-594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-595"><a href="#cb9-595" aria-hidden="true" tabindex="-1"></a><span class="fu">rbind</span>(rf_split, llf_split) <span class="sc">%&gt;%</span> </span>
<span id="cb9-596"><a href="#cb9-596" aria-hidden="true" tabindex="-1"></a>  .[, Variable <span class="sc">:</span><span class="er">=</span> <span class="fu">gsub</span>(<span class="st">"V"</span>, <span class="st">"X"</span>, variable)] <span class="sc">%&gt;%</span> </span>
<span id="cb9-597"><a href="#cb9-597" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">data =</span> .) <span class="sc">+</span> </span>
<span id="cb9-598"><a href="#cb9-598" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_tile</span>(<span class="fu">aes</span>(<span class="at">y =</span> Depth, <span class="at">x =</span> Variable, <span class="at">fill =</span> value)) <span class="sc">+</span></span>
<span id="cb9-599"><a href="#cb9-599" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(type <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb9-600"><a href="#cb9-600" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_viridis_c</span>() <span class="sc">+</span></span>
<span id="cb9-601"><a href="#cb9-601" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb9-602"><a href="#cb9-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-603"><a href="#cb9-603" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb9-604"><a href="#cb9-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-605"><a href="#cb9-605" aria-hidden="true" tabindex="-1"></a>For more extensive performance comparison via MC simulations, see @friedberg2020local. </span>
<span id="cb9-606"><a href="#cb9-606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-607"><a href="#cb9-607" aria-hidden="true" tabindex="-1"></a><span class="fu">## Extension to other GRF methods</span></span>
<span id="cb9-608"><a href="#cb9-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-609"><a href="#cb9-609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-610"><a href="#cb9-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-611"><a href="#cb9-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-612"><a href="#cb9-612" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- ## Coding by hand</span></span>
<span id="cb9-613"><a href="#cb9-613" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-614"><a href="#cb9-614" aria-hidden="true" tabindex="-1"></a><span class="co">Let's code the modified process for LLF to aid our understanding of them. </span></span>
<span id="cb9-615"><a href="#cb9-615" aria-hidden="true" tabindex="-1"></a><span class="co"> --&gt;</span></span>
<span id="cb9-616"><a href="#cb9-616" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-617"><a href="#cb9-617" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-618"><a href="#cb9-618" aria-hidden="true" tabindex="-1"></a><span class="fu">## Implementation</span></span>
<span id="cb9-619"><a href="#cb9-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-620"><a href="#cb9-620" aria-hidden="true" tabindex="-1"></a>You can use <span class="in">`ll_regression_forest()`</span> from the <span class="in">`grf`</span> package to train LLF for R and <span class="in">`GRFForestLocalLinearRegressor()`</span> from the <span class="in">`skgrf`</span> package for Python.</span>
<span id="cb9-621"><a href="#cb9-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-622"><a href="#cb9-622" aria-hidden="true" tabindex="-1"></a><span class="fu">## References {.unnumbered}</span></span>
<span id="cb9-623"><a href="#cb9-623" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-624"><a href="#cb9-624" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">"refs"</span><span class="kw">&gt;&lt;/div&gt;</span></span>
<span id="cb9-625"><a href="#cb9-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-626"><a href="#cb9-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-627"><a href="#cb9-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-628"><a href="#cb9-628" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-629"><a href="#cb9-629" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-630"><a href="#cb9-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-631"><a href="#cb9-631" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-632"><a href="#cb9-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-633"><a href="#cb9-633" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-634"><a href="#cb9-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-635"><a href="#cb9-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-636"><a href="#cb9-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-637"><a href="#cb9-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-638"><a href="#cb9-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-639"><a href="#cb9-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-640"><a href="#cb9-640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-641"><a href="#cb9-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-642"><a href="#cb9-642" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>