<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 22&nbsp; Treatment Effect Estimation</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./PROG-P-03-model-selection.html" rel="next">
<link href="./PROG-P-01-scikitlearn.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Treatment Effect Estimation</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">C0P-causal-ml.qmd</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C04-cf-extension.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Extensions of Causal Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C05-causal-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Model Selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Programming: R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Programming: Python</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-01-scikitlearn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-02-CATE-econml.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Treatment Effect Estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-03-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Model selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#average-treatment-effect" id="toc-average-treatment-effect" class="nav-link active" data-scroll-target="#average-treatment-effect"> <span class="header-section-number">22.1</span> Average Treatment Effect</a></li>
  <li><a href="#s--x--and-t-learner" id="toc-s--x--and-t-learner" class="nav-link" data-scroll-target="#s--x--and-t-learner"> <span class="header-section-number">22.2</span> S-, X-, and T-learner</a>
  <ul class="collapse">
  <li><a href="#s-learner" id="toc-s-learner" class="nav-link" data-scroll-target="#s-learner"> <span class="header-section-number">22.2.1</span> S-learner</a></li>
  <li><a href="#t-learner" id="toc-t-learner" class="nav-link" data-scroll-target="#t-learner"> <span class="header-section-number">22.2.2</span> T-learner</a></li>
  <li><a href="#x-learner" id="toc-x-learner" class="nav-link" data-scroll-target="#x-learner"> <span class="header-section-number">22.2.3</span> X-learner</a></li>
  </ul></li>
  <li><a href="#r-learner" id="toc-r-learner" class="nav-link" data-scroll-target="#r-learner"> <span class="header-section-number">22.3</span> R-learner</a>
  <ul class="collapse">
  <li><a href="#dml" id="toc-dml" class="nav-link" data-scroll-target="#dml"> <span class="header-section-number">22.3.1</span> DML</a></li>
  <li><a href="#lineardml" id="toc-lineardml" class="nav-link" data-scroll-target="#lineardml"> <span class="header-section-number">22.3.2</span> <code>LinearDML</code></a></li>
  <li><a href="#nonparamdml" id="toc-nonparamdml" class="nav-link" data-scroll-target="#nonparamdml"> <span class="header-section-number">22.3.3</span> <code>NonParamDML</code></a></li>
  <li><a href="#causalforestdml" id="toc-causalforestdml" class="nav-link" data-scroll-target="#causalforestdml"> <span class="header-section-number">22.3.4</span> CausalForestDML</a></li>
  </ul></li>
  <li><a href="#orthogonal-forest" id="toc-orthogonal-forest" class="nav-link" data-scroll-target="#orthogonal-forest"> <span class="header-section-number">22.4</span> Orthogonal Forest</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/PROG-P-02-CATE-econml.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Treatment Effect Estimation</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>This chapter presents CATE estimation using the <code>econml</code> package <span class="citation" data-cites="econml">(<a href="#ref-econml" role="doc-biblioref">Keith Battocchi 2019</a>)</span>. The <code>causalml</code> package by Uber <span class="citation" data-cites="chen2020causalml">(<a href="#ref-chen2020causalml" role="doc-biblioref">Chen et al. 2020</a>)</span> is less complete than <code>econml</code> at the moment, and we do not cover it.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML, LinearDML, SparseLinearDML, NonParamDML, CausalForestDML</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.metalearners <span class="im">import</span> TLearner, SLearner, XLearner, DomainAdaptationLearner</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.sklearn_extensions.model_selection <span class="im">import</span> GridSearchCVList</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, RandomForestClassifier</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor, GradientBoostingClassifier</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RepeatedKFold, train_test_split</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> binomial, multivariate_normal, normal, uniform</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">#=== ignore warnings ===#</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s also generate synthetic dataset using <code>make_regression()</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define DGP</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_data(n, d, controls_outcome, treatment_effect, propensity):</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generates population data for given untreated_outcome, treatment_effect and propensity functions.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">        n (int): population size</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">        d (int): number of covariates</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">        controls_outcome (func): untreated outcome conditional on covariates</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">        treatment_effect (func): treatment effect conditional on covariates</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">        propensity (func): probability of treatment conditional on covariates</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate covariates</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate treatment</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: binomial(<span class="dv">1</span>, propensity(x), <span class="dv">1</span>)[<span class="dv">0</span>], <span class="dv">1</span>, X)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate outcome</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    Y0 <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: controls_outcome(x), <span class="dv">1</span>, X)</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    treat_effect <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: treatment_effect(x), <span class="dv">1</span>, X)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> Y0 <span class="op">+</span> treat_effect <span class="op">*</span> T</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (Y, T, X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># controls outcome, treatment effect, propensity definitions</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_controls_outcome(d):</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, d)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="kw">lambda</span> x: np.dot(x, beta) <span class="op">+</span> normal(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>treatment_effect <span class="op">=</span> <span class="kw">lambda</span> x: (<span class="dv">1</span> <span class="cf">if</span> x[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="fl">0.1</span> <span class="cf">else</span> <span class="dv">0</span>)<span class="op">*</span><span class="dv">8</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>propensity <span class="op">=</span> <span class="kw">lambda</span> x: (<span class="fl">0.8</span> <span class="cf">if</span> (x[<span class="dv">2</span>]<span class="op">&gt;-</span><span class="fl">0.5</span> <span class="kw">and</span> x[<span class="dv">2</span>]<span class="op">&lt;</span><span class="fl">0.5</span>) <span class="cf">else</span> <span class="fl">0.2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># DGP constants and test data</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>n_test <span class="op">=</span> <span class="dv">250</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>controls_outcome <span class="op">=</span> generate_controls_outcome(d)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n_test)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> <span class="dv">6</span><span class="op">/</span>n_test</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>X_test[:, <span class="dv">1</span>] <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, delta)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>Y, T, X <span class="op">=</span> generate_data(n, d, controls_outcome, treatment_effect, propensity)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="average-treatment-effect" class="level2" data-number="22.1">
<h2 data-number="22.1" class="anchored" data-anchor-id="average-treatment-effect"><span class="header-section-number">22.1</span> Average Treatment Effect</h2>
<p><code>DoubleML</code></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> DoubleML</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="s--x--and-t-learner" class="level2" data-number="22.2">
<h2 data-number="22.2" class="anchored" data-anchor-id="s--x--and-t-learner"><span class="header-section-number">22.2</span> S-, X-, and T-learner</h2>
<p>This section shows how to train S-, X-, and T-learner. See <a href="C02-xstr-learner.html"><span>Chapter&nbsp;12</span></a> for how these learners work, which would help you understand what you need to specify for each of the learners.</p>
<section id="s-learner" class="level3" data-number="22.2.1">
<h3 data-number="22.2.1" class="anchored" data-anchor-id="s-learner"><span class="header-section-number">22.2.1</span> S-learner</h3>
<p>To train an S-learner, you need to specify only one estimator, which estimates <span class="math inline">\(E[Y|T, X, W]\)</span>. This can be done using <code>overall_model</code> in <code>SLearner</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== specify the overall model ===#</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>overall_model <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an S-learner ===#</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>S_learner <span class="op">=</span> SLearner(overall_model<span class="op">=</span>overall_model)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>S_learner.fit(Y, T, X<span class="op">=</span>X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;econml.metalearners._metalearners.SLearner object at 0x2c6787f40&gt;</code></pre>
</div>
</div>
<p>Estimate <span class="math inline">\(\theta(X)\)</span> using the <code>effect</code> method,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>S_te <span class="op">=</span> S_learner.effect(X_test)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(S_te[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.10399956 0.12548629 0.14681032 0.00144599 0.13612467 0.20191013
 0.25838514 0.13599036 0.11161683 0.10562265]</code></pre>
</div>
</div>
</section>
<section id="t-learner" class="level3" data-number="22.2.2">
<h3 data-number="22.2.2" class="anchored" data-anchor-id="t-learner"><span class="header-section-number">22.2.2</span> T-learner</h3>
<p>To train a T-learner, you need to specify only one estimator, which estimates <span class="math inline">\(E[Y|T=1, X, W]\)</span> and <span class="math inline">\(E[Y|T=0, X, W]\)</span> sparately. This can be done using <code>models</code> in <code>TLearner</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an estimator ===#</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>, </span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up a T-learner ===#</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>T_learner <span class="op">=</span> TLearner(models<span class="op">=</span>models)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>T_learner.fit(Y, T, X<span class="op">=</span>X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;econml.metalearners._metalearners.TLearner object at 0x2c687fe20&gt;</code></pre>
</div>
</div>
<p>Estimate <span class="math inline">\(\theta(X)\)</span> using the <code>effect</code> method,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>T_te <span class="op">=</span> T_learner.effect(X_test)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(T_te[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 0.48622386  2.61149431  0.97129611 -2.05730236  1.45988848  0.39169258
  2.58590221  0.61471128  0.07130823  0.08548441]</code></pre>
</div>
</div>
</section>
<section id="x-learner" class="level3" data-number="22.2.3">
<h3 data-number="22.2.3" class="anchored" data-anchor-id="x-learner"><span class="header-section-number">22.2.3</span> X-learner</h3>
<p>To train an X-learner, you need to specify two estimators</p>
<ol type="1">
<li>Estimator that estimates <span class="math inline">\(E[Y|T=1, X, W]\)</span> and <span class="math inline">\(E[Y|T=0, X, W]\)</span> sparately just like T-learner.</li>
<li>Estimator that estimates <span class="math inline">\(E[T|X, W]\)</span> for weighting by propensity score</li>
</ol>
<p>This can be done using <code>models</code> (for the first) and <code>propensity_model</code> (for the second) in <code>XLearner</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an estimator for 1 ===#</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up a propensity model ===#</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>propensity_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an X-learner ===#</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>X_learner <span class="op">=</span> XLearner(models<span class="op">=</span>models, propensity_model<span class="op">=</span>propensity_model)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>X_learner.fit(Y, T, X<span class="op">=</span>X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;econml.metalearners._metalearners.XLearner object at 0x2c68a3400&gt;</code></pre>
</div>
</div>
<p>Estimate <span class="math inline">\(\theta(X)\)</span> using the <code>effect</code> method,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>X_te <span class="op">=</span> X_learner.effect(X_test)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_te[:<span class="dv">10</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[ 1.42279261  2.13361636  1.53439553  0.16138867  0.87456734  1.1597326
  1.56113978  1.02188289  1.01338737 -0.23292347]</code></pre>
</div>
</div>
</section>
</section>
<section id="r-learner" class="level2" data-number="22.3">
<h2 data-number="22.3" class="anchored" data-anchor-id="r-learner"><span class="header-section-number">22.3</span> R-learner</h2>
<p>This section shows how to run various estimators that fall under R-learner, which is referred to as the <code>_Rlearner</code> class in <code>econml</code>. As we saw in <a href="C02-xstr-learner.html"><span>Chapter&nbsp;12</span></a>, R-learner is a DML and <code>econml</code> offers many estimators under <code>_Rlearner</code>.</p>
<ul>
<li><code>DML</code>
<ul>
<li><code>LinearDML</code></li>
<li><code>SparseLinearDML</code></li>
<li><code>KernelDML</code></li>
</ul></li>
<li><code>NonParamDML</code></li>
<li><code>CausalForestDML</code></li>
</ul>
<p>All the estimators under <code>_Rlearner</code> require that estimators for <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[T|X]\)</span> are specified. This can be done by <code>model_y</code> for <span class="math inline">\(E[Y|X]\)</span> and <code>model_t</code> <span class="math inline">\(E[T|X]\)</span>. However, some estimators require that you specify the final (second stage) model using <code>model_final</code> while others do not.</p>
<section id="dml" class="level3" data-number="22.3.1">
<h3 data-number="22.3.1" class="anchored" data-anchor-id="dml"><span class="header-section-number">22.3.1</span> DML</h3>
<p>In this example, let’s use gradient boosting regression for both <code>model_y</code> and <code>model_t</code> and use lasso with cross-validation for <code>model_final</code>. Let’s import <code>GradientBoostingRegressor()</code> and <code>LassoCV()</code> from the <code>scikitlearn</code> package.</p>
</section>
<section id="lineardml" class="level3" data-number="22.3.2">
<h3 data-number="22.3.2" class="anchored" data-anchor-id="lineardml"><span class="header-section-number">22.3.2</span> <code>LinearDML</code></h3>
<p><code>LinearDML</code> is a DML estimator that uses <span style="color:blue"> unregularlized </span> linear model in the second stage. So, it assumes that <span class="math inline">\(\theta(X)\)</span> can be written as follows in <a href="C02-xstr-learner.html#eq-model-framework">Equation&nbsp;<span>12.1</span></a>:</p>
<p><span class="math display">\[
\begin{aligned}
\theta(X) = \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k
\end{aligned}
\]</span></p>
<p>It solves the following minimization problem,</p>
<p><span class="math display">\[
\begin{aligned}
argmin_{\beta_1, \dots, \beta_k} \sum_{i=1}^N (\tilde{Y}_i - \beta_1 x_1\cdot \tilde{T}- \beta_2 x_2\cdot \tilde{T}, \dots, - \beta_K x_K\cdot \tilde{T})^2
\end{aligned}
\]</span></p>
<p>This can be solved by simply regressing <span class="math inline">\(\tilde{Y}_i\)</span> on <span class="math inline">\(x_1\cdot \tilde{T}\)</span> through <span class="math inline">\(x_K\cdot \tilde{T}\)</span>. Once <span class="math inline">\(\beta_1, \dots,\beta_K\)</span> are estimated, then <span class="math inline">\(\hat{\theta}(X)\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}(X) = \hat{\beta}_1 x_1 + \hat{\beta}_2 x_2 + \dots + \hat{\beta}_k x_k
\end{aligned}
\]</span></p>
<p>So, it is easy to interpret how <span class="math inline">\(X\)</span> affects treatment effects using <code>LinearDML</code>. This estimator should be used only when there are small numbers of heterogeneity drivers, <span class="math inline">\(X\)</span>.</p>
<p>Since <code>LinearDML</code> runs a linear-in-parameter model without regularization, you do not need to specify the estimator for the final stage. We use <code>GradientBoostingRegressor()</code> for <code>model_y</code> and <code>GradientBoostingClassifier()</code> for <code>model_t</code>. Let’s set up our <code>LinearDML</code>,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> LinearDML(</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  model_t <span class="op">=</span> GradientBoostingClassifier()</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now invoke the <code>fit</code> method. Here, <span class="math inline">\(W=X\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>est.fit(Y, T, X <span class="op">=</span> X, W <span class="op">=</span> X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;econml.dml.dml.LinearDML object at 0x2c68d3fa0&gt;</code></pre>
</div>
</div>
<p>Predict <span class="math inline">\(\theta(X)\)</span> for <code>X_test</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>ldml_te <span class="op">=</span> est.effect(X_test)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ldml_te[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[-2.12361228 -1.90592651 -2.17083228 -1.61453416 -2.24491242]</code></pre>
</div>
</div>
</section>
<section id="nonparamdml" class="level3" data-number="22.3.3">
<h3 data-number="22.3.3" class="anchored" data-anchor-id="nonparamdml"><span class="header-section-number">22.3.3</span> <code>NonParamDML</code></h3>
<p>As the name suggests, it runs non-parametric regression (e.g., reandom forest) at the second stage. Unlike <code>LinearDML</code>, we need to specify <code>model_final</code>. Internally, it solves the following problem:</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0
\end{aligned}
\]</span></p>
<p>The estimator specified for <code>model_final</code> regress <span class="math inline">\(\frac{\tilde{Y}_i}{\tilde{T}_i}\)</span> and <span class="math inline">\(X_i\)</span> with sample weight of <span class="math inline">\(\tilde{T}_i^2\)</span>.</p>
<p>Let’s use <code>GradientBoostingRegressor()</code> as the final model.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> NonParamDML(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>  model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  model_t <span class="op">=</span> GradientBoostingClassifier(),</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  model_final <span class="op">=</span> GradientBoostingRegressor()</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now invoke the <code>fit</code> method. Here, <span class="math inline">\(W=X\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>est.fit(Y, T, X <span class="op">=</span> X, W <span class="op">=</span> X)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;econml.dml.dml.NonParamDML object at 0x2c6a2ae80&gt;</code></pre>
</div>
</div>
<p>Predict <span class="math inline">\(\theta(X)\)</span> for <code>X_test</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>ldml_te <span class="op">=</span> est.effect(X_test)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ldml_te[:<span class="dv">5</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[0.28981164 0.32268947 1.30953616 0.81487114 0.48354545]</code></pre>
</div>
</div>
</section>
<section id="causalforestdml" class="level3" data-number="22.3.4">
<h3 data-number="22.3.4" class="anchored" data-anchor-id="causalforestdml"><span class="header-section-number">22.3.4</span> CausalForestDML</h3>
</section>
</section>
<section id="orthogonal-forest" class="level2" data-number="22.4">
<h2 data-number="22.4" class="anchored" data-anchor-id="orthogonal-forest"><span class="header-section-number">22.4</span> Orthogonal Forest</h2>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-chen2020causalml" class="csl-entry" role="doc-biblioentry">
Chen, Huigang, Totte Harinen, Jeong-Yoon Lee, Mike Yung, and Zhenyu Zhao. 2020. <span>“CausalML: Python Package for Causal Machine Learning.”</span> <a href="https://arxiv.org/abs/2002.11631">https://arxiv.org/abs/2002.11631</a>.
</div>
<div id="ref-econml" class="csl-entry" role="doc-biblioentry">
Keith Battocchi, Maggie Hei, Eleanor Dillon. 2019. <span>“<span>EconML</span>: <span class="nocase">A Python Package for ML-Based Heterogeneous Treatment Effects Estimation</span>.”</span> https://github.com/microsoft/EconML.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./PROG-P-01-scikitlearn.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./PROG-P-03-model-selection.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Model selection</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb29" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Treatment Effect Estimation</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>This chapter presents CATE estimation using the <span class="in">`econml`</span> package <span class="co">[</span><span class="ot">@econml</span><span class="co">]</span>. The <span class="in">`causalml`</span> package by Uber <span class="co">[</span><span class="ot">@chen2020causalml</span><span class="co">]</span> is less complete than <span class="in">`econml`</span> at the moment, and we do not cover it.</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"ml-learning"</span>))</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML, LinearDML, SparseLinearDML, NonParamDML, CausalForestDML</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.metalearners <span class="im">import</span> TLearner, SLearner, XLearner, DomainAdaptationLearner</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.sklearn_extensions.model_selection <span class="im">import</span> GridSearchCVList</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, RandomForestClassifier</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor, GradientBoostingClassifier</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> Lasso</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RepeatedKFold, train_test_split</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> numpy.random <span class="im">import</span> binomial, multivariate_normal, normal, uniform</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a><span class="co">#=== ignore warnings ===#</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>Let's also generate synthetic dataset using <span class="in">`make_regression()`</span>.</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Define DGP</span></span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_data(n, d, controls_outcome, treatment_effect, propensity):</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Generates population data for given untreated_outcome, treatment_effect and propensity functions.</span></span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a><span class="co">    Parameters</span></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span class="co">    ----------</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a><span class="co">        n (int): population size</span></span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a><span class="co">        d (int): number of covariates</span></span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a><span class="co">        controls_outcome (func): untreated outcome conditional on covariates</span></span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a><span class="co">        treatment_effect (func): treatment effect conditional on covariates</span></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span class="co">        propensity (func): probability of treatment conditional on covariates</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate covariates</span></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n)</span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate treatment</span></span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a>    T <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: binomial(<span class="dv">1</span>, propensity(x), <span class="dv">1</span>)[<span class="dv">0</span>], <span class="dv">1</span>, X)</span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate outcome</span></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>    Y0 <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: controls_outcome(x), <span class="dv">1</span>, X)</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>    treat_effect <span class="op">=</span> np.apply_along_axis(<span class="kw">lambda</span> x: treatment_effect(x), <span class="dv">1</span>, X)</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>    Y <span class="op">=</span> Y0 <span class="op">+</span> treat_effect <span class="op">*</span> T</span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (Y, T, X)</span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a><span class="co"># controls outcome, treatment effect, propensity definitions</span></span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_controls_outcome(d):</span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> uniform(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, d)</span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="kw">lambda</span> x: np.dot(x, beta) <span class="op">+</span> normal(<span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>treatment_effect <span class="op">=</span> <span class="kw">lambda</span> x: (<span class="dv">1</span> <span class="cf">if</span> x[<span class="dv">1</span>] <span class="op">&gt;</span> <span class="fl">0.1</span> <span class="cf">else</span> <span class="dv">0</span>)<span class="op">*</span><span class="dv">8</span></span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>propensity <span class="op">=</span> <span class="kw">lambda</span> x: (<span class="fl">0.8</span> <span class="cf">if</span> (x[<span class="dv">2</span>]<span class="op">&gt;-</span><span class="fl">0.5</span> <span class="kw">and</span> x[<span class="dv">2</span>]<span class="op">&lt;</span><span class="fl">0.5</span>) <span class="cf">else</span> <span class="fl">0.2</span>)</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a><span class="co"># DGP constants and test data</span></span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>d <span class="op">=</span> <span class="dv">5</span></span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>n <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a>n_test <span class="op">=</span> <span class="dv">250</span></span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a>controls_outcome <span class="op">=</span> generate_controls_outcome(d)</span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> multivariate_normal(np.zeros(d), np.diag(np.ones(d)), n_test)</span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>delta <span class="op">=</span> <span class="dv">6</span><span class="op">/</span>n_test</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a>X_test[:, <span class="dv">1</span>] <span class="op">=</span> np.arange(<span class="op">-</span><span class="dv">3</span>, <span class="dv">3</span>, delta)</span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>Y, T, X <span class="op">=</span> generate_data(n, d, controls_outcome, treatment_effect, propensity)</span>
<span id="cb29-90"><a href="#cb29-90" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-91"><a href="#cb29-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-92"><a href="#cb29-92" aria-hidden="true" tabindex="-1"></a><span class="fu">## Average Treatment Effect </span></span>
<span id="cb29-93"><a href="#cb29-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-94"><a href="#cb29-94" aria-hidden="true" tabindex="-1"></a><span class="in">`DoubleML`</span></span>
<span id="cb29-95"><a href="#cb29-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-98"><a href="#cb29-98" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-99"><a href="#cb29-99" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb29-100"><a href="#cb29-100" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> DoubleML</span>
<span id="cb29-101"><a href="#cb29-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-102"><a href="#cb29-102" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-103"><a href="#cb29-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-104"><a href="#cb29-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-105"><a href="#cb29-105" aria-hidden="true" tabindex="-1"></a><span class="fu">## S-, X-, and T-learner</span></span>
<span id="cb29-106"><a href="#cb29-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-107"><a href="#cb29-107" aria-hidden="true" tabindex="-1"></a>This section shows how to train S-, X-, and T-learner. See @sec-het-dml for how these learners work, which would help you understand what you need to specify for each of the learners.  </span>
<span id="cb29-108"><a href="#cb29-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-109"><a href="#cb29-109" aria-hidden="true" tabindex="-1"></a><span class="fu">### S-learner</span></span>
<span id="cb29-110"><a href="#cb29-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-111"><a href="#cb29-111" aria-hidden="true" tabindex="-1"></a>To train an S-learner, you need to specify only one estimator, which estimates $E<span class="co">[</span><span class="ot">Y|T, X, W</span><span class="co">]</span>$. This can be done using <span class="in">`overall_model`</span> in <span class="in">`SLearner`</span>.</span>
<span id="cb29-112"><a href="#cb29-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-115"><a href="#cb29-115" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-116"><a href="#cb29-116" aria-hidden="true" tabindex="-1"></a><span class="co">#=== specify the overall model ===#</span></span>
<span id="cb29-117"><a href="#cb29-117" aria-hidden="true" tabindex="-1"></a>overall_model <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb29-118"><a href="#cb29-118" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb29-119"><a href="#cb29-119" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb29-120"><a href="#cb29-120" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb29-121"><a href="#cb29-121" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-122"><a href="#cb29-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-123"><a href="#cb29-123" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an S-learner ===#</span></span>
<span id="cb29-124"><a href="#cb29-124" aria-hidden="true" tabindex="-1"></a>S_learner <span class="op">=</span> SLearner(overall_model<span class="op">=</span>overall_model)</span>
<span id="cb29-125"><a href="#cb29-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-126"><a href="#cb29-126" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb29-127"><a href="#cb29-127" aria-hidden="true" tabindex="-1"></a>S_learner.fit(Y, T, X<span class="op">=</span>X)</span>
<span id="cb29-128"><a href="#cb29-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-129"><a href="#cb29-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-130"><a href="#cb29-130" aria-hidden="true" tabindex="-1"></a>Estimate $\theta(X)$ using the <span class="in">`effect`</span> method,</span>
<span id="cb29-131"><a href="#cb29-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-134"><a href="#cb29-134" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-135"><a href="#cb29-135" aria-hidden="true" tabindex="-1"></a>S_te <span class="op">=</span> S_learner.effect(X_test)</span>
<span id="cb29-136"><a href="#cb29-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-137"><a href="#cb29-137" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb29-138"><a href="#cb29-138" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(S_te[:<span class="dv">10</span>])</span>
<span id="cb29-139"><a href="#cb29-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-140"><a href="#cb29-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-141"><a href="#cb29-141" aria-hidden="true" tabindex="-1"></a><span class="fu">### T-learner</span></span>
<span id="cb29-142"><a href="#cb29-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-143"><a href="#cb29-143" aria-hidden="true" tabindex="-1"></a>To train a T-learner, you need to specify only one estimator, which estimates $E<span class="co">[</span><span class="ot">Y|T=1, X, W</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">Y|T=0, X, W</span><span class="co">]</span>$ sparately. This can be done using <span class="in">`models`</span> in <span class="in">`TLearner`</span>.</span>
<span id="cb29-144"><a href="#cb29-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-147"><a href="#cb29-147" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-148"><a href="#cb29-148" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an estimator ===#</span></span>
<span id="cb29-149"><a href="#cb29-149" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb29-150"><a href="#cb29-150" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb29-151"><a href="#cb29-151" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>, </span>
<span id="cb29-152"><a href="#cb29-152" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb29-153"><a href="#cb29-153" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-154"><a href="#cb29-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-155"><a href="#cb29-155" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up a T-learner ===#</span></span>
<span id="cb29-156"><a href="#cb29-156" aria-hidden="true" tabindex="-1"></a>T_learner <span class="op">=</span> TLearner(models<span class="op">=</span>models)</span>
<span id="cb29-157"><a href="#cb29-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-158"><a href="#cb29-158" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb29-159"><a href="#cb29-159" aria-hidden="true" tabindex="-1"></a>T_learner.fit(Y, T, X<span class="op">=</span>X)</span>
<span id="cb29-160"><a href="#cb29-160" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-161"><a href="#cb29-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-162"><a href="#cb29-162" aria-hidden="true" tabindex="-1"></a>Estimate $\theta(X)$ using the <span class="in">`effect`</span> method,</span>
<span id="cb29-163"><a href="#cb29-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-166"><a href="#cb29-166" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-167"><a href="#cb29-167" aria-hidden="true" tabindex="-1"></a>T_te <span class="op">=</span> T_learner.effect(X_test)</span>
<span id="cb29-168"><a href="#cb29-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-169"><a href="#cb29-169" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb29-170"><a href="#cb29-170" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(T_te[:<span class="dv">10</span>])</span>
<span id="cb29-171"><a href="#cb29-171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-172"><a href="#cb29-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-173"><a href="#cb29-173" aria-hidden="true" tabindex="-1"></a><span class="fu">### X-learner</span></span>
<span id="cb29-174"><a href="#cb29-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-175"><a href="#cb29-175" aria-hidden="true" tabindex="-1"></a>To train an X-learner, you need to specify two estimators</span>
<span id="cb29-176"><a href="#cb29-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-177"><a href="#cb29-177" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimator that estimates $E<span class="co">[</span><span class="ot">Y|T=1, X, W</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">Y|T=0, X, W</span><span class="co">]</span>$ sparately just like T-learner. </span>
<span id="cb29-178"><a href="#cb29-178" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Estimator that estimates $E<span class="co">[</span><span class="ot">T|X, W</span><span class="co">]</span>$ for weighting by propensity score</span>
<span id="cb29-179"><a href="#cb29-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-180"><a href="#cb29-180" aria-hidden="true" tabindex="-1"></a>This can be done using <span class="in">`models`</span> (for the first) and <span class="in">`propensity_model`</span> (for the second) in <span class="in">`XLearner`</span>. </span>
<span id="cb29-181"><a href="#cb29-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-184"><a href="#cb29-184" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-185"><a href="#cb29-185" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an estimator for 1 ===#</span></span>
<span id="cb29-186"><a href="#cb29-186" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> GradientBoostingRegressor(</span>
<span id="cb29-187"><a href="#cb29-187" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>, </span>
<span id="cb29-188"><a href="#cb29-188" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>, </span>
<span id="cb29-189"><a href="#cb29-189" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb29-190"><a href="#cb29-190" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-191"><a href="#cb29-191" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up a propensity model ===#</span></span>
<span id="cb29-192"><a href="#cb29-192" aria-hidden="true" tabindex="-1"></a>propensity_model <span class="op">=</span> RandomForestClassifier(</span>
<span id="cb29-193"><a href="#cb29-193" aria-hidden="true" tabindex="-1"></a>  n_estimators<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb29-194"><a href="#cb29-194" aria-hidden="true" tabindex="-1"></a>  max_depth<span class="op">=</span><span class="dv">6</span>,</span>
<span id="cb29-195"><a href="#cb29-195" aria-hidden="true" tabindex="-1"></a>  min_samples_leaf<span class="op">=</span><span class="dv">10</span></span>
<span id="cb29-196"><a href="#cb29-196" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-197"><a href="#cb29-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-198"><a href="#cb29-198" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up an X-learner ===#</span></span>
<span id="cb29-199"><a href="#cb29-199" aria-hidden="true" tabindex="-1"></a>X_learner <span class="op">=</span> XLearner(models<span class="op">=</span>models, propensity_model<span class="op">=</span>propensity_model)</span>
<span id="cb29-200"><a href="#cb29-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-201"><a href="#cb29-201" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb29-202"><a href="#cb29-202" aria-hidden="true" tabindex="-1"></a>X_learner.fit(Y, T, X<span class="op">=</span>X)</span>
<span id="cb29-203"><a href="#cb29-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-204"><a href="#cb29-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-205"><a href="#cb29-205" aria-hidden="true" tabindex="-1"></a>Estimate $\theta(X)$ using the <span class="in">`effect`</span> method,</span>
<span id="cb29-206"><a href="#cb29-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-209"><a href="#cb29-209" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-210"><a href="#cb29-210" aria-hidden="true" tabindex="-1"></a>X_te <span class="op">=</span> X_learner.effect(X_test)</span>
<span id="cb29-211"><a href="#cb29-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-212"><a href="#cb29-212" aria-hidden="true" tabindex="-1"></a><span class="co">#=== see the first 10 ===#</span></span>
<span id="cb29-213"><a href="#cb29-213" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(X_te[:<span class="dv">10</span>])</span>
<span id="cb29-214"><a href="#cb29-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-215"><a href="#cb29-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-216"><a href="#cb29-216" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-learner</span></span>
<span id="cb29-217"><a href="#cb29-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-218"><a href="#cb29-218" aria-hidden="true" tabindex="-1"></a>This section shows how to run various estimators that fall under R-learner, which is referred to as the <span class="in">`_Rlearner`</span> class in <span class="in">`econml`</span>. As we saw in @sec-het-dml, R-learner is a DML and <span class="in">`econml`</span> offers many estimators under <span class="in">`_Rlearner`</span>.</span>
<span id="cb29-219"><a href="#cb29-219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-220"><a href="#cb29-220" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`DML`</span></span>
<span id="cb29-221"><a href="#cb29-221" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span><span class="in">`LinearDML`</span></span>
<span id="cb29-222"><a href="#cb29-222" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span><span class="in">`SparseLinearDML`</span></span>
<span id="cb29-223"><a href="#cb29-223" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span><span class="in">`KernelDML`</span></span>
<span id="cb29-224"><a href="#cb29-224" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`NonParamDML`</span></span>
<span id="cb29-225"><a href="#cb29-225" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`CausalForestDML`</span></span>
<span id="cb29-226"><a href="#cb29-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-227"><a href="#cb29-227" aria-hidden="true" tabindex="-1"></a>All the estimators under <span class="in">`_Rlearner`</span> require that estimators for $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ are specified. This can be done by <span class="in">`model_y`</span> for $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and <span class="in">`model_t`</span> $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$. However, some estimators require that you specify the final (second stage) model using <span class="in">`model_final`</span> while others do not. </span>
<span id="cb29-228"><a href="#cb29-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-229"><a href="#cb29-229" aria-hidden="true" tabindex="-1"></a><span class="fu">### DML</span></span>
<span id="cb29-230"><a href="#cb29-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-231"><a href="#cb29-231" aria-hidden="true" tabindex="-1"></a>In this example, let's use gradient boosting regression for both <span class="in">`model_y`</span> and <span class="in">`model_t`</span> and use lasso with cross-validation for <span class="in">`model_final`</span>. Let's import <span class="in">`GradientBoostingRegressor()`</span> and <span class="in">`LassoCV()`</span> from the <span class="in">`scikitlearn`</span> package.</span>
<span id="cb29-232"><a href="#cb29-232" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-233"><a href="#cb29-233" aria-hidden="true" tabindex="-1"></a><span class="fu">### `LinearDML`</span></span>
<span id="cb29-234"><a href="#cb29-234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-235"><a href="#cb29-235" aria-hidden="true" tabindex="-1"></a><span class="in">`LinearDML`</span> is a DML estimator that uses <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> unregularlized <span class="kw">&lt;/span&gt;</span> linear model in the second stage. So, it assumes that $\theta(X)$ can be written as follows in @eq-model-framework:</span>
<span id="cb29-236"><a href="#cb29-236" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-237"><a href="#cb29-237" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb29-238"><a href="#cb29-238" aria-hidden="true" tabindex="-1"></a>\theta(X) = \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k</span>
<span id="cb29-239"><a href="#cb29-239" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb29-240"><a href="#cb29-240" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-241"><a href="#cb29-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-242"><a href="#cb29-242" aria-hidden="true" tabindex="-1"></a>It solves the following minimization problem,</span>
<span id="cb29-243"><a href="#cb29-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-244"><a href="#cb29-244" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-245"><a href="#cb29-245" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb29-246"><a href="#cb29-246" aria-hidden="true" tabindex="-1"></a>argmin_{\beta_1, \dots, \beta_k} \sum_{i=1}^N (\tilde{Y}_i - \beta_1 x_1\cdot \tilde{T}- \beta_2 x_2\cdot \tilde{T}, \dots, - \beta_K x_K\cdot \tilde{T})^2</span>
<span id="cb29-247"><a href="#cb29-247" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb29-248"><a href="#cb29-248" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-249"><a href="#cb29-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-250"><a href="#cb29-250" aria-hidden="true" tabindex="-1"></a>This can be solved by simply regressing $\tilde{Y}_i$ on $x_1\cdot \tilde{T}$ through $x_K\cdot \tilde{T}$. Once $\beta_1, \dots,\beta_K$ are estimated, then $\hat{\theta}(X)$ is </span>
<span id="cb29-251"><a href="#cb29-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-252"><a href="#cb29-252" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-253"><a href="#cb29-253" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb29-254"><a href="#cb29-254" aria-hidden="true" tabindex="-1"></a>\hat{\theta}(X) = \hat{\beta}_1 x_1 + \hat{\beta}_2 x_2 + \dots + \hat{\beta}_k x_k</span>
<span id="cb29-255"><a href="#cb29-255" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb29-256"><a href="#cb29-256" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-257"><a href="#cb29-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-258"><a href="#cb29-258" aria-hidden="true" tabindex="-1"></a>So, it is easy to interpret how $X$ affects treatment effects using <span class="in">`LinearDML`</span>. This estimator should be used only when there are small numbers of heterogeneity drivers, $X$.</span>
<span id="cb29-259"><a href="#cb29-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-260"><a href="#cb29-260" aria-hidden="true" tabindex="-1"></a>Since <span class="in">`LinearDML`</span> runs a linear-in-parameter model without regularization, you do not need to specify the estimator for the final stage. We use <span class="in">`GradientBoostingRegressor()`</span> for <span class="in">`model_y`</span> and <span class="in">`GradientBoostingClassifier()`</span> for <span class="in">`model_t`</span>. Let's set up our <span class="in">`LinearDML`</span>,</span>
<span id="cb29-261"><a href="#cb29-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-264"><a href="#cb29-264" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-265"><a href="#cb29-265" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> LinearDML(</span>
<span id="cb29-266"><a href="#cb29-266" aria-hidden="true" tabindex="-1"></a>  model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb29-267"><a href="#cb29-267" aria-hidden="true" tabindex="-1"></a>  model_t <span class="op">=</span> GradientBoostingClassifier()</span>
<span id="cb29-268"><a href="#cb29-268" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-269"><a href="#cb29-269" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-270"><a href="#cb29-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-271"><a href="#cb29-271" aria-hidden="true" tabindex="-1"></a>We now invoke the <span class="in">`fit`</span> method. Here, $W=X$.</span>
<span id="cb29-272"><a href="#cb29-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-275"><a href="#cb29-275" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-276"><a href="#cb29-276" aria-hidden="true" tabindex="-1"></a>est.fit(Y, T, X <span class="op">=</span> X, W <span class="op">=</span> X)</span>
<span id="cb29-277"><a href="#cb29-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-278"><a href="#cb29-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-279"><a href="#cb29-279" aria-hidden="true" tabindex="-1"></a>Predict $\theta(X)$ for <span class="in">`X_test`</span>.</span>
<span id="cb29-280"><a href="#cb29-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-283"><a href="#cb29-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-284"><a href="#cb29-284" aria-hidden="true" tabindex="-1"></a>ldml_te <span class="op">=</span> est.effect(X_test)</span>
<span id="cb29-285"><a href="#cb29-285" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-286"><a href="#cb29-286" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ldml_te[:<span class="dv">5</span>])</span>
<span id="cb29-287"><a href="#cb29-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-288"><a href="#cb29-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-289"><a href="#cb29-289" aria-hidden="true" tabindex="-1"></a><span class="fu">### `NonParamDML`</span></span>
<span id="cb29-290"><a href="#cb29-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-291"><a href="#cb29-291" aria-hidden="true" tabindex="-1"></a>As the name suggests, it runs non-parametric regression (e.g., reandom forest) at the second stage. Unlike <span class="in">`LinearDML`</span>, we need to specify <span class="in">`model_final`</span>. Internally, it solves the following problem:</span>
<span id="cb29-292"><a href="#cb29-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-293"><a href="#cb29-293" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-294"><a href="#cb29-294" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb29-295"><a href="#cb29-295" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0</span>
<span id="cb29-296"><a href="#cb29-296" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb29-297"><a href="#cb29-297" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb29-298"><a href="#cb29-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-299"><a href="#cb29-299" aria-hidden="true" tabindex="-1"></a>The estimator specified for <span class="in">`model_final`</span> regress $\frac{\tilde{Y}_i}{\tilde{T}_i}$ and $X_i$ with sample weight of $\tilde{T}_i^2$.</span>
<span id="cb29-300"><a href="#cb29-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-301"><a href="#cb29-301" aria-hidden="true" tabindex="-1"></a>Let's use <span class="in">`GradientBoostingRegressor()`</span> as the final model.</span>
<span id="cb29-302"><a href="#cb29-302" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-305"><a href="#cb29-305" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-306"><a href="#cb29-306" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> NonParamDML(</span>
<span id="cb29-307"><a href="#cb29-307" aria-hidden="true" tabindex="-1"></a>  model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb29-308"><a href="#cb29-308" aria-hidden="true" tabindex="-1"></a>  model_t <span class="op">=</span> GradientBoostingClassifier(),</span>
<span id="cb29-309"><a href="#cb29-309" aria-hidden="true" tabindex="-1"></a>  model_final <span class="op">=</span> GradientBoostingRegressor()</span>
<span id="cb29-310"><a href="#cb29-310" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb29-311"><a href="#cb29-311" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-312"><a href="#cb29-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-313"><a href="#cb29-313" aria-hidden="true" tabindex="-1"></a>We now invoke the <span class="in">`fit`</span> method. Here, $W=X$.</span>
<span id="cb29-314"><a href="#cb29-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-317"><a href="#cb29-317" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-318"><a href="#cb29-318" aria-hidden="true" tabindex="-1"></a>est.fit(Y, T, X <span class="op">=</span> X, W <span class="op">=</span> X)</span>
<span id="cb29-319"><a href="#cb29-319" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-320"><a href="#cb29-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-321"><a href="#cb29-321" aria-hidden="true" tabindex="-1"></a>Predict $\theta(X)$ for <span class="in">`X_test`</span>.</span>
<span id="cb29-322"><a href="#cb29-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-325"><a href="#cb29-325" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb29-326"><a href="#cb29-326" aria-hidden="true" tabindex="-1"></a>ldml_te <span class="op">=</span> est.effect(X_test)</span>
<span id="cb29-327"><a href="#cb29-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-328"><a href="#cb29-328" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(ldml_te[:<span class="dv">5</span>])</span>
<span id="cb29-329"><a href="#cb29-329" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb29-330"><a href="#cb29-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-331"><a href="#cb29-331" aria-hidden="true" tabindex="-1"></a><span class="fu">### CausalForestDML</span></span>
<span id="cb29-332"><a href="#cb29-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-333"><a href="#cb29-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-334"><a href="#cb29-334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-335"><a href="#cb29-335" aria-hidden="true" tabindex="-1"></a><span class="fu">## Orthogonal Forest</span></span>
<span id="cb29-336"><a href="#cb29-336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-337"><a href="#cb29-337" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>