<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 12&nbsp; S-, X-, T-, and R-learner</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C03-cf-orf.html" rel="next">
<link href="./C01-dml.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C04-cf-extension.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Extensions of Causal Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C05-causal-model-selection.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Causal Model Selection</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">Programming Guide: R</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code> in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-R-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Programming Guide: Python</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-01-scikitlearn.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Prediction using <code>scikitlearn</code></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-P-02-CATE-econml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">CATE estimation using <code>econml</code></span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-7" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-7" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation"> <span class="header-section-number">12.1</span> Motivation</a></li>
  <li><a href="#modeling-framework" id="toc-modeling-framework" class="nav-link" data-scroll-target="#modeling-framework"> <span class="header-section-number">12.2</span> Modeling Framework</a></li>
  <li><a href="#sec-stx" id="toc-sec-stx" class="nav-link" data-scroll-target="#sec-stx"> <span class="header-section-number">12.3</span> S-, T-, and X-Learner</a>
  <ul class="collapse">
  <li><a href="#s-learner" id="toc-s-learner" class="nav-link" data-scroll-target="#s-learner"> <span class="header-section-number">12.3.1</span> S-learner</a></li>
  <li><a href="#t-learner" id="toc-t-learner" class="nav-link" data-scroll-target="#t-learner"> <span class="header-section-number">12.3.2</span> T-learner</a></li>
  <li><a href="#x-learner" id="toc-x-learner" class="nav-link" data-scroll-target="#x-learner"> <span class="header-section-number">12.3.3</span> X-learner</a></li>
  </ul></li>
  <li><a href="#sec-r-learner" id="toc-sec-r-learner" class="nav-link" data-scroll-target="#sec-r-learner"> <span class="header-section-number">12.4</span> R-learner</a>
  <ul class="collapse">
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link" data-scroll-target="#theoretical-background"> <span class="header-section-number">12.4.1</span> Theoretical background</a></li>
  <li><a href="#sec-est-steps" id="toc-sec-est-steps" class="nav-link" data-scroll-target="#sec-est-steps"> <span class="header-section-number">12.4.2</span> Estimation steps</a></li>
  <li><a href="#r-learner-by-hand" id="toc-r-learner-by-hand" class="nav-link" data-scroll-target="#r-learner-by-hand"> <span class="header-section-number">12.4.3</span> R-learner by hand</a></li>
  </ul></li>
  <li><a href="#comparing-the-learners" id="toc-comparing-the-learners" class="nav-link" data-scroll-target="#comparing-the-learners"> <span class="header-section-number">12.5</span> Comparing the learners</a></li>
  <li><a href="#x--s--t--r-learner-in-python" id="toc-x--s--t--r-learner-in-python" class="nav-link" data-scroll-target="#x--s--t--r-learner-in-python"> <span class="header-section-number">12.6</span> X-, S-, T-, R-learner in Python</a></li>
  <li><a href="#t-learner-v.s.-x-learner-optional-and-not-that-important" id="toc-t-learner-v.s.-x-learner-optional-and-not-that-important" class="nav-link" data-scroll-target="#t-learner-v.s.-x-learner-optional-and-not-that-important"> <span class="header-section-number">12.7</span> T-learner v.s. X-learner (Optional, and not that important)</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/C02-xstr-learner.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-het-dml" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In this section, we look at the S-, X-, T-, and R-learner, which are method that estimate heterogeneous treatment effects when the treatment is binary. While X-learner and T-learner cannot be extended to continuous treatment cases, S-learner and R-learner can be.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What you will learn
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>How S-, X-, T-, and R-learner work</li>
<li>Performance of the learners under several data generating processes (DGP)</li>
<li>Causal model selection using R-score</li>
</ul>
</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Key points
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>R-learner is the same as DML approaches by <span class="citation" data-cites="Chernozhukov2018">Chernozhukov et al. (<a href="#ref-Chernozhukov2018" role="doc-biblioref">2018</a>)</span> except that it estimates CATE eat the second stage instead of ATE.</li>
<li>R-learner seems to perform better than S-, X-, and T-learners in many practical cases</li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Packages to load for replication
</div>
</div>
<div class="callout-body-container callout-body">
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<section id="motivation" class="level2 page-columns page-full" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="motivation"><span class="header-section-number">12.1</span> Motivation</h2>
<p>In <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, the basic idea of double machine learning (DML) methods was introduced when the treatment effect is homogeneous. We now turn our focus to the task of estimating heterogeneous treatment effects: the impact of a treatment varies based on observed attributes of the subjects. Heterogeneous treatment effect is also referred to as <span style="color:blue"> conditional </span> average treatment effect (CATE).</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span style="color:blue"> Conditional </span> on observed attributes.</p>
</div></div><p>Understanding how treatment effects vary can be highly valuable in many circumstances.</p>
<p><span style="color:blue"> Example 1: </span> If we come to know a particular drug is effective on elderly people but detrimental to kids, then doctors can make a smart decision of prescribing the drug to elderly people, but not to kids.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In this example, the heterogeneity driver is age.</p>
</div></div><p><span style="color:blue"> Example 2: </span> If we come to know that fertilizer is more effective in increasing corn yield in soil type A than B, then farmers can apply more fertilizer on the parts of the field where soil type is A but less on where soil type is B.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In this example, the heterogeneity driver is soil type.</p>
</div></div><p>As you can see in these examples, knowledge on the heterogeneity of the treatment effect and its drivers can help decision makers smart-target treatments and policies.</p>
</section>
<section id="modeling-framework" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="modeling-framework"><span class="header-section-number">12.2</span> Modeling Framework</h2>
<p>The model of interest in general form is as follows:</p>
<p><span id="eq-model-framework"><span class="math display">\[
\begin{aligned}
Y_i &amp; = \theta(X_i)\cdot T_i + g(X_i) + \varepsilon_i \\
T_i &amp; = f(X_i) + \eta_i
\end{aligned}
\tag{12.1}\]</span></span></p>
<ul>
<li><span class="math inline">\(Y\)</span>: dependent variable</li>
<li><span class="math inline">\(T\)</span>: treatment variable</li>
<li><span class="math inline">\(X\)</span>: features</li>
</ul>
<p>Here are the assumptions:</p>
<ul>
<li><span class="math inline">\(E[\varepsilon|T, X] = 0\)</span></li>
<li><span class="math inline">\(E[\eta|X] = 0\)</span></li>
<li><span class="math inline">\(E[\eta\cdot\varepsilon|T, X] = 0\)</span></li>
</ul>
<p>For the notational convenicence, let <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> denote the expected value of the potential conditional outcomes:</p>
<p><span class="math display">\[
\begin{align}
\mu_1(X) &amp; = E[Y|T=1, X] = \theta(X) + g(X)\\
\mu_0(X) &amp; = E[Y|T=0, X] = g(X)
\end{align}
\]</span></p>
</section>
<section id="sec-stx" class="level2 page-columns page-full" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="sec-stx"><span class="header-section-number">12.3</span> S-, T-, and X-Learner</h2>
<p>In this section, S-, T-, and X-Learner are introduced, accompanied by a simple R code demonstrations. For demonstrations, a synthetic dataset that follows the DGP below is used.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DGP 1
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
Y_i &amp; = (x_{i,1} + x_{i,2}^2)\cdot T_i + \sqrt{x_{i,3}} + \mu_i \\
T_i|X_i &amp; = Bernouli((1+x_{i,1})/2) \\
\mu_i|X_i &amp; = N(0,1)
\end{aligned}
\]</span></p>
</div>
</div>
<p>Here is the dataset according to the DGP.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">58734</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">T :=</span> <span class="fu">runif</span>(N) <span class="sc">&lt;</span> ((<span class="fl">0.5</span><span class="sc">+</span>x1)<span class="sc">/</span><span class="dv">2</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">Y :=</span> (x1 <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> T <span class="sc">+</span> <span class="fu">sqrt</span>(x3) <span class="sc">+</span> mu] <span class="sc">%&gt;%</span> </span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">id :=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="s-learner" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="s-learner"><span class="header-section-number">12.3.1</span> S-learner</h3>
<p>S-learner estimates CATE by taking the following steps:</p>
<ol type="1">
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(T\)</span> and <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(E[Y|T, X]\)</span> using any appropriate ML regression methods and call it <span class="math inline">\(\hat{\mu}(T,X)\)</span>.</li>
<li>Estimate <span class="math inline">\(\hat{\theta}(X)\)</span> as <span class="math inline">\(\hat{\mu}(T=1,X)-\hat{\mu}(T=0,X)\)</span></li>
</ol>
<p>In this approach, no special treatment is given to <span class="math inline">\(T\)</span>. It is just a covariate along with others (<span class="math inline">\(X\)</span>). This approach is named S-learner by <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span> because it involves estimating a <span style="color:red">s</span>ingle response function.</p>
<p>Here is a quick demonstration of how S-learner works (no cross-validation conducted in estimating <span class="math inline">\(E[Y|T, X]\)</span> in this example).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> T <span class="sc">+</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for treated (1) and control (0) ===#</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>eval_data_1 <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">T =</span> <span class="cn">TRUE</span>, <span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>eval_data_0 <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">T =</span> <span class="cn">FALSE</span>, <span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">data =</span> eval_data_1)<span class="sc">$</span>predictions</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">data =</span> eval_data_0)<span class="sc">$</span>predictions</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co">#=== theta_hat(X) ===#</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> mu_hat_1 <span class="sc">-</span> mu_hat_0</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.132512</code></pre>
</div>
</div>
</section>
<section id="t-learner" class="level3" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="t-learner"><span class="header-section-number">12.3.2</span> T-learner</h3>
<ol type="1">
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> using the treated observations to estimate <span class="math inline">\(\mu_1(X)\)</span> using any appropriate ML regression methods.</li>
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(X\)</span> using the control observations to estimate <span class="math inline">\(\mu_0(X)\)</span> using any appropriate ML regression methods.</li>
<li>Estimate <span class="math inline">\(\hat{\theta}(X)\)</span> as <span class="math inline">\(\hat{\mu}_1(X)-\hat{\mu}(X)\)</span></li>
</ol>
<p>This approach is named T-learner by <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span> because it involves estimating <span style="color:red">t</span>wo functions.</p>
<p>Here is a quick demonstration of how T-learner works (no cross-validation conducted in estimating <span class="math inline">\(E[Y|T=1, X]\)</span> and <span class="math inline">\(E[Y|T=0, X]\)</span> in this example).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>rf_trained_1 <span class="ot">&lt;-</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data[T <span class="sc">==</span> <span class="cn">TRUE</span>, ]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>rf_trained_0 <span class="ot">&lt;-</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data[T <span class="sc">==</span> <span class="cn">FALSE</span>, ]</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for treated (1) and control (0) ===#</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a><span class="co">#=== theta_hat(X) ===#</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> mu_hat_1 <span class="sc">-</span> mu_hat_0</span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.185506</code></pre>
</div>
</div>
</section>
<section id="x-learner" class="level3 page-columns page-full" data-number="12.3.3">
<h3 data-number="12.3.3" class="anchored" data-anchor-id="x-learner"><span class="header-section-number">12.3.3</span> X-learner</h3>
<ol type="1">
<li>Estimate <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> using any appropriate ML regression methods. (Steps 1 and 2 of the T-learner)</li>
<li>Impute individual treatment effect for the treated and control groups as follows</li>
</ol>
<p><span class="math display">\[
\begin{align}
\tilde{D}_i^1(X_i) = Y^1_i - \hat{\mu}_0(X_i)\\
\tilde{D}_i^0(X_i) =  \hat{\mu}_1(X_i) - Y^0_i
\end{align}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This is similar to cross-fitting we saw in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, where the folds are the treated and control groups.</p>
</div></div><ol start="3" type="1">
<li></li>
</ol>
<ul>
<li><p>Regress <span class="math inline">\(\tilde{D}_i^1(X_i)\)</span> on <span class="math inline">\(X\)</span> using the observations in the treated group and denote the predicted value as <span class="math inline">\(\hat{\theta}_1(X)\)</span></p></li>
<li><p>Regress <span class="math inline">\(\tilde{D}_i^0(X_i)\)</span> on <span class="math inline">\(X\)</span> using the observations in the control group and denote the predicted value as <span class="math inline">\(\hat{\theta}_0(X)\)</span></p></li>
</ul>
<ol start="4" type="1">
<li>Calculate <span class="math inline">\(\hat{\theta}(X)\)</span> as their weighted average</li>
</ol>
<p><span id="eq-final-X"><span class="math display">\[
\begin{align}
\hat{\theta}(X) = h(X)\cdot\hat{\theta}_0(X) + [1-h(X)]\cdot\hat{\theta}_1(X)
\end{align}
\tag{12.2}\]</span></span></p>
<p>Any value of <span class="math inline">\(h(X)\)</span> is acceptable. One option of <span class="math inline">\(h(X)\)</span> may be the estimated propensity score <span class="math inline">\(E[W|X]\)</span>.</p>
<p>Here is a quick demonstration of how X-learner works (no cross-validation conducted in estimating <span class="math inline">\(E[Y|T=1, X]\)</span> and <span class="math inline">\(E[Y|T=0, X]\)</span> in this example).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>treated_data <span class="ot">&lt;-</span> data[T <span class="sc">==</span> <span class="cn">TRUE</span>, ]</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>rf_trained_1 <span class="ot">&lt;-</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> treated_data</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>control_data <span class="ot">&lt;-</span> data[T <span class="sc">==</span> <span class="cn">FALSE</span>, ]</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>rf_trained_0 <span class="ot">&lt;-</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> control_data</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2 (imputed individual treatment effect)</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="co">#=== treated samples ===#</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>treated_data[, mu_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">data =</span> treated_data)<span class="sc">$</span>predictions]</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>treated_data[, D_tilde_1 <span class="sc">:</span><span class="er">=</span> Y <span class="sc">-</span> mu_hat_0]</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a><span class="co">#=== control samples ===#</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>control_data[, mu_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">data =</span> control_data)<span class="sc">$</span>predictions]</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>control_data[, D_tilde_0 <span class="sc">:</span><span class="er">=</span> mu_hat_1 <span class="sc">-</span> Y]</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3 (regress D on X)</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a><span class="co">#=== treated ===#</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>rf_trained_D1 <span class="ot">&lt;-</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    D_tilde_1 <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> treated_data</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a><span class="co">#=== control ===#</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>rf_trained_D0 <span class="ot">&lt;-</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>    D_tilde_0 <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> control_data</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="co"># step 4</span></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>theta_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_D1, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>theta_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_D0, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a><span class="co">#=== regress T on X ===#</span></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>rf_trained_T <span class="ot">&lt;-</span></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data,</span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a><span class="co">#=== propensity score estimate ===#</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>p_score <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_T, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]</span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a><span class="co">#=== weighted average of theta_hat_1 and theta_hat_0 with propensity score ===#</span></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> p_score <span class="sc">*</span> theta_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>p_score) <span class="sc">*</span> theta_hat_1</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9973382</code></pre>
</div>
</div>
</section>
</section>
<section id="sec-r-learner" class="level2 page-columns page-full" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="sec-r-learner"><span class="header-section-number">12.4</span> R-learner</h2>
<section id="theoretical-background" class="level3 page-columns page-full" data-number="12.4.1">
<h3 data-number="12.4.1" class="anchored" data-anchor-id="theoretical-background"><span class="header-section-number">12.4.1</span> Theoretical background</h3>
<p>Under the assumptions,</p>
<p><span id="eq-yxw"><span class="math display">\[
\begin{aligned}
E[Y|X] = \theta(X)\cdot f(X) + g(X)
\end{aligned}
\tag{12.3}\]</span></span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span class="math inline">\(f(X) = E[T|X]\)</span></p>
</div></div><p>Let, <span class="math inline">\(l(X)\)</span> denote <span class="math inline">\(E[Y|X]\)</span>. Taking the difference of <a href="#eq-model-framework">Equation&nbsp;<span>12.1</span></a> and <a href="#eq-yxw">Equation&nbsp;<span>12.3</span></a> on both sides,</p>
<p><span class="math display">\[
\begin{aligned}
Y_i \textcolor{red}{-l(X_i)} &amp; = \theta(X_i)\cdot T_i + g(X_i) + \varepsilon_i \textcolor{red}{-[\theta(X_i)\cdot f(X_i) + g(X_i)]} \\
\Rightarrow Y_i - l(X_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i)) + \varepsilon_i \\
\end{aligned}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This is akin to residualization/orthogonalization seen in the DML approach in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>.</p>
</div></div><p>So, the problem of identifying <span class="math inline">\(\theta(X)\)</span> reduces to estimating the following model:</p>
<p><span class="math display">\[
\begin{aligned}
Y_i - l(X_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i)) + \varepsilon_i
\end{aligned}
\]</span></p>
<p>Since <span class="math inline">\(E[(T_i -f(X_i))\cdot\varepsilon_i|X] = E[\eta_i\cdot\varepsilon_i|X] = 0\)</span> by assumption, we can regress <span class="math inline">\(Y_i - l(X_i)\)</span> on <span class="math inline">\(X_i\)</span> and <span class="math inline">\(T_i -f(X_i)\)</span> to estimate <span class="math inline">\(\theta(X)\)</span>. Specifically, we can minimize the following objective function:</p>
<p><span id="eq-est-equation"><span class="math display">\[
\begin{aligned}
Min_{\theta(X)}\sum_{i=1}^N \large(\normalsize[Y_i - l(X_i)] - [\theta(X_i)\cdot (T_i -f(X_i))]\large)^2
\end{aligned}
\tag{12.4}\]</span></span></p>
</section>
<section id="sec-est-steps" class="level3 page-columns page-full" data-number="12.4.2">
<h3 data-number="12.4.2" class="anchored" data-anchor-id="sec-est-steps"><span class="header-section-number">12.4.2</span> Estimation steps</h3>
<p>In practice, we of course do not observe <span class="math inline">\(l(X)\)</span> and <span class="math inline">\(f(X)\)</span>. So, we first need to estimate them using the data at hand and then subtract them from <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(T_i\)</span>, respectively. You can use any suitable statistical methods to estimate <span class="math inline">\(l(X)\)</span> and <span class="math inline">\(f(X)\)</span>. Some machine learning methods allow you to estimate them without assuming any functional form or structural assumptions. If you believe they are linear (in parameter) functions of <span class="math inline">\(X\)</span>, you could alternatively use lasso or other linear models. <span class="citation" data-cites="nie_quasi-oracle_2021">X. Nie and Wager (<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">2021</a>)</span> proposes that the estimation of <span class="math inline">\(l(X)\)</span> and <span class="math inline">\(f(X)\)</span> is done by cross-fitting (see <a href="C01-dml.html#sec-cf"><span>Section&nbsp;11.1.4</span></a>) to avoid over-fitting bias. Let <span class="math inline">\(I_{-i}\)</span> denote all the observations that belong to the folds that <span class="math inline">\(i\)</span> does <span style="color:blue"> not </span> belong to. Further, let <span class="math inline">\(\hat{l}(X_i)^{I_{-i}}\)</span> and <span class="math inline">\(\hat{f}(X_i)^{I_{-i}}\)</span> denote <span class="math inline">\(l(X_i)\)</span> and <span class="math inline">\(f(X_i)\)</span> estimated using <span class="math inline">\(I_{-i}\)</span>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Just like the DML approach discussed in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, both <span class="math inline">\(Y\)</span> and <span class="math inline">\(T\)</span> are orthogonalized.</p>
</div></div><p>Then the quality of fit (explaining the heterogeneity in the impact of treatment) can be expressed as follows, which is the empirical version of <a href="#eq-est-equation">Equation&nbsp;<span>12.4</span></a>:</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N [Y_i - \hat{l}(X_i)^{I_{-i}} - \theta(X)\cdot (T_i - \hat{f}(X_i)^{I_{-i}})]^2
\end{aligned}
\]</span></p>
<p>This is called <span style="color:blue"> R-score</span>, and it can be used for causal model selection, which will be covered later.</p>
<p>Let <span class="math inline">\(\tilde{Y}_i\)</span> and <span class="math inline">\(\tilde{T}_i\)</span> denote <span class="math inline">\(Y_i - \hat{l}(X_i)^{I_{-i}}\)</span> and <span class="math inline">\(T_i - \hat{f}(X_i)^{I_{-i}}\)</span>, respectively. The final stage of the R-learner is to estimate <span class="math inline">\(\theta(X)\)</span> by minimizing the R-score plus the regularization term (if desirable).</p>
<p><span id="eq-r-min"><span class="math display">\[
\begin{aligned}
\hat{\theta}(X) = argmin_{\theta(X)}\;\;\sum_{i=1}^N [\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i]^2 + \Lambda(\theta(X))
\end{aligned}
\tag{12.5}\]</span></span></p>
<p>where <span class="math inline">\(\Lambda(\theta(X))\)</span> is the penalty on the complexity of <span class="math inline">\(\theta(X)\)</span>. For example, if you choose to use lasso, then <span class="math inline">\(\Lambda(\theta(X))\)</span> is the L1 norm. You have lots of freedom as to what model you use in the final stage. The <code>econml</code> package offers several off-the-shelf choices of R-learner (DML) approaches that differ in the model used at the final stage, including causal forest, lasso, etc.</p>
</section>
<section id="r-learner-by-hand" class="level3" data-number="12.4.3">
<h3 data-number="12.4.3" class="anchored" data-anchor-id="r-learner-by-hand"><span class="header-section-number">12.4.3</span> R-learner by hand</h3>
<p>This section goes through R codes to implement the estimation steps provided above to further our understanding of how R-learner works using the same synthetic dataset as the one used in <a href="#sec-stx"><span>Section&nbsp;12.3</span></a>.</p>
<hr>
<p>We first cross-fit <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[T|X]\)</span> using random forest for both cases. We will use repeated (3 times) 5-fold cross-fitting. Resampling the data,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(data, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#  5-fold cross-validation repeated 3 times 
# A tibble: 15 × 3
   splits            id      id2  
   &lt;list&gt;            &lt;chr&gt;   &lt;chr&gt;
 1 &lt;split [800/200]&gt; Repeat1 Fold1
 2 &lt;split [800/200]&gt; Repeat1 Fold2
 3 &lt;split [800/200]&gt; Repeat1 Fold3
 4 &lt;split [800/200]&gt; Repeat1 Fold4
 5 &lt;split [800/200]&gt; Repeat1 Fold5
 6 &lt;split [800/200]&gt; Repeat2 Fold1
 7 &lt;split [800/200]&gt; Repeat2 Fold2
 8 &lt;split [800/200]&gt; Repeat2 Fold3
 9 &lt;split [800/200]&gt; Repeat2 Fold4
10 &lt;split [800/200]&gt; Repeat2 Fold5
11 &lt;split [800/200]&gt; Repeat3 Fold1
12 &lt;split [800/200]&gt; Repeat3 Fold2
13 &lt;split [800/200]&gt; Repeat3 Fold3
14 &lt;split [800/200]&gt; Repeat3 Fold4
15 &lt;split [800/200]&gt; Repeat3 Fold5</code></pre>
</div>
</div>
<p>The following function takes a row number (<code>n</code>) and cross-fits <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[T|X]\)</span> using the training and test data stored in the <code>n</code>th row of <code>data_folds</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n, data_folds) </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">analysis</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>  eval_data <span class="ot">&lt;-</span> <span class="fu">assessment</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[Y|X]</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== train ===#</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>  rf_trained_y <span class="ot">&lt;-</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>      Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit ===#</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>  eval_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_y, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions]</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[T|X]</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  rf_trained_t <span class="ot">&lt;-</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>      T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data,</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>  eval_data[, t_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_t, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]]</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(eval_data[, .(id, y_hat, t_hat)])</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what the output of the function for the first split looks like.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cross_fit</span>(<span class="dv">1</span>, data_folds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      id      y_hat     t_hat
  1:   8 1.12894746 0.3900865
  2:  10 1.20619521 0.8137849
  3:  16 2.11055584 0.6956071
  4:  19 1.66612748 0.7430183
  5:  24 0.97711495 0.2783762
 ---                         
196: 976 1.24745823 0.3559905
197: 986 1.90226459 0.7848286
198: 988 0.09856452 0.3313690
199: 994 1.15828871 0.3815524
200: 999 1.23109488 0.4655611</code></pre>
</div>
</div>
<p>Repeating this for all the splits,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>cross_fitted_data_rp <span class="ot">&lt;-</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       id     y_hat     t_hat
   1:   8 1.1265820 0.3838746
   2:  10 1.2710531 0.7914683
   3:  16 2.0934446 0.6716373
   4:  19 1.5689207 0.7728349
   5:  24 0.9738104 0.2713413
  ---                        
2996: 984 1.4447333 0.6111246
2997: 988 0.2112768 0.3394246
2998: 989 1.2142513 0.5499603
2999: 994 1.0262291 0.3408294
3000: 996 0.9049447 0.5382365</code></pre>
</div>
</div>
<p>We finally take the mean of the cross-fits by <code>id</code> as each <code>id</code> has tree estimates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>cross_fitted_data <span class="ot">&lt;-</span> </span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data_rp[, .(</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_hat =</span> <span class="fu">mean</span>(t_hat),</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> <span class="fu">mean</span>(y_hat)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">by =</span> id]</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>        id     t_hat     y_hat
   1:    8 0.4532550 1.1761568
   2:   10 0.7740161 1.1470253
   3:   16 0.5242056 1.9554895
   4:   19 0.6223349 1.6357163
   5:   24 0.3034603 1.0096122
  ---                         
 996:  980 0.4608352 1.5986389
 997:  981 0.1200376 0.8747466
 998:  982 0.6291434 1.0229563
 999:  996 0.5064177 0.8796906
1000: 1000 0.3033786 1.3630618</code></pre>
</div>
</div>
<p>We then merge the data to the original data, and define <span class="math inline">\(\tilde{Y}\)</span> and <span class="math inline">\(\tilde{T}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>data_2nd <span class="ot">&lt;-</span> </span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data[data, <span class="at">on =</span> <span class="st">"id"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_tilde =</span> Y <span class="sc">-</span> y_hat,</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_tilde =</span> T <span class="sc">-</span> t_hat</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  .[, .(y_tilde, t_tilde, x1, x2, x3)]</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          y_tilde    t_tilde          x1         x2        x3
   1:  0.02185133 -0.5942087 0.260608266 0.06164198 0.4589749
   2: -1.03373018 -0.5714296 0.766984113 0.54764941 0.2009673
   3:  1.60365721  0.4938529 0.826228121 0.87144558 0.9021309
   4:  1.32224214  0.5060730 0.640185426 0.60915635 0.9121869
   5:  0.29076658  0.5654463 0.513102608 0.98349865 0.2889536
  ---                                                        
 996: -1.92603402 -0.5064177 0.503932977 0.98448894 0.4080396
 997: -0.94039653 -0.3125415 0.004402003 0.08928705 0.7901242
 998:  0.11977427  0.5844593 0.543469334 0.67529131 0.8898840
 999:  1.29398249 -0.4388722 0.927181725 0.58389265 0.4166628
1000: -0.69038873 -0.3033786 0.037774180 0.66973547 0.8149703</code></pre>
</div>
</div>
<hr>
<p>The first order condition of <a href="#eq-r-min">Equation&nbsp;<span>12.5</span></a> without <span class="math inline">\(\Lambda(\theta(X))\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N (\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i)\cdot \tilde{T}_i = 0
\end{aligned}
\]</span></p>
<p>This can be rewritten as</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0
\end{aligned}
\]</span></p>
<p>So, this problem can be considered the problem of estimating <span class="math inline">\(\theta(X)\)</span> when the dependent variable is <span class="math inline">\(\frac{\tilde{Y}_i}{\tilde{T}_i}\)</span> with individual weights of <span class="math inline">\(\tilde{T}_i^2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>data_2nd[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">weight =</span> t_tilde<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_to_t =</span> y_tilde <span class="sc">/</span> t_tilde</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s use <code>xgboost()</code> for a non-parametric estimation of <span class="math inline">\(\theta(X)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can now predict <span class="math inline">\(\theta(X)\)</span> at particular values of <span class="math inline">\(X\)</span>. Let’s estimate <span class="math inline">\(\theta(X)\)</span> at <span class="math inline">\(X_0 = \{x_1 = 0.5, x_2 = 0.5, x_3 = 0.5\}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> </span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> .)</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_trained_2nd, eval_data)</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.164435</code></pre>
</div>
</div>
<p>You could alternatively estimate <span class="math inline">\(\theta(X)\)</span> parametrically using OLS. Suppose we somehow know that <span class="math inline">\(\theta(X)\)</span> takes the following form <span class="math inline">\(\beta_1 x_1 + \beta_2 x_2^2 + \beta_3 x_3\)</span>. Then, the second stage estimation would be regressing <span class="math inline">\(\tilde{Y}\)</span> on <span class="math inline">\(x_1\times T\)</span>, <span class="math inline">\(x_2^2\times T\)</span>, and <span class="math inline">\(x_2\times T\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>ols_2nd_stage <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_tilde <span class="sc">~</span> <span class="fu">I</span>(x1<span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x2<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">*</span>t_tilde), <span class="at">data =</span> data_2nd)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== summary ===#</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ols_2nd_stage)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y_tilde ~ I(x1 * t_tilde) + I(x2^2 * t_tilde) + 
    I(x3 * t_tilde), data = data_2nd)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3354 -0.7314  0.0390  0.6332  3.3914 

Coefficients:
                  Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       -0.01052    0.03239  -0.325    0.745    
I(x1 * t_tilde)    0.80643    0.18888   4.269 2.15e-05 ***
I(x2^2 * t_tilde)  1.10509    0.19827   5.574 3.21e-08 ***
I(x3 * t_tilde)    0.28246    0.18708   1.510    0.131    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.022 on 996 degrees of freedom
Multiple R-squared:  0.2038,    Adjusted R-squared:  0.2015 
F-statistic: 85.01 on 3 and 996 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The results look pretty good mostly because we are cheating and using the correct functional form. Of course, in practice, you would not know the correct functional form of <span class="math inline">\(\theta(X)\)</span>. Finally, note that you should not use the codes here since they are just for demonstration to enhance our understanding of how R-learner works.</p>
</section>
</section>
<section id="comparing-the-learners" class="level2 page-columns page-full" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="comparing-the-learners"><span class="header-section-number">12.5</span> Comparing the learners</h2>
<p>In this section, we compare the performance of the learners under two DGPs, which fall under the following general model:</p>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp; =\theta(X_i)\cdot T + \alpha\cdot g(X_i) + \mu_i \\
T_i &amp; = Bernouli(f(X_i))
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(\alpha\)</span> is a constant that changes the share of the nuisance function <span class="math inline">\(g(X)\)</span> in <span class="math inline">\(Y\)</span>’s variation (larger <span class="math inline">\(\alpha\)</span> in magnitude, larger share of <span class="math inline">\(g(X)\)</span>).</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Caveats
</div>
</div>
<div class="callout-body-container callout-body">
<p>We cannot draw any generalizable conclusions about the performance of the learners because we only consider a specific case of the learners where the extreme gradient boost is used for all the estimation tasks and also because we consider only several DGPs.</p>
</div>
</div>
<p>Performance comparisons under more DGPs can be found in <span class="citation" data-cites="nie_quasi-oracle_2021">X. Nie and Wager (<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">2021</a>)</span>. MC simulations here focus more on the role of the magnitude of the nuisance part in <span class="math inline">\(Y\)</span>, which <span class="citation" data-cites="nie_quasi-oracle_2021">X. Nie and Wager (<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">2021</a>)</span> does not look at.</p>
<hr>
<p>We first work on the following DGP (named DGP A).</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DGP A
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
g(X_i) &amp; = sin(\pi X_{i,1}X_{i,2}) + 2(X_{i,3}-0.5)^2 + X_{i,4} + 0.5 X_{i,5}\\
f(X_i) &amp; = max(0.1, min(sin(\pi X_{i,1}X_{i,2}), 0.9)) \\
\theta(X_i) &amp; = (X_{i,1}, X_{i,2}) / 2 \\
X_i &amp; \sim Uni(0,1)^5
\end{aligned}
\]</span></p>
</div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p>DGP A with <span class="math inline">\(\alpha =1\)</span> is almost the same as Set-up A of <span class="citation" data-cites="nie_quasi-oracle_2021">X. Nie and Wager (<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">2021</a>)</span> except that they use <span class="math inline">\(Y_i =\theta(X_i)\cdot (T-0.5) + \alpha\cdot g(X_i) + \mu_i\)</span>, so that <span class="math inline">\(-0.5*\theta(X)\)</span> is actually a part of the nuisance for <span class="math inline">\(Y\)</span>.</p>
</div></div><p>The following code generate data according to DGP A.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>gen_data_A <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha){</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> alpha <span class="sc">*</span> (<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x4 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x5),</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">f_x =</span> <span class="fu">pmax</span>(<span class="fl">0.1</span>, <span class="fu">pmin</span>(<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2), <span class="fl">0.9</span>)),</span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> (x1<span class="sc">+</span>x2)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> f_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u] <span class="sc">%&gt;%</span> </span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>    .[, id <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use the <code>rlearner</code> package <span class="citation" data-cites="Xinkun-rlearner-package">(<a href="#ref-Xinkun-rlearner-package" role="doc-biblioref">Xinkun Nie, Schuler, and Wager 2022</a>)</span> to implement S-, T-, X-, and R-learner. In particular, we will use the <code>*boost()</code> functions (e.g., <code>rboost()</code> for R-learner), which use <code>xgboost()</code> for all the estimation tasks. Parameter tuning is done internally (see <a href="https://github.com/xnie/rlearner/blob/6806396960e672214e2ef36e16c76bbb58ef9114/R/cvboost.R#L70-L78">here</a> for the hyper parameter search space). S-learner implemented by <code>sboost()</code> is different from the S-learner described above in that it include the interactions of the treatment variable and feature variables: that is, it regresses <span class="math inline">\(Y\)</span> on <span class="math inline">\(T\)</span>, <span class="math inline">\(X\)</span>, and <span class="math inline">\(T*X\)</span>.</p>
<!-- So, we call the implementation of S-learner by `sboost()` "S-learner with interactions." We also implement an S-learner where $Y$ is regressed on only $T$ and $X$, which is called "S-learner without interactions." -->
<p>The following code implements S-, T-, X-, and R-learner for a single iteration and calculate MSE of estimating <span class="math inline">\(\theta(X)\)</span> on the test data.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>The <code>rlearner</code> package also offers <code>*lasso()</code> and <code>*kern()</code> series. The package is not designed to be flexible as there are fixed combinations of learners and you cannot specify estimation methods yourself.</p>
</div></div><div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>get_mse <span class="ot">&lt;-</span> <span class="cf">function</span>(i, gen_data, alpha) {</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prepare data</span></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">gen_data_A</span>(N, alpha)</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">gen_data_A</span>(N, alpha)</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>  test_X <span class="ot">&lt;-</span> test_data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cor(train_data[, .(theta_x, g_x)])</span></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Train and predict </span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  learner_ls <span class="ot">&lt;-</span> <span class="fu">list</span>(rboost, sboost, xboost, tboost)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>      learner_ls,</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(learner) {</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        trained_learner <span class="ot">&lt;-</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>          <span class="fu">learner</span>(</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>            train_data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>            train_data<span class="sc">$</span>t, </span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>            train_data<span class="sc">$</span>y</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>        theta_data <span class="ot">&lt;-</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>          <span class="fu">data.table</span>(</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_true =</span> test_data<span class="sc">$</span>theta_x,</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_hat =</span> <span class="fu">predict</span>(trained_learner, test_X)</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(theta_data)</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"learner"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">fcase</span>(</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"R"</span>,</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">2</span>, <span class="st">"S"</span>,</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">3</span>, <span class="st">"X"</span>,</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">4</span>, <span class="st">"T"</span></span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>    )]</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(results)</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Repeating experiments 100 times for <span class="math inline">\(\alpha = 1\)</span>,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha)</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<div class="cell">

</div>
<p><a href="#fig-log-mse-dgp-A-1">Figure&nbsp;<span>12.1</span></a> shows the histogram of MSE by learner.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>mse_data_1 <span class="ot">&lt;-</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  mc_results_1 <span class="sc">%&gt;%</span> </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 1"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>  .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">factor</span>(learner, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"S"</span>, <span class="st">"T"</span>, <span class="st">"X"</span>, <span class="st">"R"</span>))]</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_1) <span class="sc">+</span> </span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> mse)) <span class="sc">+</span></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-log-mse-dgp-A-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-log-mse-dgp-A-1-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.1: Density of Log MSE of estimating CATE by method</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As you can see, R-learner performs the best, followed closely by X-learner, then by S-learner, and T-learner.</p>
<p>Now, we change the value of <span class="math inline">\(\alpha\)</span> to 10 from 1 to make the nuisance part have a much larger share in <span class="math inline">\(Y\)</span>’s variation.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>mc_results <span class="ot">&lt;-</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha)</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">

</div>
<div class="cell">

</div>
<p><a href="#fig-log-mse-dgp-A-1-10">Figure&nbsp;<span>12.2</span></a> shows the histogram of MSE by learner for <span class="math inline">\(\alpha=1\)</span> and <span class="math inline">\(\alpha=10\)</span>. All the methods are negatively affected by the increase in the influence of the nuisance function, <span class="math inline">\(g(X)\)</span>. However, some learners are affected more than others. R-learner is. much less affected by the change than the other methods, and R-learner is clearly the best performing learner at <span class="math inline">\(\alpha = 10\)</span>. All the other learners performed considerably poorer compared to the case with <span class="math inline">\(\alpha =1\)</span>. This shows that R-learner shines particularly when the treatment effect is only the small portion of the total variation in <span class="math inline">\(Y\)</span>. This is a very important property because it is often the case for many scientific fields. For example, consider estimating the impact of a vocational training program on income. Such a program is unlikely to drastically change participants income level. Other factors that have nothing to do with the program (nuisance part) are likely to have much bigger role in determining income.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>mse_data_10 <span class="ot">&lt;-</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>  mc_results_10 <span class="sc">%&gt;%</span> </span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 10"</span>]</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>mse_data_all <span class="ot">&lt;-</span> </span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbind</span>(mse_data_1, mse_data_10) <span class="sc">%&gt;%</span> </span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>  .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">factor</span>(learner, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"S"</span>, <span class="st">"T"</span>, <span class="st">"X"</span>, <span class="st">"R"</span>))]</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_all) <span class="sc">+</span> </span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> mse, <span class="at">fill =</span> type), </span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">bins =</span> <span class="dv">75</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-log-mse-dgp-A-1-10" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-log-mse-dgp-A-1-10-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.2: Density of Log MSE of estimating CATE by method</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-s-iter">Figure&nbsp;<span>12.3</span></a> plots the true (y-axis) and estimated (x-axis) treatment effect by learner for a single iteration at <span class="math inline">\(\alpha = 10\)</span>, which gives us insights into the decomposition of MSE (variance and bias).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_10[sim <span class="sc">==</span> <span class="dv">1</span>, ]) <span class="sc">+</span> </span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theta_true, <span class="at">x =</span> theta_hat)) <span class="sc">+</span></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Estimated Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"True Treatment Effect"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-s-iter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-s-iter-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.3: True v.s. estimated treatment effects by learner for a single iteration (<span class="math inline">\(\alpha\)</span> = 10)</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>According to the figure, all of them seem to suffer from positive bias. Here is the average of the true treatment effects less the estimated treatment effects by learner. So, indeed, they all suffer from bias. T-learner suffers from the most severe bias, and R-learner suffers from the smallest bias.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>mc_results_10[, .(<span class="at">bias =</span> <span class="fu">mean</span>(theta_true <span class="sc">-</span> theta_hat)), by <span class="ot">=</span> learner]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   learner       bias
1:       R -0.1312763
2:       S -0.5830240
3:       X -0.2645536
4:       T -0.7078119</code></pre>
</div>
</div>
<p>T-learner has the highest variance of treatment effect estimates, followed by S-learner, X-learner, and then R-learner. Here is the average (over iterations) standard deviation of treatment effect estimates by learner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>mc_results_10[, .(<span class="at">sd =</span> <span class="fu">sd</span>(theta_true <span class="sc">-</span> theta_hat)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span> </span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">sd =</span> <span class="fu">mean</span>(sd)), by <span class="ot">=</span> learner]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   learner        sd
1:       R 0.2839190
2:       S 0.8823216
3:       X 0.6298141
4:       T 1.2539635</code></pre>
</div>
</div>
<p>The problem with high variance in CATE estimation is that, the effect of treatment “looks” much more heterogeneous than it truly is. This leads to over-estimation of the benefit of targeted treatment (e.g., policy, medical treatment) assignment.</p>
<hr>
<p>Let’s look at another DGP.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
DGP B (randomized trial)
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
g(X_i) &amp; = max(X_{i,1} + X_{i,2}, X_{i,3}, 0) + max(X_{i,4}+ X_{i,5},0)\\
e(X_i) &amp; = 1/2 \\
\theta(X_i) &amp; = X_{i,1} + log(1+exp(X_{i,2})) \\
X_i &amp; \sim N(0,I_5)
\end{aligned}
\]</span></p>
</div>
</div>
<p>Here is the code to generate data according to DGP B.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>gen_data_B <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha){</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> alpha <span class="sc">*</span> (<span class="fu">pmax</span>(x1 <span class="sc">+</span> x2, x3) <span class="sc">+</span> <span class="fu">pmax</span>(x4 <span class="sc">+</span> x5, <span class="dv">0</span>)),</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> x1<span class="sc">+</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x2))</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">

</div>
<div class="cell">

</div>
<p>Here is the code to run MC simulations for <span class="math inline">\(\alpha = 1\)</span> and <span class="math inline">\(\alpha = 10\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">10</span>)</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a>mse_data_1 <span class="ot">&lt;-</span></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a>  mc_results_1 <span class="sc">%&gt;%</span> </span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 1"</span>]</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>mse_data_10 <span class="ot">&lt;-</span></span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>  mc_results_10 <span class="sc">%&gt;%</span> </span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 10"</span>]</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>mse_data_all <span class="ot">&lt;-</span> <span class="fu">rbind</span>(mse_data_1, mse_data_10) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-log-mse-dgp-B-1-10">Figure&nbsp;<span>12.4</span></a> presents the results. Compared to DGP A, S- and T-learner performs much better at <span class="math inline">\(\alpha = 1\)</span> almost matching that of X- and R-learner. However, once the role of nuisance function is greater at <span class="math inline">\(\alpha = 10\)</span>, then the performance of S-, T-, and X-learner deteriorate substantially (especially T-learner).</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_all) <span class="sc">+</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> mse, <span class="at">fill =</span> type), </span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">bins =</span> <span class="dv">75</span></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-log-mse-dgp-B-1-10" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-log-mse-dgp-B-1-10-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.4: Density of Log MSE of estimating CATE by method</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><a href="#fig-s-iter-B">Figure&nbsp;<span>12.5</span></a> presents the scatter plot of the true and estimated treatment effects by learner for a single iteration. None of them seem to be biased, but there is a clear difference in variance of CATE estimates.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_10[sim <span class="sc">==</span> <span class="dv">1</span>, ]) <span class="sc">+</span> </span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theta_true, <span class="at">x =</span> theta_hat)) <span class="sc">+</span></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Estimated Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"True Treatment Effect"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div id="fig-s-iter-B" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-s-iter-B-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.5: True v.s. estimated treatment effects by learner for a single iteration (<span class="math inline">\(\alpha\)</span> = 10)</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="x--s--t--r-learner-in-python" class="level2 page-columns page-full" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="x--s--t--r-learner-in-python"><span class="header-section-number">12.6</span> X-, S-, T-, R-learner in Python</h2>
<p>We saw a general R-learner framework for CATE estimation. We now look at an example of Linear DML, which uses a linear model at the final stage. So, we are assuming that <span class="math inline">\(\theta(X)\)</span> can be written as follows in <a href="#eq-model-framework">Equation&nbsp;<span>12.1</span></a>:</p>
<p><span class="math display">\[
\begin{aligned}
\theta(X) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(x_1\)</span> through <span class="math inline">\(x_k\)</span> are the drivers of heterogeneity in treatment effects and <span class="math inline">\(\beta_1\)</span> through <span class="math inline">\(\beta_k\)</span> are their coefficients.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p>We use both Python and R for this demonstration. So, let’s set things up for that.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"ml-learning"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For this demonstration, we use synthetic data according to the following data generating process:</p>
<p><span class="math display">\[
\begin{aligned}
y_i = exp(x_{i,1}) d_i + x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} + \mu_i \\
d_i = \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3}+ \eta_i
\end{aligned}
\]</span></p>
<p>Note that this is the same data generating process used in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a> except that the impact of the treatment (<span class="math inline">\(d\)</span>) now depends on <span class="math inline">\(x_1\)</span>. We can use <code>gen_data()</code> function that is defined in <a href="C01-dml.html#sec-dml-naive"><span>Section&nbsp;11.1.2</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== sample size ===#</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== generate data ===#</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>synth_data <span class="ot">&lt;-</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_data</span>(</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">*</span>d)),</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> N <span class="sc">*</span><span class="dv">2</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(synth_data, <span class="fu">starts_with</span>(<span class="st">"x"</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> synth_data[, y]</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> synth_data[, d]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now split the data into training and test datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb44-2"><a href="#cb44-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb44-3"><a href="#cb44-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test, d_train, d_test<span class="op">=</span> train_test_split(r.X, r.y, r.d,  test_size <span class="op">=</span> <span class="fl">0.5</span>, random_state <span class="op">=</span> <span class="dv">8923</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, to train a linear DML model, we use the Python <code>econml</code> package, which offers one of the most comprehensive sets of off-the-shelf R-learner (DML) methods <span class="citation" data-cites="econml">(<a href="#ref-econml" role="doc-biblioref">Keith Battocchi 2019</a>)</span>. We can use the <code>DML</code> class to implement linear DML.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><code>DML</code> is a child class of <code>_Rlearner</code>, which is a private class. The <code>DML</code> class has several child classes: <code>LinearDML</code>, <code>SpatseLinearDML</code>, <code>NonParamDML</code>, and <code>CausalForestDML</code>.</p>
</div></div><p>As we saw above in <a href="#sec-est-steps"><span>Section&nbsp;12.4.2</span></a>, we need to specify three models:</p>
<ul>
<li><code>model_y</code>: model for estimating <span class="math inline">\(E[Y|X,W]\)</span></li>
<li><code>model_t</code>: model for estimating <span class="math inline">\(E[T|X,W]\)</span></li>
<li><code>model_final</code>: model for estimating <span class="math inline">\(\theta(X)\)</span></li>
</ul>
<p>In this example, let’s use gradient boosting regression for both <code>model_y</code> and <code>model_t</code> and use lasso with cross-validation for <code>model_final</code>. Let’s import <code>GradientBoostingRegressor()</code> and <code>LassoCV()</code> from the <code>scikitlearn</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now set up our DML framework like below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> DML(</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>    model_t <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>    model_final <span class="op">=</span> LassoCV(fit_intercept <span class="op">=</span> <span class="va">False</span>) </span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that no training has happened yet at this point. We simply created a recipe. Once we provide ingredients (data), we can cook (train) with the <code>fit()</code> method.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>est.fit(y_train, d_train, X <span class="op">=</span> X_train, W <span class="op">=</span> X_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>first argument: dependent variable</li>
<li>second argument: treatment variable</li>
<li><code>X</code>: variables that drive treatment effect heterogeneity</li>
<li><code>W</code>: variables that affect the dependent variable directly</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>Here, we set <code>X = W</code>.</p>
</div></div><p>Once, the training is done. We can use the <code>effect()</code> method to predict <span class="math inline">\(\theta(X)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a>te_test <span class="op">=</span> est.effect(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-est-theta-hat">Figure&nbsp;<span>12.6</span></a> presents the estimated and true marginal treatment effect (<span class="math inline">\(\theta(X)\)</span>) as a function of <code>x1</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> </span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> py<span class="sc">$</span>X_test[, <span class="dv">1</span>],</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">te =</span> py<span class="sc">$</span>te_test</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data) <span class="sc">+</span></span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> te, <span class="at">x =</span> x1)) <span class="sc">+</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">exp</span>(x1), <span class="at">x =</span> x1), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-est-theta-hat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-est-theta-hat-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.6: Estimated and true marginal treatment effects</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Since we forced <span class="math inline">\(\theta(X)\)</span> to be linear in <code>x1</code>, it is not surprising that the estimated MTE looks linear in <code>x1</code> even though the true MTE is an exponential function of <code>x1</code>. In the next chapter (<span class="quarto-unresolved-ref">?sec-forest-cate</span>), we discuss CATE estimators based on forest, which estimates <span class="math inline">\(\theta(X)\)</span> non-parametrically, relaxing the assumption of <span class="math inline">\(\theta(X)\)</span> being linear-in-parameter.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are many more variations in DML than the one presented here. For those who are interested, I recommend going through examples presented <a href="https://github.com/microsoft/EconML/blob/main/notebooks/Double%20Machine%20Learning%20Examples.ipynb">here</a> for <code>DML</code></p>
</div>
</div>
</section>
<section id="t-learner-v.s.-x-learner-optional-and-not-that-important" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="t-learner-v.s.-x-learner-optional-and-not-that-important"><span class="header-section-number">12.7</span> T-learner v.s. X-learner (Optional, and not that important)</h2>
<p>Here, an advantage of X-learner over T-learner is demonstrated. This example also serves as an illustration of how these learners are implemented. Specifically, X-learner can be advantageous when the control-treatment assignments in the sample are unbalanced. For example, it is often the case that there are plenty of observations in the control group, while there are not many treated observations. For the purpose of illustration, consider a rather extreme case where there are only 10 observations in the treated group, while there are 300 observations in the control group. We use the following toy data generating process:</p>
<p><span class="math display">\[
\begin{align}
y = \tau W + |x| + v
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\tau = 1\)</span>. So, the treatment effect is not heterogeneous. For the purpose of illustrating the advantage of X-learner over T-learner, it is convenient if the underlying model is simpler.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4345</span>)</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>N_trt <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a>N_ctrl <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> N_trt <span class="sc">+</span> N_ctrl</span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,N_trt), <span class="fu">rep</span>(<span class="dv">0</span>, N_ctrl)),</span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Treated"</span>, N_trt), <span class="fu">rep</span>(<span class="st">"Control"</span>, N_ctrl)),</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">runif</span>(N)<span class="sc">-</span><span class="dv">1</span>,</span>
<span id="cb51-12"><a href="#cb51-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">v =</span> <span class="fu">rnorm</span>(N) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb51-13"><a href="#cb51-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb51-14"><a href="#cb51-14" aria-hidden="true" tabindex="-1"></a>  .[, y <span class="sc">:</span><span class="er">=</span> W <span class="sc">+</span> <span class="fu">abs</span>(x) <span class="sc">+</span> v]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> data) <span class="sc">+</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-49-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s first estimate <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> (Step 1). Since we have only <span class="math inline">\(20\)</span> observations in the treated group, we will use a linear regression to avoid over-fitting (following the example in <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>mu_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a>mu_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> are estimated, we can estimate <span class="math inline">\(\hat{\theta}(X)\)</span> by T-learner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a><span class="co">#=== T-learner ===#</span></span>
<span id="cb54-3"><a href="#cb54-3" aria-hidden="true" tabindex="-1"></a>tau_hat_data <span class="ot">&lt;-</span> </span>
<span id="cb54-4"><a href="#cb54-4" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="sc">%&gt;%</span></span>
<span id="cb54-5"><a href="#cb54-5" aria-hidden="true" tabindex="-1"></a>  .[, mu_1_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb54-6"><a href="#cb54-6" aria-hidden="true" tabindex="-1"></a>  .[, mu_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb54-7"><a href="#cb54-7" aria-hidden="true" tabindex="-1"></a>  .[, tau_hat_T <span class="sc">:</span><span class="er">=</span> mu_1_hat <span class="sc">-</span> mu_0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see, T-learner is heavily biased. This is because of the unreliable estimation of <span class="math inline">\(\mu_1(X)\)</span> due to lack of observations in the treated group.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-52-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now, let’s move on to X-learner. We impute individual treatment effects (Step 2).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (treated) ===#</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (control) ===#</span></span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a><span class="co">#=== assign the values ===#</span></span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Treated"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_1]</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Control"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_0]</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== find individual TE ===#</span></span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>data[, D <span class="sc">:</span><span class="er">=</span> <span class="fu">ifelse</span>(type <span class="sc">==</span> <span class="st">"Treated"</span>, y <span class="sc">-</span> mu_hat, mu_hat <span class="sc">-</span> y)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now regress <span class="math inline">\(D\)</span> on <span class="math inline">\(X\)</span> (Step 3),</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (treated)</span></span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>tau_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(D <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_1_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (control)</span></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>tau_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(D <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_0_trained, <span class="at">newdata =</span> tau_hat_data)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_1, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Treated"</span>)) <span class="sc">+</span></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_0, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Control"</span>)) <span class="sc">+</span></span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Treated"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Control"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-55-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s use propensity score as <span class="math inline">\(g(X)\)</span> in Step 4.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>w_gam_trained <span class="ot">&lt;-</span> </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gam</span>(</span>
<span id="cb59-3"><a href="#cb59-3" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), </span>
<span id="cb59-4"><a href="#cb59-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data, </span>
<span id="cb59-5"><a href="#cb59-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb59-6"><a href="#cb59-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s predict <span class="math inline">\(E[W|X]\)</span> at each value of <span class="math inline">\(X\)</span> at which we are estiamting <span class="math inline">\(\tau\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, g_x <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(w_gam_trained, <span class="at">newdata =</span> tau_hat_data, <span class="at">type =</span> <span class="st">"response"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see below, the mean value of <span class="math inline">\(g(x)\)</span> is small because the treatment probability is very low (it is only <span class="math inline">\(20\)</span> out of <span class="math inline">\(320\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(tau_hat_data[, g_x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.06451538</code></pre>
</div>
</div>
<p>This number is basically <span class="math inline">\(20/320\)</span>. So, in this example, we could have just used the proportion of the treated observations. Notice that <span class="math inline">\(g(X)\)</span> is multiplied to <span class="math inline">\(\hat{\theta}_0(X)\)</span> in <a href="#eq-final-X">Equation&nbsp;<span>12.2</span></a>. So, we are giving a lower weight to <span class="math inline">\(\hat{\theta}_0(X)\)</span>. This is because <span class="math inline">\(\hat{\theta}_0(X)\)</span> is less reliable because <span class="math inline">\(\hat{\mu}_1(X)\)</span> is less reliable due to the lack of samples in the treated group.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_X <span class="sc">:</span><span class="er">=</span> g_x <span class="sc">*</span> tau_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>g_x) <span class="sc">*</span> tau_hat_1]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see, X-learner outperforms T-learner in this particular instance at least in terms of point estimates of <span class="math inline">\(\tau(X)\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"T-learner"</span>)) <span class="sc">+</span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_X, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"X-learner"</span>)) <span class="sc">+</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">"True Treatment Effect"</span>)) <span class="sc">+</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"T-learner"</span> <span class="ot">=</span> <span class="st">"red"</span>, </span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"X-learner"</span> <span class="ot">=</span> <span class="st">"blue"</span>, </span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"True Treatment Effect"</span> <span class="ot">=</span> <span class="st">"black"</span></span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-60-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<div class="cell">

</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Chernozhukov2018" class="csl-entry" role="doc-biblioentry">
Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. <span>“<span class="nocase">Double/debiased machine learning for treatment and structural parameters</span>.”</span> <em>The Econometrics Journal</em> 21 (1): C1–68. <a href="https://doi.org/10.1111/ectj.12097">https://doi.org/10.1111/ectj.12097</a>.
</div>
<div id="ref-econml" class="csl-entry" role="doc-biblioentry">
Keith Battocchi, Maggie Hei, Eleanor Dillon. 2019. <span>“<span>EconML</span>: <span class="nocase">A Python Package for ML-Based Heterogeneous Treatment Effects Estimation</span>.”</span> https://github.com/microsoft/EconML.
</div>
<div id="ref-kunzel_metalearners_2019" class="csl-entry" role="doc-biblioentry">
Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. 2019. <span>“Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning.”</span> <em>Proceedings of the National Academy of Sciences</em> 116 (10): 4156–65. <a href="https://doi.org/10.1073/pnas.1804597116">https://doi.org/10.1073/pnas.1804597116</a>.
</div>
<div id="ref-Xinkun-rlearner-package" class="csl-entry" role="doc-biblioentry">
Nie, Xinkun, Alejandro Schuler, and Stefan Wager. 2022. <em>Rlearner: R-Learner for Heterogeneous Treatment Effect Estimation</em>.
</div>
<div id="ref-nie_quasi-oracle_2021" class="csl-entry" role="doc-biblioentry">
Nie, X, and S Wager. 2021. <span>“Quasi-Oracle Estimation of Heterogeneous Treatment Effects.”</span> <em>Biometrika</em> 108 (2): 299–319. <a href="https://doi.org/10.1093/biomet/asaa076">https://doi.org/10.1093/biomet/asaa076</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C01-dml.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C03-cf-orf.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb65" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># S-, X-, T-, and R-learner {#sec-het-dml}</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>In this section, we look at the S-, X-, T-, and R-learner, which are method that estimate heterogeneous treatment effects when the treatment is binary. While X-learner and T-learner cannot be extended to continuous treatment cases, S-learner and R-learner can be. </span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a><span class="fu">## What you will learn</span></span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>How S-, X-, T-, and R-learner work</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Performance of the learners under several data generating processes (DGP)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Causal model selection using R-score</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key points</span></span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>R-learner is the same as DML approaches by @Chernozhukov2018 except that it estimates CATE eat the second stage instead of ATE.</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>R-learner seems to perform better than S-, X-, and T-learners in many practical cases </span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a><span class="fu">## Packages to load for replication</span></span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-33"><a href="#cb65-33" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb65-34"><a href="#cb65-34" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb65-35"><a href="#cb65-35" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb65-36"><a href="#cb65-36" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb65-37"><a href="#cb65-37" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb65-38"><a href="#cb65-38" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb65-39"><a href="#cb65-39" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb65-40"><a href="#cb65-40" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb65-41"><a href="#cb65-41" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-42"><a href="#cb65-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-45"><a href="#cb65-45" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-46"><a href="#cb65-46" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-47"><a href="#cb65-47" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb65-48"><a href="#cb65-48" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb65-49"><a href="#cb65-49" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb65-50"><a href="#cb65-50" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb65-51"><a href="#cb65-51" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb65-52"><a href="#cb65-52" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb65-53"><a href="#cb65-53" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb65-54"><a href="#cb65-54" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb65-55"><a href="#cb65-55" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-56"><a href="#cb65-56" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-57"><a href="#cb65-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-58"><a href="#cb65-58" aria-hidden="true" tabindex="-1"></a><span class="fu">## Motivation</span></span>
<span id="cb65-59"><a href="#cb65-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-60"><a href="#cb65-60" aria-hidden="true" tabindex="-1"></a>In @sec-dml, the basic idea of double machine learning (DML) methods was introduced when the treatment effect is homogeneous. We now turn our focus to the task of estimating heterogeneous treatment effects: the impact of a treatment varies based on observed attributes of the subjects. Heterogeneous treatment effect is also referred to as <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> conditional <span class="kw">&lt;/span&gt;</span> average treatment effect (CATE).</span>
<span id="cb65-61"><a href="#cb65-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-62"><a href="#cb65-62" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-63"><a href="#cb65-63" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Conditional <span class="kw">&lt;/span&gt;</span> on observed attributes.</span>
<span id="cb65-64"><a href="#cb65-64" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-65"><a href="#cb65-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-66"><a href="#cb65-66" aria-hidden="true" tabindex="-1"></a>Understanding how treatment effects vary can be highly valuable in many circumstances. </span>
<span id="cb65-67"><a href="#cb65-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-68"><a href="#cb65-68" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Example 1: <span class="kw">&lt;/span&gt;</span></span>
<span id="cb65-69"><a href="#cb65-69" aria-hidden="true" tabindex="-1"></a>If we come to know a particular drug is effective on elderly people but detrimental to kids, then doctors can make a smart decision of prescribing the drug to elderly people, but not to kids. </span>
<span id="cb65-70"><a href="#cb65-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-71"><a href="#cb65-71" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-72"><a href="#cb65-72" aria-hidden="true" tabindex="-1"></a>In this example, the heterogeneity driver is age.</span>
<span id="cb65-73"><a href="#cb65-73" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-74"><a href="#cb65-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-75"><a href="#cb65-75" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Example 2: <span class="kw">&lt;/span&gt;</span></span>
<span id="cb65-76"><a href="#cb65-76" aria-hidden="true" tabindex="-1"></a>If we come to know that fertilizer is more effective in increasing corn yield in soil type A than B, then farmers can apply more fertilizer on the parts of the field where soil type is A but less on where soil type is B. </span>
<span id="cb65-77"><a href="#cb65-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-78"><a href="#cb65-78" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-79"><a href="#cb65-79" aria-hidden="true" tabindex="-1"></a>In this example, the heterogeneity driver is soil type.</span>
<span id="cb65-80"><a href="#cb65-80" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-81"><a href="#cb65-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-82"><a href="#cb65-82" aria-hidden="true" tabindex="-1"></a>As you can see in these examples, knowledge on the heterogeneity of the treatment effect and its drivers can help decision makers smart-target treatments and policies. </span>
<span id="cb65-83"><a href="#cb65-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-84"><a href="#cb65-84" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modeling Framework</span></span>
<span id="cb65-85"><a href="#cb65-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-86"><a href="#cb65-86" aria-hidden="true" tabindex="-1"></a>The model of interest in general form is as follows:</span>
<span id="cb65-87"><a href="#cb65-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-88"><a href="#cb65-88" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-89"><a href="#cb65-89" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-90"><a href="#cb65-90" aria-hidden="true" tabindex="-1"></a>Y_i &amp; = \theta(X_i)\cdot T_i + g(X_i) + \varepsilon_i <span class="sc">\\</span></span>
<span id="cb65-91"><a href="#cb65-91" aria-hidden="true" tabindex="-1"></a>T_i &amp; = f(X_i) + \eta_i </span>
<span id="cb65-92"><a href="#cb65-92" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-93"><a href="#cb65-93" aria-hidden="true" tabindex="-1"></a>$$ {#eq-model-framework}</span>
<span id="cb65-94"><a href="#cb65-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-95"><a href="#cb65-95" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$Y$: dependent variable</span>
<span id="cb65-96"><a href="#cb65-96" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$T$: treatment variable</span>
<span id="cb65-97"><a href="#cb65-97" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$X$: features</span>
<span id="cb65-98"><a href="#cb65-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-99"><a href="#cb65-99" aria-hidden="true" tabindex="-1"></a>Here are the assumptions:</span>
<span id="cb65-100"><a href="#cb65-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-101"><a href="#cb65-101" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\varepsilon|T, X</span><span class="co">]</span> = 0$</span>
<span id="cb65-102"><a href="#cb65-102" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta|X</span><span class="co">]</span> = 0$</span>
<span id="cb65-103"><a href="#cb65-103" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta\cdot\varepsilon|T, X</span><span class="co">]</span> = 0$</span>
<span id="cb65-104"><a href="#cb65-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-105"><a href="#cb65-105" aria-hidden="true" tabindex="-1"></a>For the notational convenicence, let $\mu_1(X)$ and $\mu_0(X)$ denote the expected value of the potential conditional outcomes:</span>
<span id="cb65-106"><a href="#cb65-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-107"><a href="#cb65-107" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-108"><a href="#cb65-108" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb65-109"><a href="#cb65-109" aria-hidden="true" tabindex="-1"></a>\mu_1(X) &amp; = E<span class="co">[</span><span class="ot">Y|T=1, X</span><span class="co">]</span> = \theta(X) + g(X)<span class="sc">\\</span> </span>
<span id="cb65-110"><a href="#cb65-110" aria-hidden="true" tabindex="-1"></a>\mu_0(X) &amp; = E<span class="co">[</span><span class="ot">Y|T=0, X</span><span class="co">]</span> = g(X)</span>
<span id="cb65-111"><a href="#cb65-111" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb65-112"><a href="#cb65-112" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-113"><a href="#cb65-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-114"><a href="#cb65-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-115"><a href="#cb65-115" aria-hidden="true" tabindex="-1"></a><span class="fu">## S-, T-, and X-Learner {#sec-stx}</span></span>
<span id="cb65-116"><a href="#cb65-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-117"><a href="#cb65-117" aria-hidden="true" tabindex="-1"></a>In this section, S-, T-, and X-Learner are introduced, accompanied by a simple R code demonstrations. For demonstrations, a synthetic dataset that follows the DGP below is used.</span>
<span id="cb65-118"><a href="#cb65-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-119"><a href="#cb65-119" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb65-120"><a href="#cb65-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-121"><a href="#cb65-121" aria-hidden="true" tabindex="-1"></a><span class="fu">## DGP 1</span></span>
<span id="cb65-122"><a href="#cb65-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-123"><a href="#cb65-123" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-124"><a href="#cb65-124" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-125"><a href="#cb65-125" aria-hidden="true" tabindex="-1"></a>Y_i &amp; = (x_{i,1} + x_{i,2}^2)\cdot T_i + \sqrt{x_{i,3}} + \mu_i <span class="sc">\\</span></span>
<span id="cb65-126"><a href="#cb65-126" aria-hidden="true" tabindex="-1"></a>T_i|X_i &amp; = Bernouli((1+x_{i,1})/2) <span class="sc">\\</span></span>
<span id="cb65-127"><a href="#cb65-127" aria-hidden="true" tabindex="-1"></a>\mu_i|X_i &amp; = N(0,1)</span>
<span id="cb65-128"><a href="#cb65-128" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-129"><a href="#cb65-129" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-130"><a href="#cb65-130" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-131"><a href="#cb65-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-132"><a href="#cb65-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-133"><a href="#cb65-133" aria-hidden="true" tabindex="-1"></a>Here is the dataset according to the DGP.</span>
<span id="cb65-134"><a href="#cb65-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-137"><a href="#cb65-137" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-138"><a href="#cb65-138" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">58734</span>)</span>
<span id="cb65-139"><a href="#cb65-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-140"><a href="#cb65-140" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb65-141"><a href="#cb65-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-142"><a href="#cb65-142" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-143"><a href="#cb65-143" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span></span>
<span id="cb65-144"><a href="#cb65-144" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb65-145"><a href="#cb65-145" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-146"><a href="#cb65-146" aria-hidden="true" tabindex="-1"></a>    <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-147"><a href="#cb65-147" aria-hidden="true" tabindex="-1"></a>    <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-148"><a href="#cb65-148" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb65-149"><a href="#cb65-149" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-150"><a href="#cb65-150" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">T :=</span> <span class="fu">runif</span>(N) <span class="sc">&lt;</span> ((<span class="fl">0.5</span><span class="sc">+</span>x1)<span class="sc">/</span><span class="dv">2</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb65-151"><a href="#cb65-151" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">Y :=</span> (x1 <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> T <span class="sc">+</span> <span class="fu">sqrt</span>(x3) <span class="sc">+</span> mu] <span class="sc">%&gt;%</span> </span>
<span id="cb65-152"><a href="#cb65-152" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">id :=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb65-153"><a href="#cb65-153" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb65-154"><a href="#cb65-154" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-155"><a href="#cb65-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-156"><a href="#cb65-156" aria-hidden="true" tabindex="-1"></a><span class="fu">### S-learner</span></span>
<span id="cb65-157"><a href="#cb65-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-158"><a href="#cb65-158" aria-hidden="true" tabindex="-1"></a>S-learner estimates CATE by taking the following steps:</span>
<span id="cb65-159"><a href="#cb65-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-160"><a href="#cb65-160" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Regress $Y$ on $T$ and $X$ to estimate $E<span class="co">[</span><span class="ot">Y|T, X</span><span class="co">]</span>$ using any appropriate ML regression methods and call it $\hat{\mu}(T,X)$.</span>
<span id="cb65-161"><a href="#cb65-161" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Estimate $\hat{\theta}(X)$ as $\hat{\mu}(T=1,X)-\hat{\mu}(T=0,X)$</span>
<span id="cb65-162"><a href="#cb65-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-163"><a href="#cb65-163" aria-hidden="true" tabindex="-1"></a>In this approach, no special treatment is given to $T$. It is just a covariate along with others ($X$). This approach is named S-learner by @kunzel_metalearners_2019 because it involves estimating a <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:red'</span><span class="kw">&gt;</span>s<span class="kw">&lt;/span&gt;</span>ingle response function.</span>
<span id="cb65-164"><a href="#cb65-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-165"><a href="#cb65-165" aria-hidden="true" tabindex="-1"></a>Here is a quick demonstration of how S-learner works (no cross-validation conducted in estimating $E<span class="co">[</span><span class="ot">Y|T, X</span><span class="co">]</span>$ in this example). </span>
<span id="cb65-166"><a href="#cb65-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-169"><a href="#cb65-169" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-170"><a href="#cb65-170" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-171"><a href="#cb65-171" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1</span></span>
<span id="cb65-172"><a href="#cb65-172" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-173"><a href="#cb65-173" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb65-174"><a href="#cb65-174" aria-hidden="true" tabindex="-1"></a>rf_trained <span class="ot">&lt;-</span></span>
<span id="cb65-175"><a href="#cb65-175" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-176"><a href="#cb65-176" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> T <span class="sc">+</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-177"><a href="#cb65-177" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data</span>
<span id="cb65-178"><a href="#cb65-178" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-179"><a href="#cb65-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-180"><a href="#cb65-180" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-181"><a href="#cb65-181" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2</span></span>
<span id="cb65-182"><a href="#cb65-182" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-183"><a href="#cb65-183" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb65-184"><a href="#cb65-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-185"><a href="#cb65-185" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for treated (1) and control (0) ===#</span></span>
<span id="cb65-186"><a href="#cb65-186" aria-hidden="true" tabindex="-1"></a>eval_data_1 <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">T =</span> <span class="cn">TRUE</span>, <span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb65-187"><a href="#cb65-187" aria-hidden="true" tabindex="-1"></a>eval_data_0 <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">T =</span> <span class="cn">FALSE</span>, <span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb65-188"><a href="#cb65-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-189"><a href="#cb65-189" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb65-190"><a href="#cb65-190" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">data =</span> eval_data_1)<span class="sc">$</span>predictions</span>
<span id="cb65-191"><a href="#cb65-191" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">data =</span> eval_data_0)<span class="sc">$</span>predictions</span>
<span id="cb65-192"><a href="#cb65-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-193"><a href="#cb65-193" aria-hidden="true" tabindex="-1"></a><span class="co">#=== theta_hat(X) ===#</span></span>
<span id="cb65-194"><a href="#cb65-194" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-195"><a href="#cb65-195" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> mu_hat_1 <span class="sc">-</span> mu_hat_0</span>
<span id="cb65-196"><a href="#cb65-196" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-197"><a href="#cb65-197" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-198"><a href="#cb65-198" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-199"><a href="#cb65-199" aria-hidden="true" tabindex="-1"></a><span class="fu">### T-learner</span></span>
<span id="cb65-200"><a href="#cb65-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-201"><a href="#cb65-201" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Regress $Y$ on $X$ using the treated observations to estimate $\mu_1(X)$ using any appropriate ML regression methods.</span>
<span id="cb65-202"><a href="#cb65-202" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Regress $Y$ on $X$ using the control observations to estimate $\mu_0(X)$ using any appropriate ML regression methods.</span>
<span id="cb65-203"><a href="#cb65-203" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Estimate $\hat{\theta}(X)$ as $\hat{\mu}_1(X)-\hat{\mu}(X)$</span>
<span id="cb65-204"><a href="#cb65-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-205"><a href="#cb65-205" aria-hidden="true" tabindex="-1"></a>This approach is named T-learner by @kunzel_metalearners_2019 because it involves estimating <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:red'</span><span class="kw">&gt;</span>t<span class="kw">&lt;/span&gt;</span>wo functions.</span>
<span id="cb65-206"><a href="#cb65-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-207"><a href="#cb65-207" aria-hidden="true" tabindex="-1"></a>Here is a quick demonstration of how T-learner works (no cross-validation conducted in estimating $E<span class="co">[</span><span class="ot">Y|T=1, X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">Y|T=0, X</span><span class="co">]</span>$ in this example). </span>
<span id="cb65-208"><a href="#cb65-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-211"><a href="#cb65-211" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-212"><a href="#cb65-212" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-213"><a href="#cb65-213" aria-hidden="true" tabindex="-1"></a><span class="co"># step 1</span></span>
<span id="cb65-214"><a href="#cb65-214" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-215"><a href="#cb65-215" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb65-216"><a href="#cb65-216" aria-hidden="true" tabindex="-1"></a>rf_trained_1 <span class="ot">&lt;-</span></span>
<span id="cb65-217"><a href="#cb65-217" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-218"><a href="#cb65-218" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-219"><a href="#cb65-219" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data[T <span class="sc">==</span> <span class="cn">TRUE</span>, ]</span>
<span id="cb65-220"><a href="#cb65-220" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-221"><a href="#cb65-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-222"><a href="#cb65-222" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-223"><a href="#cb65-223" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2</span></span>
<span id="cb65-224"><a href="#cb65-224" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-225"><a href="#cb65-225" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb65-226"><a href="#cb65-226" aria-hidden="true" tabindex="-1"></a>rf_trained_0 <span class="ot">&lt;-</span></span>
<span id="cb65-227"><a href="#cb65-227" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-228"><a href="#cb65-228" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-229"><a href="#cb65-229" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data[T <span class="sc">==</span> <span class="cn">FALSE</span>, ]</span>
<span id="cb65-230"><a href="#cb65-230" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-231"><a href="#cb65-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-232"><a href="#cb65-232" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-233"><a href="#cb65-233" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3</span></span>
<span id="cb65-234"><a href="#cb65-234" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-235"><a href="#cb65-235" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb65-236"><a href="#cb65-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-237"><a href="#cb65-237" aria-hidden="true" tabindex="-1"></a><span class="co">#=== data for treated (1) and control (0) ===#</span></span>
<span id="cb65-238"><a href="#cb65-238" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb65-239"><a href="#cb65-239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-240"><a href="#cb65-240" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb65-241"><a href="#cb65-241" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb65-242"><a href="#cb65-242" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb65-243"><a href="#cb65-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-244"><a href="#cb65-244" aria-hidden="true" tabindex="-1"></a><span class="co">#=== theta_hat(X) ===#</span></span>
<span id="cb65-245"><a href="#cb65-245" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-246"><a href="#cb65-246" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> mu_hat_1 <span class="sc">-</span> mu_hat_0</span>
<span id="cb65-247"><a href="#cb65-247" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-248"><a href="#cb65-248" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-249"><a href="#cb65-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-250"><a href="#cb65-250" aria-hidden="true" tabindex="-1"></a><span class="fu">### X-learner</span></span>
<span id="cb65-251"><a href="#cb65-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-252"><a href="#cb65-252" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate $\mu_1(X)$ and $\mu_0(X)$ using any appropriate ML regression methods. (Steps 1 and 2 of the T-learner)</span>
<span id="cb65-253"><a href="#cb65-253" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Impute individual treatment effect for the treated and control groups as follows</span>
<span id="cb65-254"><a href="#cb65-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-255"><a href="#cb65-255" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-256"><a href="#cb65-256" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb65-257"><a href="#cb65-257" aria-hidden="true" tabindex="-1"></a>\tilde{D}_i^1(X_i) = Y^1_i - \hat{\mu}_0(X_i)<span class="sc">\\</span></span>
<span id="cb65-258"><a href="#cb65-258" aria-hidden="true" tabindex="-1"></a>\tilde{D}_i^0(X_i) =  \hat{\mu}_1(X_i) - Y^0_i </span>
<span id="cb65-259"><a href="#cb65-259" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb65-260"><a href="#cb65-260" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb65-261"><a href="#cb65-261" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-262"><a href="#cb65-262" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-263"><a href="#cb65-263" aria-hidden="true" tabindex="-1"></a>This is similar to cross-fitting we saw in @sec-dml, where the folds are the treated and control groups.</span>
<span id="cb65-264"><a href="#cb65-264" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-265"><a href="#cb65-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-266"><a href="#cb65-266" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span></span>
<span id="cb65-267"><a href="#cb65-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-268"><a href="#cb65-268" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Regress $\tilde{D}_i^1(X_i)$ on $X$ using the observations in the treated group and denote the predicted value as $\hat{\theta}_1(X)$</span>
<span id="cb65-269"><a href="#cb65-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-270"><a href="#cb65-270" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Regress $\tilde{D}_i^0(X_i)$ on $X$ using the observations in the control group and denote the predicted value as $\hat{\theta}_0(X)$</span>
<span id="cb65-271"><a href="#cb65-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-272"><a href="#cb65-272" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Calculate $\hat{\theta}(X)$ as their weighted average</span>
<span id="cb65-273"><a href="#cb65-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-274"><a href="#cb65-274" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-275"><a href="#cb65-275" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb65-276"><a href="#cb65-276" aria-hidden="true" tabindex="-1"></a>\hat{\theta}(X) = h(X)\cdot\hat{\theta}_0(X) + [1-h(X)]\cdot\hat{\theta}_1(X)</span>
<span id="cb65-277"><a href="#cb65-277" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb65-278"><a href="#cb65-278" aria-hidden="true" tabindex="-1"></a>$$ {#eq-final-X}</span>
<span id="cb65-279"><a href="#cb65-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-280"><a href="#cb65-280" aria-hidden="true" tabindex="-1"></a>Any value of $h(X)$ is acceptable. One option of $h(X)$ may be the estimated propensity score $E<span class="co">[</span><span class="ot">W|X</span><span class="co">]</span>$.</span>
<span id="cb65-281"><a href="#cb65-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-282"><a href="#cb65-282" aria-hidden="true" tabindex="-1"></a>Here is a quick demonstration of how X-learner works (no cross-validation conducted in estimating $E<span class="co">[</span><span class="ot">Y|T=1, X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">Y|T=0, X</span><span class="co">]</span>$ in this example). </span>
<span id="cb65-283"><a href="#cb65-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-286"><a href="#cb65-286" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-287"><a href="#cb65-287" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-288"><a href="#cb65-288" aria-hidden="true" tabindex="-1"></a><span class="co"># Step 1</span></span>
<span id="cb65-289"><a href="#cb65-289" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-290"><a href="#cb65-290" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb65-291"><a href="#cb65-291" aria-hidden="true" tabindex="-1"></a>treated_data <span class="ot">&lt;-</span> data[T <span class="sc">==</span> <span class="cn">TRUE</span>, ]</span>
<span id="cb65-292"><a href="#cb65-292" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-293"><a href="#cb65-293" aria-hidden="true" tabindex="-1"></a>rf_trained_1 <span class="ot">&lt;-</span></span>
<span id="cb65-294"><a href="#cb65-294" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-295"><a href="#cb65-295" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-296"><a href="#cb65-296" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> treated_data</span>
<span id="cb65-297"><a href="#cb65-297" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-298"><a href="#cb65-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-299"><a href="#cb65-299" aria-hidden="true" tabindex="-1"></a><span class="co"># RF used here, but any appropriate method is acceptable</span></span>
<span id="cb65-300"><a href="#cb65-300" aria-hidden="true" tabindex="-1"></a>control_data <span class="ot">&lt;-</span> data[T <span class="sc">==</span> <span class="cn">FALSE</span>, ]</span>
<span id="cb65-301"><a href="#cb65-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-302"><a href="#cb65-302" aria-hidden="true" tabindex="-1"></a>rf_trained_0 <span class="ot">&lt;-</span></span>
<span id="cb65-303"><a href="#cb65-303" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-304"><a href="#cb65-304" aria-hidden="true" tabindex="-1"></a>    Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-305"><a href="#cb65-305" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> control_data</span>
<span id="cb65-306"><a href="#cb65-306" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-307"><a href="#cb65-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-308"><a href="#cb65-308" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-309"><a href="#cb65-309" aria-hidden="true" tabindex="-1"></a><span class="co"># step 2 (imputed individual treatment effect)</span></span>
<span id="cb65-310"><a href="#cb65-310" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-311"><a href="#cb65-311" aria-hidden="true" tabindex="-1"></a><span class="co">#=== treated samples ===#</span></span>
<span id="cb65-312"><a href="#cb65-312" aria-hidden="true" tabindex="-1"></a>treated_data[, mu_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">data =</span> treated_data)<span class="sc">$</span>predictions]</span>
<span id="cb65-313"><a href="#cb65-313" aria-hidden="true" tabindex="-1"></a>treated_data[, D_tilde_1 <span class="sc">:</span><span class="er">=</span> Y <span class="sc">-</span> mu_hat_0]</span>
<span id="cb65-314"><a href="#cb65-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-315"><a href="#cb65-315" aria-hidden="true" tabindex="-1"></a><span class="co">#=== control samples ===#</span></span>
<span id="cb65-316"><a href="#cb65-316" aria-hidden="true" tabindex="-1"></a>control_data[, mu_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">data =</span> control_data)<span class="sc">$</span>predictions]</span>
<span id="cb65-317"><a href="#cb65-317" aria-hidden="true" tabindex="-1"></a>control_data[, D_tilde_0 <span class="sc">:</span><span class="er">=</span> mu_hat_1 <span class="sc">-</span> Y]</span>
<span id="cb65-318"><a href="#cb65-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-319"><a href="#cb65-319" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-320"><a href="#cb65-320" aria-hidden="true" tabindex="-1"></a><span class="co"># step 3 (regress D on X)</span></span>
<span id="cb65-321"><a href="#cb65-321" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-322"><a href="#cb65-322" aria-hidden="true" tabindex="-1"></a><span class="co">#=== treated ===#</span></span>
<span id="cb65-323"><a href="#cb65-323" aria-hidden="true" tabindex="-1"></a>rf_trained_D1 <span class="ot">&lt;-</span></span>
<span id="cb65-324"><a href="#cb65-324" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-325"><a href="#cb65-325" aria-hidden="true" tabindex="-1"></a>    D_tilde_1 <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-326"><a href="#cb65-326" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> treated_data</span>
<span id="cb65-327"><a href="#cb65-327" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-328"><a href="#cb65-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-329"><a href="#cb65-329" aria-hidden="true" tabindex="-1"></a><span class="co">#=== control ===#</span></span>
<span id="cb65-330"><a href="#cb65-330" aria-hidden="true" tabindex="-1"></a>rf_trained_D0 <span class="ot">&lt;-</span></span>
<span id="cb65-331"><a href="#cb65-331" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-332"><a href="#cb65-332" aria-hidden="true" tabindex="-1"></a>    D_tilde_0 <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-333"><a href="#cb65-333" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> control_data</span>
<span id="cb65-334"><a href="#cb65-334" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-335"><a href="#cb65-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-336"><a href="#cb65-336" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-337"><a href="#cb65-337" aria-hidden="true" tabindex="-1"></a><span class="co"># step 4</span></span>
<span id="cb65-338"><a href="#cb65-338" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-339"><a href="#cb65-339" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimate treatment effect at X_0 = {x1 = 0.5, x2 = 0.5, x3 = 0.5}</span></span>
<span id="cb65-340"><a href="#cb65-340" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>)</span>
<span id="cb65-341"><a href="#cb65-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-342"><a href="#cb65-342" aria-hidden="true" tabindex="-1"></a><span class="co">#=== predicted value of Y conditional on Y and X ===#</span></span>
<span id="cb65-343"><a href="#cb65-343" aria-hidden="true" tabindex="-1"></a>theta_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_D1, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb65-344"><a href="#cb65-344" aria-hidden="true" tabindex="-1"></a>theta_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_D0, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions</span>
<span id="cb65-345"><a href="#cb65-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-346"><a href="#cb65-346" aria-hidden="true" tabindex="-1"></a><span class="co">#=== regress T on X ===#</span></span>
<span id="cb65-347"><a href="#cb65-347" aria-hidden="true" tabindex="-1"></a>rf_trained_T <span class="ot">&lt;-</span></span>
<span id="cb65-348"><a href="#cb65-348" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ranger</span>(</span>
<span id="cb65-349"><a href="#cb65-349" aria-hidden="true" tabindex="-1"></a>    T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-350"><a href="#cb65-350" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data,</span>
<span id="cb65-351"><a href="#cb65-351" aria-hidden="true" tabindex="-1"></a>    <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb65-352"><a href="#cb65-352" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-353"><a href="#cb65-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-354"><a href="#cb65-354" aria-hidden="true" tabindex="-1"></a><span class="co">#=== propensity score estimate ===#</span></span>
<span id="cb65-355"><a href="#cb65-355" aria-hidden="true" tabindex="-1"></a>p_score <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_T, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]</span>
<span id="cb65-356"><a href="#cb65-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-357"><a href="#cb65-357" aria-hidden="true" tabindex="-1"></a><span class="co">#=== weighted average of theta_hat_1 and theta_hat_0 with propensity score ===#</span></span>
<span id="cb65-358"><a href="#cb65-358" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-359"><a href="#cb65-359" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> p_score <span class="sc">*</span> theta_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>p_score) <span class="sc">*</span> theta_hat_1</span>
<span id="cb65-360"><a href="#cb65-360" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-361"><a href="#cb65-361" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-362"><a href="#cb65-362" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-363"><a href="#cb65-363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-364"><a href="#cb65-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-365"><a href="#cb65-365" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-learner {#sec-r-learner}</span></span>
<span id="cb65-366"><a href="#cb65-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-367"><a href="#cb65-367" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical background</span></span>
<span id="cb65-368"><a href="#cb65-368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-369"><a href="#cb65-369" aria-hidden="true" tabindex="-1"></a>Under the assumptions,</span>
<span id="cb65-370"><a href="#cb65-370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-371"><a href="#cb65-371" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-372"><a href="#cb65-372" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-373"><a href="#cb65-373" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span> = \theta(X)\cdot f(X) + g(X)</span>
<span id="cb65-374"><a href="#cb65-374" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-375"><a href="#cb65-375" aria-hidden="true" tabindex="-1"></a>$$ {#eq-yxw}</span>
<span id="cb65-376"><a href="#cb65-376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-377"><a href="#cb65-377" aria-hidden="true" tabindex="-1"></a>:::{.column-margin}</span>
<span id="cb65-378"><a href="#cb65-378" aria-hidden="true" tabindex="-1"></a>$f(X) = E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ </span>
<span id="cb65-379"><a href="#cb65-379" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-380"><a href="#cb65-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-381"><a href="#cb65-381" aria-hidden="true" tabindex="-1"></a>Let, $l(X)$ denote $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$. Taking the difference of @eq-model-framework and @eq-yxw on both sides,</span>
<span id="cb65-382"><a href="#cb65-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-383"><a href="#cb65-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-384"><a href="#cb65-384" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-385"><a href="#cb65-385" aria-hidden="true" tabindex="-1"></a>Y_i \textcolor{red}{-l(X_i)} &amp; = \theta(X_i)\cdot T_i + g(X_i) + \varepsilon_i \textcolor{red}{-<span class="co">[</span><span class="ot">\theta(X_i)\cdot f(X_i) + g(X_i)</span><span class="co">]</span>} <span class="sc">\\</span></span>
<span id="cb65-386"><a href="#cb65-386" aria-hidden="true" tabindex="-1"></a>\Rightarrow Y_i - l(X_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i)) + \varepsilon_i <span class="sc">\\</span></span>
<span id="cb65-387"><a href="#cb65-387" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-388"><a href="#cb65-388" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-389"><a href="#cb65-389" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-390"><a href="#cb65-390" aria-hidden="true" tabindex="-1"></a>:::{.column-margin}</span>
<span id="cb65-391"><a href="#cb65-391" aria-hidden="true" tabindex="-1"></a>This is akin to residualization/orthogonalization seen in the DML approach in @sec-dml.</span>
<span id="cb65-392"><a href="#cb65-392" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-393"><a href="#cb65-393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-394"><a href="#cb65-394" aria-hidden="true" tabindex="-1"></a>So, the problem of identifying $\theta(X)$ reduces to estimating the following model:</span>
<span id="cb65-395"><a href="#cb65-395" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-396"><a href="#cb65-396" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-397"><a href="#cb65-397" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-398"><a href="#cb65-398" aria-hidden="true" tabindex="-1"></a>Y_i - l(X_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i)) + \varepsilon_i</span>
<span id="cb65-399"><a href="#cb65-399" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-400"><a href="#cb65-400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-401"><a href="#cb65-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-402"><a href="#cb65-402" aria-hidden="true" tabindex="-1"></a>Since $E<span class="co">[</span><span class="ot">(T_i -f(X_i))\cdot\varepsilon_i|X</span><span class="co">]</span> = E<span class="co">[</span><span class="ot">\eta_i\cdot\varepsilon_i|X</span><span class="co">]</span> = 0$ by assumption, we can regress $Y_i - l(X_i)$ on $X_i$ and $T_i -f(X_i)$ to estimate $\theta(X)$. Specifically, we can minimize the following objective function:</span>
<span id="cb65-403"><a href="#cb65-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-404"><a href="#cb65-404" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-405"><a href="#cb65-405" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-406"><a href="#cb65-406" aria-hidden="true" tabindex="-1"></a>Min_{\theta(X)}\sum_{i=1}^N \large(\normalsize<span class="co">[</span><span class="ot">Y_i - l(X_i)</span><span class="co">]</span> - <span class="co">[</span><span class="ot">\theta(X_i)\cdot (T_i -f(X_i))</span><span class="co">]</span>\large)^2 </span>
<span id="cb65-407"><a href="#cb65-407" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-408"><a href="#cb65-408" aria-hidden="true" tabindex="-1"></a>$$ {#eq-est-equation}</span>
<span id="cb65-409"><a href="#cb65-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-410"><a href="#cb65-410" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation steps {#sec-est-steps}</span></span>
<span id="cb65-411"><a href="#cb65-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-412"><a href="#cb65-412" aria-hidden="true" tabindex="-1"></a>In practice, we of course do not observe $l(X)$ and $f(X)$. So, we first need to estimate them using the data at hand and then subtract them from $Y_i$ and $T_i$, respectively. You can use any suitable statistical methods to estimate $l(X)$ and $f(X)$. Some machine learning methods allow you to estimate them without assuming any functional form or structural assumptions. If you believe they are linear (in parameter) functions of $X$, you could alternatively use lasso or other linear models. @nie_quasi-oracle_2021 proposes that the estimation of $l(X)$ and $f(X)$ is done by cross-fitting (see @sec-cf) to avoid over-fitting bias. Let $I_{-i}$ denote all the observations that belong to the folds that $i$ does <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> not <span class="kw">&lt;/span&gt;</span> belong to. Further, let $\hat{l}(X_i)^{I_{-i}}$ and $\hat{f}(X_i)^{I_{-i}}$ denote $l(X_i)$ and $f(X_i)$ estimated using $I_{-i}$. </span>
<span id="cb65-413"><a href="#cb65-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-414"><a href="#cb65-414" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-415"><a href="#cb65-415" aria-hidden="true" tabindex="-1"></a>Just like the DML approach discussed in @sec-dml, both $Y$ and $T$ are orthogonalized.</span>
<span id="cb65-416"><a href="#cb65-416" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-417"><a href="#cb65-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-418"><a href="#cb65-418" aria-hidden="true" tabindex="-1"></a>Then the quality of fit (explaining the heterogeneity in the impact of treatment) can be expressed as follows, which is the empirical version of @eq-est-equation:</span>
<span id="cb65-419"><a href="#cb65-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-420"><a href="#cb65-420" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-421"><a href="#cb65-421" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-422"><a href="#cb65-422" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N <span class="co">[</span><span class="ot">Y_i - \hat{l}(X_i)^{I_{-i}} - \theta(X)\cdot (T_i - \hat{f}(X_i)^{I_{-i}})</span><span class="co">]</span>^2</span>
<span id="cb65-423"><a href="#cb65-423" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-424"><a href="#cb65-424" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-425"><a href="#cb65-425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-426"><a href="#cb65-426" aria-hidden="true" tabindex="-1"></a>This is called <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> R-score<span class="kw">&lt;/span&gt;</span>, and it can be used for causal model selection, which will be covered later. </span>
<span id="cb65-427"><a href="#cb65-427" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-428"><a href="#cb65-428" aria-hidden="true" tabindex="-1"></a>Let $\tilde{Y}_i$ and $\tilde{T}_i$ denote $Y_i - \hat{l}(X_i)^{I_{-i}}$ and $T_i - \hat{f}(X_i)^{I_{-i}}$, respectively. The final stage of the R-learner is to estimate $\theta(X)$ by minimizing the R-score plus the regularization term (if desirable).</span>
<span id="cb65-429"><a href="#cb65-429" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-430"><a href="#cb65-430" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-431"><a href="#cb65-431" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-432"><a href="#cb65-432" aria-hidden="true" tabindex="-1"></a>\hat{\theta}(X) = argmin_{\theta(X)}\;\;\sum_{i=1}^N <span class="co">[</span><span class="ot">\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i</span><span class="co">]</span>^2 + \Lambda(\theta(X))</span>
<span id="cb65-433"><a href="#cb65-433" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-434"><a href="#cb65-434" aria-hidden="true" tabindex="-1"></a>$$ {#eq-r-min}</span>
<span id="cb65-435"><a href="#cb65-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-436"><a href="#cb65-436" aria-hidden="true" tabindex="-1"></a>where $\Lambda(\theta(X))$ is the penalty on the complexity of $\theta(X)$. For example, if you choose to use lasso, then $\Lambda(\theta(X))$ is the L1 norm. You have lots of freedom as to what model you use in the final stage. The <span class="in">`econml`</span> package offers several off-the-shelf choices of R-learner (DML) approaches that differ in the model used at the final stage, including causal forest, lasso, etc.</span>
<span id="cb65-437"><a href="#cb65-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-438"><a href="#cb65-438" aria-hidden="true" tabindex="-1"></a><span class="fu">### R-learner by hand</span></span>
<span id="cb65-439"><a href="#cb65-439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-440"><a href="#cb65-440" aria-hidden="true" tabindex="-1"></a>This section goes through R codes to implement the estimation steps provided above to further our understanding of how R-learner works using the same synthetic dataset as the one used in @sec-stx.</span>
<span id="cb65-441"><a href="#cb65-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-442"><a href="#cb65-442" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb65-443"><a href="#cb65-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-444"><a href="#cb65-444" aria-hidden="true" tabindex="-1"></a>We first cross-fit $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ using random forest for both cases. We will use repeated (3 times) 5-fold cross-fitting. Resampling the data,</span>
<span id="cb65-445"><a href="#cb65-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-448"><a href="#cb65-448" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-449"><a href="#cb65-449" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-450"><a href="#cb65-450" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(data, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb65-451"><a href="#cb65-451" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-452"><a href="#cb65-452" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-453"><a href="#cb65-453" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-454"><a href="#cb65-454" aria-hidden="true" tabindex="-1"></a>The following function takes a row number (<span class="in">`n`</span>) and cross-fits $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ using the training and test data stored in the <span class="in">`n`</span>th row of <span class="in">`data_folds`</span>.</span>
<span id="cb65-455"><a href="#cb65-455" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-458"><a href="#cb65-458" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-459"><a href="#cb65-459" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n, data_folds) </span>
<span id="cb65-460"><a href="#cb65-460" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb65-461"><a href="#cb65-461" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">analysis</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb65-462"><a href="#cb65-462" aria-hidden="true" tabindex="-1"></a>  eval_data <span class="ot">&lt;-</span> <span class="fu">assessment</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb65-463"><a href="#cb65-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-464"><a href="#cb65-464" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-465"><a href="#cb65-465" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[Y|X]</span></span>
<span id="cb65-466"><a href="#cb65-466" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-467"><a href="#cb65-467" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== train ===#</span></span>
<span id="cb65-468"><a href="#cb65-468" aria-hidden="true" tabindex="-1"></a>  rf_trained_y <span class="ot">&lt;-</span></span>
<span id="cb65-469"><a href="#cb65-469" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb65-470"><a href="#cb65-470" aria-hidden="true" tabindex="-1"></a>      Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-471"><a href="#cb65-471" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data</span>
<span id="cb65-472"><a href="#cb65-472" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-473"><a href="#cb65-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-474"><a href="#cb65-474" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit ===#</span></span>
<span id="cb65-475"><a href="#cb65-475" aria-hidden="true" tabindex="-1"></a>  eval_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_y, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions]</span>
<span id="cb65-476"><a href="#cb65-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-477"><a href="#cb65-477" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-478"><a href="#cb65-478" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[T|X]</span></span>
<span id="cb65-479"><a href="#cb65-479" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-480"><a href="#cb65-480" aria-hidden="true" tabindex="-1"></a>  rf_trained_t <span class="ot">&lt;-</span></span>
<span id="cb65-481"><a href="#cb65-481" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb65-482"><a href="#cb65-482" aria-hidden="true" tabindex="-1"></a>      T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb65-483"><a href="#cb65-483" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data,</span>
<span id="cb65-484"><a href="#cb65-484" aria-hidden="true" tabindex="-1"></a>      <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb65-485"><a href="#cb65-485" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-486"><a href="#cb65-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-487"><a href="#cb65-487" aria-hidden="true" tabindex="-1"></a>  eval_data[, t_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_t, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]]</span>
<span id="cb65-488"><a href="#cb65-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-489"><a href="#cb65-489" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(eval_data[, .(id, y_hat, t_hat)])</span>
<span id="cb65-490"><a href="#cb65-490" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-491"><a href="#cb65-491" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-492"><a href="#cb65-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-493"><a href="#cb65-493" aria-hidden="true" tabindex="-1"></a>Here is what the output of the function for the first split looks like.</span>
<span id="cb65-494"><a href="#cb65-494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-497"><a href="#cb65-497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-498"><a href="#cb65-498" aria-hidden="true" tabindex="-1"></a><span class="fu">cross_fit</span>(<span class="dv">1</span>, data_folds)</span>
<span id="cb65-499"><a href="#cb65-499" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-500"><a href="#cb65-500" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-501"><a href="#cb65-501" aria-hidden="true" tabindex="-1"></a>Repeating this for all the splits,</span>
<span id="cb65-502"><a href="#cb65-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-505"><a href="#cb65-505" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-506"><a href="#cb65-506" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-507"><a href="#cb65-507" aria-hidden="true" tabindex="-1"></a>cross_fitted_data_rp <span class="ot">&lt;-</span></span>
<span id="cb65-508"><a href="#cb65-508" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb65-509"><a href="#cb65-509" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb65-510"><a href="#cb65-510" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds)</span>
<span id="cb65-511"><a href="#cb65-511" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-512"><a href="#cb65-512" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb65-513"><a href="#cb65-513" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-514"><a href="#cb65-514" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-515"><a href="#cb65-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-516"><a href="#cb65-516" aria-hidden="true" tabindex="-1"></a>We finally take the mean of the cross-fits by <span class="in">`id`</span> as each <span class="in">`id`</span> has tree estimates. </span>
<span id="cb65-517"><a href="#cb65-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-520"><a href="#cb65-520" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-521"><a href="#cb65-521" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-522"><a href="#cb65-522" aria-hidden="true" tabindex="-1"></a>cross_fitted_data <span class="ot">&lt;-</span> </span>
<span id="cb65-523"><a href="#cb65-523" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data_rp[, .(</span>
<span id="cb65-524"><a href="#cb65-524" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_hat =</span> <span class="fu">mean</span>(t_hat),</span>
<span id="cb65-525"><a href="#cb65-525" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> <span class="fu">mean</span>(y_hat)</span>
<span id="cb65-526"><a href="#cb65-526" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">by =</span> id]</span>
<span id="cb65-527"><a href="#cb65-527" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-528"><a href="#cb65-528" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-529"><a href="#cb65-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-530"><a href="#cb65-530" aria-hidden="true" tabindex="-1"></a>We then merge the data to the original data, and define $\tilde{Y}$ and $\tilde{T}$.</span>
<span id="cb65-531"><a href="#cb65-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-534"><a href="#cb65-534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-535"><a href="#cb65-535" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-536"><a href="#cb65-536" aria-hidden="true" tabindex="-1"></a>data_2nd <span class="ot">&lt;-</span> </span>
<span id="cb65-537"><a href="#cb65-537" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data[data, <span class="at">on =</span> <span class="st">"id"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb65-538"><a href="#cb65-538" aria-hidden="true" tabindex="-1"></a>  .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-539"><a href="#cb65-539" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_tilde =</span> Y <span class="sc">-</span> y_hat,</span>
<span id="cb65-540"><a href="#cb65-540" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_tilde =</span> T <span class="sc">-</span> t_hat</span>
<span id="cb65-541"><a href="#cb65-541" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb65-542"><a href="#cb65-542" aria-hidden="true" tabindex="-1"></a>  .[, .(y_tilde, t_tilde, x1, x2, x3)]</span>
<span id="cb65-543"><a href="#cb65-543" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-544"><a href="#cb65-544" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-545"><a href="#cb65-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-546"><a href="#cb65-546" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb65-547"><a href="#cb65-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-548"><a href="#cb65-548" aria-hidden="true" tabindex="-1"></a>The first order condition of @eq-r-min without $\Lambda(\theta(X))$ is</span>
<span id="cb65-549"><a href="#cb65-549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-550"><a href="#cb65-550" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-551"><a href="#cb65-551" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-552"><a href="#cb65-552" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N (\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i)\cdot \tilde{T}_i = 0</span>
<span id="cb65-553"><a href="#cb65-553" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-554"><a href="#cb65-554" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-555"><a href="#cb65-555" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-556"><a href="#cb65-556" aria-hidden="true" tabindex="-1"></a>This can be rewritten as </span>
<span id="cb65-557"><a href="#cb65-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-558"><a href="#cb65-558" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-559"><a href="#cb65-559" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-560"><a href="#cb65-560" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0</span>
<span id="cb65-561"><a href="#cb65-561" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-562"><a href="#cb65-562" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-563"><a href="#cb65-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-564"><a href="#cb65-564" aria-hidden="true" tabindex="-1"></a>So, this problem can be considered the problem of estimating $\theta(X)$ when the dependent variable is $\frac{\tilde{Y}_i}{\tilde{T}_i}$ with individual weights of $\tilde{T}_i^2$.</span>
<span id="cb65-565"><a href="#cb65-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-568"><a href="#cb65-568" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-569"><a href="#cb65-569" aria-hidden="true" tabindex="-1"></a>data_2nd[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-570"><a href="#cb65-570" aria-hidden="true" tabindex="-1"></a>  <span class="at">weight =</span> t_tilde<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb65-571"><a href="#cb65-571" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_to_t =</span> y_tilde <span class="sc">/</span> t_tilde</span>
<span id="cb65-572"><a href="#cb65-572" aria-hidden="true" tabindex="-1"></a>)]</span>
<span id="cb65-573"><a href="#cb65-573" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-574"><a href="#cb65-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-575"><a href="#cb65-575" aria-hidden="true" tabindex="-1"></a>Let's use <span class="in">`xgboost()`</span> for a non-parametric estimation of $\theta(X)$.</span>
<span id="cb65-576"><a href="#cb65-576" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-579"><a href="#cb65-579" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-580"><a href="#cb65-580" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb65-581"><a href="#cb65-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-582"><a href="#cb65-582" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb65-583"><a href="#cb65-583" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb65-584"><a href="#cb65-584" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb65-585"><a href="#cb65-585" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb65-586"><a href="#cb65-586" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb65-587"><a href="#cb65-587" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb65-588"><a href="#cb65-588" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-589"><a href="#cb65-589" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-590"><a href="#cb65-590" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb65-591"><a href="#cb65-591" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb65-592"><a href="#cb65-592" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb65-593"><a href="#cb65-593" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb65-594"><a href="#cb65-594" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb65-595"><a href="#cb65-595" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb65-596"><a href="#cb65-596" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-597"><a href="#cb65-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-598"><a href="#cb65-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-601"><a href="#cb65-601" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-602"><a href="#cb65-602" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-603"><a href="#cb65-603" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-604"><a href="#cb65-604" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb65-605"><a href="#cb65-605" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb65-606"><a href="#cb65-606" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb65-607"><a href="#cb65-607" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb65-608"><a href="#cb65-608" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb65-609"><a href="#cb65-609" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb65-610"><a href="#cb65-610" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-611"><a href="#cb65-611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-612"><a href="#cb65-612" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb65-613"><a href="#cb65-613" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb65-614"><a href="#cb65-614" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb65-615"><a href="#cb65-615" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb65-616"><a href="#cb65-616" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb65-617"><a href="#cb65-617" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb65-618"><a href="#cb65-618" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-619"><a href="#cb65-619" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-620"><a href="#cb65-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-621"><a href="#cb65-621" aria-hidden="true" tabindex="-1"></a>You can now predict $\theta(X)$ at particular values of $X$. Let's estimate $\theta(X)$ at $X_0 = <span class="sc">\{</span>x_1 = 0.5, x_2 = 0.5, x_3 = 0.5<span class="sc">\}</span>$.</span>
<span id="cb65-622"><a href="#cb65-622" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-625"><a href="#cb65-625" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-626"><a href="#cb65-626" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> </span>
<span id="cb65-627"><a href="#cb65-627" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb65-628"><a href="#cb65-628" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb65-629"><a href="#cb65-629" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> .)</span>
<span id="cb65-630"><a href="#cb65-630" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-631"><a href="#cb65-631" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb65-632"><a href="#cb65-632" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_trained_2nd, eval_data)</span>
<span id="cb65-633"><a href="#cb65-633" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-634"><a href="#cb65-634" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-635"><a href="#cb65-635" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-636"><a href="#cb65-636" aria-hidden="true" tabindex="-1"></a>You could alternatively estimate $\theta(X)$ parametrically using OLS. Suppose we somehow know that $\theta(X)$ takes the following form $\beta_1 x_1 + \beta_2 x_2^2 + \beta_3 x_3$. Then, the second stage estimation would be regressing $\tilde{Y}$ on $x_1\times T$, $x_2^2\times T$, and $x_2\times T$.</span>
<span id="cb65-637"><a href="#cb65-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-640"><a href="#cb65-640" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-641"><a href="#cb65-641" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb65-642"><a href="#cb65-642" aria-hidden="true" tabindex="-1"></a>ols_2nd_stage <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_tilde <span class="sc">~</span> <span class="fu">I</span>(x1<span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x2<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">*</span>t_tilde), <span class="at">data =</span> data_2nd)</span>
<span id="cb65-643"><a href="#cb65-643" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-644"><a href="#cb65-644" aria-hidden="true" tabindex="-1"></a><span class="co">#=== summary ===#</span></span>
<span id="cb65-645"><a href="#cb65-645" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ols_2nd_stage)</span>
<span id="cb65-646"><a href="#cb65-646" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-647"><a href="#cb65-647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-648"><a href="#cb65-648" aria-hidden="true" tabindex="-1"></a>The results look pretty good mostly because we are cheating and using the correct functional form. Of course, in practice, you would not know the correct functional form of $\theta(X)$. Finally, note that you should not use the codes here since they are just for demonstration to enhance our understanding of how R-learner works.</span>
<span id="cb65-649"><a href="#cb65-649" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-650"><a href="#cb65-650" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparing the learners</span></span>
<span id="cb65-651"><a href="#cb65-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-652"><a href="#cb65-652" aria-hidden="true" tabindex="-1"></a>In this section, we compare the performance of the learners under two DGPs, which fall under the following general model:</span>
<span id="cb65-653"><a href="#cb65-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-654"><a href="#cb65-654" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-655"><a href="#cb65-655" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-656"><a href="#cb65-656" aria-hidden="true" tabindex="-1"></a>Y_i &amp; =\theta(X_i)\cdot T + \alpha\cdot g(X_i) + \mu_i <span class="sc">\\</span></span>
<span id="cb65-657"><a href="#cb65-657" aria-hidden="true" tabindex="-1"></a>T_i &amp; = Bernouli(f(X_i))</span>
<span id="cb65-658"><a href="#cb65-658" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-659"><a href="#cb65-659" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-660"><a href="#cb65-660" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-661"><a href="#cb65-661" aria-hidden="true" tabindex="-1"></a>where $\alpha$ is a constant that changes the share of the nuisance function $g(X)$ in $Y$'s variation (larger $\alpha$ in magnitude, larger share of $g(X)$).</span>
<span id="cb65-662"><a href="#cb65-662" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-663"><a href="#cb65-663" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb65-664"><a href="#cb65-664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-665"><a href="#cb65-665" aria-hidden="true" tabindex="-1"></a><span class="fu">## Caveats</span></span>
<span id="cb65-666"><a href="#cb65-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-667"><a href="#cb65-667" aria-hidden="true" tabindex="-1"></a>We cannot draw any generalizable conclusions about the performance of the learners because we only consider a specific case of the learners where the extreme gradient boost is used for all the estimation tasks and also because we consider only several DGPs. </span>
<span id="cb65-668"><a href="#cb65-668" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-669"><a href="#cb65-669" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-670"><a href="#cb65-670" aria-hidden="true" tabindex="-1"></a>Performance comparisons under more DGPs can be found in @nie_quasi-oracle_2021. MC simulations here focus more on the role of the magnitude of the nuisance part in $Y$, which @nie_quasi-oracle_2021 does not look at.</span>
<span id="cb65-671"><a href="#cb65-671" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-672"><a href="#cb65-672" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb65-673"><a href="#cb65-673" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-674"><a href="#cb65-674" aria-hidden="true" tabindex="-1"></a>We first work on the following DGP (named DGP A).</span>
<span id="cb65-675"><a href="#cb65-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-676"><a href="#cb65-676" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb65-677"><a href="#cb65-677" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-678"><a href="#cb65-678" aria-hidden="true" tabindex="-1"></a><span class="fu">## DGP A</span></span>
<span id="cb65-679"><a href="#cb65-679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-680"><a href="#cb65-680" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-681"><a href="#cb65-681" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-682"><a href="#cb65-682" aria-hidden="true" tabindex="-1"></a>g(X_i) &amp; = sin(\pi X_{i,1}X_{i,2}) + 2(X_{i,3}-0.5)^2 + X_{i,4} + 0.5 X_{i,5}<span class="sc">\\</span></span>
<span id="cb65-683"><a href="#cb65-683" aria-hidden="true" tabindex="-1"></a>f(X_i) &amp; = max(0.1, min(sin(\pi X_{i,1}X_{i,2}), 0.9)) <span class="sc">\\</span></span>
<span id="cb65-684"><a href="#cb65-684" aria-hidden="true" tabindex="-1"></a>\theta(X_i) &amp; = (X_{i,1}, X_{i,2}) / 2 <span class="sc">\\</span></span>
<span id="cb65-685"><a href="#cb65-685" aria-hidden="true" tabindex="-1"></a>X_i &amp; \sim Uni(0,1)^5</span>
<span id="cb65-686"><a href="#cb65-686" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-687"><a href="#cb65-687" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-688"><a href="#cb65-688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-689"><a href="#cb65-689" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-690"><a href="#cb65-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-691"><a href="#cb65-691" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-692"><a href="#cb65-692" aria-hidden="true" tabindex="-1"></a>DGP A with $\alpha =1$ is almost the same as Set-up A of @nie_quasi-oracle_2021 except that they use $Y_i =\theta(X_i)\cdot (T-0.5) + \alpha\cdot g(X_i) + \mu_i$, so that $-0.5*\theta(X)$ is actually a part of the nuisance for $Y$. </span>
<span id="cb65-693"><a href="#cb65-693" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-694"><a href="#cb65-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-695"><a href="#cb65-695" aria-hidden="true" tabindex="-1"></a>The following code generate data according to DGP A. </span>
<span id="cb65-696"><a href="#cb65-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-699"><a href="#cb65-699" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-700"><a href="#cb65-700" aria-hidden="true" tabindex="-1"></a>gen_data_A <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha){</span>
<span id="cb65-701"><a href="#cb65-701" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb65-702"><a href="#cb65-702" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb65-703"><a href="#cb65-703" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-704"><a href="#cb65-704" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-705"><a href="#cb65-705" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-706"><a href="#cb65-706" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-707"><a href="#cb65-707" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb65-708"><a href="#cb65-708" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb65-709"><a href="#cb65-709" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-710"><a href="#cb65-710" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-711"><a href="#cb65-711" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> alpha <span class="sc">*</span> (<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x4 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x5),</span>
<span id="cb65-712"><a href="#cb65-712" aria-hidden="true" tabindex="-1"></a>      <span class="at">f_x =</span> <span class="fu">pmax</span>(<span class="fl">0.1</span>, <span class="fu">pmin</span>(<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2), <span class="fl">0.9</span>)),</span>
<span id="cb65-713"><a href="#cb65-713" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> (x1<span class="sc">+</span>x2)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb65-714"><a href="#cb65-714" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb65-715"><a href="#cb65-715" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> f_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb65-716"><a href="#cb65-716" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u] <span class="sc">%&gt;%</span> </span>
<span id="cb65-717"><a href="#cb65-717" aria-hidden="true" tabindex="-1"></a>    .[, id <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb65-718"><a href="#cb65-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-719"><a href="#cb65-719" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb65-720"><a href="#cb65-720" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-721"><a href="#cb65-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-722"><a href="#cb65-722" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-723"><a href="#cb65-723" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-724"><a href="#cb65-724" aria-hidden="true" tabindex="-1"></a>We use the <span class="in">`rlearner`</span> package <span class="co">[</span><span class="ot">@Xinkun-rlearner-package</span><span class="co">]</span> to implement S-, T-, X-, and R-learner. In particular, we will use the <span class="in">`*boost()`</span> functions (e.g., <span class="in">`rboost()`</span> for R-learner), which use <span class="in">`xgboost()`</span> for all the estimation tasks. Parameter tuning is done internally (see <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/xnie/rlearner/blob/6806396960e672214e2ef36e16c76bbb58ef9114/R/cvboost.R#L70-L78)</span> for the hyper parameter search space). S-learner implemented by <span class="in">`sboost()`</span> is different from the S-learner described above in that it include the interactions of the treatment variable and feature variables: that is, it regresses $Y$ on $T$, $X$, and $T*X$. </span>
<span id="cb65-725"><a href="#cb65-725" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-726"><a href="#cb65-726" aria-hidden="true" tabindex="-1"></a><span class="co">&lt;!-- So, we call the implementation of S-learner by `sboost()` "S-learner with interactions." We also implement an S-learner where $Y$ is regressed on only $T$ and $X$, which is called "S-learner without interactions." --&gt;</span></span>
<span id="cb65-727"><a href="#cb65-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-728"><a href="#cb65-728" aria-hidden="true" tabindex="-1"></a>The following code implements S-, T-, X-, and R-learner for a single iteration and calculate MSE of estimating $\theta(X)$ on the test data. </span>
<span id="cb65-729"><a href="#cb65-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-730"><a href="#cb65-730" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-731"><a href="#cb65-731" aria-hidden="true" tabindex="-1"></a>The <span class="in">`rlearner`</span> package also offers <span class="in">`*lasso()`</span> and <span class="in">`*kern()`</span> series. The package is not designed to be flexible as there are fixed combinations of learners and you cannot specify estimation methods yourself.</span>
<span id="cb65-732"><a href="#cb65-732" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-733"><a href="#cb65-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-734"><a href="#cb65-734" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-737"><a href="#cb65-737" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-738"><a href="#cb65-738" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb65-739"><a href="#cb65-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-740"><a href="#cb65-740" aria-hidden="true" tabindex="-1"></a>get_mse <span class="ot">&lt;-</span> <span class="cf">function</span>(i, gen_data, alpha) {</span>
<span id="cb65-741"><a href="#cb65-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-742"><a href="#cb65-742" aria-hidden="true" tabindex="-1"></a>  <span class="fu">print</span>(i)</span>
<span id="cb65-743"><a href="#cb65-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-744"><a href="#cb65-744" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-745"><a href="#cb65-745" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Prepare data</span></span>
<span id="cb65-746"><a href="#cb65-746" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-747"><a href="#cb65-747" aria-hidden="true" tabindex="-1"></a>  train_data <span class="ot">&lt;-</span> <span class="fu">gen_data_A</span>(N, alpha)</span>
<span id="cb65-748"><a href="#cb65-748" aria-hidden="true" tabindex="-1"></a>  test_data <span class="ot">&lt;-</span> <span class="fu">gen_data_A</span>(N, alpha)</span>
<span id="cb65-749"><a href="#cb65-749" aria-hidden="true" tabindex="-1"></a>  test_X <span class="ot">&lt;-</span> test_data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb65-750"><a href="#cb65-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-751"><a href="#cb65-751" aria-hidden="true" tabindex="-1"></a>  <span class="co"># cor(train_data[, .(theta_x, g_x)])</span></span>
<span id="cb65-752"><a href="#cb65-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-753"><a href="#cb65-753" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-754"><a href="#cb65-754" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Train and predict </span></span>
<span id="cb65-755"><a href="#cb65-755" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-756"><a href="#cb65-756" aria-hidden="true" tabindex="-1"></a>  learner_ls <span class="ot">&lt;-</span> <span class="fu">list</span>(rboost, sboost, xboost, tboost)</span>
<span id="cb65-757"><a href="#cb65-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-758"><a href="#cb65-758" aria-hidden="true" tabindex="-1"></a>  results <span class="ot">&lt;-</span></span>
<span id="cb65-759"><a href="#cb65-759" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb65-760"><a href="#cb65-760" aria-hidden="true" tabindex="-1"></a>      learner_ls,</span>
<span id="cb65-761"><a href="#cb65-761" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(learner) {</span>
<span id="cb65-762"><a href="#cb65-762" aria-hidden="true" tabindex="-1"></a>        trained_learner <span class="ot">&lt;-</span></span>
<span id="cb65-763"><a href="#cb65-763" aria-hidden="true" tabindex="-1"></a>          <span class="fu">learner</span>(</span>
<span id="cb65-764"><a href="#cb65-764" aria-hidden="true" tabindex="-1"></a>            train_data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb65-765"><a href="#cb65-765" aria-hidden="true" tabindex="-1"></a>            train_data<span class="sc">$</span>t, </span>
<span id="cb65-766"><a href="#cb65-766" aria-hidden="true" tabindex="-1"></a>            train_data<span class="sc">$</span>y</span>
<span id="cb65-767"><a href="#cb65-767" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb65-768"><a href="#cb65-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-769"><a href="#cb65-769" aria-hidden="true" tabindex="-1"></a>        theta_data <span class="ot">&lt;-</span></span>
<span id="cb65-770"><a href="#cb65-770" aria-hidden="true" tabindex="-1"></a>          <span class="fu">data.table</span>(</span>
<span id="cb65-771"><a href="#cb65-771" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_true =</span> test_data<span class="sc">$</span>theta_x,</span>
<span id="cb65-772"><a href="#cb65-772" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_hat =</span> <span class="fu">predict</span>(trained_learner, test_X)</span>
<span id="cb65-773"><a href="#cb65-773" aria-hidden="true" tabindex="-1"></a>          )</span>
<span id="cb65-774"><a href="#cb65-774" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb65-775"><a href="#cb65-775" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(theta_data)</span>
<span id="cb65-776"><a href="#cb65-776" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb65-777"><a href="#cb65-777" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-778"><a href="#cb65-778" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"learner"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb65-779"><a href="#cb65-779" aria-hidden="true" tabindex="-1"></a>    .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">fcase</span>(</span>
<span id="cb65-780"><a href="#cb65-780" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"R"</span>,</span>
<span id="cb65-781"><a href="#cb65-781" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">2</span>, <span class="st">"S"</span>,</span>
<span id="cb65-782"><a href="#cb65-782" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">3</span>, <span class="st">"X"</span>,</span>
<span id="cb65-783"><a href="#cb65-783" aria-hidden="true" tabindex="-1"></a>      learner <span class="sc">==</span> <span class="dv">4</span>, <span class="st">"T"</span></span>
<span id="cb65-784"><a href="#cb65-784" aria-hidden="true" tabindex="-1"></a>    )]</span>
<span id="cb65-785"><a href="#cb65-785" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-786"><a href="#cb65-786" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(results)</span>
<span id="cb65-787"><a href="#cb65-787" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-788"><a href="#cb65-788" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-789"><a href="#cb65-789" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-790"><a href="#cb65-790" aria-hidden="true" tabindex="-1"></a>Repeating experiments 100 times for $\alpha = 1$,</span>
<span id="cb65-791"><a href="#cb65-791" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-794"><a href="#cb65-794" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-795"><a href="#cb65-795" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-796"><a href="#cb65-796" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb65-797"><a href="#cb65-797" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb65-798"><a href="#cb65-798" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb65-799"><a href="#cb65-799" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-800"><a href="#cb65-800" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha)</span>
<span id="cb65-801"><a href="#cb65-801" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-802"><a href="#cb65-802" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-803"><a href="#cb65-803" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-804"><a href="#cb65-804" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-805"><a href="#cb65-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-808"><a href="#cb65-808" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-809"><a href="#cb65-809" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-810"><a href="#cb65-810" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-811"><a href="#cb65-811" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb65-812"><a href="#cb65-812" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb65-813"><a href="#cb65-813" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-814"><a href="#cb65-814" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha),</span>
<span id="cb65-815"><a href="#cb65-815" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb65-816"><a href="#cb65-816" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-817"><a href="#cb65-817" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-818"><a href="#cb65-818" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-819"><a href="#cb65-819" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(mc_results_1, here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"LectureNotes/Data/mc_xstr_results_alpha_1.rds"</span>))</span>
<span id="cb65-820"><a href="#cb65-820" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-821"><a href="#cb65-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-824"><a href="#cb65-824" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-825"><a href="#cb65-825" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-826"><a href="#cb65-826" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"Data/mc_xstr_results_alpha_1.rds"</span>)</span>
<span id="cb65-827"><a href="#cb65-827" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_1 &lt;- readRDS(here::here("LectureNotes/Data/mc_xstr_results_alpha_1.rds"))</span></span>
<span id="cb65-828"><a href="#cb65-828" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-829"><a href="#cb65-829" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-830"><a href="#cb65-830" aria-hidden="true" tabindex="-1"></a>@fig-log-mse-dgp-A-1 shows the histogram of MSE by learner. </span>
<span id="cb65-831"><a href="#cb65-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-834"><a href="#cb65-834" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-835"><a href="#cb65-835" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-836"><a href="#cb65-836" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Density of Log MSE of estimating CATE by method</span></span>
<span id="cb65-837"><a href="#cb65-837" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-log-mse-dgp-A-1</span></span>
<span id="cb65-838"><a href="#cb65-838" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-839"><a href="#cb65-839" aria-hidden="true" tabindex="-1"></a>mse_data_1 <span class="ot">&lt;-</span></span>
<span id="cb65-840"><a href="#cb65-840" aria-hidden="true" tabindex="-1"></a>  mc_results_1 <span class="sc">%&gt;%</span> </span>
<span id="cb65-841"><a href="#cb65-841" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb65-842"><a href="#cb65-842" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 1"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb65-843"><a href="#cb65-843" aria-hidden="true" tabindex="-1"></a>  .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">factor</span>(learner, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"S"</span>, <span class="st">"T"</span>, <span class="st">"X"</span>, <span class="st">"R"</span>))]</span>
<span id="cb65-844"><a href="#cb65-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-845"><a href="#cb65-845" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_1) <span class="sc">+</span> </span>
<span id="cb65-846"><a href="#cb65-846" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">x =</span> mse)) <span class="sc">+</span></span>
<span id="cb65-847"><a href="#cb65-847" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb65-848"><a href="#cb65-848" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb65-849"><a href="#cb65-849" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-850"><a href="#cb65-850" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-851"><a href="#cb65-851" aria-hidden="true" tabindex="-1"></a>As you can see, R-learner performs the best, followed closely by X-learner, then by S-learner, and T-learner. </span>
<span id="cb65-852"><a href="#cb65-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-853"><a href="#cb65-853" aria-hidden="true" tabindex="-1"></a>Now, we change the value of $\alpha$ to 10 from 1 to make the nuisance part have a much larger share in $Y$'s variation.</span>
<span id="cb65-854"><a href="#cb65-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-857"><a href="#cb65-857" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-858"><a href="#cb65-858" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-859"><a href="#cb65-859" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb65-860"><a href="#cb65-860" aria-hidden="true" tabindex="-1"></a>mc_results <span class="ot">&lt;-</span></span>
<span id="cb65-861"><a href="#cb65-861" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb65-862"><a href="#cb65-862" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-863"><a href="#cb65-863" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha)</span>
<span id="cb65-864"><a href="#cb65-864" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-865"><a href="#cb65-865" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-866"><a href="#cb65-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-867"><a href="#cb65-867" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-868"><a href="#cb65-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-871"><a href="#cb65-871" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-872"><a href="#cb65-872" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-873"><a href="#cb65-873" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-874"><a href="#cb65-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-875"><a href="#cb65-875" aria-hidden="true" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb65-876"><a href="#cb65-876" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span></span>
<span id="cb65-877"><a href="#cb65-877" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mclapply</span>(</span>
<span id="cb65-878"><a href="#cb65-878" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-879"><a href="#cb65-879" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_A, alpha),</span>
<span id="cb65-880"><a href="#cb65-880" aria-hidden="true" tabindex="-1"></a>    <span class="at">mc.cores =</span> <span class="dv">12</span></span>
<span id="cb65-881"><a href="#cb65-881" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-882"><a href="#cb65-882" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-883"><a href="#cb65-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-884"><a href="#cb65-884" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(mc_results_10, here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"LectureNotes/Data/mc_xstr_results_alpha_10.rds"</span>))</span>
<span id="cb65-885"><a href="#cb65-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-886"><a href="#cb65-886" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-887"><a href="#cb65-887" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-888"><a href="#cb65-888" aria-hidden="true" tabindex="-1"></a><span class="in">```{r read-mc-10-DGP-A}</span></span>
<span id="cb65-889"><a href="#cb65-889" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-890"><a href="#cb65-890" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"Data/mc_xstr_results_alpha_10.rds"</span>)</span>
<span id="cb65-891"><a href="#cb65-891" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_10 &lt;- readRDS(here::here("LectureNotes/Data/mc_xstr_results_alpha_10.rds"))</span></span>
<span id="cb65-892"><a href="#cb65-892" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-893"><a href="#cb65-893" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-894"><a href="#cb65-894" aria-hidden="true" tabindex="-1"></a>@fig-log-mse-dgp-A-1-10 shows the histogram of MSE by learner for $\alpha=1$ and $\alpha=10$. All the methods are negatively affected by the increase in the influence of the nuisance function, $g(X)$. However, some learners are affected more than others. R-learner is. much less affected by the change than the other methods, and R-learner is clearly the best performing learner at $\alpha = 10$. All the other learners performed considerably poorer compared to the case with $\alpha =1$. This shows that R-learner shines particularly when the treatment effect is only the small portion of the total variation in $Y$. This is a very important property because it is often the case for many scientific fields. For example, consider estimating the impact of a vocational training program on income. Such a program is unlikely to drastically change participants income level. Other factors that have nothing to do with the program (nuisance part) are likely to have much bigger role in determining income.</span>
<span id="cb65-895"><a href="#cb65-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-898"><a href="#cb65-898" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-899"><a href="#cb65-899" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-900"><a href="#cb65-900" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Density of Log MSE of estimating CATE by method</span></span>
<span id="cb65-901"><a href="#cb65-901" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-log-mse-dgp-A-1-10</span></span>
<span id="cb65-902"><a href="#cb65-902" aria-hidden="true" tabindex="-1"></a>mse_data_10 <span class="ot">&lt;-</span></span>
<span id="cb65-903"><a href="#cb65-903" aria-hidden="true" tabindex="-1"></a>  mc_results_10 <span class="sc">%&gt;%</span> </span>
<span id="cb65-904"><a href="#cb65-904" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb65-905"><a href="#cb65-905" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 10"</span>]</span>
<span id="cb65-906"><a href="#cb65-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-907"><a href="#cb65-907" aria-hidden="true" tabindex="-1"></a>mse_data_all <span class="ot">&lt;-</span> </span>
<span id="cb65-908"><a href="#cb65-908" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbind</span>(mse_data_1, mse_data_10) <span class="sc">%&gt;%</span> </span>
<span id="cb65-909"><a href="#cb65-909" aria-hidden="true" tabindex="-1"></a>  .[, learner <span class="sc">:</span><span class="er">=</span> <span class="fu">factor</span>(learner, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">"S"</span>, <span class="st">"T"</span>, <span class="st">"X"</span>, <span class="st">"R"</span>))]</span>
<span id="cb65-910"><a href="#cb65-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-911"><a href="#cb65-911" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_all) <span class="sc">+</span> </span>
<span id="cb65-912"><a href="#cb65-912" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb65-913"><a href="#cb65-913" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> mse, <span class="at">fill =</span> type), </span>
<span id="cb65-914"><a href="#cb65-914" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb65-915"><a href="#cb65-915" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb65-916"><a href="#cb65-916" aria-hidden="true" tabindex="-1"></a>    <span class="at">bins =</span> <span class="dv">75</span></span>
<span id="cb65-917"><a href="#cb65-917" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb65-918"><a href="#cb65-918" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb65-919"><a href="#cb65-919" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb65-920"><a href="#cb65-920" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-921"><a href="#cb65-921" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb65-922"><a href="#cb65-922" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-923"><a href="#cb65-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-924"><a href="#cb65-924" aria-hidden="true" tabindex="-1"></a>@fig-s-iter plots the true (y-axis) and estimated (x-axis) treatment effect by learner for a single iteration at $\alpha = 10$, which gives us insights into the decomposition of MSE (variance and bias). </span>
<span id="cb65-925"><a href="#cb65-925" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-926"><a href="#cb65-926" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-929"><a href="#cb65-929" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-930"><a href="#cb65-930" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-931"><a href="#cb65-931" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: True v.s. estimated treatment effects by learner for a single iteration ($\alpha$ = 10)</span></span>
<span id="cb65-932"><a href="#cb65-932" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-s-iter</span></span>
<span id="cb65-933"><a href="#cb65-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-934"><a href="#cb65-934" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_10[sim <span class="sc">==</span> <span class="dv">1</span>, ]) <span class="sc">+</span> </span>
<span id="cb65-935"><a href="#cb65-935" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theta_true, <span class="at">x =</span> theta_hat)) <span class="sc">+</span></span>
<span id="cb65-936"><a href="#cb65-936" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb65-937"><a href="#cb65-937" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb65-938"><a href="#cb65-938" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-939"><a href="#cb65-939" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Estimated Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb65-940"><a href="#cb65-940" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"True Treatment Effect"</span>)</span>
<span id="cb65-941"><a href="#cb65-941" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-942"><a href="#cb65-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-943"><a href="#cb65-943" aria-hidden="true" tabindex="-1"></a>According to the figure, all of them seem to suffer from positive bias. Here is the average of the true treatment effects less the estimated treatment effects by learner. So, indeed, they all suffer from bias. T-learner suffers from the most severe bias, and R-learner suffers from the smallest bias.</span>
<span id="cb65-944"><a href="#cb65-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-947"><a href="#cb65-947" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-948"><a href="#cb65-948" aria-hidden="true" tabindex="-1"></a>mc_results_10[, .(<span class="at">bias =</span> <span class="fu">mean</span>(theta_true <span class="sc">-</span> theta_hat)), by <span class="ot">=</span> learner]</span>
<span id="cb65-949"><a href="#cb65-949" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-950"><a href="#cb65-950" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-951"><a href="#cb65-951" aria-hidden="true" tabindex="-1"></a>T-learner has the highest variance of treatment effect estimates, followed by S-learner, X-learner, and then R-learner. Here is the average (over iterations) standard deviation of treatment effect estimates by learner.</span>
<span id="cb65-952"><a href="#cb65-952" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-955"><a href="#cb65-955" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-956"><a href="#cb65-956" aria-hidden="true" tabindex="-1"></a>mc_results_10[, .(<span class="at">sd =</span> <span class="fu">sd</span>(theta_true <span class="sc">-</span> theta_hat)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span> </span>
<span id="cb65-957"><a href="#cb65-957" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">sd =</span> <span class="fu">mean</span>(sd)), by <span class="ot">=</span> learner]</span>
<span id="cb65-958"><a href="#cb65-958" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-959"><a href="#cb65-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-960"><a href="#cb65-960" aria-hidden="true" tabindex="-1"></a>The problem with high variance in CATE estimation is that, the effect of treatment "looks" much more heterogeneous than it truly is. This leads to over-estimation of the benefit of targeted treatment (e.g., policy, medical treatment) assignment. </span>
<span id="cb65-961"><a href="#cb65-961" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-962"><a href="#cb65-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-963"><a href="#cb65-963" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-964"><a href="#cb65-964" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb65-965"><a href="#cb65-965" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-966"><a href="#cb65-966" aria-hidden="true" tabindex="-1"></a>Let's look at another DGP.</span>
<span id="cb65-967"><a href="#cb65-967" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-968"><a href="#cb65-968" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb65-969"><a href="#cb65-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-970"><a href="#cb65-970" aria-hidden="true" tabindex="-1"></a><span class="fu">## DGP B (randomized trial)</span></span>
<span id="cb65-971"><a href="#cb65-971" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-972"><a href="#cb65-972" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-973"><a href="#cb65-973" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-974"><a href="#cb65-974" aria-hidden="true" tabindex="-1"></a>g(X_i) &amp; = max(X_{i,1} + X_{i,2}, X_{i,3}, 0) + max(X_{i,4}+ X_{i,5},0)<span class="sc">\\</span></span>
<span id="cb65-975"><a href="#cb65-975" aria-hidden="true" tabindex="-1"></a>e(X_i) &amp; = 1/2 <span class="sc">\\</span></span>
<span id="cb65-976"><a href="#cb65-976" aria-hidden="true" tabindex="-1"></a>\theta(X_i) &amp; = X_{i,1} + log(1+exp(X_{i,2})) <span class="sc">\\</span></span>
<span id="cb65-977"><a href="#cb65-977" aria-hidden="true" tabindex="-1"></a>X_i &amp; \sim N(0,I_5)</span>
<span id="cb65-978"><a href="#cb65-978" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-979"><a href="#cb65-979" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-980"><a href="#cb65-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-981"><a href="#cb65-981" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-982"><a href="#cb65-982" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-983"><a href="#cb65-983" aria-hidden="true" tabindex="-1"></a>Here is the code to generate data according to DGP B.</span>
<span id="cb65-984"><a href="#cb65-984" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb65-987"><a href="#cb65-987" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-988"><a href="#cb65-988" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true </span></span>
<span id="cb65-989"><a href="#cb65-989" aria-hidden="true" tabindex="-1"></a>gen_data_B <span class="ot">&lt;-</span> <span class="cf">function</span>(N, alpha){</span>
<span id="cb65-990"><a href="#cb65-990" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb65-991"><a href="#cb65-991" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb65-992"><a href="#cb65-992" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb65-993"><a href="#cb65-993" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb65-994"><a href="#cb65-994" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb65-995"><a href="#cb65-995" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb65-996"><a href="#cb65-996" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb65-997"><a href="#cb65-997" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb65-998"><a href="#cb65-998" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-999"><a href="#cb65-999" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-1000"><a href="#cb65-1000" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> alpha <span class="sc">*</span> (<span class="fu">pmax</span>(x1 <span class="sc">+</span> x2, x3) <span class="sc">+</span> <span class="fu">pmax</span>(x4 <span class="sc">+</span> x5, <span class="dv">0</span>)),</span>
<span id="cb65-1001"><a href="#cb65-1001" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb65-1002"><a href="#cb65-1002" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> x1<span class="sc">+</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x2))</span>
<span id="cb65-1003"><a href="#cb65-1003" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb65-1004"><a href="#cb65-1004" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb65-1005"><a href="#cb65-1005" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb65-1006"><a href="#cb65-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1007"><a href="#cb65-1007" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb65-1008"><a href="#cb65-1008" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-1009"><a href="#cb65-1009" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1010"><a href="#cb65-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1013"><a href="#cb65-1013" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1014"><a href="#cb65-1014" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1015"><a href="#cb65-1015" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-1016"><a href="#cb65-1016" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(future.apply)</span>
<span id="cb65-1017"><a href="#cb65-1017" aria-hidden="true" tabindex="-1"></a><span class="fu">plan</span>(<span class="st">"multicore"</span>, <span class="at">workers =</span> <span class="fu">detectCores</span>() <span class="sc">-</span> <span class="dv">4</span>)</span>
<span id="cb65-1018"><a href="#cb65-1018" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1019"><a href="#cb65-1019" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb65-1020"><a href="#cb65-1020" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb65-1021"><a href="#cb65-1021" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-1022"><a href="#cb65-1022" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb65-1023"><a href="#cb65-1023" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1024"><a href="#cb65-1024" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-1025"><a href="#cb65-1025" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1026"><a href="#cb65-1026" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(</span>
<span id="cb65-1027"><a href="#cb65-1027" aria-hidden="true" tabindex="-1"></a>  mc_results_1, </span>
<span id="cb65-1028"><a href="#cb65-1028" aria-hidden="true" tabindex="-1"></a>  here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"LectureNotes/Data/mc_xstr_results_DGP_B_alpha_1.rds"</span>)</span>
<span id="cb65-1029"><a href="#cb65-1029" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-1030"><a href="#cb65-1030" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1031"><a href="#cb65-1031" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span></span>
<span id="cb65-1032"><a href="#cb65-1032" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb65-1033"><a href="#cb65-1033" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-1034"><a href="#cb65-1034" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">10</span>)</span>
<span id="cb65-1035"><a href="#cb65-1035" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1036"><a href="#cb65-1036" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-1037"><a href="#cb65-1037" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1038"><a href="#cb65-1038" aria-hidden="true" tabindex="-1"></a><span class="fu">saveRDS</span>(</span>
<span id="cb65-1039"><a href="#cb65-1039" aria-hidden="true" tabindex="-1"></a>  mc_results_10, </span>
<span id="cb65-1040"><a href="#cb65-1040" aria-hidden="true" tabindex="-1"></a>  here<span class="sc">::</span><span class="fu">here</span>(<span class="st">"LectureNotes/Data/mc_xstr_results_DGP_B_alpha_10.rds"</span>)</span>
<span id="cb65-1041"><a href="#cb65-1041" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb65-1042"><a href="#cb65-1042" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1043"><a href="#cb65-1043" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1044"><a href="#cb65-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1047"><a href="#cb65-1047" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1048"><a href="#cb65-1048" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-1049"><a href="#cb65-1049" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_1 &lt;- readRDS(here::here("LectureNotes/Data/mc_xstr_results_DGP_B_alpha_1.rds"))</span></span>
<span id="cb65-1050"><a href="#cb65-1050" aria-hidden="true" tabindex="-1"></a><span class="co"># mc_results_10 &lt;- readRDS(here::here("LectureNotes/Data/mc_xstr_results_DGP_B_alpha_10.rds"))</span></span>
<span id="cb65-1051"><a href="#cb65-1051" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1052"><a href="#cb65-1052" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"Data/mc_xstr_results_DGP_B_alpha_1.rds"</span>)</span>
<span id="cb65-1053"><a href="#cb65-1053" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"Data/mc_xstr_results_DGP_B_alpha_10.rds"</span>)</span>
<span id="cb65-1054"><a href="#cb65-1054" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1055"><a href="#cb65-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1056"><a href="#cb65-1056" aria-hidden="true" tabindex="-1"></a>Here is the code to run MC simulations for $\alpha = 1$ and $\alpha = 10$.</span>
<span id="cb65-1057"><a href="#cb65-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1060"><a href="#cb65-1060" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1061"><a href="#cb65-1061" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1062"><a href="#cb65-1062" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1063"><a href="#cb65-1063" aria-hidden="true" tabindex="-1"></a>mc_results_1 <span class="ot">&lt;-</span></span>
<span id="cb65-1064"><a href="#cb65-1064" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb65-1065"><a href="#cb65-1065" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-1066"><a href="#cb65-1066" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb65-1067"><a href="#cb65-1067" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1068"><a href="#cb65-1068" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-1069"><a href="#cb65-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1070"><a href="#cb65-1070" aria-hidden="true" tabindex="-1"></a>mc_results_10 <span class="ot">&lt;-</span></span>
<span id="cb65-1071"><a href="#cb65-1071" aria-hidden="true" tabindex="-1"></a>  <span class="fu">future_lapply</span>(</span>
<span id="cb65-1072"><a href="#cb65-1072" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="dv">100</span>),</span>
<span id="cb65-1073"><a href="#cb65-1073" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(i) <span class="fu">get_mse</span>(i, gen_data_B, <span class="at">alpha =</span> <span class="dv">10</span>)</span>
<span id="cb65-1074"><a href="#cb65-1074" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1075"><a href="#cb65-1075" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>(<span class="at">idcol =</span> <span class="st">"sim"</span>)</span>
<span id="cb65-1076"><a href="#cb65-1076" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1077"><a href="#cb65-1077" aria-hidden="true" tabindex="-1"></a>mse_data_1 <span class="ot">&lt;-</span></span>
<span id="cb65-1078"><a href="#cb65-1078" aria-hidden="true" tabindex="-1"></a>  mc_results_1 <span class="sc">%&gt;%</span> </span>
<span id="cb65-1079"><a href="#cb65-1079" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb65-1080"><a href="#cb65-1080" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 1"</span>]</span>
<span id="cb65-1081"><a href="#cb65-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1082"><a href="#cb65-1082" aria-hidden="true" tabindex="-1"></a>mse_data_10 <span class="ot">&lt;-</span></span>
<span id="cb65-1083"><a href="#cb65-1083" aria-hidden="true" tabindex="-1"></a>  mc_results_10 <span class="sc">%&gt;%</span> </span>
<span id="cb65-1084"><a href="#cb65-1084" aria-hidden="true" tabindex="-1"></a>  .[, .(<span class="at">mse =</span> <span class="fu">mean</span>((theta_true <span class="sc">-</span> theta_hat)<span class="sc">^</span><span class="dv">2</span>)), by <span class="ot">=</span> .(learner, sim)] <span class="sc">%&gt;%</span></span>
<span id="cb65-1085"><a href="#cb65-1085" aria-hidden="true" tabindex="-1"></a>  .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"alpha = 10"</span>]</span>
<span id="cb65-1086"><a href="#cb65-1086" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1087"><a href="#cb65-1087" aria-hidden="true" tabindex="-1"></a>mse_data_all <span class="ot">&lt;-</span> <span class="fu">rbind</span>(mse_data_1, mse_data_10) </span>
<span id="cb65-1088"><a href="#cb65-1088" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1089"><a href="#cb65-1089" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1090"><a href="#cb65-1090" aria-hidden="true" tabindex="-1"></a>@fig-log-mse-dgp-B-1-10 presents the results. Compared to DGP A, S- and T-learner performs much better at $\alpha = 1$ almost matching that of X- and R-learner. However, once the role of nuisance function is greater at $\alpha = 10$, then the performance of S-, T-, and X-learner deteriorate substantially (especially T-learner). </span>
<span id="cb65-1091"><a href="#cb65-1091" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1094"><a href="#cb65-1094" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1095"><a href="#cb65-1095" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-1096"><a href="#cb65-1096" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Density of Log MSE of estimating CATE by method</span></span>
<span id="cb65-1097"><a href="#cb65-1097" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-log-mse-dgp-B-1-10</span></span>
<span id="cb65-1098"><a href="#cb65-1098" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1099"><a href="#cb65-1099" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mse_data_all) <span class="sc">+</span> </span>
<span id="cb65-1100"><a href="#cb65-1100" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(</span>
<span id="cb65-1101"><a href="#cb65-1101" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(<span class="at">x =</span> mse, <span class="at">fill =</span> type), </span>
<span id="cb65-1102"><a href="#cb65-1102" aria-hidden="true" tabindex="-1"></a>    <span class="at">position =</span> <span class="st">"identity"</span>, </span>
<span id="cb65-1103"><a href="#cb65-1103" aria-hidden="true" tabindex="-1"></a>    <span class="at">alpha =</span> <span class="fl">0.5</span>,</span>
<span id="cb65-1104"><a href="#cb65-1104" aria-hidden="true" tabindex="-1"></a>    <span class="at">bins =</span> <span class="dv">75</span></span>
<span id="cb65-1105"><a href="#cb65-1105" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb65-1106"><a href="#cb65-1106" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb65-1107"><a href="#cb65-1107" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_discrete</span>(<span class="at">name =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb65-1108"><a href="#cb65-1108" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-1109"><a href="#cb65-1109" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb65-1110"><a href="#cb65-1110" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1111"><a href="#cb65-1111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1112"><a href="#cb65-1112" aria-hidden="true" tabindex="-1"></a>@fig-s-iter-B presents the scatter plot of the true and estimated treatment effects by learner for a single iteration. None of them seem to be biased, but there is a clear difference in variance of CATE estimates. </span>
<span id="cb65-1113"><a href="#cb65-1113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1116"><a href="#cb65-1116" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1117"><a href="#cb65-1117" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-1118"><a href="#cb65-1118" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: True v.s. estimated treatment effects by learner for a single iteration ($\alpha$ = 10)</span></span>
<span id="cb65-1119"><a href="#cb65-1119" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-s-iter-B</span></span>
<span id="cb65-1120"><a href="#cb65-1120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1121"><a href="#cb65-1121" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> mc_results_10[sim <span class="sc">==</span> <span class="dv">1</span>, ]) <span class="sc">+</span> </span>
<span id="cb65-1122"><a href="#cb65-1122" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theta_true, <span class="at">x =</span> theta_hat)) <span class="sc">+</span></span>
<span id="cb65-1123"><a href="#cb65-1123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb65-1124"><a href="#cb65-1124" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_grid</span>(learner <span class="sc">~</span> .) <span class="sc">+</span></span>
<span id="cb65-1125"><a href="#cb65-1125" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-1126"><a href="#cb65-1126" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlab</span>(<span class="st">"Estimated Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb65-1127"><a href="#cb65-1127" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"True Treatment Effect"</span>)</span>
<span id="cb65-1128"><a href="#cb65-1128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1129"><a href="#cb65-1129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1130"><a href="#cb65-1130" aria-hidden="true" tabindex="-1"></a><span class="fu">## X-, S-, T-, R-learner in Python</span></span>
<span id="cb65-1131"><a href="#cb65-1131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1132"><a href="#cb65-1132" aria-hidden="true" tabindex="-1"></a>We saw a general R-learner framework for CATE estimation. We now look at an example of Linear DML, which uses a linear model at the final stage. So, we are assuming that $\theta(X)$ can be written as follows in @eq-model-framework:</span>
<span id="cb65-1133"><a href="#cb65-1133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1134"><a href="#cb65-1134" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-1135"><a href="#cb65-1135" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-1136"><a href="#cb65-1136" aria-hidden="true" tabindex="-1"></a>\theta(X) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k</span>
<span id="cb65-1137"><a href="#cb65-1137" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-1138"><a href="#cb65-1138" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-1139"><a href="#cb65-1139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1140"><a href="#cb65-1140" aria-hidden="true" tabindex="-1"></a>where $x_1$ through $x_k$ are the drivers of heterogeneity in treatment effects and $\beta_1$ through $\beta_k$ are their coefficients.</span>
<span id="cb65-1141"><a href="#cb65-1141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1142"><a href="#cb65-1142" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-1143"><a href="#cb65-1143" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb65-1144"><a href="#cb65-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1145"><a href="#cb65-1145" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb65-1146"><a href="#cb65-1146" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb65-1147"><a href="#cb65-1147" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb65-1148"><a href="#cb65-1148" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb65-1149"><a href="#cb65-1149" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb65-1150"><a href="#cb65-1150" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb65-1151"><a href="#cb65-1151" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb65-1152"><a href="#cb65-1152" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb65-1153"><a href="#cb65-1153" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb65-1154"><a href="#cb65-1154" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb65-1155"><a href="#cb65-1155" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb65-1156"><a href="#cb65-1156" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1157"><a href="#cb65-1157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1160"><a href="#cb65-1160" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1161"><a href="#cb65-1161" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1162"><a href="#cb65-1162" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb65-1163"><a href="#cb65-1163" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb65-1164"><a href="#cb65-1164" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb65-1165"><a href="#cb65-1165" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb65-1166"><a href="#cb65-1166" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb65-1167"><a href="#cb65-1167" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb65-1168"><a href="#cb65-1168" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb65-1169"><a href="#cb65-1169" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb65-1170"><a href="#cb65-1170" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb65-1171"><a href="#cb65-1171" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1172"><a href="#cb65-1172" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-1173"><a href="#cb65-1173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1174"><a href="#cb65-1174" aria-hidden="true" tabindex="-1"></a>We use both Python and R for this demonstration. So, let's set things up for that.</span>
<span id="cb65-1175"><a href="#cb65-1175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1178"><a href="#cb65-1178" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1179"><a href="#cb65-1179" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb65-1180"><a href="#cb65-1180" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb65-1181"><a href="#cb65-1181" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"ml-learning"</span>)</span>
<span id="cb65-1182"><a href="#cb65-1182" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1183"><a href="#cb65-1183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1184"><a href="#cb65-1184" aria-hidden="true" tabindex="-1"></a>For this demonstration, we use synthetic data according to the following data generating process:</span>
<span id="cb65-1185"><a href="#cb65-1185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1186"><a href="#cb65-1186" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-1187"><a href="#cb65-1187" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb65-1188"><a href="#cb65-1188" aria-hidden="true" tabindex="-1"></a>y_i = exp(x_{i,1}) d_i + x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} + \mu_i <span class="sc">\\</span></span>
<span id="cb65-1189"><a href="#cb65-1189" aria-hidden="true" tabindex="-1"></a>d_i = \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3}+ \eta_i</span>
<span id="cb65-1190"><a href="#cb65-1190" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb65-1191"><a href="#cb65-1191" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-1192"><a href="#cb65-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1193"><a href="#cb65-1193" aria-hidden="true" tabindex="-1"></a>Note that this is the same data generating process used in @sec-dml except that the impact of the treatment ($d$) now depends on $x_1$. We can use <span class="in">`gen_data()`</span> function that is defined in @sec-dml-naive.</span>
<span id="cb65-1194"><a href="#cb65-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1197"><a href="#cb65-1197" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1198"><a href="#cb65-1198" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb65-1199"><a href="#cb65-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1200"><a href="#cb65-1200" aria-hidden="true" tabindex="-1"></a><span class="co">#=== sample size ===#</span></span>
<span id="cb65-1201"><a href="#cb65-1201" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb65-1202"><a href="#cb65-1202" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1203"><a href="#cb65-1203" aria-hidden="true" tabindex="-1"></a><span class="co">#=== generate data ===#</span></span>
<span id="cb65-1204"><a href="#cb65-1204" aria-hidden="true" tabindex="-1"></a>synth_data <span class="ot">&lt;-</span></span>
<span id="cb65-1205"><a href="#cb65-1205" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_data</span>(</span>
<span id="cb65-1206"><a href="#cb65-1206" aria-hidden="true" tabindex="-1"></a>    <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">*</span>d)),</span>
<span id="cb65-1207"><a href="#cb65-1207" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> N <span class="sc">*</span><span class="dv">2</span></span>
<span id="cb65-1208"><a href="#cb65-1208" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-1209"><a href="#cb65-1209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1210"><a href="#cb65-1210" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(synth_data, <span class="fu">starts_with</span>(<span class="st">"x"</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb65-1211"><a href="#cb65-1211" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> synth_data[, y]</span>
<span id="cb65-1212"><a href="#cb65-1212" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> synth_data[, d]</span>
<span id="cb65-1213"><a href="#cb65-1213" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1214"><a href="#cb65-1214" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1215"><a href="#cb65-1215" aria-hidden="true" tabindex="-1"></a>We now split the data into training and test datasets. </span>
<span id="cb65-1216"><a href="#cb65-1216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1219"><a href="#cb65-1219" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1220"><a href="#cb65-1220" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1221"><a href="#cb65-1221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1222"><a href="#cb65-1222" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb65-1223"><a href="#cb65-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1224"><a href="#cb65-1224" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test, d_train, d_test<span class="op">=</span> train_test_split(r.X, r.y, r.d,  test_size <span class="op">=</span> <span class="fl">0.5</span>, random_state <span class="op">=</span> <span class="dv">8923</span>)</span>
<span id="cb65-1225"><a href="#cb65-1225" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1226"><a href="#cb65-1226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1227"><a href="#cb65-1227" aria-hidden="true" tabindex="-1"></a>Here, to train a linear DML model, we use the Python <span class="in">`econml`</span> package, which offers one of the most comprehensive sets of off-the-shelf R-learner (DML) methods <span class="co">[</span><span class="ot">@econml</span><span class="co">]</span>. We can use the <span class="in">`DML`</span> class to implement linear DML.</span>
<span id="cb65-1228"><a href="#cb65-1228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1231"><a href="#cb65-1231" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1232"><a href="#cb65-1232" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1233"><a href="#cb65-1233" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML</span>
<span id="cb65-1234"><a href="#cb65-1234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1235"><a href="#cb65-1235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1236"><a href="#cb65-1236" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-1237"><a href="#cb65-1237" aria-hidden="true" tabindex="-1"></a><span class="in">`DML`</span> is a child class of <span class="in">`_Rlearner`</span>, which is a private class. The <span class="in">`DML`</span> class has several child classes: <span class="in">`LinearDML`</span>, <span class="in">`SpatseLinearDML`</span>, <span class="in">`NonParamDML`</span>, and <span class="in">`CausalForestDML`</span>. </span>
<span id="cb65-1238"><a href="#cb65-1238" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-1239"><a href="#cb65-1239" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1240"><a href="#cb65-1240" aria-hidden="true" tabindex="-1"></a>As we saw above in @sec-est-steps, we need to specify three models:</span>
<span id="cb65-1241"><a href="#cb65-1241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1242"><a href="#cb65-1242" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_y`</span>: model for estimating $E<span class="co">[</span><span class="ot">Y|X,W</span><span class="co">]</span>$</span>
<span id="cb65-1243"><a href="#cb65-1243" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_t`</span>: model for estimating $E<span class="co">[</span><span class="ot">T|X,W</span><span class="co">]</span>$</span>
<span id="cb65-1244"><a href="#cb65-1244" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_final`</span>: model for estimating $\theta(X)$</span>
<span id="cb65-1245"><a href="#cb65-1245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1246"><a href="#cb65-1246" aria-hidden="true" tabindex="-1"></a>In this example, let's use gradient boosting regression for both <span class="in">`model_y`</span> and <span class="in">`model_t`</span> and use lasso with cross-validation for <span class="in">`model_final`</span>. Let's import <span class="in">`GradientBoostingRegressor()`</span> and <span class="in">`LassoCV()`</span> from the <span class="in">`scikitlearn`</span> package.</span>
<span id="cb65-1247"><a href="#cb65-1247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1250"><a href="#cb65-1250" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1251"><a href="#cb65-1251" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1252"><a href="#cb65-1252" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb65-1253"><a href="#cb65-1253" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span>
<span id="cb65-1254"><a href="#cb65-1254" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1255"><a href="#cb65-1255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1256"><a href="#cb65-1256" aria-hidden="true" tabindex="-1"></a>We can now set up our DML framework like below:</span>
<span id="cb65-1257"><a href="#cb65-1257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1260"><a href="#cb65-1260" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1261"><a href="#cb65-1261" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1262"><a href="#cb65-1262" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> DML(</span>
<span id="cb65-1263"><a href="#cb65-1263" aria-hidden="true" tabindex="-1"></a>    model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb65-1264"><a href="#cb65-1264" aria-hidden="true" tabindex="-1"></a>    model_t <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb65-1265"><a href="#cb65-1265" aria-hidden="true" tabindex="-1"></a>    model_final <span class="op">=</span> LassoCV(fit_intercept <span class="op">=</span> <span class="va">False</span>) </span>
<span id="cb65-1266"><a href="#cb65-1266" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-1267"><a href="#cb65-1267" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1268"><a href="#cb65-1268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1269"><a href="#cb65-1269" aria-hidden="true" tabindex="-1"></a>Note that no training has happened yet at this point. We simply created a recipe. Once we provide ingredients (data), we can cook (train) with the <span class="in">`fit()`</span> method. </span>
<span id="cb65-1270"><a href="#cb65-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1273"><a href="#cb65-1273" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1274"><a href="#cb65-1274" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1275"><a href="#cb65-1275" aria-hidden="true" tabindex="-1"></a>est.fit(y_train, d_train, X <span class="op">=</span> X_train, W <span class="op">=</span> X_train)</span>
<span id="cb65-1276"><a href="#cb65-1276" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1277"><a href="#cb65-1277" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1278"><a href="#cb65-1278" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>first argument: dependent variable</span>
<span id="cb65-1279"><a href="#cb65-1279" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>second argument: treatment variable </span>
<span id="cb65-1280"><a href="#cb65-1280" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`X`</span>: variables that drive treatment effect heterogeneity</span>
<span id="cb65-1281"><a href="#cb65-1281" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`W`</span>: variables that affect the dependent variable directly</span>
<span id="cb65-1282"><a href="#cb65-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1283"><a href="#cb65-1283" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb65-1284"><a href="#cb65-1284" aria-hidden="true" tabindex="-1"></a>Here, we set <span class="in">`X = W`</span>.</span>
<span id="cb65-1285"><a href="#cb65-1285" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-1286"><a href="#cb65-1286" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1287"><a href="#cb65-1287" aria-hidden="true" tabindex="-1"></a>Once, the training is done. We can use the <span class="in">`effect()`</span> method to predict $\theta(X)$.</span>
<span id="cb65-1288"><a href="#cb65-1288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1291"><a href="#cb65-1291" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb65-1292"><a href="#cb65-1292" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1293"><a href="#cb65-1293" aria-hidden="true" tabindex="-1"></a>te_test <span class="op">=</span> est.effect(X_test)</span>
<span id="cb65-1294"><a href="#cb65-1294" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1295"><a href="#cb65-1295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1296"><a href="#cb65-1296" aria-hidden="true" tabindex="-1"></a>@fig-est-theta-hat presents the estimated and true marginal treatment effect ($\theta(X)$) as a function of <span class="in">`x1`</span>. </span>
<span id="cb65-1297"><a href="#cb65-1297" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1300"><a href="#cb65-1300" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1301"><a href="#cb65-1301" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb65-1302"><a href="#cb65-1302" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> </span>
<span id="cb65-1303"><a href="#cb65-1303" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb65-1304"><a href="#cb65-1304" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> py<span class="sc">$</span>X_test[, <span class="dv">1</span>],</span>
<span id="cb65-1305"><a href="#cb65-1305" aria-hidden="true" tabindex="-1"></a>    <span class="at">te =</span> py<span class="sc">$</span>te_test</span>
<span id="cb65-1306"><a href="#cb65-1306" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-1307"><a href="#cb65-1307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1308"><a href="#cb65-1308" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data) <span class="sc">+</span></span>
<span id="cb65-1309"><a href="#cb65-1309" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> te, <span class="at">x =</span> x1)) <span class="sc">+</span></span>
<span id="cb65-1310"><a href="#cb65-1310" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">exp</span>(x1), <span class="at">x =</span> x1), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb65-1311"><a href="#cb65-1311" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb65-1312"><a href="#cb65-1312" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1313"><a href="#cb65-1313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1316"><a href="#cb65-1316" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1317"><a href="#cb65-1317" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Estimated and true marginal treatment effects</span></span>
<span id="cb65-1318"><a href="#cb65-1318" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-est-theta-hat</span></span>
<span id="cb65-1319"><a href="#cb65-1319" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb65-1320"><a href="#cb65-1320" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_data &lt;- </span></span>
<span id="cb65-1321"><a href="#cb65-1321" aria-hidden="true" tabindex="-1"></a><span class="co">#   data.table(</span></span>
<span id="cb65-1322"><a href="#cb65-1322" aria-hidden="true" tabindex="-1"></a><span class="co">#     x1 = py$X_test[, 1],</span></span>
<span id="cb65-1323"><a href="#cb65-1323" aria-hidden="true" tabindex="-1"></a><span class="co">#     te = py$te_test</span></span>
<span id="cb65-1324"><a href="#cb65-1324" aria-hidden="true" tabindex="-1"></a><span class="co">#   )</span></span>
<span id="cb65-1325"><a href="#cb65-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1326"><a href="#cb65-1326" aria-hidden="true" tabindex="-1"></a><span class="co"># g_het_te &lt;-</span></span>
<span id="cb65-1327"><a href="#cb65-1327" aria-hidden="true" tabindex="-1"></a><span class="co">#   ggplot(plot_data) +</span></span>
<span id="cb65-1328"><a href="#cb65-1328" aria-hidden="true" tabindex="-1"></a><span class="co">#   geom_point(aes(y = te, x = x1)) +</span></span>
<span id="cb65-1329"><a href="#cb65-1329" aria-hidden="true" tabindex="-1"></a><span class="co">#   geom_line(aes(y = exp(x1), x = x1), color = "blue") +</span></span>
<span id="cb65-1330"><a href="#cb65-1330" aria-hidden="true" tabindex="-1"></a><span class="co">#   theme_bw()</span></span>
<span id="cb65-1331"><a href="#cb65-1331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1332"><a href="#cb65-1332" aria-hidden="true" tabindex="-1"></a>g_het_te <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"g_hte_te.rds"</span>)</span>
<span id="cb65-1333"><a href="#cb65-1333" aria-hidden="true" tabindex="-1"></a>g_het_te</span>
<span id="cb65-1334"><a href="#cb65-1334" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1335"><a href="#cb65-1335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1336"><a href="#cb65-1336" aria-hidden="true" tabindex="-1"></a>Since we forced $\theta(X)$ to be linear in <span class="in">`x1`</span>, it is not surprising that the estimated MTE looks linear in <span class="in">`x1`</span> even though the true MTE is an exponential function of <span class="in">`x1`</span>. In the next chapter (@sec-forest-cate), we discuss CATE estimators based on forest, which estimates $\theta(X)$ non-parametrically, relaxing the assumption of $\theta(X)$ being linear-in-parameter.</span>
<span id="cb65-1337"><a href="#cb65-1337" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1338"><a href="#cb65-1338" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb65-1339"><a href="#cb65-1339" aria-hidden="true" tabindex="-1"></a>There are many more variations in DML than the one presented here. For those who are interested, I recommend going through examples presented <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/microsoft/EconML/blob/main/notebooks/Double%20Machine%20Learning%20Examples.ipynb)</span> for <span class="in">`DML`</span></span>
<span id="cb65-1340"><a href="#cb65-1340" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb65-1341"><a href="#cb65-1341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1342"><a href="#cb65-1342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1343"><a href="#cb65-1343" aria-hidden="true" tabindex="-1"></a><span class="fu">## T-learner v.s. X-learner (Optional, and not that important)</span></span>
<span id="cb65-1344"><a href="#cb65-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1345"><a href="#cb65-1345" aria-hidden="true" tabindex="-1"></a>Here, an advantage of X-learner over T-learner is demonstrated. This example also serves as an illustration of how these learners are implemented. Specifically, X-learner can be advantageous when the control-treatment assignments in the sample are unbalanced. For example, it is often the case that there are plenty of observations in the control group, while there are not many treated observations. For the purpose of illustration, consider a rather extreme case where there are only 10 observations in the treated group, while there are 300 observations in the control group. We use the following toy data generating process:</span>
<span id="cb65-1346"><a href="#cb65-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1347"><a href="#cb65-1347" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb65-1348"><a href="#cb65-1348" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb65-1349"><a href="#cb65-1349" aria-hidden="true" tabindex="-1"></a>y = \tau W + |x| + v</span>
<span id="cb65-1350"><a href="#cb65-1350" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb65-1351"><a href="#cb65-1351" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb65-1352"><a href="#cb65-1352" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1353"><a href="#cb65-1353" aria-hidden="true" tabindex="-1"></a>where $\tau = 1$. So, the treatment effect is not heterogeneous. For the purpose of illustrating the advantage of X-learner over T-learner, it is convenient if the underlying model is simpler.</span>
<span id="cb65-1354"><a href="#cb65-1354" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1357"><a href="#cb65-1357" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1358"><a href="#cb65-1358" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4345</span>)</span>
<span id="cb65-1359"><a href="#cb65-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1360"><a href="#cb65-1360" aria-hidden="true" tabindex="-1"></a>N_trt <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb65-1361"><a href="#cb65-1361" aria-hidden="true" tabindex="-1"></a>N_ctrl <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb65-1362"><a href="#cb65-1362" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> N_trt <span class="sc">+</span> N_ctrl</span>
<span id="cb65-1363"><a href="#cb65-1363" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1364"><a href="#cb65-1364" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb65-1365"><a href="#cb65-1365" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb65-1366"><a href="#cb65-1366" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,N_trt), <span class="fu">rep</span>(<span class="dv">0</span>, N_ctrl)),</span>
<span id="cb65-1367"><a href="#cb65-1367" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Treated"</span>, N_trt), <span class="fu">rep</span>(<span class="st">"Control"</span>, N_ctrl)),</span>
<span id="cb65-1368"><a href="#cb65-1368" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">runif</span>(N)<span class="sc">-</span><span class="dv">1</span>,</span>
<span id="cb65-1369"><a href="#cb65-1369" aria-hidden="true" tabindex="-1"></a>    <span class="at">v =</span> <span class="fu">rnorm</span>(N) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb65-1370"><a href="#cb65-1370" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1371"><a href="#cb65-1371" aria-hidden="true" tabindex="-1"></a>  .[, y <span class="sc">:</span><span class="er">=</span> W <span class="sc">+</span> <span class="fu">abs</span>(x) <span class="sc">+</span> v]</span>
<span id="cb65-1372"><a href="#cb65-1372" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1373"><a href="#cb65-1373" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1376"><a href="#cb65-1376" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1377"><a href="#cb65-1377" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> data) <span class="sc">+</span></span>
<span id="cb65-1378"><a href="#cb65-1378" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb65-1379"><a href="#cb65-1379" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb65-1380"><a href="#cb65-1380" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1381"><a href="#cb65-1381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1382"><a href="#cb65-1382" aria-hidden="true" tabindex="-1"></a>Let's first estimate $\mu_1(X)$ and $\mu_0(X)$ (Step 1). Since we have only $<span class="in">`r N_trt`</span>$ observations in the treated group, we will use a linear regression to avoid over-fitting (following the example in @kunzel_metalearners_2019).</span>
<span id="cb65-1383"><a href="#cb65-1383" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1386"><a href="#cb65-1386" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1387"><a href="#cb65-1387" aria-hidden="true" tabindex="-1"></a>mu_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb65-1388"><a href="#cb65-1388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1389"><a href="#cb65-1389" aria-hidden="true" tabindex="-1"></a>mu_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb65-1390"><a href="#cb65-1390" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1391"><a href="#cb65-1391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1392"><a href="#cb65-1392" aria-hidden="true" tabindex="-1"></a>Now that  $\mu_1(X)$ and $\mu_0(X)$ are estimated, we can estimate $\hat{\theta}(X)$ by T-learner.</span>
<span id="cb65-1393"><a href="#cb65-1393" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1396"><a href="#cb65-1396" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1397"><a href="#cb65-1397" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb65-1398"><a href="#cb65-1398" aria-hidden="true" tabindex="-1"></a><span class="co">#=== T-learner ===#</span></span>
<span id="cb65-1399"><a href="#cb65-1399" aria-hidden="true" tabindex="-1"></a>tau_hat_data <span class="ot">&lt;-</span> </span>
<span id="cb65-1400"><a href="#cb65-1400" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="sc">%&gt;%</span></span>
<span id="cb65-1401"><a href="#cb65-1401" aria-hidden="true" tabindex="-1"></a>  .[, mu_1_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb65-1402"><a href="#cb65-1402" aria-hidden="true" tabindex="-1"></a>  .[, mu_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb65-1403"><a href="#cb65-1403" aria-hidden="true" tabindex="-1"></a>  .[, tau_hat_T <span class="sc">:</span><span class="er">=</span> mu_1_hat <span class="sc">-</span> mu_0_hat]</span>
<span id="cb65-1404"><a href="#cb65-1404" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1405"><a href="#cb65-1405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1406"><a href="#cb65-1406" aria-hidden="true" tabindex="-1"></a>As you can see, T-learner is heavily biased. This is because of the unreliable estimation of $\mu_1(X)$ due to lack of observations in the treated group.</span>
<span id="cb65-1407"><a href="#cb65-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1410"><a href="#cb65-1410" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1411"><a href="#cb65-1411" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-1412"><a href="#cb65-1412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1413"><a href="#cb65-1413" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb65-1414"><a href="#cb65-1414" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb65-1415"><a href="#cb65-1415" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb65-1416"><a href="#cb65-1416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1417"><a href="#cb65-1417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1418"><a href="#cb65-1418" aria-hidden="true" tabindex="-1"></a>Now, let's move on to X-learner. We impute individual treatment effects (Step 2).</span>
<span id="cb65-1419"><a href="#cb65-1419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1422"><a href="#cb65-1422" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1423"><a href="#cb65-1423" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (treated) ===#</span></span>
<span id="cb65-1424"><a href="#cb65-1424" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb65-1425"><a href="#cb65-1425" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1426"><a href="#cb65-1426" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (control) ===#</span></span>
<span id="cb65-1427"><a href="#cb65-1427" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb65-1428"><a href="#cb65-1428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1429"><a href="#cb65-1429" aria-hidden="true" tabindex="-1"></a><span class="co">#=== assign the values ===#</span></span>
<span id="cb65-1430"><a href="#cb65-1430" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Treated"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_1]</span>
<span id="cb65-1431"><a href="#cb65-1431" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Control"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_0]</span>
<span id="cb65-1432"><a href="#cb65-1432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1433"><a href="#cb65-1433" aria-hidden="true" tabindex="-1"></a><span class="co">#=== find individual TE ===#</span></span>
<span id="cb65-1434"><a href="#cb65-1434" aria-hidden="true" tabindex="-1"></a>data[, D <span class="sc">:</span><span class="er">=</span> <span class="fu">ifelse</span>(type <span class="sc">==</span> <span class="st">"Treated"</span>, y <span class="sc">-</span> mu_hat, mu_hat <span class="sc">-</span> y)]</span>
<span id="cb65-1435"><a href="#cb65-1435" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1436"><a href="#cb65-1436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1437"><a href="#cb65-1437" aria-hidden="true" tabindex="-1"></a>We can now regress $D$ on $X$ (Step 3),</span>
<span id="cb65-1438"><a href="#cb65-1438" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1441"><a href="#cb65-1441" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1442"><a href="#cb65-1442" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-1443"><a href="#cb65-1443" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (treated)</span></span>
<span id="cb65-1444"><a href="#cb65-1444" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-1445"><a href="#cb65-1445" aria-hidden="true" tabindex="-1"></a>tau_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(D <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb65-1446"><a href="#cb65-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1447"><a href="#cb65-1447" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb65-1448"><a href="#cb65-1448" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_1_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb65-1449"><a href="#cb65-1449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1450"><a href="#cb65-1450" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-1451"><a href="#cb65-1451" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (control)</span></span>
<span id="cb65-1452"><a href="#cb65-1452" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb65-1453"><a href="#cb65-1453" aria-hidden="true" tabindex="-1"></a>tau_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(D <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb65-1454"><a href="#cb65-1454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1455"><a href="#cb65-1455" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb65-1456"><a href="#cb65-1456" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_0_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb65-1457"><a href="#cb65-1457" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1458"><a href="#cb65-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1461"><a href="#cb65-1461" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1462"><a href="#cb65-1462" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-1463"><a href="#cb65-1463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1464"><a href="#cb65-1464" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb65-1465"><a href="#cb65-1465" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_1, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Treated"</span>)) <span class="sc">+</span></span>
<span id="cb65-1466"><a href="#cb65-1466" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_0, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Control"</span>)) <span class="sc">+</span></span>
<span id="cb65-1467"><a href="#cb65-1467" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Treated"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Control"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb65-1468"><a href="#cb65-1468" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb65-1469"><a href="#cb65-1469" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1470"><a href="#cb65-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1471"><a href="#cb65-1471" aria-hidden="true" tabindex="-1"></a>Let's use propensity score as $g(X)$ in Step 4.</span>
<span id="cb65-1472"><a href="#cb65-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1475"><a href="#cb65-1475" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1476"><a href="#cb65-1476" aria-hidden="true" tabindex="-1"></a>w_gam_trained <span class="ot">&lt;-</span> </span>
<span id="cb65-1477"><a href="#cb65-1477" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gam</span>(</span>
<span id="cb65-1478"><a href="#cb65-1478" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), </span>
<span id="cb65-1479"><a href="#cb65-1479" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data, </span>
<span id="cb65-1480"><a href="#cb65-1480" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb65-1481"><a href="#cb65-1481" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb65-1482"><a href="#cb65-1482" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1483"><a href="#cb65-1483" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1484"><a href="#cb65-1484" aria-hidden="true" tabindex="-1"></a>Let's predict $E<span class="co">[</span><span class="ot">W|X</span><span class="co">]</span>$ at each value of $X$ at which we are estiamting $\tau$. </span>
<span id="cb65-1485"><a href="#cb65-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1488"><a href="#cb65-1488" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1489"><a href="#cb65-1489" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, g_x <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(w_gam_trained, <span class="at">newdata =</span> tau_hat_data, <span class="at">type =</span> <span class="st">"response"</span>)]</span>
<span id="cb65-1490"><a href="#cb65-1490" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1491"><a href="#cb65-1491" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1492"><a href="#cb65-1492" aria-hidden="true" tabindex="-1"></a>As you can see below, the mean value of $g(x)$ is small because the treatment probability is very low (it is only $<span class="in">`r N_trt`</span>$ out of $<span class="in">`r N`</span>$).</span>
<span id="cb65-1493"><a href="#cb65-1493" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1496"><a href="#cb65-1496" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1497"><a href="#cb65-1497" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(tau_hat_data[, g_x])</span>
<span id="cb65-1498"><a href="#cb65-1498" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1499"><a href="#cb65-1499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1500"><a href="#cb65-1500" aria-hidden="true" tabindex="-1"></a>This number is basically $<span class="in">`r N_trt`</span>/320$. So, in this example, we could have just used the proportion of the treated observations. Notice that $g(X)$ is multiplied to $\hat{\theta}_0(X)$ in @eq-final-X. So, we are giving a lower weight to $\hat{\theta}_0(X)$. This is because $\hat{\theta}_0(X)$ is less reliable because $\hat{\mu}_1(X)$ is less reliable due to the lack of samples in the treated group. </span>
<span id="cb65-1501"><a href="#cb65-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1504"><a href="#cb65-1504" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1505"><a href="#cb65-1505" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_X <span class="sc">:</span><span class="er">=</span> g_x <span class="sc">*</span> tau_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>g_x) <span class="sc">*</span> tau_hat_1]</span>
<span id="cb65-1506"><a href="#cb65-1506" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1507"><a href="#cb65-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1508"><a href="#cb65-1508" aria-hidden="true" tabindex="-1"></a>As you can see, X-learner outperforms T-learner in this particular instance at least in terms of point estimates of $\tau(X)$. </span>
<span id="cb65-1509"><a href="#cb65-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1512"><a href="#cb65-1512" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1513"><a href="#cb65-1513" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb65-1514"><a href="#cb65-1514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1515"><a href="#cb65-1515" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb65-1516"><a href="#cb65-1516" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"T-learner"</span>)) <span class="sc">+</span></span>
<span id="cb65-1517"><a href="#cb65-1517" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_X, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"X-learner"</span>)) <span class="sc">+</span></span>
<span id="cb65-1518"><a href="#cb65-1518" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">"True Treatment Effect"</span>)) <span class="sc">+</span></span>
<span id="cb65-1519"><a href="#cb65-1519" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb65-1520"><a href="#cb65-1520" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb65-1521"><a href="#cb65-1521" aria-hidden="true" tabindex="-1"></a>        <span class="st">"T-learner"</span> <span class="ot">=</span> <span class="st">"red"</span>, </span>
<span id="cb65-1522"><a href="#cb65-1522" aria-hidden="true" tabindex="-1"></a>        <span class="st">"X-learner"</span> <span class="ot">=</span> <span class="st">"blue"</span>, </span>
<span id="cb65-1523"><a href="#cb65-1523" aria-hidden="true" tabindex="-1"></a>        <span class="st">"True Treatment Effect"</span> <span class="ot">=</span> <span class="st">"black"</span></span>
<span id="cb65-1524"><a href="#cb65-1524" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb65-1525"><a href="#cb65-1525" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb65-1526"><a href="#cb65-1526" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb65-1527"><a href="#cb65-1527" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb65-1528"><a href="#cb65-1528" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-1529"><a href="#cb65-1529" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb65-1530"><a href="#cb65-1530" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb65-1531"><a href="#cb65-1531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1534"><a href="#cb65-1534" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb65-1535"><a href="#cb65-1535" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false </span></span>
<span id="cb65-1536"><a href="#cb65-1536" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb65-1537"><a href="#cb65-1537" aria-hidden="true" tabindex="-1"></a>s_learner_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(train_data, test_data, Kx)</span>
<span id="cb65-1538"><a href="#cb65-1538" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb65-1539"><a href="#cb65-1539" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1540"><a href="#cb65-1540" aria-hidden="true" tabindex="-1"></a>  features <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"t"</span>, <span class="fu">paste0</span>(<span class="st">"x"</span>, <span class="fu">seq_len</span>(Kx)))</span>
<span id="cb65-1541"><a href="#cb65-1541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1542"><a href="#cb65-1542" aria-hidden="true" tabindex="-1"></a>  rf_trained <span class="ot">&lt;-</span></span>
<span id="cb65-1543"><a href="#cb65-1543" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1544"><a href="#cb65-1544" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data[, ..features], </span>
<span id="cb65-1545"><a href="#cb65-1545" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> train_data<span class="sc">$</span>y,</span>
<span id="cb65-1546"><a href="#cb65-1546" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1547"><a href="#cb65-1547" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1548"><a href="#cb65-1548" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1549"><a href="#cb65-1549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1550"><a href="#cb65-1550" aria-hidden="true" tabindex="-1"></a>  test_X <span class="ot">&lt;-</span> test_data[, ..features]</span>
<span id="cb65-1551"><a href="#cb65-1551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1552"><a href="#cb65-1552" aria-hidden="true" tabindex="-1"></a>  test_data_0 <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_X) <span class="sc">%&gt;%</span> .[, t <span class="sc">:</span><span class="er">=</span> <span class="dv">0</span>]</span>
<span id="cb65-1553"><a href="#cb65-1553" aria-hidden="true" tabindex="-1"></a>  y_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">newdata =</span> test_data_0)<span class="sc">$</span>predictions</span>
<span id="cb65-1554"><a href="#cb65-1554" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb65-1555"><a href="#cb65-1555" aria-hidden="true" tabindex="-1"></a>  test_data_1 <span class="ot">&lt;-</span> <span class="fu">copy</span>(test_X) <span class="sc">%&gt;%</span> .[, t <span class="sc">:</span><span class="er">=</span> <span class="dv">1</span>]</span>
<span id="cb65-1556"><a href="#cb65-1556" aria-hidden="true" tabindex="-1"></a>  y_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, <span class="at">newdata =</span> test_data_1)<span class="sc">$</span>predictions</span>
<span id="cb65-1557"><a href="#cb65-1557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1558"><a href="#cb65-1558" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> y_hat_1 <span class="sc">-</span> y_hat_0</span>
<span id="cb65-1559"><a href="#cb65-1559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1560"><a href="#cb65-1560" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span></span>
<span id="cb65-1561"><a href="#cb65-1561" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb65-1562"><a href="#cb65-1562" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_true =</span> test_data<span class="sc">$</span>theta_x,</span>
<span id="cb65-1563"><a href="#cb65-1563" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_hat =</span> theta_hat,</span>
<span id="cb65-1564"><a href="#cb65-1564" aria-hidden="true" tabindex="-1"></a>      <span class="at">type =</span> <span class="st">"S-learner"</span></span>
<span id="cb65-1565"><a href="#cb65-1565" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1566"><a href="#cb65-1566" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-1567"><a href="#cb65-1567" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1568"><a href="#cb65-1568" aria-hidden="true" tabindex="-1"></a>tx_learner_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(train_data, test_data, Kx)</span>
<span id="cb65-1569"><a href="#cb65-1569" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb65-1570"><a href="#cb65-1570" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1571"><a href="#cb65-1571" aria-hidden="true" tabindex="-1"></a>  features <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">paste0</span>(<span class="st">"x"</span>, <span class="fu">seq_len</span>(Kx)))</span>
<span id="cb65-1572"><a href="#cb65-1572" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1573"><a href="#cb65-1573" aria-hidden="true" tabindex="-1"></a>  train_data_1 <span class="ot">&lt;-</span> train_data[t <span class="sc">==</span> <span class="dv">1</span>, ]</span>
<span id="cb65-1574"><a href="#cb65-1574" aria-hidden="true" tabindex="-1"></a>  train_data_0 <span class="ot">&lt;-</span> train_data[t <span class="sc">==</span> <span class="dv">0</span>, ]</span>
<span id="cb65-1575"><a href="#cb65-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1576"><a href="#cb65-1576" aria-hidden="true" tabindex="-1"></a>  rf_trained_1 <span class="ot">&lt;-</span></span>
<span id="cb65-1577"><a href="#cb65-1577" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1578"><a href="#cb65-1578" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data_1[, ..features], </span>
<span id="cb65-1579"><a href="#cb65-1579" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> train_data_1<span class="sc">$</span>y,</span>
<span id="cb65-1580"><a href="#cb65-1580" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1581"><a href="#cb65-1581" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1582"><a href="#cb65-1582" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1583"><a href="#cb65-1583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1584"><a href="#cb65-1584" aria-hidden="true" tabindex="-1"></a>  rf_trained_0 <span class="ot">&lt;-</span></span>
<span id="cb65-1585"><a href="#cb65-1585" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1586"><a href="#cb65-1586" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data_0[, ..features], </span>
<span id="cb65-1587"><a href="#cb65-1587" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> train_data_0<span class="sc">$</span>y,</span>
<span id="cb65-1588"><a href="#cb65-1588" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1589"><a href="#cb65-1589" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1590"><a href="#cb65-1590" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1591"><a href="#cb65-1591" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1592"><a href="#cb65-1592" aria-hidden="true" tabindex="-1"></a>  test_X <span class="ot">&lt;-</span> test_data[, ..features]</span>
<span id="cb65-1593"><a href="#cb65-1593" aria-hidden="true" tabindex="-1"></a>  train_X <span class="ot">&lt;-</span> train_data[, ..features]</span>
<span id="cb65-1594"><a href="#cb65-1594" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1595"><a href="#cb65-1595" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1596"><a href="#cb65-1596" aria-hidden="true" tabindex="-1"></a>  <span class="co"># T-learner</span></span>
<span id="cb65-1597"><a href="#cb65-1597" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1598"><a href="#cb65-1598" aria-hidden="true" tabindex="-1"></a>  y_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">newdata =</span> test_X)<span class="sc">$</span>predictions</span>
<span id="cb65-1599"><a href="#cb65-1599" aria-hidden="true" tabindex="-1"></a>  y_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">newdata =</span> test_X)<span class="sc">$</span>predictions</span>
<span id="cb65-1600"><a href="#cb65-1600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1601"><a href="#cb65-1601" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> y_hat_1 <span class="sc">-</span> y_hat_0</span>
<span id="cb65-1602"><a href="#cb65-1602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1603"><a href="#cb65-1603" aria-hidden="true" tabindex="-1"></a>  return_data_T <span class="ot">&lt;-</span></span>
<span id="cb65-1604"><a href="#cb65-1604" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb65-1605"><a href="#cb65-1605" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_true =</span> test_data<span class="sc">$</span>theta_x,</span>
<span id="cb65-1606"><a href="#cb65-1606" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_hat =</span> theta_hat,</span>
<span id="cb65-1607"><a href="#cb65-1607" aria-hidden="true" tabindex="-1"></a>      <span class="at">type =</span> <span class="st">"T-learner"</span></span>
<span id="cb65-1608"><a href="#cb65-1608" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1609"><a href="#cb65-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1610"><a href="#cb65-1610" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1611"><a href="#cb65-1611" aria-hidden="true" tabindex="-1"></a>  <span class="co"># X-learner</span></span>
<span id="cb65-1612"><a href="#cb65-1612" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1613"><a href="#cb65-1613" aria-hidden="true" tabindex="-1"></a>  mu_0_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_0, <span class="at">newdata =</span> train_data_1[, ..features])<span class="sc">$</span>predictions</span>
<span id="cb65-1614"><a href="#cb65-1614" aria-hidden="true" tabindex="-1"></a>  train_data_1[, D <span class="sc">:</span><span class="er">=</span> y <span class="sc">-</span> mu_0_hat]</span>
<span id="cb65-1615"><a href="#cb65-1615" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1616"><a href="#cb65-1616" aria-hidden="true" tabindex="-1"></a>  mu_1_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_1, <span class="at">newdata =</span> train_data_0[, ..features])<span class="sc">$</span>predictions</span>
<span id="cb65-1617"><a href="#cb65-1617" aria-hidden="true" tabindex="-1"></a>  train_data_0[, D <span class="sc">:</span><span class="er">=</span> mu_1_hat <span class="sc">-</span> y]</span>
<span id="cb65-1618"><a href="#cb65-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1619"><a href="#cb65-1619" aria-hidden="true" tabindex="-1"></a>  rf_trained_D1 <span class="ot">&lt;-</span></span>
<span id="cb65-1620"><a href="#cb65-1620" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1621"><a href="#cb65-1621" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data_1[, ..features], </span>
<span id="cb65-1622"><a href="#cb65-1622" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> train_data_1<span class="sc">$</span>D,</span>
<span id="cb65-1623"><a href="#cb65-1623" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1624"><a href="#cb65-1624" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1625"><a href="#cb65-1625" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1626"><a href="#cb65-1626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1627"><a href="#cb65-1627" aria-hidden="true" tabindex="-1"></a>  rf_trained_D0 <span class="ot">&lt;-</span></span>
<span id="cb65-1628"><a href="#cb65-1628" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1629"><a href="#cb65-1629" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data_0[, ..features], </span>
<span id="cb65-1630"><a href="#cb65-1630" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> train_data_0<span class="sc">$</span>D,</span>
<span id="cb65-1631"><a href="#cb65-1631" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1632"><a href="#cb65-1632" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1633"><a href="#cb65-1633" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1634"><a href="#cb65-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1635"><a href="#cb65-1635" aria-hidden="true" tabindex="-1"></a>  rf_trained_T <span class="ot">&lt;-</span></span>
<span id="cb65-1636"><a href="#cb65-1636" aria-hidden="true" tabindex="-1"></a>    <span class="fu">probability_forest</span>(</span>
<span id="cb65-1637"><a href="#cb65-1637" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> train_data[, ..features], </span>
<span id="cb65-1638"><a href="#cb65-1638" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> <span class="fu">factor</span>(train_data<span class="sc">$</span>t)</span>
<span id="cb65-1639"><a href="#cb65-1639" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1640"><a href="#cb65-1640" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1641"><a href="#cb65-1641" aria-hidden="true" tabindex="-1"></a>  test_data[, pscore <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_T, test_X)<span class="sc">$</span>predictions[, <span class="dv">2</span>]]</span>
<span id="cb65-1642"><a href="#cb65-1642" aria-hidden="true" tabindex="-1"></a>  test_data[, theta_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_D1, test_X)<span class="sc">$</span>predictions]</span>
<span id="cb65-1643"><a href="#cb65-1643" aria-hidden="true" tabindex="-1"></a>  test_data[, theta_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_D0, test_X)<span class="sc">$</span>predictions]</span>
<span id="cb65-1644"><a href="#cb65-1644" aria-hidden="true" tabindex="-1"></a>  test_data[, theta_hat <span class="sc">:</span><span class="er">=</span> pscore <span class="sc">*</span> theta_0 <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> pscore) <span class="sc">*</span> theta_1]</span>
<span id="cb65-1645"><a href="#cb65-1645" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb65-1646"><a href="#cb65-1646" aria-hidden="true" tabindex="-1"></a>  return_data_X <span class="ot">&lt;-</span></span>
<span id="cb65-1647"><a href="#cb65-1647" aria-hidden="true" tabindex="-1"></a>    test_data[, .(theta_x, theta_hat)] <span class="sc">%&gt;%</span> </span>
<span id="cb65-1648"><a href="#cb65-1648" aria-hidden="true" tabindex="-1"></a>    <span class="fu">setnames</span>(<span class="st">"theta_x"</span>, <span class="st">"theta_true"</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1649"><a href="#cb65-1649" aria-hidden="true" tabindex="-1"></a>    .[, type <span class="sc">:</span><span class="er">=</span> <span class="st">"X-learner"</span>]</span>
<span id="cb65-1650"><a href="#cb65-1650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1651"><a href="#cb65-1651" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1652"><a href="#cb65-1652" aria-hidden="true" tabindex="-1"></a>  <span class="co"># combine and return</span></span>
<span id="cb65-1653"><a href="#cb65-1653" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1654"><a href="#cb65-1654" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(return_data_T, return_data_X)</span>
<span id="cb65-1655"><a href="#cb65-1655" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1656"><a href="#cb65-1656" aria-hidden="true" tabindex="-1"></a>  (return_data)</span>
<span id="cb65-1657"><a href="#cb65-1657" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-1658"><a href="#cb65-1658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1659"><a href="#cb65-1659" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n, data_folds, features) </span>
<span id="cb65-1660"><a href="#cb65-1660" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb65-1661"><a href="#cb65-1661" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">analysis</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb65-1662"><a href="#cb65-1662" aria-hidden="true" tabindex="-1"></a>  eval_data <span class="ot">&lt;-</span> <span class="fu">assessment</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb65-1663"><a href="#cb65-1663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1664"><a href="#cb65-1664" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1665"><a href="#cb65-1665" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[Y|X]</span></span>
<span id="cb65-1666"><a href="#cb65-1666" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1667"><a href="#cb65-1667" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== train ===#</span></span>
<span id="cb65-1668"><a href="#cb65-1668" aria-hidden="true" tabindex="-1"></a>  rf_trained_y <span class="ot">&lt;-</span></span>
<span id="cb65-1669"><a href="#cb65-1669" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1670"><a href="#cb65-1670" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> training_data[, ..features], </span>
<span id="cb65-1671"><a href="#cb65-1671" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> training_data<span class="sc">$</span>y,</span>
<span id="cb65-1672"><a href="#cb65-1672" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1673"><a href="#cb65-1673" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1674"><a href="#cb65-1674" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1675"><a href="#cb65-1675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1676"><a href="#cb65-1676" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit ===#</span></span>
<span id="cb65-1677"><a href="#cb65-1677" aria-hidden="true" tabindex="-1"></a>  y_hat_vec <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_y, eval_data[, ..features])<span class="sc">$</span>predictions</span>
<span id="cb65-1678"><a href="#cb65-1678" aria-hidden="true" tabindex="-1"></a>  eval_data[, y_hat <span class="sc">:</span><span class="er">=</span> y_hat_vec]</span>
<span id="cb65-1679"><a href="#cb65-1679" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1680"><a href="#cb65-1680" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1681"><a href="#cb65-1681" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[T|X]</span></span>
<span id="cb65-1682"><a href="#cb65-1682" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb65-1683"><a href="#cb65-1683" aria-hidden="true" tabindex="-1"></a>  rf_trained_T <span class="ot">&lt;-</span></span>
<span id="cb65-1684"><a href="#cb65-1684" aria-hidden="true" tabindex="-1"></a>    <span class="fu">probability_forest</span>(</span>
<span id="cb65-1685"><a href="#cb65-1685" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> training_data[, ..features], </span>
<span id="cb65-1686"><a href="#cb65-1686" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> <span class="fu">factor</span>(training_data<span class="sc">$</span>t)</span>
<span id="cb65-1687"><a href="#cb65-1687" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1688"><a href="#cb65-1688" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1689"><a href="#cb65-1689" aria-hidden="true" tabindex="-1"></a>  t_hat_vec <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained_T, eval_data[, ..features])<span class="sc">$</span>predictions[, <span class="dv">2</span>]</span>
<span id="cb65-1690"><a href="#cb65-1690" aria-hidden="true" tabindex="-1"></a>  eval_data[, t_hat <span class="sc">:</span><span class="er">=</span> t_hat_vec]</span>
<span id="cb65-1691"><a href="#cb65-1691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1692"><a href="#cb65-1692" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(eval_data[, .(id, y_hat, t_hat)])</span>
<span id="cb65-1693"><a href="#cb65-1693" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-1694"><a href="#cb65-1694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1695"><a href="#cb65-1695" aria-hidden="true" tabindex="-1"></a>r_learner_rf <span class="ot">&lt;-</span> <span class="cf">function</span>(train_data, test_data, Kx){</span>
<span id="cb65-1696"><a href="#cb65-1696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1697"><a href="#cb65-1697" aria-hidden="true" tabindex="-1"></a>  features <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">paste0</span>(<span class="st">"x"</span>, <span class="fu">seq_len</span>(Kx)))</span>
<span id="cb65-1698"><a href="#cb65-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1699"><a href="#cb65-1699" aria-hidden="true" tabindex="-1"></a>  data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(train_data, <span class="at">v =</span> <span class="dv">6</span>)</span>
<span id="cb65-1700"><a href="#cb65-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1701"><a href="#cb65-1701" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data <span class="ot">&lt;-</span></span>
<span id="cb65-1702"><a href="#cb65-1702" aria-hidden="true" tabindex="-1"></a>    <span class="fu">lapply</span>(</span>
<span id="cb65-1703"><a href="#cb65-1703" aria-hidden="true" tabindex="-1"></a>      <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb65-1704"><a href="#cb65-1704" aria-hidden="true" tabindex="-1"></a>      <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds, features)</span>
<span id="cb65-1705"><a href="#cb65-1705" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb65-1706"><a href="#cb65-1706" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rbindlist</span>()</span>
<span id="cb65-1707"><a href="#cb65-1707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1708"><a href="#cb65-1708" aria-hidden="true" tabindex="-1"></a>  data_2nd <span class="ot">&lt;-</span> </span>
<span id="cb65-1709"><a href="#cb65-1709" aria-hidden="true" tabindex="-1"></a>    cross_fitted_data[train_data, on <span class="ot">=</span> <span class="st">"id"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb65-1710"><a href="#cb65-1710" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-1711"><a href="#cb65-1711" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_tilde =</span> y <span class="sc">-</span> y_hat,</span>
<span id="cb65-1712"><a href="#cb65-1712" aria-hidden="true" tabindex="-1"></a>      <span class="at">t_tilde =</span> t <span class="sc">-</span> t_hat</span>
<span id="cb65-1713"><a href="#cb65-1713" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb65-1714"><a href="#cb65-1714" aria-hidden="true" tabindex="-1"></a>    .[,<span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb65-1715"><a href="#cb65-1715" aria-hidden="true" tabindex="-1"></a>      <span class="at">weight =</span> t_tilde<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb65-1716"><a href="#cb65-1716" aria-hidden="true" tabindex="-1"></a>      <span class="at">y_to_t =</span> y_tilde<span class="sc">/</span>t_tilde</span>
<span id="cb65-1717"><a href="#cb65-1717" aria-hidden="true" tabindex="-1"></a>    )]</span>
<span id="cb65-1718"><a href="#cb65-1718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1719"><a href="#cb65-1719" aria-hidden="true" tabindex="-1"></a>  rf_trained <span class="ot">&lt;-</span></span>
<span id="cb65-1720"><a href="#cb65-1720" aria-hidden="true" tabindex="-1"></a>    <span class="fu">regression_forest</span>(</span>
<span id="cb65-1721"><a href="#cb65-1721" aria-hidden="true" tabindex="-1"></a>      <span class="at">X =</span> data_2nd[, ..features], </span>
<span id="cb65-1722"><a href="#cb65-1722" aria-hidden="true" tabindex="-1"></a>      <span class="at">Y =</span> data_2nd<span class="sc">$</span>y_to_t,</span>
<span id="cb65-1723"><a href="#cb65-1723" aria-hidden="true" tabindex="-1"></a>      <span class="at">sample.weights =</span> data_2nd<span class="sc">$</span>weight,</span>
<span id="cb65-1724"><a href="#cb65-1724" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.parameters =</span> <span class="st">"all"</span>,</span>
<span id="cb65-1725"><a href="#cb65-1725" aria-hidden="true" tabindex="-1"></a>      <span class="at">tune.num.trees =</span> <span class="dv">500</span></span>
<span id="cb65-1726"><a href="#cb65-1726" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1727"><a href="#cb65-1727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1728"><a href="#cb65-1728" aria-hidden="true" tabindex="-1"></a>  theta_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(rf_trained, test_data[, ..features])<span class="sc">$</span>predictions</span>
<span id="cb65-1729"><a href="#cb65-1729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1730"><a href="#cb65-1730" aria-hidden="true" tabindex="-1"></a>  return_data <span class="ot">&lt;-</span></span>
<span id="cb65-1731"><a href="#cb65-1731" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb65-1732"><a href="#cb65-1732" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_true =</span> test_data<span class="sc">$</span>theta_x,</span>
<span id="cb65-1733"><a href="#cb65-1733" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_hat =</span> theta_hat,</span>
<span id="cb65-1734"><a href="#cb65-1734" aria-hidden="true" tabindex="-1"></a>      <span class="at">type =</span> <span class="st">"R-learner"</span></span>
<span id="cb65-1735"><a href="#cb65-1735" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb65-1736"><a href="#cb65-1736" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1737"><a href="#cb65-1737" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="at">data =</span> return_data) <span class="sc">+</span> </span>
<span id="cb65-1738"><a href="#cb65-1738" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theta_true, <span class="at">x =</span> theta_hat)) <span class="sc">+</span></span>
<span id="cb65-1739"><a href="#cb65-1739" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_abline</span>(<span class="at">slope =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb65-1740"><a href="#cb65-1740" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb65-1741"><a href="#cb65-1741" aria-hidden="true" tabindex="-1"></a>    <span class="fu">coord_equal</span>()</span>
<span id="cb65-1742"><a href="#cb65-1742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1743"><a href="#cb65-1743" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-1744"><a href="#cb65-1744" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-1745"><a href="#cb65-1745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>