<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.629">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Introduction to Machine Learning for Economists (Under Construction) - 12&nbsp; S-, X-, T-, and R-learner</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./C03-cf-orf.html" rel="next">
<link href="./C01-dml.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<link href="style.css" rel="stylesheet" type="text/css">

<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-45VKT2HZSL"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag() { dataLayer.push(arguments); }
  gtag('js', new Date());

  gtag('config', 'G-45VKT2HZSL');
</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Machine Learning for Economists (Under Construction)</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/tmieno2/ML-Economist" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=|url|">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=|url|">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.linkedin.com/sharing/share-offsite/?url=|url|">
            <i class="bi bi-bi-linkedin pe-1"></i>
          LinkedIn
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Welcome</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./H00-preface.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Basics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B01-nonlinear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Non-linear function estimation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B02-bias-variance-tradeoff.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Bias-variance Trade-off</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B03-cross-validation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B04-regularization.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Regression Shrinkage Methods</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./B05-bootstrap.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Bootstrap</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Prediction ML</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P01-random-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Random Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P02-boosted-regression-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Boosted Regression Forest</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P03-xgb.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Extreme Gradient Boosting</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./P04-local-linear-forest.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Local Linear Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./C0P-causal-ml.html" class="sidebar-item-text sidebar-link">Causal Machine Learning (CML) Methods</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C00-why-not-this.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Why can’t we just do this?</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C01-dml.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C02-xstr-learner.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./C03-cf-orf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./E0P-extensions.html" class="sidebar-item-text sidebar-link">Extensions</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E01-spatial-cv.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Spatial Cross-validation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./E02-grf.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Generalized Random Forest</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a href="./PROG-00-programming.html" class="sidebar-item-text sidebar-link">Programming Guide</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-01-mlr3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Machine Learning with <code>mlr3</code> in R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-02-reticulate.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Running Python from R</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./PROG-03-model-selection-prediction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Model Selection (Prediction)</span></a>
  </div>
</li>
    </ul>
  </li>
        <li class="px-0"><hr class="sidebar-divider hi "></li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">Appendices</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A01-mc-simulation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Monte Carlo (MC) Simulation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./A02-method-of-moment.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Primer on method of moment</span></a>
  </div>
</li>
    </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#motivation" id="toc-motivation" class="nav-link active" data-scroll-target="#motivation"> <span class="header-section-number">12.1</span> Motivation</a></li>
  <li><a href="#modeling-framework" id="toc-modeling-framework" class="nav-link" data-scroll-target="#modeling-framework"> <span class="header-section-number">12.2</span> Modeling Framework</a></li>
  <li><a href="#s--t--and-x-learner" id="toc-s--t--and-x-learner" class="nav-link" data-scroll-target="#s--t--and-x-learner"> <span class="header-section-number">12.3</span> S-, T-, and X-Learner</a>
  <ul class="collapse">
  <li><a href="#s-learner" id="toc-s-learner" class="nav-link" data-scroll-target="#s-learner"> <span class="header-section-number">12.3.1</span> S-learner</a></li>
  <li><a href="#t-learner" id="toc-t-learner" class="nav-link" data-scroll-target="#t-learner"> <span class="header-section-number">12.3.2</span> T-learner</a></li>
  <li><a href="#x-learner" id="toc-x-learner" class="nav-link" data-scroll-target="#x-learner"> <span class="header-section-number">12.3.3</span> X-learner</a></li>
  </ul></li>
  <li><a href="#t-learner-v.s.-x-learner" id="toc-t-learner-v.s.-x-learner" class="nav-link" data-scroll-target="#t-learner-v.s.-x-learner"> <span class="header-section-number">12.4</span> T-learner v.s. X-learner</a></li>
  <li><a href="#sec-r-learner" id="toc-sec-r-learner" class="nav-link" data-scroll-target="#sec-r-learner"> <span class="header-section-number">12.5</span> R-learner</a>
  <ul class="collapse">
  <li><a href="#theoretical-background" id="toc-theoretical-background" class="nav-link" data-scroll-target="#theoretical-background"> <span class="header-section-number">12.5.1</span> Theoretical background</a></li>
  <li><a href="#sec-est-steps" id="toc-sec-est-steps" class="nav-link" data-scroll-target="#sec-est-steps"> <span class="header-section-number">12.5.2</span> Estimation steps</a></li>
  <li><a href="#r-learner-by-hand" id="toc-r-learner-by-hand" class="nav-link" data-scroll-target="#r-learner-by-hand"> <span class="header-section-number">12.5.3</span> R-learner by hand</a></li>
  </ul></li>
  <li><a href="#comparing-the-learners" id="toc-comparing-the-learners" class="nav-link" data-scroll-target="#comparing-the-learners"> <span class="header-section-number">12.6</span> Comparing the learners</a></li>
  <li><a href="#x--s--t--r-learner-in-python" id="toc-x--s--t--r-learner-in-python" class="nav-link" data-scroll-target="#x--s--t--r-learner-in-python"> <span class="header-section-number">12.7</span> X-, S-, T-, R-learner in Python</a></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/tmieno2/ML-Economist/edit/master/C02-xstr-learner.qmd" class="toc-action">Edit this page</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span id="sec-het-dml" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">S-, X-, T-, and R-learner</span></span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Code</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Show All Code</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Hide All Code</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">View Source</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<p>In this section, we look at the S-, X-, T-, and R-learner, which are method that estimate heterogeneous treatment effects when the treatment is binary. While X-learner and T-learner cannot be extended to continuous treatment cases, S-learner and R-learner can be. Mathematical notations used in this chapter closely follow those of <span class="citation" data-cites="kunzel_metalearners_2019">(<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">Künzel et al. 2019</a>)</span> and <span class="citation" data-cites="nie_quasi-oracle_2021">(<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">Nie and Wager 2021</a>)</span>.</p>
<div class="callout-important callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What you will learn
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Key points
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>R-learner is the same as DML approaches by <span class="citation" data-cites="Chernozhukov2018">Chernozhukov et al. (<a href="#ref-Chernozhukov2018" role="doc-biblioref">2018</a>)</span> except that it estimates CATE eat the second stag instead of ATE.</li>
<li>In many practical cases, R-learner performs better than S-, X-, and T-learners.</li>
<li>S- and T-learners are especially undesirable due to its tendency to underestimate CATE</li>
</ul>
</div>
</div>
<section id="motivation" class="level2 page-columns page-full" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="motivation"><span class="header-section-number">12.1</span> Motivation</h2>
<p>In <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, the basic idea of double machine learning (DML) methods was introduced when the treatment effect is homogeneous. We now turn our focus to the task of estimating heterogeneous treatment effects: the impact of a treatment varies based on observed attributes of the subjects. Heterogeneous treatment effect is also referred to as <span style="color:blue"> conditional </span> average treatment effect (CATE).</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span style="color:blue"> Conditional </span> on observed attributes.</p>
</div></div><p>Understanding how treatment effects vary can be highly valuable in many circumstances.</p>
<p><span style="color:blue"> Example 1: </span> If we come to know a particular drug is effective on elderly people but detrimental to kids, then doctors can make a smart decision of prescribing the drug to elderly people, but not to kids.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In this example, the heterogeneity driver is age.</p>
</div></div><p><span style="color:blue"> Example 2: </span> If we come to know that fertilizer is more effective in increasing corn yield in soil type A than B, then farmers can apply more fertilizer on the parts of the field where soil type is A but less on where soil type is B.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>In this example, the heterogeneity driver is soil type.</p>
</div></div><p>As you can see in these examples, knowledge on the heterogeneity of the treatment effect and its drivers can help decision makers smart-target treatments and policies.</p>
</section>
<section id="modeling-framework" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="modeling-framework"><span class="header-section-number">12.2</span> Modeling Framework</h2>
<p>The model of interest in general form is as follows:</p>
<p><span id="eq-model-framework"><span class="math display">\[
\begin{aligned}
Y_i &amp; = \theta(X_i)\cdot T_i + g(X_i, W_i) + \varepsilon_i \\
T_i &amp; = f(X_i, W_i) + \eta_i
\end{aligned}
\tag{12.1}\]</span></span></p>
<ul>
<li><span class="math inline">\(Y\)</span>: dependent variable</li>
<li><span class="math inline">\(T\)</span>: treatment variable</li>
<li><span class="math inline">\(X\)</span>: collection of variables that affect Y indirectly through the treatment (<span class="math inline">\(\theta(X)\cdot T\)</span>) and directly (<span class="math inline">\(g(X, W)\)</span>) independent of the treatment</li>
<li><span class="math inline">\(W\)</span>: collection of variables that affect directly (<span class="math inline">\(g(X, W)\)</span>) independent of the treatment, but not through the treatment</li>
</ul>
<p>Here are the assumptions:</p>
<ul>
<li><span class="math inline">\(E[\varepsilon|X, W] = 0\)</span></li>
<li><span class="math inline">\(E[\eta|X, W] = 0\)</span></li>
<li><span class="math inline">\(E[\eta\cdot\varepsilon|X, W] = 0\)</span></li>
</ul>
<p>For the notational convenicence, let <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> denote the expected value of the potential conditional outcomes:</p>
<p><span class="math display">\[
\begin{align}
\mu_1(X) &amp; = E[Y|W=1, X] = g(X, W)\\
\mu_0(X) &amp; = E[Y|W=0, X] =  \theta(X) + g(X, W)
\end{align}
\]</span></p>
</section>
<section id="s--t--and-x-learner" class="level2 page-columns page-full" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="s--t--and-x-learner"><span class="header-section-number">12.3</span> S-, T-, and X-Learner</h2>
<section id="s-learner" class="level3" data-number="12.3.1">
<h3 data-number="12.3.1" class="anchored" data-anchor-id="s-learner"><span class="header-section-number">12.3.1</span> S-learner</h3>
<p>S-learner estimates CATE by taking the following steps:</p>
<ol type="1">
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(W\)</span> and <span class="math inline">\(X\)</span> to estimate <span class="math inline">\(E[Y|W,X]\)</span> using any appropriate ML regression methods and call it <span class="math inline">\(\hat{\mu}(W,X)\)</span>.</li>
<li>Estimate <span class="math inline">\(\hat{\theta}(X)\)</span> as <span class="math inline">\(\hat{\mu}(W=1,X)-\hat{\mu}(W=0,X)\)</span></li>
</ol>
<p>In this approach, no special treatment is given to <span class="math inline">\(W\)</span>. It is just a covariate along with others (<span class="math inline">\(X\)</span>). This approach is named S-learner by <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span> because it involves estimating a <span style="color:red">s</span>ingle response function.</p>
</section>
<section id="t-learner" class="level3" data-number="12.3.2">
<h3 data-number="12.3.2" class="anchored" data-anchor-id="t-learner"><span class="header-section-number">12.3.2</span> T-learner</h3>
<ol type="1">
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(W\)</span> and <span class="math inline">\(X\)</span> using the treated observations to estimate <span class="math inline">\(\mu_1(X)\)</span> using any appropriate ML regression methods.</li>
<li>Regress <span class="math inline">\(Y\)</span> on <span class="math inline">\(W\)</span> and <span class="math inline">\(X\)</span> using the control observations to estimate <span class="math inline">\(\mu_0(X)\)</span> using any appropriate ML regression methods.</li>
<li>Estimate <span class="math inline">\(\hat{\theta}(X)\)</span> as <span class="math inline">\(\hat{\mu}_1(X)-\hat{\mu}(X)\)</span></li>
</ol>
<p>This approach is named T-learner by <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span> because it involves estimating <span style="color:red">t</span>wo functions.</p>
</section>
<section id="x-learner" class="level3 page-columns page-full" data-number="12.3.3">
<h3 data-number="12.3.3" class="anchored" data-anchor-id="x-learner"><span class="header-section-number">12.3.3</span> X-learner</h3>
<ol type="1">
<li>Estimate <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> using any appropriate ML regression methods. (Steps 1 and 2 of the T-learner)</li>
<li>Impute individual treatment effect for the treated and control groups as follows</li>
</ol>
<p><span class="math display">\[
\begin{align}
\tilde{D}_i^1(X_i) = Y^1_i - \hat{\mu}_0(X_i)\\
\tilde{D}_i^0(X_i) =  \hat{\mu}_1(X_i) - Y^0_i
\end{align}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This is similar to cross-fitting we saw in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, where the folds are the treated and control groups.</p>
</div></div><ol start="3" type="1">
<li></li>
</ol>
<ul>
<li><p>Regress <span class="math inline">\(\tilde{D}_i^1(X_i)\)</span> on <span class="math inline">\(X\)</span> using the observations in the treated group and denote the predicted value as <span class="math inline">\(\hat{\theta}_1(X)\)</span></p></li>
<li><p>Regress <span class="math inline">\(\tilde{D}_i^0(X_i)\)</span> on <span class="math inline">\(X\)</span> using the observations in the control group and denote the predicted value as <span class="math inline">\(\hat{\theta}_0(X)\)</span></p></li>
</ul>
<ol start="4" type="1">
<li>Calculate <span class="math inline">\(\hat{\theta}(X)\)</span> as their weighted average</li>
</ol>
<p><span id="eq-final-X"><span class="math display">\[
\begin{align}
\hat{\theta}(X) = g(X)\cdot\hat{\theta}_0(X) + [1-g(X)]\cdot\hat{\theta}_1(X)
\end{align}
\tag{12.2}\]</span></span></p>
<p>Any value of <span class="math inline">\(g(X)\)</span> is acceptable. One option of <span class="math inline">\(g(X)\)</span> may be the estimated propensity score <span class="math inline">\(E[W|X]\)</span>.</p>
</section>
</section>
<section id="t-learner-v.s.-x-learner" class="level2 page-columns page-full" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="t-learner-v.s.-x-learner"><span class="header-section-number">12.4</span> T-learner v.s. X-learner</h2>
<p>Here, an advantage of X-learner over T-learner is demonstrated. This example also serves as an illustration of how these learners are implemented. Specifically, X-learner can be advantageous when the control-treatment assignments in the sample are unbalanced. For example, it is often the case that there are plenty of observations in the control group, while there are not many treated observations. For the purpose of illustration, consider a rather extreme case where there are only 10 observations in the treated group, while there are 300 observations in the control group. We use the following toy data generating process:</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p><span class="math display">\[
\begin{align}
y = \tau W + |x| + v
\end{align}
\]</span></p>
<p>where <span class="math inline">\(\tau = 1\)</span>. So, the treatment effect is not heterogeneous. For the purpose of illustrating the advantage of X-learner over T-learner, it is convenient if the underlying model is simpler.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4345</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>N_trt <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>N_ctrl <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> N_trt <span class="sc">+</span> N_ctrl</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,N_trt), <span class="fu">rep</span>(<span class="dv">0</span>, N_ctrl)),</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Treated"</span>, N_trt), <span class="fu">rep</span>(<span class="st">"Control"</span>, N_ctrl)),</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">runif</span>(N)<span class="sc">-</span><span class="dv">1</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">v =</span> <span class="fu">rnorm</span>(N) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>  .[, y <span class="sc">:</span><span class="er">=</span> W <span class="sc">+</span> <span class="fu">abs</span>(x) <span class="sc">+</span> v]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> data) <span class="sc">+</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s first estimate <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> (Step 1). Since we have only <span class="math inline">\(20\)</span> observations in the treated group, we will use a linear regression to avoid over-fitting (following the example in <span class="citation" data-cites="kunzel_metalearners_2019">Künzel et al. (<a href="#ref-kunzel_metalearners_2019" role="doc-biblioref">2019</a>)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>mu_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>mu_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now that <span class="math inline">\(\mu_1(X)\)</span> and <span class="math inline">\(\mu_0(X)\)</span> are estimated, we can estimate <span class="math inline">\(\hat{\theta}(X)\)</span> by T-learner.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="co">#=== T-learner ===#</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>tau_hat_data <span class="ot">&lt;-</span> </span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="sc">%&gt;%</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>  .[, mu_1_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  .[, mu_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>  .[, tau_hat_T <span class="sc">:</span><span class="er">=</span> mu_1_hat <span class="sc">-</span> mu_0_hat]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see, T-learner is heavily biased. This is because of the unreliable estimation of <span class="math inline">\(\mu_1(X)\)</span> due to lack of observations in the treated group.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Now, let’s move on to X-learner. We impute individual treatment effects (Step 2).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (treated) ===#</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (control) ===#</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#=== assign the values ===#</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Treated"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_1]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Control"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_0]</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">#=== find individual TE ===#</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>data[, D <span class="sc">:</span><span class="er">=</span> <span class="fu">ifelse</span>(type <span class="sc">==</span> <span class="st">"Treated"</span>, y <span class="sc">-</span> mu_hat, mu_hat <span class="sc">-</span> y)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now regress <span class="math inline">\(D\)</span> on <span class="math inline">\(X\)</span> (Step 3),</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (treated)</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>tau_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(D <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_1_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (control)</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>tau_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(D <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_0_trained, <span class="at">newdata =</span> tau_hat_data)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_1, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Treated"</span>)) <span class="sc">+</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_0, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Control"</span>)) <span class="sc">+</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Treated"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Control"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p>Let’s use propensity score as <span class="math inline">\(g(X)\)</span> in Step 4.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>w_gam_trained <span class="ot">&lt;-</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gam</span>(</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data, </span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Let’s predict <span class="math inline">\(E[W|X]\)</span> at each value of <span class="math inline">\(X\)</span> at which we are estiamting <span class="math inline">\(\tau\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, g_x <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(w_gam_trained, <span class="at">newdata =</span> tau_hat_data, <span class="at">type =</span> <span class="st">"response"</span>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see below, the mean value of <span class="math inline">\(g(x)\)</span> is small because the treatment probability is very low (it is only <span class="math inline">\(20\)</span> out of <span class="math inline">\(320\)</span>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(tau_hat_data[, g_x])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.06451538</code></pre>
</div>
</div>
<p>This number is basically <span class="math inline">\(20/320\)</span>. So, in this example, we could have just used the proportion of the treated observations. Notice that <span class="math inline">\(g(X)\)</span> is multiplied to <span class="math inline">\(\hat{\theta}_0(X)\)</span> in <a href="#eq-final-X">Equation&nbsp;<span>12.2</span></a>. So, we are giving a lower weight to <span class="math inline">\(\hat{\theta}_0(X)\)</span>. This is because <span class="math inline">\(\hat{\theta}_0(X)\)</span> is less reliable because <span class="math inline">\(\hat{\mu}_1(X)\)</span> is less reliable due to the lack of samples in the treated group.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_X <span class="sc">:</span><span class="er">=</span> g_x <span class="sc">*</span> tau_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>g_x) <span class="sc">*</span> tau_hat_1]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As you can see, X-learner outperforms T-learner in this particular instance at least in terms of point estimates of <span class="math inline">\(\tau(X)\)</span>.</p>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"T-learner"</span>)) <span class="sc">+</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_X, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"X-learner"</span>)) <span class="sc">+</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">"True Treatment Effect"</span>)) <span class="sc">+</span></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">"T-learner"</span> <span class="ot">=</span> <span class="st">"red"</span>, </span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">"X-learner"</span> <span class="ot">=</span> <span class="st">"blue"</span>, </span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">"True Treatment Effect"</span> <span class="ot">=</span> <span class="st">"black"</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<p><img src="C02-xstr-learner_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid" width="672"></p>
</div>
</div>
</section>
<section id="sec-r-learner" class="level2 page-columns page-full" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="sec-r-learner"><span class="header-section-number">12.5</span> R-learner</h2>
<section id="theoretical-background" class="level3 page-columns page-full" data-number="12.5.1">
<h3 data-number="12.5.1" class="anchored" data-anchor-id="theoretical-background"><span class="header-section-number">12.5.1</span> Theoretical background</h3>
<p>Under the assumptions,</p>
<p><span id="eq-yxw"><span class="math display">\[
\begin{aligned}
E[Y|X, W] = \theta(X)\cdot f(X,W) + g(X,W)
\end{aligned}
\tag{12.3}\]</span></span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p><span class="math inline">\(f(X,W) = E[T|X,W]\)</span></p>
</div></div><p>Let, <span class="math inline">\(l(X,W)\)</span> denote <span class="math inline">\(E[Y|X, W]\)</span>. Taking the difference of <a href="#eq-model-framework">Equation&nbsp;<span>12.1</span></a> and <a href="#eq-yxw">Equation&nbsp;<span>12.3</span></a> on both sides,</p>
<p><span class="math display">\[
\begin{aligned}
Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot T_i + g(X_i,W_i) + \varepsilon_i - [\theta(X_i)\cdot f(X_i,W_i) + g(X_i,W_i)] \\
\Rightarrow Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i \\
\end{aligned}
\]</span></p>

<div class="no-row-height column-margin column-container"><div class="">
<p>This is akin to residualization/orthogonalization seen in the DML approach in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>.</p>
</div></div><p>So, the problem of identifying <span class="math inline">\(\theta(X)\)</span> reduces to estimating the following model:</p>
<p><span class="math display">\[
\begin{aligned}
Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i
\end{aligned}
\]</span></p>
<p>Since <span class="math inline">\(E[(T_i -f(X_i,W_i))\cdot\varepsilon_i|X] = E[\eta_i\cdot\varepsilon_i|X] = 0\)</span> by assumption, we can regress <span class="math inline">\(Y_i - l(X_i,W_i)\)</span> on <span class="math inline">\(X_i\)</span> and <span class="math inline">\(T_i -f(X_i,W_i)\)</span> to estimate <span class="math inline">\(\theta(X)\)</span>. Specifically, we can minimize the following objective function:</p>
<p><span id="eq-est-equation"><span class="math display">\[
\begin{aligned}
Min_{\theta(X)}\sum_{i=1}^N \large(\normalsize[Y_i - l(X_i,W_i)] - [\theta(X_i)\cdot (T_i -f(X_i,W_i))]\large)^2
\end{aligned}
\tag{12.4}\]</span></span></p>
</section>
<section id="sec-est-steps" class="level3 page-columns page-full" data-number="12.5.2">
<h3 data-number="12.5.2" class="anchored" data-anchor-id="sec-est-steps"><span class="header-section-number">12.5.2</span> Estimation steps</h3>
<p>In practice, we of course do not observe <span class="math inline">\(l(X,W)\)</span> and <span class="math inline">\(f(X,W)\)</span>. So, we first need to estimate them using the data at hand and then subtract them from <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(T_i\)</span>, respectively. You can use any suitable statistical methods to estimate <span class="math inline">\(l(X, W)\)</span> and <span class="math inline">\(f(X,W)\)</span>. Some machine learning methods allow you to estimate them without assuming any functional form or structural assumptions. If you believe they are linear functions of <span class="math inline">\(X\)</span> and <span class="math inline">\(W\)</span>, you could alternatively use lasso or other linear models. <span class="citation" data-cites="nie_quasi-oracle_2021">Nie and Wager (<a href="#ref-nie_quasi-oracle_2021" role="doc-biblioref">2021</a>)</span> proposes that the estimation of <span class="math inline">\(l(X,W)\)</span> and <span class="math inline">\(f(X,W)\)</span> is done by cross-fitting (see <a href="C01-dml.html#sec-cf"><span>Section&nbsp;11.1.4</span></a>) to avoid over-fitting bias. Let <span class="math inline">\(I_{-i}\)</span> denote all the observations that belong to the folds that <span class="math inline">\(i\)</span> does <span style="color:blue"> not </span> belong to. Further, let <span class="math inline">\(\hat{l}(X_i, W_i)^{I_{-i}}\)</span> and <span class="math inline">\(\hat{f}(X_i, W_i)^{I_{-i}}\)</span> denote <span class="math inline">\(l(X_i, W_i)\)</span> and <span class="math inline">\(f(X_i, W_i)\)</span> estimated using <span class="math inline">\(I_{-i}\)</span>.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>Just like the DML approach discussed in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a>, both <span class="math inline">\(Y\)</span> and <span class="math inline">\(T\)</span> are orthogonalized.</p>
</div></div><p>Then the quality of fit (explaining the heterogeneity in the impact of treatment) can be expressed as follows, which is the empirical version of <a href="#eq-est-equation">Equation&nbsp;<span>12.4</span></a>:</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N [Y_i - \hat{l}(X_i,W_i)^{I_{-i}} - \theta(X)\cdot (T_i - \hat{f}(X_i,W_i)^{I_{-i}})]^2
\end{aligned}
\]</span></p>
<p>This is called <span style="color:blue"> R-score</span>, and it can be used for causal model selection, which will be covered later.</p>
<p>Let <span class="math inline">\(\tilde{Y}_i\)</span> and <span class="math inline">\(\tilde{T}_i\)</span> denote <span class="math inline">\(Y_i - \hat{l}(X_i,W_i)^{I_{-i}}\)</span> and <span class="math inline">\(T_i - \hat{f}(X_i,W_i)^{I_{-i}}\)</span>, respectively. The final stage of the R-learner is to estimate <span class="math inline">\(\theta(X)\)</span> by minimizing the R-score plus the regularization term (if desirable).</p>
<p><span id="eq-r-min"><span class="math display">\[
\begin{aligned}
\hat{\theta}(X) = argmin_{\theta(X)}\;\;\sum_{i=1}^N [\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i]^2 + \Lambda(\theta(X))
\end{aligned}
\tag{12.5}\]</span></span></p>
<p>where <span class="math inline">\(\Lambda(\theta(X))\)</span> is the penalty on the complexity of <span class="math inline">\(\theta(X)\)</span>. For example, if you choose to use lasso, then <span class="math inline">\(\Lambda(\theta(X))\)</span> is the L1 norm. You have lots of freedom as to what model you use in the final stage. The <code>econml</code> package offers several off-the-shelf choices of R-learner (DML) approaches that differ in the model used at the final stage, including causal forest, lasso, etc.</p>
</section>
<section id="r-learner-by-hand" class="level3" data-number="12.5.3">
<h3 data-number="12.5.3" class="anchored" data-anchor-id="r-learner-by-hand"><span class="header-section-number">12.5.3</span> R-learner by hand</h3>
<p>This section goes through the estimation steps provided above to further the understanding of how R-learner works using a synthetic dataset that follows the DGP below.</p>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp; = (x_{i,1} + x_{i,2}^2)\cdot T_i + \sqrt{x_{i,3}} + \mu_i \\
T_i|X_i &amp; = Bernouli((1+x_{i,1})/2) \\
\mu_i|X_i &amp; = N(0,1)
\end{aligned}
\]</span></p>
<p>Let’s generate a dataset according to the DGP.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">58734</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">T :=</span> <span class="fu">runif</span>(N) <span class="sc">&lt;</span> ((<span class="fl">0.5</span><span class="sc">+</span>x1)<span class="sc">/</span><span class="dv">2</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">Y :=</span> (x1 <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> T <span class="sc">+</span> <span class="fu">sqrt</span>(x3) <span class="sc">+</span> mu] <span class="sc">%&gt;%</span> </span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">id :=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p>We first cross-fit <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[T|X]\)</span> using random forest for both cases. We will use repeated (3 times) 5-fold cross-fitting. Resampling the data,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(data, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>#  5-fold cross-validation repeated 3 times 
# A tibble: 15 × 3
   splits            id      id2  
   &lt;list&gt;            &lt;chr&gt;   &lt;chr&gt;
 1 &lt;split [800/200]&gt; Repeat1 Fold1
 2 &lt;split [800/200]&gt; Repeat1 Fold2
 3 &lt;split [800/200]&gt; Repeat1 Fold3
 4 &lt;split [800/200]&gt; Repeat1 Fold4
 5 &lt;split [800/200]&gt; Repeat1 Fold5
 6 &lt;split [800/200]&gt; Repeat2 Fold1
 7 &lt;split [800/200]&gt; Repeat2 Fold2
 8 &lt;split [800/200]&gt; Repeat2 Fold3
 9 &lt;split [800/200]&gt; Repeat2 Fold4
10 &lt;split [800/200]&gt; Repeat2 Fold5
11 &lt;split [800/200]&gt; Repeat3 Fold1
12 &lt;split [800/200]&gt; Repeat3 Fold2
13 &lt;split [800/200]&gt; Repeat3 Fold3
14 &lt;split [800/200]&gt; Repeat3 Fold4
15 &lt;split [800/200]&gt; Repeat3 Fold5</code></pre>
</div>
</div>
<p>The following function takes a row number (<code>n</code>) and cross-fits <span class="math inline">\(E[Y|X]\)</span> and <span class="math inline">\(E[T|X]\)</span> for the training and test data split stored in the <code>n</code>th row of <code>data_folds</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n, data_folds) </span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">analysis</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  eval_data <span class="ot">&lt;-</span> <span class="fu">assessment</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[Y|X]</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== train ===#</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>  rf_trained_y <span class="ot">&lt;-</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>      Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit ===#</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>  eval_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_y, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions]</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[T|X]</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>  rf_trained_t <span class="ot">&lt;-</span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>      T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data,</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>      <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>  eval_data[, t_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_t, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]]</span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(eval_data[, .(id, y_hat, t_hat)])</span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here is what the output of the function for the first split looks like.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cross_fit</span>(<span class="dv">1</span>, data_folds)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>      id     y_hat     t_hat
  1:   6 0.9501526 0.3393762
  2:   8 1.0243377 0.4105849
  3:  11 2.3829353 0.7505262
  4:  14 1.2664673 0.2735690
  5:  24 0.8221323 0.2022452
 ---                        
196: 976 1.2029792 0.4037865
197: 982 1.4004625 0.6835349
198: 985 0.9873009 0.7058357
199: 986 1.6350936 0.7844119
200: 989 1.3315096 0.6196008</code></pre>
</div>
</div>
<p>Repeating this for all the splits,</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>cross_fitted_data_rp <span class="ot">&lt;-</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       id     y_hat     t_hat
   1:   6 1.0983042 0.3675159
   2:   8 1.0192703 0.3822087
   3:  11 2.3859858 0.7118770
   4:  14 1.3490575 0.2809548
   5:  24 0.8445691 0.1891198
  ---                        
2996: 980 1.5404706 0.4571746
2997: 981 0.9643170 0.1216540
2998: 982 0.8932837 0.6276294
2999: 987 1.3730824 0.3106548
3000: 999 1.2796463 0.4727944</code></pre>
</div>
</div>
<p>We finally take the mean of the cross-fits by <code>id</code> as each <code>id</code> has tree estimates.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>cross_fitted_data <span class="ot">&lt;-</span> </span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data_rp[, .(</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_hat =</span> <span class="fu">mean</span>(t_hat),</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> <span class="fu">mean</span>(y_hat)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">by =</span> id]</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       id     t_hat     y_hat
   1:   6 0.4075370 1.1753271
   2:   8 0.3879296 1.1170714
   3:  11 0.6472622 2.3270883
   4:  14 0.3384108 1.2757203
   5:  24 0.2117574 0.8174066
  ---                        
 996: 960 0.3923807 0.9133472
 997: 971 0.4096185 1.0594023
 998: 973 0.4568971 0.8298878
 999: 979 0.5767799 1.5053943
1000: 997 0.4255442 0.7439748</code></pre>
</div>
</div>
<p>We then merge the data to the original data, and define <span class="math inline">\(\tilde{Y}\)</span> and <span class="math inline">\(\tilde{T}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>data_2nd <span class="ot">&lt;-</span> </span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data[data, <span class="at">on =</span> <span class="st">"id"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>  .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_tilde =</span> Y <span class="sc">-</span> y_hat,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_tilde =</span> T <span class="sc">-</span> t_hat</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>  .[, .(y_tilde, t_tilde, x1, x2, x3)]</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>          y_tilde    t_tilde          x1         x2        x3
   1: -0.05078105 -0.5599698 0.260608266 0.06164198 0.4589749
   2: -0.95021925 -0.4845212 0.766984113 0.54764941 0.2009673
   3:  1.68239276  0.5095140 0.826228121 0.87144558 0.9021309
   4:  1.32646805  0.5239016 0.640185426 0.60915635 0.9121869
   5:  0.56495269  0.5633217 0.513102608 0.98349865 0.2889536
  ---                                                        
 996: -1.88084933 -0.5059008 0.503932977 0.98448894 0.4080396
 997: -0.95304562 -0.4255442 0.004402003 0.08928705 0.7901242
 998:  0.13521343  0.5495262 0.543469334 0.67529131 0.8898840
 999:  1.19121092 -0.4589937 0.927181725 0.58389265 0.4166628
1000: -0.74149133 -0.3224005 0.037774180 0.66973547 0.8149703</code></pre>
</div>
</div>
<hr>
<p>The first order condition of <a href="#eq-r-min">Equation&nbsp;<span>12.5</span></a> without <span class="math inline">\(\Lambda(\theta(X))\)</span> is</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N (\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i)\cdot \tilde{T}_i = 0
\end{aligned}
\]</span></p>
<p>This can be rewritten as</p>
<p><span class="math display">\[
\begin{aligned}
\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0
\end{aligned}
\]</span></p>
<p>So, this problem can be considered the problem of estimating <span class="math inline">\(\theta(X)\)</span> when the dependent variable is <span class="math inline">\(\frac{\tilde{Y}_i}{\tilde{T}_i}\)</span> with individual weights of <span class="math inline">\(\tilde{T}_i^2\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>data_2nd[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">weight =</span> t_tilde<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_to_t =</span> y_tilde <span class="sc">/</span> t_tilde</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>)]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use <code>xgboost()</code> for a non-parametric estimation of <span class="math inline">\(\theta(X)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>You can now predict <span class="math inline">\(\theta(X)\)</span> at particular values of <span class="math inline">\(X\)</span>. Let’s estimate <span class="math inline">\(\theta(X)\)</span> at <span class="math inline">\(X_0 = \{x_1 = 0.5, x_2 = 0.5, x_3 = 0.5\}\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> </span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> .)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_trained_2nd, eval_data)</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.944087</code></pre>
</div>
</div>
<p>You could alternatively estimate <span class="math inline">\(\theta(X)\)</span> parametrically using OLS. Suppose we somehow know that <span class="math inline">\(\theta(X)\)</span> takes the following form <span class="math inline">\(\beta_1 x_1 + \beta_2 x_2^2 + \beta_3 x_3\)</span>. Then, the second stage estimation would be regressing <span class="math inline">\(\tilde{Y}\)</span> on <span class="math inline">\(x_1\times T\)</span>, <span class="math inline">\(x_2^2\times T\)</span>, and <span class="math inline">\(x_2\times T\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>ols_2nd_stage <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_tilde <span class="sc">~</span> <span class="fu">I</span>(x1<span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x2<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">*</span>t_tilde), <span class="at">data =</span> data_2nd)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== summary ===#</span></span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ols_2nd_stage)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = y_tilde ~ I(x1 * t_tilde) + I(x2^2 * t_tilde) + 
    I(x3 * t_tilde), data = data_2nd)

Residuals:
    Min      1Q  Median      3Q     Max 
-3.3874 -0.7038  0.0348  0.6613  3.3934 

Coefficients:
                   Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)       -0.002771   0.032237  -0.086    0.932    
I(x1 * t_tilde)    0.862736   0.185098   4.661 3.57e-06 ***
I(x2^2 * t_tilde)  0.976104   0.198821   4.909 1.07e-06 ***
I(x3 * t_tilde)    0.274054   0.182000   1.506    0.132    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 1.017 on 996 degrees of freedom
Multiple R-squared:  0.1935,    Adjusted R-squared:  0.1911 
F-statistic: 79.67 on 3 and 996 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>The results look pretty good mostly because we are cheating and using the correct functional form. Of course, in practice, you would not know the correct functional form of <span class="math inline">\(\theta(X)\)</span>. Finally, note that you should not use the codes here since they are just for demonstration to enhance our understanding of how R-learner works.</p>
</section>
</section>
<section id="comparing-the-learners" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="comparing-the-learners"><span class="header-section-number">12.6</span> Comparing the learners</h2>
<p><span class="math display">\[
\begin{aligned}
Y_i =\theta(X_i)\cdot T + \alpha g(X_i) + \mu_i
\end{aligned}
\]</span></p>
<ul>
<li><span class="math inline">\(X_i = \{X_{i,1}, X_{i,2}, X_{i,3}, X_{i,4}, X_{i,5}\}\)</span></li>
<li><span class="math inline">\(T_i|X_i \sim Bernouli(f(X_i))\)</span></li>
<li><span class="math inline">\(\mu_i|X_i \sim N(0,1)\)</span></li>
</ul>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Case A
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
g(X_i) &amp; = sin(\pi X_{i,1}X_{i,2}) + 2(X_{i,3}-0.5)^2 + X_{i,4} + 0.5 X_{i,5}\\
e(X_i) &amp; = max(0.1, min(sin(\pi X_{i,1}X_{i,2}), 0.9)) \\
\theta(X_i) &amp; = (X_{i,1}, X_{i,2}) / 2 \\
X_i &amp; \sim Uni(0,1)^5
\end{aligned}
\]</span></p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>gen_data_A <span class="ot">&lt;-</span> <span class="cf">function</span>(N){</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> <span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x4 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x5,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="fu">pmax</span>(<span class="fl">0.1</span>, <span class="fu">pmin</span>(<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2), <span class="fl">0.9</span>)),</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> (x1<span class="sc">+</span>x2)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div class="cell">

</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Case B (randomized trial)
</div>
</div>
<div class="callout-body-container callout-body">
<p><span class="math display">\[
\begin{aligned}
g(X_i) &amp; = max(X_{i,1} + X_{i,2}, X_{i,3}, 0) + max(X_{i,4}+ X_{i,5},0)\\
e(X_i) &amp; = 1/2 \\
\theta(X_i) &amp; = X_{i,1} + log(1+exp(X_{i,2})) \\
X_i &amp; \sim N(0,I_5)
\end{aligned}
\]</span></p>
</div>
</div>
<div class="cell">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>gen_data_B <span class="ot">&lt;-</span> <span class="cf">function</span>(N){</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> <span class="fu">pmax</span>(x1 <span class="sc">+</span> x2, x3) <span class="sc">+</span> <span class="fu">pmax</span>(x4 <span class="sc">+</span> x5, <span class="dv">0</span>),</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> x1<span class="sc">+</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x2))</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> (<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="x--s--t--r-learner-in-python" class="level2 page-columns page-full" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="x--s--t--r-learner-in-python"><span class="header-section-number">12.7</span> X-, S-, T-, R-learner in Python</h2>
<p>We saw a general R-learner framework for CATE estimation. We now look at an example of Linear DML, which uses a linear model at the final stage. So, we are assuming that <span class="math inline">\(\theta(X)\)</span> can be written as follows in <a href="#eq-model-framework">Equation&nbsp;<span>12.1</span></a>:</p>
<p><span class="math display">\[
\begin{aligned}
\theta(X) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k
\end{aligned}
\]</span></p>
<p>where <span class="math inline">\(x_1\)</span> through <span class="math inline">\(x_k\)</span> are the drivers of heterogeneity in treatment effects and <span class="math inline">\(\beta_1\)</span> through <span class="math inline">\(\beta_k\)</span> are their coefficients.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Packages to load for replication</strong></p>
<div class="cell">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div></div><p>We use both Python and R for this demonstration. So, let’s set things up for that.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"ml-learning"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>For this demonstration, we use synthetic data according to the following data generating process:</p>
<p><span class="math display">\[
\begin{aligned}
y_i = exp(x_{i,1}) d_i + x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} + \mu_i \\
d_i = \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3}+ \eta_i
\end{aligned}
\]</span></p>
<p>Note that this is the same data generating process used in <a href="C01-dml.html"><span>Chapter&nbsp;11</span></a> except that the impact of the treatment (<span class="math inline">\(d\)</span>) now depends on <span class="math inline">\(x_1\)</span>. We can use <code>gen_data()</code> function that is defined in <a href="C01-dml.html#sec-dml-naive"><span>Section&nbsp;11.1.2</span></a>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="co">#=== sample size ===#</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a><span class="co">#=== generate data ===#</span></span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>synth_data <span class="ot">&lt;-</span></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_data</span>(</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">*</span>d)),</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> N <span class="sc">*</span><span class="dv">2</span></span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(synth_data, <span class="fu">starts_with</span>(<span class="st">"x"</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> synth_data[, y]</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> synth_data[, d]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We now split the data into training and test datasets.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test, d_train, d_test<span class="op">=</span> train_test_split(r.X, r.y, r.d,  test_size <span class="op">=</span> <span class="fl">0.5</span>, random_state <span class="op">=</span> <span class="dv">8923</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, to train a linear DML model, we use the Python <code>econml</code> package, which offers one of the most comprehensive sets of off-the-shelf R-learner (DML) methods <span class="citation" data-cites="econml">(<a href="#ref-econml" role="doc-biblioref">Keith Battocchi 2019</a>)</span>. We can use the <code>DML</code> class to implement linear DML.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><code>DML</code> is a child class of <code>_Rlearner</code>, which is a private class. The <code>DML</code> class has several child classes: <code>LinearDML</code>, <code>SpatseLinearDML</code>, <code>NonParamDML</code>, and <code>CausalForestDML</code>.</p>
</div></div><p>As we saw above in <a href="#sec-est-steps"><span>Section&nbsp;12.5.2</span></a>, we need to specify three models:</p>
<ul>
<li><code>model_y</code>: model for estimating <span class="math inline">\(E[Y|X,W]\)</span></li>
<li><code>model_t</code>: model for estimating <span class="math inline">\(E[T|X,W]\)</span></li>
<li><code>model_final</code>: model for estimating <span class="math inline">\(\theta(X)\)</span></li>
</ul>
<p>In this example, let’s use gradient boosting regression for both <code>model_y</code> and <code>model_t</code> and use lasso with cross-validation for <code>model_final</code>. Let’s import <code>GradientBoostingRegressor()</code> and <code>LassoCV()</code> from the <code>scikitlearn</code> package.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We can now set up our DML framework like below:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> DML(</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>    model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>    model_t <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>    model_final <span class="op">=</span> LassoCV(fit_intercept <span class="op">=</span> <span class="va">False</span>) </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Note that no training has happened yet at this point. We simply created a recipe. Once we provide ingredients (data), we can cook (train) with the <code>fit()</code> method.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>est.fit(y_train, d_train, X <span class="op">=</span> X_train, W <span class="op">=</span> X_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>first argument: dependent variable</li>
<li>second argument: treatment variable</li>
<li><code>X</code>: variables that drive treatment effect heterogeneity</li>
<li><code>W</code>: variables that affect the dependent variable directly</li>
</ul>

<div class="no-row-height column-margin column-container"><div class="">
<p>Here, we set <code>X = W</code>.</p>
</div></div><p>Once, the training is done. We can use the <code>effect()</code> method to predict <span class="math inline">\(\theta(X)\)</span>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>te_test <span class="op">=</span> est.effect(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><a href="#fig-est-theta-hat">Figure&nbsp;<span>12.1</span></a> presents the estimated and true marginal treatment effect (<span class="math inline">\(\theta(X)\)</span>) as a function of <code>x1</code>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> </span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> py<span class="sc">$</span>X_test[, <span class="dv">1</span>],</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">te =</span> py<span class="sc">$</span>te_test</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data) <span class="sc">+</span></span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> te, <span class="at">x =</span> x1)) <span class="sc">+</span></span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">exp</span>(x1), <span class="at">x =</span> x1), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-est-theta-hat" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="C02-xstr-learner_files/figure-html/fig-est-theta-hat-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 12.1: Estimated and true marginal treatment effects</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Since we forced <span class="math inline">\(\theta(X)\)</span> to be linear in <code>x1</code>, it is not surprising that the estimated MTE looks linear in <code>x1</code> even though the true MTE is an exponential function of <code>x1</code>. In the next chapter (<span class="quarto-unresolved-ref">?sec-forest-cate</span>), we discuss CATE estimators based on forest, which estimates <span class="math inline">\(\theta(X)\)</span> non-parametrically, relaxing the assumption of <span class="math inline">\(\theta(X)\)</span> being linear-in-parameter.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are many more variations in DML than the one presented here. For those who are interested, I recommend going through examples presented <a href="https://github.com/microsoft/EconML/blob/main/notebooks/Double%20Machine%20Learning%20Examples.ipynb">here</a> for <code>DML</code></p>
</div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography">
<div id="ref-Chernozhukov2018" class="csl-entry" role="doc-biblioentry">
Chernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. <span>“<span class="nocase">Double/debiased machine learning for treatment and structural parameters</span>.”</span> <em>The Econometrics Journal</em> 21 (1): C1–68. <a href="https://doi.org/10.1111/ectj.12097">https://doi.org/10.1111/ectj.12097</a>.
</div>
<div id="ref-econml" class="csl-entry" role="doc-biblioentry">
Keith Battocchi, Maggie Hei, Eleanor Dillon. 2019. <span>“<span>EconML</span>: <span class="nocase">A Python Package for ML-Based Heterogeneous Treatment Effects Estimation</span>.”</span> https://github.com/microsoft/EconML.
</div>
<div id="ref-kunzel_metalearners_2019" class="csl-entry" role="doc-biblioentry">
Künzel, Sören R., Jasjeet S. Sekhon, Peter J. Bickel, and Bin Yu. 2019. <span>“Metalearners for Estimating Heterogeneous Treatment Effects Using Machine Learning.”</span> <em>Proceedings of the National Academy of Sciences</em> 116 (10): 4156–65. <a href="https://doi.org/10.1073/pnas.1804597116">https://doi.org/10.1073/pnas.1804597116</a>.
</div>
<div id="ref-nie_quasi-oracle_2021" class="csl-entry" role="doc-biblioentry">
Nie, X, and S Wager. 2021. <span>“Quasi-Oracle Estimation of Heterogeneous Treatment Effects.”</span> <em>Biometrika</em> 108 (2): 299–319. <a href="https://doi.org/10.1093/biomet/asaa076">https://doi.org/10.1093/biomet/asaa076</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./C01-dml.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Double Machine Learning</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./C03-cf-orf.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Forest-based CATE Estimators</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb46" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># S-, X-, T-, and R-learner {#sec-het-dml}</span></span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>In this section, we look at the S-, X-, T-, and R-learner, which are method that estimate heterogeneous treatment effects when the treatment is binary. While X-learner and T-learner cannot be extended to continuous treatment cases, S-learner and R-learner can be. Mathematical notations used in this chapter closely follow those of <span class="co">[</span><span class="ot">@kunzel_metalearners_2019</span><span class="co">]</span> and <span class="co">[</span><span class="ot">@nie_quasi-oracle_2021</span><span class="co">]</span>.</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>:::{.callout-important}</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a><span class="fu">## What you will learn</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb46-12"><a href="#cb46-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-13"><a href="#cb46-13" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key points</span></span>
<span id="cb46-14"><a href="#cb46-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-15"><a href="#cb46-15" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>R-learner is the same as DML approaches by @Chernozhukov2018 except that it estimates CATE eat the second stag instead of ATE.</span>
<span id="cb46-16"><a href="#cb46-16" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>In many practical cases, R-learner performs better than S-, X-, and T-learners. </span>
<span id="cb46-17"><a href="#cb46-17" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>S- and T-learners are especially undesirable due to its tendency to underestimate CATE</span>
<span id="cb46-18"><a href="#cb46-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-19"><a href="#cb46-19" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-20"><a href="#cb46-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-21"><a href="#cb46-21" aria-hidden="true" tabindex="-1"></a><span class="fu">## Motivation</span></span>
<span id="cb46-22"><a href="#cb46-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-23"><a href="#cb46-23" aria-hidden="true" tabindex="-1"></a>In @sec-dml, the basic idea of double machine learning (DML) methods was introduced when the treatment effect is homogeneous. We now turn our focus to the task of estimating heterogeneous treatment effects: the impact of a treatment varies based on observed attributes of the subjects. Heterogeneous treatment effect is also referred to as <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> conditional <span class="kw">&lt;/span&gt;</span> average treatment effect (CATE).</span>
<span id="cb46-24"><a href="#cb46-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-25"><a href="#cb46-25" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-26"><a href="#cb46-26" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Conditional <span class="kw">&lt;/span&gt;</span> on observed attributes.</span>
<span id="cb46-27"><a href="#cb46-27" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-28"><a href="#cb46-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-29"><a href="#cb46-29" aria-hidden="true" tabindex="-1"></a>Understanding how treatment effects vary can be highly valuable in many circumstances. </span>
<span id="cb46-30"><a href="#cb46-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-31"><a href="#cb46-31" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Example 1: <span class="kw">&lt;/span&gt;</span></span>
<span id="cb46-32"><a href="#cb46-32" aria-hidden="true" tabindex="-1"></a>If we come to know a particular drug is effective on elderly people but detrimental to kids, then doctors can make a smart decision of prescribing the drug to elderly people, but not to kids. </span>
<span id="cb46-33"><a href="#cb46-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-34"><a href="#cb46-34" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-35"><a href="#cb46-35" aria-hidden="true" tabindex="-1"></a>In this example, the heterogeneity driver is age.</span>
<span id="cb46-36"><a href="#cb46-36" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-37"><a href="#cb46-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-38"><a href="#cb46-38" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> Example 2: <span class="kw">&lt;/span&gt;</span></span>
<span id="cb46-39"><a href="#cb46-39" aria-hidden="true" tabindex="-1"></a>If we come to know that fertilizer is more effective in increasing corn yield in soil type A than B, then farmers can apply more fertilizer on the parts of the field where soil type is A but less on where soil type is B. </span>
<span id="cb46-40"><a href="#cb46-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-41"><a href="#cb46-41" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-42"><a href="#cb46-42" aria-hidden="true" tabindex="-1"></a>In this example, the heterogeneity driver is soil type.</span>
<span id="cb46-43"><a href="#cb46-43" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-44"><a href="#cb46-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-45"><a href="#cb46-45" aria-hidden="true" tabindex="-1"></a>As you can see in these examples, knowledge on the heterogeneity of the treatment effect and its drivers can help decision makers smart-target treatments and policies. </span>
<span id="cb46-46"><a href="#cb46-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-47"><a href="#cb46-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## Modeling Framework</span></span>
<span id="cb46-48"><a href="#cb46-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-49"><a href="#cb46-49" aria-hidden="true" tabindex="-1"></a>The model of interest in general form is as follows:</span>
<span id="cb46-50"><a href="#cb46-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-51"><a href="#cb46-51" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-52"><a href="#cb46-52" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-53"><a href="#cb46-53" aria-hidden="true" tabindex="-1"></a>Y_i &amp; = \theta(X_i)\cdot T_i + g(X_i, W_i) + \varepsilon_i <span class="sc">\\</span></span>
<span id="cb46-54"><a href="#cb46-54" aria-hidden="true" tabindex="-1"></a>T_i &amp; = f(X_i, W_i) + \eta_i </span>
<span id="cb46-55"><a href="#cb46-55" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-56"><a href="#cb46-56" aria-hidden="true" tabindex="-1"></a>$$ {#eq-model-framework}</span>
<span id="cb46-57"><a href="#cb46-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-58"><a href="#cb46-58" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$Y$: dependent variable</span>
<span id="cb46-59"><a href="#cb46-59" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$T$: treatment variable</span>
<span id="cb46-60"><a href="#cb46-60" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$X$: collection of variables that affect Y indirectly through the treatment ($\theta(X)\cdot T$) and directly ($g(X, W)$) independent of the treatment</span>
<span id="cb46-61"><a href="#cb46-61" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$W$: collection of variables that affect directly ($g(X, W)$) independent of the treatment, but not through the treatment</span>
<span id="cb46-62"><a href="#cb46-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-63"><a href="#cb46-63" aria-hidden="true" tabindex="-1"></a>Here are the assumptions:</span>
<span id="cb46-64"><a href="#cb46-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-65"><a href="#cb46-65" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\varepsilon|X, W</span><span class="co">]</span> = 0$</span>
<span id="cb46-66"><a href="#cb46-66" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta|X, W</span><span class="co">]</span> = 0$</span>
<span id="cb46-67"><a href="#cb46-67" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$E<span class="co">[</span><span class="ot">\eta\cdot\varepsilon|X, W</span><span class="co">]</span> = 0$</span>
<span id="cb46-68"><a href="#cb46-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-69"><a href="#cb46-69" aria-hidden="true" tabindex="-1"></a>For the notational convenicence, let $\mu_1(X)$ and $\mu_0(X)$ denote the expected value of the potential conditional outcomes:</span>
<span id="cb46-70"><a href="#cb46-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-71"><a href="#cb46-71" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-72"><a href="#cb46-72" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb46-73"><a href="#cb46-73" aria-hidden="true" tabindex="-1"></a>\mu_1(X) &amp; = E<span class="co">[</span><span class="ot">Y|W=1, X</span><span class="co">]</span> = g(X, W)<span class="sc">\\</span> </span>
<span id="cb46-74"><a href="#cb46-74" aria-hidden="true" tabindex="-1"></a>\mu_0(X) &amp; = E<span class="co">[</span><span class="ot">Y|W=0, X</span><span class="co">]</span> =  \theta(X) + g(X, W)</span>
<span id="cb46-75"><a href="#cb46-75" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb46-76"><a href="#cb46-76" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-77"><a href="#cb46-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-78"><a href="#cb46-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-79"><a href="#cb46-79" aria-hidden="true" tabindex="-1"></a><span class="fu">## S-, T-, and X-Learner</span></span>
<span id="cb46-80"><a href="#cb46-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-81"><a href="#cb46-81" aria-hidden="true" tabindex="-1"></a><span class="fu">### S-learner</span></span>
<span id="cb46-82"><a href="#cb46-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-83"><a href="#cb46-83" aria-hidden="true" tabindex="-1"></a>S-learner estimates CATE by taking the following steps:</span>
<span id="cb46-84"><a href="#cb46-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-85"><a href="#cb46-85" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Regress $Y$ on $W$ and $X$ to estimate $E<span class="co">[</span><span class="ot">Y|W,X</span><span class="co">]</span>$ using any appropriate ML regression methods and call it $\hat{\mu}(W,X)$.</span>
<span id="cb46-86"><a href="#cb46-86" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Estimate $\hat{\theta}(X)$ as $\hat{\mu}(W=1,X)-\hat{\mu}(W=0,X)$</span>
<span id="cb46-87"><a href="#cb46-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-88"><a href="#cb46-88" aria-hidden="true" tabindex="-1"></a>In this approach, no special treatment is given to $W$. It is just a covariate along with others ($X$). This approach is named S-learner by @kunzel_metalearners_2019 because it involves estimating a <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:red'</span><span class="kw">&gt;</span>s<span class="kw">&lt;/span&gt;</span>ingle response function.</span>
<span id="cb46-89"><a href="#cb46-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-90"><a href="#cb46-90" aria-hidden="true" tabindex="-1"></a><span class="fu">### T-learner</span></span>
<span id="cb46-91"><a href="#cb46-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-92"><a href="#cb46-92" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Regress $Y$ on $W$ and $X$ using the treated observations to estimate $\mu_1(X)$ using any appropriate ML regression methods.</span>
<span id="cb46-93"><a href="#cb46-93" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Regress $Y$ on $W$ and $X$ using the control  observations to estimate $\mu_0(X)$ using any appropriate ML regression methods.</span>
<span id="cb46-94"><a href="#cb46-94" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>Estimate $\hat{\theta}(X)$ as $\hat{\mu}_1(X)-\hat{\mu}(X)$</span>
<span id="cb46-95"><a href="#cb46-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-96"><a href="#cb46-96" aria-hidden="true" tabindex="-1"></a>This approach is named T-learner by @kunzel_metalearners_2019 because it involves estimating <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">'color:red'</span><span class="kw">&gt;</span>t<span class="kw">&lt;/span&gt;</span>wo functions.</span>
<span id="cb46-97"><a href="#cb46-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-98"><a href="#cb46-98" aria-hidden="true" tabindex="-1"></a><span class="fu">### X-learner</span></span>
<span id="cb46-99"><a href="#cb46-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-100"><a href="#cb46-100" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>Estimate $\mu_1(X)$ and $\mu_0(X)$ using any appropriate ML regression methods. (Steps 1 and 2 of the T-learner)</span>
<span id="cb46-101"><a href="#cb46-101" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>Impute individual treatment effect for the treated and control groups as follows</span>
<span id="cb46-102"><a href="#cb46-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-103"><a href="#cb46-103" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-104"><a href="#cb46-104" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb46-105"><a href="#cb46-105" aria-hidden="true" tabindex="-1"></a>\tilde{D}_i^1(X_i) = Y^1_i - \hat{\mu}_0(X_i)<span class="sc">\\</span></span>
<span id="cb46-106"><a href="#cb46-106" aria-hidden="true" tabindex="-1"></a>\tilde{D}_i^0(X_i) =  \hat{\mu}_1(X_i) - Y^0_i </span>
<span id="cb46-107"><a href="#cb46-107" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb46-108"><a href="#cb46-108" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb46-109"><a href="#cb46-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-110"><a href="#cb46-110" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-111"><a href="#cb46-111" aria-hidden="true" tabindex="-1"></a>This is similar to cross-fitting we saw in @sec-dml, where the folds are the treated and control groups.</span>
<span id="cb46-112"><a href="#cb46-112" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-113"><a href="#cb46-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-114"><a href="#cb46-114" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span></span>
<span id="cb46-115"><a href="#cb46-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-116"><a href="#cb46-116" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Regress $\tilde{D}_i^1(X_i)$ on $X$ using the observations in the treated group and denote the predicted value as $\hat{\theta}_1(X)$</span>
<span id="cb46-117"><a href="#cb46-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-118"><a href="#cb46-118" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>Regress $\tilde{D}_i^0(X_i)$ on $X$ using the observations in the control group and denote the predicted value as $\hat{\theta}_0(X)$</span>
<span id="cb46-119"><a href="#cb46-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-120"><a href="#cb46-120" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>Calculate $\hat{\theta}(X)$ as their weighted average</span>
<span id="cb46-121"><a href="#cb46-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-122"><a href="#cb46-122" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-123"><a href="#cb46-123" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb46-124"><a href="#cb46-124" aria-hidden="true" tabindex="-1"></a>\hat{\theta}(X) = g(X)\cdot\hat{\theta}_0(X) + [1-g(X)]\cdot\hat{\theta}_1(X)</span>
<span id="cb46-125"><a href="#cb46-125" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb46-126"><a href="#cb46-126" aria-hidden="true" tabindex="-1"></a>$$ {#eq-final-X}</span>
<span id="cb46-127"><a href="#cb46-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-128"><a href="#cb46-128" aria-hidden="true" tabindex="-1"></a>Any value of $g(X)$ is acceptable. One option of $g(X)$ may be the estimated propensity score $E<span class="co">[</span><span class="ot">W|X</span><span class="co">]</span>$.</span>
<span id="cb46-129"><a href="#cb46-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-130"><a href="#cb46-130" aria-hidden="true" tabindex="-1"></a><span class="fu">## T-learner v.s. X-learner</span></span>
<span id="cb46-131"><a href="#cb46-131" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-132"><a href="#cb46-132" aria-hidden="true" tabindex="-1"></a>Here, an advantage of X-learner over T-learner is demonstrated. This example also serves as an illustration of how these learners are implemented. Specifically, X-learner can be advantageous when the control-treatment assignments in the sample are unbalanced. For example, it is often the case that there are plenty of observations in the control group, while there are not many treated observations. For the purpose of illustration, consider a rather extreme case where there are only 10 observations in the treated group, while there are 300 observations in the control group. We use the following toy data generating process:</span>
<span id="cb46-133"><a href="#cb46-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-134"><a href="#cb46-134" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-135"><a href="#cb46-135" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb46-136"><a href="#cb46-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-139"><a href="#cb46-139" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-140"><a href="#cb46-140" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb46-141"><a href="#cb46-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-142"><a href="#cb46-142" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb46-143"><a href="#cb46-143" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb46-144"><a href="#cb46-144" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb46-145"><a href="#cb46-145" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb46-146"><a href="#cb46-146" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb46-147"><a href="#cb46-147" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb46-148"><a href="#cb46-148" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb46-149"><a href="#cb46-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-150"><a href="#cb46-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-153"><a href="#cb46-153" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-154"><a href="#cb46-154" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-155"><a href="#cb46-155" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb46-156"><a href="#cb46-156" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb46-157"><a href="#cb46-157" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ranger)</span>
<span id="cb46-158"><a href="#cb46-158" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb46-159"><a href="#cb46-159" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mgcv)</span>
<span id="cb46-160"><a href="#cb46-160" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rsample)</span>
<span id="cb46-161"><a href="#cb46-161" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(xgboost)</span>
<span id="cb46-162"><a href="#cb46-162" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-163"><a href="#cb46-163" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-164"><a href="#cb46-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-165"><a href="#cb46-165" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-166"><a href="#cb46-166" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb46-167"><a href="#cb46-167" aria-hidden="true" tabindex="-1"></a>y = \tau W + |x| + v</span>
<span id="cb46-168"><a href="#cb46-168" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb46-169"><a href="#cb46-169" aria-hidden="true" tabindex="-1"></a>$$ </span>
<span id="cb46-170"><a href="#cb46-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-171"><a href="#cb46-171" aria-hidden="true" tabindex="-1"></a>where $\tau = 1$. So, the treatment effect is not heterogeneous. For the purpose of illustrating the advantage of X-learner over T-learner, it is convenient if the underlying model is simpler.</span>
<span id="cb46-172"><a href="#cb46-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-175"><a href="#cb46-175" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-176"><a href="#cb46-176" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4345</span>)</span>
<span id="cb46-177"><a href="#cb46-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-178"><a href="#cb46-178" aria-hidden="true" tabindex="-1"></a>N_trt <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb46-179"><a href="#cb46-179" aria-hidden="true" tabindex="-1"></a>N_ctrl <span class="ot">&lt;-</span> <span class="dv">300</span></span>
<span id="cb46-180"><a href="#cb46-180" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> N_trt <span class="sc">+</span> N_ctrl</span>
<span id="cb46-181"><a href="#cb46-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-182"><a href="#cb46-182" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> </span>
<span id="cb46-183"><a href="#cb46-183" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb46-184"><a href="#cb46-184" aria-hidden="true" tabindex="-1"></a>    <span class="at">W =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,N_trt), <span class="fu">rep</span>(<span class="dv">0</span>, N_ctrl)),</span>
<span id="cb46-185"><a href="#cb46-185" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Treated"</span>, N_trt), <span class="fu">rep</span>(<span class="st">"Control"</span>, N_ctrl)),</span>
<span id="cb46-186"><a href="#cb46-186" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">runif</span>(N)<span class="sc">-</span><span class="dv">1</span>,</span>
<span id="cb46-187"><a href="#cb46-187" aria-hidden="true" tabindex="-1"></a>    <span class="at">v =</span> <span class="fu">rnorm</span>(N) <span class="sc">/</span> <span class="dv">2</span></span>
<span id="cb46-188"><a href="#cb46-188" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-189"><a href="#cb46-189" aria-hidden="true" tabindex="-1"></a>  .[, y <span class="sc">:</span><span class="er">=</span> W <span class="sc">+</span> <span class="fu">abs</span>(x) <span class="sc">+</span> v]</span>
<span id="cb46-190"><a href="#cb46-190" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-191"><a href="#cb46-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-194"><a href="#cb46-194" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-195"><a href="#cb46-195" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> data) <span class="sc">+</span></span>
<span id="cb46-196"><a href="#cb46-196" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> y, <span class="at">x =</span> x, <span class="at">color =</span> type)) <span class="sc">+</span></span>
<span id="cb46-197"><a href="#cb46-197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb46-198"><a href="#cb46-198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-199"><a href="#cb46-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-200"><a href="#cb46-200" aria-hidden="true" tabindex="-1"></a>Let's first estimate $\mu_1(X)$ and $\mu_0(X)$ (Step 1). Since we have only $<span class="in">`r N_trt`</span>$ observations in the treated group, we will use a linear regression to avoid over-fitting (following the example in @kunzel_metalearners_2019).</span>
<span id="cb46-201"><a href="#cb46-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-204"><a href="#cb46-204" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-205"><a href="#cb46-205" aria-hidden="true" tabindex="-1"></a>mu_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb46-206"><a href="#cb46-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-207"><a href="#cb46-207" aria-hidden="true" tabindex="-1"></a>mu_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(y <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb46-208"><a href="#cb46-208" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-209"><a href="#cb46-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-210"><a href="#cb46-210" aria-hidden="true" tabindex="-1"></a>Now that  $\mu_1(X)$ and $\mu_0(X)$ are estimated, we can estimate $\hat{\theta}(X)$ by T-learner.</span>
<span id="cb46-211"><a href="#cb46-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-214"><a href="#cb46-214" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-215"><a href="#cb46-215" aria-hidden="true" tabindex="-1"></a>x_seq <span class="ot">&lt;-</span> <span class="fu">data.table</span>(<span class="at">x =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="at">length =</span> <span class="dv">100</span>))</span>
<span id="cb46-216"><a href="#cb46-216" aria-hidden="true" tabindex="-1"></a><span class="co">#=== T-learner ===#</span></span>
<span id="cb46-217"><a href="#cb46-217" aria-hidden="true" tabindex="-1"></a>tau_hat_data <span class="ot">&lt;-</span> </span>
<span id="cb46-218"><a href="#cb46-218" aria-hidden="true" tabindex="-1"></a>  x_seq <span class="sc">%&gt;%</span></span>
<span id="cb46-219"><a href="#cb46-219" aria-hidden="true" tabindex="-1"></a>  .[, mu_1_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb46-220"><a href="#cb46-220" aria-hidden="true" tabindex="-1"></a>  .[, mu_0_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> x_seq)] <span class="sc">%&gt;%</span></span>
<span id="cb46-221"><a href="#cb46-221" aria-hidden="true" tabindex="-1"></a>  .[, tau_hat_T <span class="sc">:</span><span class="er">=</span> mu_1_hat <span class="sc">-</span> mu_0_hat]</span>
<span id="cb46-222"><a href="#cb46-222" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-223"><a href="#cb46-223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-224"><a href="#cb46-224" aria-hidden="true" tabindex="-1"></a>As you can see, T-learner is heavily biased. This is because of the unreliable estimation of $\mu_1(X)$ due to lack of observations in the treated group.</span>
<span id="cb46-225"><a href="#cb46-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-228"><a href="#cb46-228" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-229"><a href="#cb46-229" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-230"><a href="#cb46-230" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-231"><a href="#cb46-231" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb46-232"><a href="#cb46-232" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb46-233"><a href="#cb46-233" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb46-234"><a href="#cb46-234" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-235"><a href="#cb46-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-236"><a href="#cb46-236" aria-hidden="true" tabindex="-1"></a>Now, let's move on to X-learner. We impute individual treatment effects (Step 2).</span>
<span id="cb46-237"><a href="#cb46-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-240"><a href="#cb46-240" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-241"><a href="#cb46-241" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (treated) ===#</span></span>
<span id="cb46-242"><a href="#cb46-242" aria-hidden="true" tabindex="-1"></a>mu_hat_1 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_0_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb46-243"><a href="#cb46-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-244"><a href="#cb46-244" aria-hidden="true" tabindex="-1"></a><span class="co">#=== mu (control) ===#</span></span>
<span id="cb46-245"><a href="#cb46-245" aria-hidden="true" tabindex="-1"></a>mu_hat_0 <span class="ot">&lt;-</span> <span class="fu">predict</span>(mu_1_trained, <span class="at">newdata =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb46-246"><a href="#cb46-246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-247"><a href="#cb46-247" aria-hidden="true" tabindex="-1"></a><span class="co">#=== assign the values ===#</span></span>
<span id="cb46-248"><a href="#cb46-248" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Treated"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_1]</span>
<span id="cb46-249"><a href="#cb46-249" aria-hidden="true" tabindex="-1"></a>data[type <span class="sc">==</span> <span class="st">"Control"</span>, mu_hat <span class="sc">:</span><span class="er">=</span> mu_hat_0]</span>
<span id="cb46-250"><a href="#cb46-250" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-251"><a href="#cb46-251" aria-hidden="true" tabindex="-1"></a><span class="co">#=== find individual TE ===#</span></span>
<span id="cb46-252"><a href="#cb46-252" aria-hidden="true" tabindex="-1"></a>data[, D <span class="sc">:</span><span class="er">=</span> <span class="fu">ifelse</span>(type <span class="sc">==</span> <span class="st">"Treated"</span>, y <span class="sc">-</span> mu_hat, mu_hat <span class="sc">-</span> y)]</span>
<span id="cb46-253"><a href="#cb46-253" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-254"><a href="#cb46-254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-255"><a href="#cb46-255" aria-hidden="true" tabindex="-1"></a>We can now regress $D$ on $X$ (Step 3),</span>
<span id="cb46-256"><a href="#cb46-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-259"><a href="#cb46-259" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-260"><a href="#cb46-260" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-261"><a href="#cb46-261" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (treated)</span></span>
<span id="cb46-262"><a href="#cb46-262" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-263"><a href="#cb46-263" aria-hidden="true" tabindex="-1"></a>tau_1_trained <span class="ot">&lt;-</span> <span class="fu">lm</span>(D <span class="sc">~</span> x, <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Treated"</span>, ])</span>
<span id="cb46-264"><a href="#cb46-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-265"><a href="#cb46-265" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb46-266"><a href="#cb46-266" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_1 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_1_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb46-267"><a href="#cb46-267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-268"><a href="#cb46-268" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-269"><a href="#cb46-269" aria-hidden="true" tabindex="-1"></a><span class="co"># tau (control)</span></span>
<span id="cb46-270"><a href="#cb46-270" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-271"><a href="#cb46-271" aria-hidden="true" tabindex="-1"></a>tau_0_trained <span class="ot">&lt;-</span> <span class="fu">gam</span>(D <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), <span class="at">data =</span> data[type <span class="sc">==</span> <span class="st">"Control"</span>, ])</span>
<span id="cb46-272"><a href="#cb46-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-273"><a href="#cb46-273" aria-hidden="true" tabindex="-1"></a><span class="co">#=== estimate tau_1 ===#</span></span>
<span id="cb46-274"><a href="#cb46-274" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_0 <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(tau_0_trained, <span class="at">newdata =</span> tau_hat_data)]</span>
<span id="cb46-275"><a href="#cb46-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-276"><a href="#cb46-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-279"><a href="#cb46-279" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-280"><a href="#cb46-280" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-281"><a href="#cb46-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-282"><a href="#cb46-282" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb46-283"><a href="#cb46-283" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_1, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Treated"</span>)) <span class="sc">+</span></span>
<span id="cb46-284"><a href="#cb46-284" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_0, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"Control"</span>)) <span class="sc">+</span></span>
<span id="cb46-285"><a href="#cb46-285" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Treated"</span> <span class="ot">=</span> <span class="st">"blue"</span>, <span class="st">"Control"</span> <span class="ot">=</span> <span class="st">"red"</span>)) <span class="sc">+</span></span>
<span id="cb46-286"><a href="#cb46-286" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb46-287"><a href="#cb46-287" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-288"><a href="#cb46-288" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-289"><a href="#cb46-289" aria-hidden="true" tabindex="-1"></a>Let's use propensity score as $g(X)$ in Step 4.</span>
<span id="cb46-290"><a href="#cb46-290" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-293"><a href="#cb46-293" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-294"><a href="#cb46-294" aria-hidden="true" tabindex="-1"></a>w_gam_trained <span class="ot">&lt;-</span> </span>
<span id="cb46-295"><a href="#cb46-295" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gam</span>(</span>
<span id="cb46-296"><a href="#cb46-296" aria-hidden="true" tabindex="-1"></a>    W <span class="sc">~</span> <span class="fu">s</span>(x, <span class="at">k =</span> <span class="dv">4</span>), </span>
<span id="cb46-297"><a href="#cb46-297" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data, </span>
<span id="cb46-298"><a href="#cb46-298" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> <span class="st">"probit"</span>)</span>
<span id="cb46-299"><a href="#cb46-299" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-300"><a href="#cb46-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-301"><a href="#cb46-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-302"><a href="#cb46-302" aria-hidden="true" tabindex="-1"></a>Let's predict $E<span class="co">[</span><span class="ot">W|X</span><span class="co">]</span>$ at each value of $X$ at which we are estiamting $\tau$. </span>
<span id="cb46-303"><a href="#cb46-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-306"><a href="#cb46-306" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-307"><a href="#cb46-307" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, g_x <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(w_gam_trained, <span class="at">newdata =</span> tau_hat_data, <span class="at">type =</span> <span class="st">"response"</span>)]</span>
<span id="cb46-308"><a href="#cb46-308" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-309"><a href="#cb46-309" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-310"><a href="#cb46-310" aria-hidden="true" tabindex="-1"></a>As you can see below, the mean value of $g(x)$ is small because the treatment probability is very low (it is only $<span class="in">`r N_trt`</span>$ out of $<span class="in">`r N`</span>$).</span>
<span id="cb46-311"><a href="#cb46-311" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-314"><a href="#cb46-314" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-315"><a href="#cb46-315" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(tau_hat_data[, g_x])</span>
<span id="cb46-316"><a href="#cb46-316" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-317"><a href="#cb46-317" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-318"><a href="#cb46-318" aria-hidden="true" tabindex="-1"></a>This number is basically $<span class="in">`r N_trt`</span>/320$. So, in this example, we could have just used the proportion of the treated observations. Notice that $g(X)$ is multiplied to $\hat{\theta}_0(X)$ in @eq-final-X. So, we are giving a lower weight to $\hat{\theta}_0(X)$. This is because $\hat{\theta}_0(X)$ is less reliable because $\hat{\mu}_1(X)$ is less reliable due to the lack of samples in the treated group. </span>
<span id="cb46-319"><a href="#cb46-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-322"><a href="#cb46-322" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-323"><a href="#cb46-323" aria-hidden="true" tabindex="-1"></a>tau_hat_data[, tau_hat_X <span class="sc">:</span><span class="er">=</span> g_x <span class="sc">*</span> tau_hat_0 <span class="sc">+</span> (<span class="dv">1</span><span class="sc">-</span>g_x) <span class="sc">*</span> tau_hat_1]</span>
<span id="cb46-324"><a href="#cb46-324" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-325"><a href="#cb46-325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-326"><a href="#cb46-326" aria-hidden="true" tabindex="-1"></a>As you can see, X-learner outperforms T-learner in this particular instance at least in terms of point estimates of $\tau(X)$. </span>
<span id="cb46-327"><a href="#cb46-327" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-330"><a href="#cb46-330" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-331"><a href="#cb46-331" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb46-332"><a href="#cb46-332" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-333"><a href="#cb46-333" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> tau_hat_data) <span class="sc">+</span></span>
<span id="cb46-334"><a href="#cb46-334" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_T, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"T-learner"</span>)) <span class="sc">+</span></span>
<span id="cb46-335"><a href="#cb46-335" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> tau_hat_X, <span class="at">x =</span> x, <span class="at">color =</span> <span class="st">"X-learner"</span>)) <span class="sc">+</span></span>
<span id="cb46-336"><a href="#cb46-336" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">1</span>, <span class="fu">aes</span>(<span class="at">color =</span> <span class="st">"True Treatment Effect"</span>)) <span class="sc">+</span></span>
<span id="cb46-337"><a href="#cb46-337" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb46-338"><a href="#cb46-338" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(</span>
<span id="cb46-339"><a href="#cb46-339" aria-hidden="true" tabindex="-1"></a>        <span class="st">"T-learner"</span> <span class="ot">=</span> <span class="st">"red"</span>, </span>
<span id="cb46-340"><a href="#cb46-340" aria-hidden="true" tabindex="-1"></a>        <span class="st">"X-learner"</span> <span class="ot">=</span> <span class="st">"blue"</span>, </span>
<span id="cb46-341"><a href="#cb46-341" aria-hidden="true" tabindex="-1"></a>        <span class="st">"True Treatment Effect"</span> <span class="ot">=</span> <span class="st">"black"</span></span>
<span id="cb46-342"><a href="#cb46-342" aria-hidden="true" tabindex="-1"></a>      ),</span>
<span id="cb46-343"><a href="#cb46-343" aria-hidden="true" tabindex="-1"></a>    <span class="at">name =</span> <span class="st">""</span></span>
<span id="cb46-344"><a href="#cb46-344" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">+</span></span>
<span id="cb46-345"><a href="#cb46-345" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ylab</span>(<span class="st">"Treatment Effect"</span>) <span class="sc">+</span></span>
<span id="cb46-346"><a href="#cb46-346" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb46-347"><a href="#cb46-347" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb46-348"><a href="#cb46-348" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-349"><a href="#cb46-349" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-350"><a href="#cb46-350" aria-hidden="true" tabindex="-1"></a><span class="fu">## R-learner {#sec-r-learner}</span></span>
<span id="cb46-351"><a href="#cb46-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-352"><a href="#cb46-352" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theoretical background</span></span>
<span id="cb46-353"><a href="#cb46-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-354"><a href="#cb46-354" aria-hidden="true" tabindex="-1"></a>Under the assumptions,</span>
<span id="cb46-355"><a href="#cb46-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-356"><a href="#cb46-356" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-357"><a href="#cb46-357" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-358"><a href="#cb46-358" aria-hidden="true" tabindex="-1"></a>E<span class="co">[</span><span class="ot">Y|X, W</span><span class="co">]</span> = \theta(X)\cdot f(X,W) + g(X,W)</span>
<span id="cb46-359"><a href="#cb46-359" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-360"><a href="#cb46-360" aria-hidden="true" tabindex="-1"></a>$$ {#eq-yxw}</span>
<span id="cb46-361"><a href="#cb46-361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-362"><a href="#cb46-362" aria-hidden="true" tabindex="-1"></a>:::{.column-margin}</span>
<span id="cb46-363"><a href="#cb46-363" aria-hidden="true" tabindex="-1"></a>$f(X,W) = E<span class="co">[</span><span class="ot">T|X,W</span><span class="co">]</span>$ </span>
<span id="cb46-364"><a href="#cb46-364" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-365"><a href="#cb46-365" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-366"><a href="#cb46-366" aria-hidden="true" tabindex="-1"></a>Let, $l(X,W)$ denote $E<span class="co">[</span><span class="ot">Y|X, W</span><span class="co">]</span>$. Taking the difference of @eq-model-framework and @eq-yxw on both sides,</span>
<span id="cb46-367"><a href="#cb46-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-368"><a href="#cb46-368" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-369"><a href="#cb46-369" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-370"><a href="#cb46-370" aria-hidden="true" tabindex="-1"></a>Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot T_i + g(X_i,W_i) + \varepsilon_i - <span class="co">[</span><span class="ot">\theta(X_i)\cdot f(X_i,W_i) + g(X_i,W_i)</span><span class="co">]</span> <span class="sc">\\</span></span>
<span id="cb46-371"><a href="#cb46-371" aria-hidden="true" tabindex="-1"></a>\Rightarrow Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i <span class="sc">\\</span></span>
<span id="cb46-372"><a href="#cb46-372" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-373"><a href="#cb46-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-374"><a href="#cb46-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-375"><a href="#cb46-375" aria-hidden="true" tabindex="-1"></a>:::{.column-margin}</span>
<span id="cb46-376"><a href="#cb46-376" aria-hidden="true" tabindex="-1"></a>This is akin to residualization/orthogonalization seen in the DML approach in @sec-dml.</span>
<span id="cb46-377"><a href="#cb46-377" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-378"><a href="#cb46-378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-379"><a href="#cb46-379" aria-hidden="true" tabindex="-1"></a>So, the problem of identifying $\theta(X)$ reduces to estimating the following model:</span>
<span id="cb46-380"><a href="#cb46-380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-381"><a href="#cb46-381" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-382"><a href="#cb46-382" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-383"><a href="#cb46-383" aria-hidden="true" tabindex="-1"></a>Y_i - l(X_i,W_i) &amp; = \theta(X_i)\cdot (T_i -f(X_i,W_i)) + \varepsilon_i</span>
<span id="cb46-384"><a href="#cb46-384" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-385"><a href="#cb46-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-386"><a href="#cb46-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-387"><a href="#cb46-387" aria-hidden="true" tabindex="-1"></a>Since $E<span class="co">[</span><span class="ot">(T_i -f(X_i,W_i))\cdot\varepsilon_i|X</span><span class="co">]</span> = E<span class="co">[</span><span class="ot">\eta_i\cdot\varepsilon_i|X</span><span class="co">]</span> = 0$ by assumption, we can regress $Y_i - l(X_i,W_i)$ on $X_i$ and $T_i -f(X_i,W_i)$ to estimate $\theta(X)$. Specifically, we can minimize the following objective function:</span>
<span id="cb46-388"><a href="#cb46-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-389"><a href="#cb46-389" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-390"><a href="#cb46-390" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-391"><a href="#cb46-391" aria-hidden="true" tabindex="-1"></a>Min_{\theta(X)}\sum_{i=1}^N \large(\normalsize<span class="co">[</span><span class="ot">Y_i - l(X_i,W_i)</span><span class="co">]</span> - <span class="co">[</span><span class="ot">\theta(X_i)\cdot (T_i -f(X_i,W_i))</span><span class="co">]</span>\large)^2 </span>
<span id="cb46-392"><a href="#cb46-392" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-393"><a href="#cb46-393" aria-hidden="true" tabindex="-1"></a>$$ {#eq-est-equation}</span>
<span id="cb46-394"><a href="#cb46-394" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-395"><a href="#cb46-395" aria-hidden="true" tabindex="-1"></a><span class="fu">### Estimation steps {#sec-est-steps}</span></span>
<span id="cb46-396"><a href="#cb46-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-397"><a href="#cb46-397" aria-hidden="true" tabindex="-1"></a>In practice, we of course do not observe $l(X,W)$ and $f(X,W)$. So, we first need to estimate them using the data at hand and then subtract them from $Y_i$ and $T_i$, respectively. You can use any suitable statistical methods to estimate $l(X, W)$ and $f(X,W)$. Some machine learning methods allow you to estimate them without assuming any functional form or structural assumptions. If you believe they are linear functions of $X$ and $W$, you could alternatively use lasso or other linear models. @nie_quasi-oracle_2021 proposes that the estimation of $l(X,W)$ and $f(X,W)$ is done by cross-fitting (see @sec-cf) to avoid over-fitting bias. Let $I_{-i}$ denote all the observations that belong to the folds that $i$ does <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> not <span class="kw">&lt;/span&gt;</span> belong to. Further, let $\hat{l}(X_i, W_i)^{I_{-i}}$ and $\hat{f}(X_i, W_i)^{I_{-i}}$ denote $l(X_i, W_i)$ and $f(X_i, W_i)$ estimated using $I_{-i}$. </span>
<span id="cb46-398"><a href="#cb46-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-399"><a href="#cb46-399" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-400"><a href="#cb46-400" aria-hidden="true" tabindex="-1"></a>Just like the DML approach discussed in @sec-dml, both $Y$ and $T$ are orthogonalized.</span>
<span id="cb46-401"><a href="#cb46-401" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-402"><a href="#cb46-402" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-403"><a href="#cb46-403" aria-hidden="true" tabindex="-1"></a>Then the quality of fit (explaining the heterogeneity in the impact of treatment) can be expressed as follows, which is the empirical version of @eq-est-equation:</span>
<span id="cb46-404"><a href="#cb46-404" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-405"><a href="#cb46-405" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-406"><a href="#cb46-406" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-407"><a href="#cb46-407" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N <span class="co">[</span><span class="ot">Y_i - \hat{l}(X_i,W_i)^{I_{-i}} - \theta(X)\cdot (T_i - \hat{f}(X_i,W_i)^{I_{-i}})</span><span class="co">]</span>^2</span>
<span id="cb46-408"><a href="#cb46-408" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-409"><a href="#cb46-409" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-410"><a href="#cb46-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-411"><a href="#cb46-411" aria-hidden="true" tabindex="-1"></a>This is called <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span> R-score<span class="kw">&lt;/span&gt;</span>, and it can be used for causal model selection, which will be covered later. </span>
<span id="cb46-412"><a href="#cb46-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-413"><a href="#cb46-413" aria-hidden="true" tabindex="-1"></a>Let $\tilde{Y}_i$ and $\tilde{T}_i$ denote $Y_i - \hat{l}(X_i,W_i)^{I_{-i}}$ and $T_i - \hat{f}(X_i,W_i)^{I_{-i}}$, respectively. The final stage of the R-learner is to estimate $\theta(X)$ by minimizing the R-score plus the regularization term (if desirable).</span>
<span id="cb46-414"><a href="#cb46-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-415"><a href="#cb46-415" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-416"><a href="#cb46-416" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-417"><a href="#cb46-417" aria-hidden="true" tabindex="-1"></a>\hat{\theta}(X) = argmin_{\theta(X)}\;\;\sum_{i=1}^N <span class="co">[</span><span class="ot">\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i</span><span class="co">]</span>^2 + \Lambda(\theta(X))</span>
<span id="cb46-418"><a href="#cb46-418" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-419"><a href="#cb46-419" aria-hidden="true" tabindex="-1"></a>$$ {#eq-r-min}</span>
<span id="cb46-420"><a href="#cb46-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-421"><a href="#cb46-421" aria-hidden="true" tabindex="-1"></a>where $\Lambda(\theta(X))$ is the penalty on the complexity of $\theta(X)$. For example, if you choose to use lasso, then $\Lambda(\theta(X))$ is the L1 norm. You have lots of freedom as to what model you use in the final stage. The <span class="in">`econml`</span> package offers several off-the-shelf choices of R-learner (DML) approaches that differ in the model used at the final stage, including causal forest, lasso, etc.</span>
<span id="cb46-422"><a href="#cb46-422" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-423"><a href="#cb46-423" aria-hidden="true" tabindex="-1"></a><span class="fu">### R-learner by hand</span></span>
<span id="cb46-424"><a href="#cb46-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-425"><a href="#cb46-425" aria-hidden="true" tabindex="-1"></a>This section goes through the estimation steps provided above to further the understanding of how R-learner works using a synthetic dataset that follows the DGP below.</span>
<span id="cb46-426"><a href="#cb46-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-427"><a href="#cb46-427" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-428"><a href="#cb46-428" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-429"><a href="#cb46-429" aria-hidden="true" tabindex="-1"></a>Y_i &amp; = (x_{i,1} + x_{i,2}^2)\cdot T_i + \sqrt{x_{i,3}} + \mu_i <span class="sc">\\</span></span>
<span id="cb46-430"><a href="#cb46-430" aria-hidden="true" tabindex="-1"></a>T_i|X_i &amp; = Bernouli((1+x_{i,1})/2) <span class="sc">\\</span></span>
<span id="cb46-431"><a href="#cb46-431" aria-hidden="true" tabindex="-1"></a>\mu_i|X_i &amp; = N(0,1)</span>
<span id="cb46-432"><a href="#cb46-432" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-433"><a href="#cb46-433" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-434"><a href="#cb46-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-435"><a href="#cb46-435" aria-hidden="true" tabindex="-1"></a>Let's generate a dataset according to the DGP.</span>
<span id="cb46-436"><a href="#cb46-436" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-439"><a href="#cb46-439" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-440"><a href="#cb46-440" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">58734</span>)</span>
<span id="cb46-441"><a href="#cb46-441" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-442"><a href="#cb46-442" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb46-443"><a href="#cb46-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-444"><a href="#cb46-444" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-445"><a href="#cb46-445" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span></span>
<span id="cb46-446"><a href="#cb46-446" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb46-447"><a href="#cb46-447" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-448"><a href="#cb46-448" aria-hidden="true" tabindex="-1"></a>    <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-449"><a href="#cb46-449" aria-hidden="true" tabindex="-1"></a>    <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-450"><a href="#cb46-450" aria-hidden="true" tabindex="-1"></a>    <span class="at">mu =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb46-451"><a href="#cb46-451" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-452"><a href="#cb46-452" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">T :=</span> <span class="fu">runif</span>(N) <span class="sc">&lt;</span> ((<span class="fl">0.5</span><span class="sc">+</span>x1)<span class="sc">/</span><span class="dv">2</span>)] <span class="sc">%&gt;%</span> </span>
<span id="cb46-453"><a href="#cb46-453" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">Y :=</span> (x1 <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span>) <span class="sc">*</span> T <span class="sc">+</span> <span class="fu">sqrt</span>(x3) <span class="sc">+</span> mu] <span class="sc">%&gt;%</span> </span>
<span id="cb46-454"><a href="#cb46-454" aria-hidden="true" tabindex="-1"></a>  .[, <span class="at">id :=</span> <span class="dv">1</span><span class="sc">:</span>.N]</span>
<span id="cb46-455"><a href="#cb46-455" aria-hidden="true" tabindex="-1"></a>) </span>
<span id="cb46-456"><a href="#cb46-456" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-457"><a href="#cb46-457" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-458"><a href="#cb46-458" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb46-459"><a href="#cb46-459" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-460"><a href="#cb46-460" aria-hidden="true" tabindex="-1"></a>We first cross-fit $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ using random forest for both cases. We will use repeated (3 times) 5-fold cross-fitting. Resampling the data,</span>
<span id="cb46-461"><a href="#cb46-461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-464"><a href="#cb46-464" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-465"><a href="#cb46-465" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-466"><a href="#cb46-466" aria-hidden="true" tabindex="-1"></a>data_folds <span class="ot">&lt;-</span> rsample<span class="sc">::</span><span class="fu">vfold_cv</span>(data, <span class="at">v =</span> <span class="dv">5</span>, <span class="at">repeats =</span> <span class="dv">3</span>)</span>
<span id="cb46-467"><a href="#cb46-467" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-468"><a href="#cb46-468" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-469"><a href="#cb46-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-470"><a href="#cb46-470" aria-hidden="true" tabindex="-1"></a>The following function takes a row number (<span class="in">`n`</span>) and cross-fits $E<span class="co">[</span><span class="ot">Y|X</span><span class="co">]</span>$ and $E<span class="co">[</span><span class="ot">T|X</span><span class="co">]</span>$ for the training and test data split stored in the <span class="in">`n`</span>th row of <span class="in">`data_folds`</span>.</span>
<span id="cb46-471"><a href="#cb46-471" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-474"><a href="#cb46-474" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-475"><a href="#cb46-475" aria-hidden="true" tabindex="-1"></a>cross_fit <span class="ot">&lt;-</span> <span class="cf">function</span>(n, data_folds) </span>
<span id="cb46-476"><a href="#cb46-476" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb46-477"><a href="#cb46-477" aria-hidden="true" tabindex="-1"></a>  training_data <span class="ot">&lt;-</span> <span class="fu">analysis</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb46-478"><a href="#cb46-478" aria-hidden="true" tabindex="-1"></a>  eval_data <span class="ot">&lt;-</span> <span class="fu">assessment</span>(data_folds[n, ]<span class="sc">$</span>splits[[<span class="dv">1</span>]])</span>
<span id="cb46-479"><a href="#cb46-479" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-480"><a href="#cb46-480" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb46-481"><a href="#cb46-481" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[Y|X]</span></span>
<span id="cb46-482"><a href="#cb46-482" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb46-483"><a href="#cb46-483" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== train ===#</span></span>
<span id="cb46-484"><a href="#cb46-484" aria-hidden="true" tabindex="-1"></a>  rf_trained_y <span class="ot">&lt;-</span></span>
<span id="cb46-485"><a href="#cb46-485" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb46-486"><a href="#cb46-486" aria-hidden="true" tabindex="-1"></a>      Y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb46-487"><a href="#cb46-487" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data</span>
<span id="cb46-488"><a href="#cb46-488" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb46-489"><a href="#cb46-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-490"><a href="#cb46-490" aria-hidden="true" tabindex="-1"></a>  <span class="co">#=== fit ===#</span></span>
<span id="cb46-491"><a href="#cb46-491" aria-hidden="true" tabindex="-1"></a>  eval_data[, y_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_y, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions]</span>
<span id="cb46-492"><a href="#cb46-492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-493"><a href="#cb46-493" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb46-494"><a href="#cb46-494" aria-hidden="true" tabindex="-1"></a>  <span class="co"># E[T|X]</span></span>
<span id="cb46-495"><a href="#cb46-495" aria-hidden="true" tabindex="-1"></a>  <span class="co">#--------------------------</span></span>
<span id="cb46-496"><a href="#cb46-496" aria-hidden="true" tabindex="-1"></a>  rf_trained_t <span class="ot">&lt;-</span></span>
<span id="cb46-497"><a href="#cb46-497" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ranger</span>(</span>
<span id="cb46-498"><a href="#cb46-498" aria-hidden="true" tabindex="-1"></a>      T <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3,</span>
<span id="cb46-499"><a href="#cb46-499" aria-hidden="true" tabindex="-1"></a>      <span class="at">data =</span> training_data,</span>
<span id="cb46-500"><a href="#cb46-500" aria-hidden="true" tabindex="-1"></a>      <span class="at">probability =</span> <span class="cn">TRUE</span></span>
<span id="cb46-501"><a href="#cb46-501" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb46-502"><a href="#cb46-502" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-503"><a href="#cb46-503" aria-hidden="true" tabindex="-1"></a>  eval_data[, t_hat <span class="sc">:</span><span class="er">=</span> <span class="fu">predict</span>(rf_trained_t, <span class="at">data =</span> eval_data)<span class="sc">$</span>predictions[, <span class="dv">2</span>]]</span>
<span id="cb46-504"><a href="#cb46-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-505"><a href="#cb46-505" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(eval_data[, .(id, y_hat, t_hat)])</span>
<span id="cb46-506"><a href="#cb46-506" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-507"><a href="#cb46-507" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-508"><a href="#cb46-508" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-509"><a href="#cb46-509" aria-hidden="true" tabindex="-1"></a>Here is what the output of the function for the first split looks like.</span>
<span id="cb46-510"><a href="#cb46-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-513"><a href="#cb46-513" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-514"><a href="#cb46-514" aria-hidden="true" tabindex="-1"></a><span class="fu">cross_fit</span>(<span class="dv">1</span>, data_folds)</span>
<span id="cb46-515"><a href="#cb46-515" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-516"><a href="#cb46-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-517"><a href="#cb46-517" aria-hidden="true" tabindex="-1"></a>Repeating this for all the splits,</span>
<span id="cb46-518"><a href="#cb46-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-521"><a href="#cb46-521" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-522"><a href="#cb46-522" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-523"><a href="#cb46-523" aria-hidden="true" tabindex="-1"></a>cross_fitted_data_rp <span class="ot">&lt;-</span></span>
<span id="cb46-524"><a href="#cb46-524" aria-hidden="true" tabindex="-1"></a>  <span class="fu">lapply</span>(</span>
<span id="cb46-525"><a href="#cb46-525" aria-hidden="true" tabindex="-1"></a>    <span class="fu">seq_len</span>(<span class="fu">nrow</span>(data_folds)),</span>
<span id="cb46-526"><a href="#cb46-526" aria-hidden="true" tabindex="-1"></a>    <span class="cf">function</span>(x) <span class="fu">cross_fit</span>(x, data_folds)</span>
<span id="cb46-527"><a href="#cb46-527" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-528"><a href="#cb46-528" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rbindlist</span>()</span>
<span id="cb46-529"><a href="#cb46-529" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-530"><a href="#cb46-530" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-531"><a href="#cb46-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-532"><a href="#cb46-532" aria-hidden="true" tabindex="-1"></a>We finally take the mean of the cross-fits by <span class="in">`id`</span> as each <span class="in">`id`</span> has tree estimates. </span>
<span id="cb46-533"><a href="#cb46-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-536"><a href="#cb46-536" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-537"><a href="#cb46-537" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-538"><a href="#cb46-538" aria-hidden="true" tabindex="-1"></a>cross_fitted_data <span class="ot">&lt;-</span> </span>
<span id="cb46-539"><a href="#cb46-539" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data_rp[, .(</span>
<span id="cb46-540"><a href="#cb46-540" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_hat =</span> <span class="fu">mean</span>(t_hat),</span>
<span id="cb46-541"><a href="#cb46-541" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_hat =</span> <span class="fu">mean</span>(y_hat)</span>
<span id="cb46-542"><a href="#cb46-542" aria-hidden="true" tabindex="-1"></a>  ), <span class="at">by =</span> id]</span>
<span id="cb46-543"><a href="#cb46-543" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-544"><a href="#cb46-544" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-545"><a href="#cb46-545" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-546"><a href="#cb46-546" aria-hidden="true" tabindex="-1"></a>We then merge the data to the original data, and define $\tilde{Y}$ and $\tilde{T}$.</span>
<span id="cb46-547"><a href="#cb46-547" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-550"><a href="#cb46-550" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-551"><a href="#cb46-551" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-552"><a href="#cb46-552" aria-hidden="true" tabindex="-1"></a>data_2nd <span class="ot">&lt;-</span> </span>
<span id="cb46-553"><a href="#cb46-553" aria-hidden="true" tabindex="-1"></a>  cross_fitted_data[data, <span class="at">on =</span> <span class="st">"id"</span>] <span class="sc">%&gt;%</span> </span>
<span id="cb46-554"><a href="#cb46-554" aria-hidden="true" tabindex="-1"></a>  .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb46-555"><a href="#cb46-555" aria-hidden="true" tabindex="-1"></a>    <span class="at">y_tilde =</span> Y <span class="sc">-</span> y_hat,</span>
<span id="cb46-556"><a href="#cb46-556" aria-hidden="true" tabindex="-1"></a>    <span class="at">t_tilde =</span> T <span class="sc">-</span> t_hat</span>
<span id="cb46-557"><a href="#cb46-557" aria-hidden="true" tabindex="-1"></a>  )] <span class="sc">%&gt;%</span> </span>
<span id="cb46-558"><a href="#cb46-558" aria-hidden="true" tabindex="-1"></a>  .[, .(y_tilde, t_tilde, x1, x2, x3)]</span>
<span id="cb46-559"><a href="#cb46-559" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-560"><a href="#cb46-560" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-561"><a href="#cb46-561" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-562"><a href="#cb46-562" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb46-563"><a href="#cb46-563" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-564"><a href="#cb46-564" aria-hidden="true" tabindex="-1"></a>The first order condition of @eq-r-min without $\Lambda(\theta(X))$ is</span>
<span id="cb46-565"><a href="#cb46-565" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-566"><a href="#cb46-566" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-567"><a href="#cb46-567" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-568"><a href="#cb46-568" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N (\tilde{Y}_i - \theta(X)\cdot\tilde{T}_i)\cdot \tilde{T}_i = 0</span>
<span id="cb46-569"><a href="#cb46-569" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-570"><a href="#cb46-570" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-571"><a href="#cb46-571" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-572"><a href="#cb46-572" aria-hidden="true" tabindex="-1"></a>This can be rewritten as </span>
<span id="cb46-573"><a href="#cb46-573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-574"><a href="#cb46-574" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-575"><a href="#cb46-575" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-576"><a href="#cb46-576" aria-hidden="true" tabindex="-1"></a>\sum_{i=1}^N \tilde{T}_i^2(\frac{\tilde{Y}_i}{\tilde{T}_i} - \theta(X)) = 0</span>
<span id="cb46-577"><a href="#cb46-577" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-578"><a href="#cb46-578" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-579"><a href="#cb46-579" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-580"><a href="#cb46-580" aria-hidden="true" tabindex="-1"></a>So, this problem can be considered the problem of estimating $\theta(X)$ when the dependent variable is $\frac{\tilde{Y}_i}{\tilde{T}_i}$ with individual weights of $\tilde{T}_i^2$.</span>
<span id="cb46-581"><a href="#cb46-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-584"><a href="#cb46-584" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-585"><a href="#cb46-585" aria-hidden="true" tabindex="-1"></a>data_2nd[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb46-586"><a href="#cb46-586" aria-hidden="true" tabindex="-1"></a>  <span class="at">weight =</span> t_tilde<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb46-587"><a href="#cb46-587" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_to_t =</span> y_tilde <span class="sc">/</span> t_tilde</span>
<span id="cb46-588"><a href="#cb46-588" aria-hidden="true" tabindex="-1"></a>)]</span>
<span id="cb46-589"><a href="#cb46-589" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-590"><a href="#cb46-590" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-591"><a href="#cb46-591" aria-hidden="true" tabindex="-1"></a>We use <span class="in">`xgboost()`</span> for a non-parametric estimation of $\theta(X)$.</span>
<span id="cb46-592"><a href="#cb46-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-595"><a href="#cb46-595" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-596"><a href="#cb46-596" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb46-597"><a href="#cb46-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-598"><a href="#cb46-598" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb46-599"><a href="#cb46-599" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb46-600"><a href="#cb46-600" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb46-601"><a href="#cb46-601" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb46-602"><a href="#cb46-602" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb46-603"><a href="#cb46-603" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb46-604"><a href="#cb46-604" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-605"><a href="#cb46-605" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-606"><a href="#cb46-606" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb46-607"><a href="#cb46-607" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb46-608"><a href="#cb46-608" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb46-609"><a href="#cb46-609" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb46-610"><a href="#cb46-610" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb46-611"><a href="#cb46-611" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb46-612"><a href="#cb46-612" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-613"><a href="#cb46-613" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-614"><a href="#cb46-614" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-617"><a href="#cb46-617" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-618"><a href="#cb46-618" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-619"><a href="#cb46-619" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-620"><a href="#cb46-620" aria-hidden="true" tabindex="-1"></a><span class="co">#=== set up the data with weights ===#</span></span>
<span id="cb46-621"><a href="#cb46-621" aria-hidden="true" tabindex="-1"></a>data_2nd_xgb <span class="ot">&lt;-</span> </span>
<span id="cb46-622"><a href="#cb46-622" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(</span>
<span id="cb46-623"><a href="#cb46-623" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd[, .(x1, x2, x3)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(),</span>
<span id="cb46-624"><a href="#cb46-624" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> data_2nd[, y_to_t],</span>
<span id="cb46-625"><a href="#cb46-625" aria-hidden="true" tabindex="-1"></a>    <span class="at">weight =</span> data_2nd[, weight]</span>
<span id="cb46-626"><a href="#cb46-626" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-627"><a href="#cb46-627" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-628"><a href="#cb46-628" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb46-629"><a href="#cb46-629" aria-hidden="true" tabindex="-1"></a>xgb_trained_2nd <span class="ot">&lt;-</span></span>
<span id="cb46-630"><a href="#cb46-630" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgboost</span>(</span>
<span id="cb46-631"><a href="#cb46-631" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> data_2nd_xgb,</span>
<span id="cb46-632"><a href="#cb46-632" aria-hidden="true" tabindex="-1"></a>    <span class="at">nrounds =</span> <span class="dv">200</span>,</span>
<span id="cb46-633"><a href="#cb46-633" aria-hidden="true" tabindex="-1"></a>    <span class="at">objective =</span> <span class="st">"reg:squarederror"</span></span>
<span id="cb46-634"><a href="#cb46-634" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-635"><a href="#cb46-635" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-636"><a href="#cb46-636" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-637"><a href="#cb46-637" aria-hidden="true" tabindex="-1"></a>You can now predict $\theta(X)$ at particular values of $X$. Let's estimate $\theta(X)$ at $X_0 = <span class="sc">\{</span>x_1 = 0.5, x_2 = 0.5, x_3 = 0.5<span class="sc">\}</span>$.</span>
<span id="cb46-638"><a href="#cb46-638" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-641"><a href="#cb46-641" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-642"><a href="#cb46-642" aria-hidden="true" tabindex="-1"></a>eval_data <span class="ot">&lt;-</span> </span>
<span id="cb46-643"><a href="#cb46-643" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(<span class="at">x1 =</span> <span class="fl">0.5</span>, <span class="at">x2 =</span> <span class="fl">0.5</span>, <span class="at">x3 =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb46-644"><a href="#cb46-644" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.matrix</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb46-645"><a href="#cb46-645" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xgb.DMatrix</span>(<span class="at">data =</span> .)</span>
<span id="cb46-646"><a href="#cb46-646" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-647"><a href="#cb46-647" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb46-648"><a href="#cb46-648" aria-hidden="true" tabindex="-1"></a>theta_hat <span class="ot">&lt;-</span> <span class="fu">predict</span>(xgb_trained_2nd, eval_data)</span>
<span id="cb46-649"><a href="#cb46-649" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb46-650"><a href="#cb46-650" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-651"><a href="#cb46-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-652"><a href="#cb46-652" aria-hidden="true" tabindex="-1"></a>You could alternatively estimate $\theta(X)$ parametrically using OLS. Suppose we somehow know that $\theta(X)$ takes the following form $\beta_1 x_1 + \beta_2 x_2^2 + \beta_3 x_3$. Then, the second stage estimation would be regressing $\tilde{Y}$ on $x_1\times T$, $x_2^2\times T$, and $x_2\times T$.</span>
<span id="cb46-653"><a href="#cb46-653" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-656"><a href="#cb46-656" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-657"><a href="#cb46-657" aria-hidden="true" tabindex="-1"></a><span class="co">#=== train ===#</span></span>
<span id="cb46-658"><a href="#cb46-658" aria-hidden="true" tabindex="-1"></a>ols_2nd_stage <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_tilde <span class="sc">~</span> <span class="fu">I</span>(x1<span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x2<span class="sc">^</span><span class="dv">2</span><span class="sc">*</span>t_tilde) <span class="sc">+</span> <span class="fu">I</span>(x3<span class="sc">*</span>t_tilde), <span class="at">data =</span> data_2nd)</span>
<span id="cb46-659"><a href="#cb46-659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-660"><a href="#cb46-660" aria-hidden="true" tabindex="-1"></a><span class="co">#=== summary ===#</span></span>
<span id="cb46-661"><a href="#cb46-661" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(ols_2nd_stage)</span>
<span id="cb46-662"><a href="#cb46-662" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-663"><a href="#cb46-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-664"><a href="#cb46-664" aria-hidden="true" tabindex="-1"></a>The results look pretty good mostly because we are cheating and using the correct functional form. Of course, in practice, you would not know the correct functional form of $\theta(X)$. Finally, note that you should not use the codes here since they are just for demonstration to enhance our understanding of how R-learner works. </span>
<span id="cb46-665"><a href="#cb46-665" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-666"><a href="#cb46-666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-667"><a href="#cb46-667" aria-hidden="true" tabindex="-1"></a><span class="fu">## Comparing the learners</span></span>
<span id="cb46-668"><a href="#cb46-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-669"><a href="#cb46-669" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-670"><a href="#cb46-670" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-671"><a href="#cb46-671" aria-hidden="true" tabindex="-1"></a>Y_i =\theta(X_i)\cdot T + \alpha g(X_i) + \mu_i</span>
<span id="cb46-672"><a href="#cb46-672" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-673"><a href="#cb46-673" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-674"><a href="#cb46-674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-675"><a href="#cb46-675" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$X_i = \{X_{i,1}, X_{i,2}, X_{i,3}, X_{i,4}, X_{i,5}<span class="sc">\}</span>$</span>
<span id="cb46-676"><a href="#cb46-676" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$T_i|X_i \sim Bernouli(f(X_i))$</span>
<span id="cb46-677"><a href="#cb46-677" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>$\mu_i|X_i \sim N(0,1)$</span>
<span id="cb46-678"><a href="#cb46-678" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-679"><a href="#cb46-679" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb46-680"><a href="#cb46-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-681"><a href="#cb46-681" aria-hidden="true" tabindex="-1"></a><span class="fu">## Case A</span></span>
<span id="cb46-682"><a href="#cb46-682" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-683"><a href="#cb46-683" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-684"><a href="#cb46-684" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-685"><a href="#cb46-685" aria-hidden="true" tabindex="-1"></a>g(X_i) &amp; = sin(\pi X_{i,1}X_{i,2}) + 2(X_{i,3}-0.5)^2 + X_{i,4} + 0.5 X_{i,5}<span class="sc">\\</span></span>
<span id="cb46-686"><a href="#cb46-686" aria-hidden="true" tabindex="-1"></a>e(X_i) &amp; = max(0.1, min(sin(\pi X_{i,1}X_{i,2}), 0.9)) <span class="sc">\\</span></span>
<span id="cb46-687"><a href="#cb46-687" aria-hidden="true" tabindex="-1"></a>\theta(X_i) &amp; = (X_{i,1}, X_{i,2}) / 2 <span class="sc">\\</span></span>
<span id="cb46-688"><a href="#cb46-688" aria-hidden="true" tabindex="-1"></a>X_i &amp; \sim Uni(0,1)^5</span>
<span id="cb46-689"><a href="#cb46-689" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-690"><a href="#cb46-690" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-691"><a href="#cb46-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-692"><a href="#cb46-692" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-693"><a href="#cb46-693" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb46-696"><a href="#cb46-696" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-697"><a href="#cb46-697" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true </span></span>
<span id="cb46-698"><a href="#cb46-698" aria-hidden="true" tabindex="-1"></a>gen_data_A <span class="ot">&lt;-</span> <span class="cf">function</span>(N){</span>
<span id="cb46-699"><a href="#cb46-699" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb46-700"><a href="#cb46-700" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb46-701"><a href="#cb46-701" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-702"><a href="#cb46-702" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-703"><a href="#cb46-703" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-704"><a href="#cb46-704" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-705"><a href="#cb46-705" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">runif</span>(N),</span>
<span id="cb46-706"><a href="#cb46-706" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb46-707"><a href="#cb46-707" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-708"><a href="#cb46-708" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb46-709"><a href="#cb46-709" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> <span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2) <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>(x3<span class="fl">-0.5</span>)<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x4 <span class="sc">+</span> <span class="fl">0.5</span><span class="sc">*</span>x5,</span>
<span id="cb46-710"><a href="#cb46-710" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="fu">pmax</span>(<span class="fl">0.1</span>, <span class="fu">pmin</span>(<span class="fu">sin</span>(pi <span class="sc">*</span> x1<span class="sc">*</span>x2), <span class="fl">0.9</span>)),</span>
<span id="cb46-711"><a href="#cb46-711" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> (x1<span class="sc">+</span>x2)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb46-712"><a href="#cb46-712" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb46-713"><a href="#cb46-713" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> <span class="fu">as.numeric</span>(<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb46-714"><a href="#cb46-714" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb46-715"><a href="#cb46-715" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-716"><a href="#cb46-716" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb46-717"><a href="#cb46-717" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-718"><a href="#cb46-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-719"><a href="#cb46-719" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-720"><a href="#cb46-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-723"><a href="#cb46-723" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-724"><a href="#cb46-724" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-725"><a href="#cb46-725" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-726"><a href="#cb46-726" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-727"><a href="#cb46-727" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rlearner)</span>
<span id="cb46-728"><a href="#cb46-728" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">gen_data_A</span>(N)</span>
<span id="cb46-729"><a href="#cb46-729" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-730"><a href="#cb46-730" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-731"><a href="#cb46-731" aria-hidden="true" tabindex="-1"></a><span class="co"># R-learner</span></span>
<span id="cb46-732"><a href="#cb46-732" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-733"><a href="#cb46-733" aria-hidden="true" tabindex="-1"></a>rboost_fit <span class="ot">&lt;-</span> </span>
<span id="cb46-734"><a href="#cb46-734" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rboost</span>(</span>
<span id="cb46-735"><a href="#cb46-735" aria-hidden="true" tabindex="-1"></a>    data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb46-736"><a href="#cb46-736" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>t, </span>
<span id="cb46-737"><a href="#cb46-737" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>y</span>
<span id="cb46-738"><a href="#cb46-738" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-739"><a href="#cb46-739" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-740"><a href="#cb46-740" aria-hidden="true" tabindex="-1"></a>rboost_est <span class="ot">&lt;-</span> <span class="fu">predict</span>(rboost_fit, data<span class="sc">$</span>x)</span>
<span id="cb46-741"><a href="#cb46-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-742"><a href="#cb46-742" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-743"><a href="#cb46-743" aria-hidden="true" tabindex="-1"></a><span class="co"># S-learner</span></span>
<span id="cb46-744"><a href="#cb46-744" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-745"><a href="#cb46-745" aria-hidden="true" tabindex="-1"></a>sboost_fit <span class="ot">&lt;-</span> </span>
<span id="cb46-746"><a href="#cb46-746" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sboost</span>(</span>
<span id="cb46-747"><a href="#cb46-747" aria-hidden="true" tabindex="-1"></a>    data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb46-748"><a href="#cb46-748" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>t, </span>
<span id="cb46-749"><a href="#cb46-749" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>y</span>
<span id="cb46-750"><a href="#cb46-750" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-751"><a href="#cb46-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-752"><a href="#cb46-752" aria-hidden="true" tabindex="-1"></a>sboost_est <span class="ot">&lt;-</span> <span class="fu">predict</span>(rboost_fit, data<span class="sc">$</span>x)</span>
<span id="cb46-753"><a href="#cb46-753" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-754"><a href="#cb46-754" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-755"><a href="#cb46-755" aria-hidden="true" tabindex="-1"></a><span class="co"># T-learner</span></span>
<span id="cb46-756"><a href="#cb46-756" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-757"><a href="#cb46-757" aria-hidden="true" tabindex="-1"></a>tboost_fit <span class="ot">&lt;-</span> </span>
<span id="cb46-758"><a href="#cb46-758" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tboost</span>(</span>
<span id="cb46-759"><a href="#cb46-759" aria-hidden="true" tabindex="-1"></a>    data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb46-760"><a href="#cb46-760" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>t, </span>
<span id="cb46-761"><a href="#cb46-761" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>y</span>
<span id="cb46-762"><a href="#cb46-762" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-763"><a href="#cb46-763" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-764"><a href="#cb46-764" aria-hidden="true" tabindex="-1"></a>tboost_est <span class="ot">&lt;-</span> <span class="fu">predict</span>(rboost_fit, data<span class="sc">$</span>x)</span>
<span id="cb46-765"><a href="#cb46-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-766"><a href="#cb46-766" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-767"><a href="#cb46-767" aria-hidden="true" tabindex="-1"></a><span class="co"># X-learner</span></span>
<span id="cb46-768"><a href="#cb46-768" aria-hidden="true" tabindex="-1"></a><span class="co">#--------------------------</span></span>
<span id="cb46-769"><a href="#cb46-769" aria-hidden="true" tabindex="-1"></a>xboost_fit <span class="ot">&lt;-</span> </span>
<span id="cb46-770"><a href="#cb46-770" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xboost</span>(</span>
<span id="cb46-771"><a href="#cb46-771" aria-hidden="true" tabindex="-1"></a>    data[, .(x1, x2, x3, x4, x5)] <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>(), </span>
<span id="cb46-772"><a href="#cb46-772" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>t, </span>
<span id="cb46-773"><a href="#cb46-773" aria-hidden="true" tabindex="-1"></a>    data<span class="sc">$</span>y</span>
<span id="cb46-774"><a href="#cb46-774" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-775"><a href="#cb46-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-776"><a href="#cb46-776" aria-hidden="true" tabindex="-1"></a>xboost_est <span class="ot">&lt;-</span> <span class="fu">predict</span>(rboost_fit, data<span class="sc">$</span>x)</span>
<span id="cb46-777"><a href="#cb46-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-778"><a href="#cb46-778" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-779"><a href="#cb46-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-780"><a href="#cb46-780" aria-hidden="true" tabindex="-1"></a>:::{.callout-note}</span>
<span id="cb46-781"><a href="#cb46-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-782"><a href="#cb46-782" aria-hidden="true" tabindex="-1"></a><span class="fu">## Case B (randomized trial)</span></span>
<span id="cb46-783"><a href="#cb46-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-784"><a href="#cb46-784" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-785"><a href="#cb46-785" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-786"><a href="#cb46-786" aria-hidden="true" tabindex="-1"></a>g(X_i) &amp; = max(X_{i,1} + X_{i,2}, X_{i,3}, 0) + max(X_{i,4}+ X_{i,5},0)<span class="sc">\\</span></span>
<span id="cb46-787"><a href="#cb46-787" aria-hidden="true" tabindex="-1"></a>e(X_i) &amp; = 1/2 <span class="sc">\\</span></span>
<span id="cb46-788"><a href="#cb46-788" aria-hidden="true" tabindex="-1"></a>\theta(X_i) &amp; = X_{i,1} + log(1+exp(X_{i,2})) <span class="sc">\\</span></span>
<span id="cb46-789"><a href="#cb46-789" aria-hidden="true" tabindex="-1"></a>X_i &amp; \sim N(0,I_5)</span>
<span id="cb46-790"><a href="#cb46-790" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-791"><a href="#cb46-791" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-792"><a href="#cb46-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-793"><a href="#cb46-793" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-794"><a href="#cb46-794" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb46-797"><a href="#cb46-797" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-798"><a href="#cb46-798" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true </span></span>
<span id="cb46-799"><a href="#cb46-799" aria-hidden="true" tabindex="-1"></a>gen_data_B <span class="ot">&lt;-</span> <span class="cf">function</span>(N){</span>
<span id="cb46-800"><a href="#cb46-800" aria-hidden="true" tabindex="-1"></a>  data <span class="ot">&lt;-</span></span>
<span id="cb46-801"><a href="#cb46-801" aria-hidden="true" tabindex="-1"></a>    <span class="fu">data.table</span>(</span>
<span id="cb46-802"><a href="#cb46-802" aria-hidden="true" tabindex="-1"></a>      <span class="at">x1 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb46-803"><a href="#cb46-803" aria-hidden="true" tabindex="-1"></a>      <span class="at">x2 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb46-804"><a href="#cb46-804" aria-hidden="true" tabindex="-1"></a>      <span class="at">x3 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb46-805"><a href="#cb46-805" aria-hidden="true" tabindex="-1"></a>      <span class="at">x4 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb46-806"><a href="#cb46-806" aria-hidden="true" tabindex="-1"></a>      <span class="at">x5 =</span> <span class="fu">rnorm</span>(N),</span>
<span id="cb46-807"><a href="#cb46-807" aria-hidden="true" tabindex="-1"></a>      <span class="at">u =</span> <span class="fu">rnorm</span>(N)</span>
<span id="cb46-808"><a href="#cb46-808" aria-hidden="true" tabindex="-1"></a>    ) <span class="sc">%&gt;%</span> </span>
<span id="cb46-809"><a href="#cb46-809" aria-hidden="true" tabindex="-1"></a>    .[, <span class="st">`</span><span class="at">:=</span><span class="st">`</span>(</span>
<span id="cb46-810"><a href="#cb46-810" aria-hidden="true" tabindex="-1"></a>      <span class="at">g_x =</span> <span class="fu">pmax</span>(x1 <span class="sc">+</span> x2, x3) <span class="sc">+</span> <span class="fu">pmax</span>(x4 <span class="sc">+</span> x5, <span class="dv">0</span>),</span>
<span id="cb46-811"><a href="#cb46-811" aria-hidden="true" tabindex="-1"></a>      <span class="at">e_x =</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>,</span>
<span id="cb46-812"><a href="#cb46-812" aria-hidden="true" tabindex="-1"></a>      <span class="at">theta_x =</span> x1<span class="sc">+</span><span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(x2))</span>
<span id="cb46-813"><a href="#cb46-813" aria-hidden="true" tabindex="-1"></a>    )] <span class="sc">%&gt;%</span> </span>
<span id="cb46-814"><a href="#cb46-814" aria-hidden="true" tabindex="-1"></a>    .[, t <span class="sc">:</span><span class="er">=</span> (<span class="fu">runif</span>(N) <span class="sc">&lt;</span> e_x)] <span class="sc">%&gt;%</span> </span>
<span id="cb46-815"><a href="#cb46-815" aria-hidden="true" tabindex="-1"></a>    .[, y <span class="sc">:</span><span class="er">=</span> theta_x <span class="sc">*</span> t <span class="sc">+</span> g_x <span class="sc">+</span> u]</span>
<span id="cb46-816"><a href="#cb46-816" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-817"><a href="#cb46-817" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(data)</span>
<span id="cb46-818"><a href="#cb46-818" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb46-819"><a href="#cb46-819" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-820"><a href="#cb46-820" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-821"><a href="#cb46-821" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-822"><a href="#cb46-822" aria-hidden="true" tabindex="-1"></a><span class="fu">## X-, S-, T-, R-learner in Python</span></span>
<span id="cb46-823"><a href="#cb46-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-824"><a href="#cb46-824" aria-hidden="true" tabindex="-1"></a>We saw a general R-learner framework for CATE estimation. We now look at an example of Linear DML, which uses a linear model at the final stage. So, we are assuming that $\theta(X)$ can be written as follows in @eq-model-framework:</span>
<span id="cb46-825"><a href="#cb46-825" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-826"><a href="#cb46-826" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-827"><a href="#cb46-827" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-828"><a href="#cb46-828" aria-hidden="true" tabindex="-1"></a>\theta(X) = \alpha + \beta_1 x_1 + \beta_2 x_2 + \dots + \beta_k x_k</span>
<span id="cb46-829"><a href="#cb46-829" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-830"><a href="#cb46-830" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-831"><a href="#cb46-831" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-832"><a href="#cb46-832" aria-hidden="true" tabindex="-1"></a>where $x_1$ through $x_k$ are the drivers of heterogeneity in treatment effects and $\beta_1$ through $\beta_k$ are their coefficients.</span>
<span id="cb46-833"><a href="#cb46-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-834"><a href="#cb46-834" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-835"><a href="#cb46-835" aria-hidden="true" tabindex="-1"></a>**Packages to load for replication**</span>
<span id="cb46-836"><a href="#cb46-836" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-837"><a href="#cb46-837" aria-hidden="true" tabindex="-1"></a><span class="in">```{r }</span></span>
<span id="cb46-838"><a href="#cb46-838" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: false</span></span>
<span id="cb46-839"><a href="#cb46-839" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb46-840"><a href="#cb46-840" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb46-841"><a href="#cb46-841" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb46-842"><a href="#cb46-842" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb46-843"><a href="#cb46-843" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb46-844"><a href="#cb46-844" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb46-845"><a href="#cb46-845" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb46-846"><a href="#cb46-846" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb46-847"><a href="#cb46-847" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb46-848"><a href="#cb46-848" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-849"><a href="#cb46-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-852"><a href="#cb46-852" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-853"><a href="#cb46-853" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-854"><a href="#cb46-854" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(data.table)</span>
<span id="cb46-855"><a href="#cb46-855" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(magick)</span>
<span id="cb46-856"><a href="#cb46-856" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fixest)</span>
<span id="cb46-857"><a href="#cb46-857" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(officer)</span>
<span id="cb46-858"><a href="#cb46-858" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb46-859"><a href="#cb46-859" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb46-860"><a href="#cb46-860" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb46-861"><a href="#cb46-861" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(DoubleML)</span>
<span id="cb46-862"><a href="#cb46-862" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb46-863"><a href="#cb46-863" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-864"><a href="#cb46-864" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-865"><a href="#cb46-865" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-866"><a href="#cb46-866" aria-hidden="true" tabindex="-1"></a>We use both Python and R for this demonstration. So, let's set things up for that.</span>
<span id="cb46-867"><a href="#cb46-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-870"><a href="#cb46-870" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-871"><a href="#cb46-871" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb46-872"><a href="#cb46-872" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(reticulate)</span>
<span id="cb46-873"><a href="#cb46-873" aria-hidden="true" tabindex="-1"></a><span class="fu">use_virtualenv</span>(<span class="st">"ml-learning"</span>)</span>
<span id="cb46-874"><a href="#cb46-874" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-875"><a href="#cb46-875" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-876"><a href="#cb46-876" aria-hidden="true" tabindex="-1"></a>For this demonstration, we use synthetic data according to the following data generating process:</span>
<span id="cb46-877"><a href="#cb46-877" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-878"><a href="#cb46-878" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-879"><a href="#cb46-879" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb46-880"><a href="#cb46-880" aria-hidden="true" tabindex="-1"></a>y_i = exp(x_{i,1}) d_i + x_{i,1} + \frac{1}{4}\cdot\frac{exp(x_{i,3})}{1 + exp(x_{i,3})} + \mu_i <span class="sc">\\</span></span>
<span id="cb46-881"><a href="#cb46-881" aria-hidden="true" tabindex="-1"></a>d_i = \frac{exp(x_{i,1})}{1 + exp(x_{i,1})} + \frac{1}{4}\cdot x_{i,3}+ \eta_i</span>
<span id="cb46-882"><a href="#cb46-882" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb46-883"><a href="#cb46-883" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb46-884"><a href="#cb46-884" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-885"><a href="#cb46-885" aria-hidden="true" tabindex="-1"></a>Note that this is the same data generating process used in @sec-dml except that the impact of the treatment ($d$) now depends on $x_1$. We can use <span class="in">`gen_data()`</span> function that is defined in @sec-dml-naive.</span>
<span id="cb46-886"><a href="#cb46-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-889"><a href="#cb46-889" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-890"><a href="#cb46-890" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb46-891"><a href="#cb46-891" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-892"><a href="#cb46-892" aria-hidden="true" tabindex="-1"></a><span class="co">#=== sample size ===#</span></span>
<span id="cb46-893"><a href="#cb46-893" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">1000</span> </span>
<span id="cb46-894"><a href="#cb46-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-895"><a href="#cb46-895" aria-hidden="true" tabindex="-1"></a><span class="co">#=== generate data ===#</span></span>
<span id="cb46-896"><a href="#cb46-896" aria-hidden="true" tabindex="-1"></a>synth_data <span class="ot">&lt;-</span></span>
<span id="cb46-897"><a href="#cb46-897" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gen_data</span>(</span>
<span id="cb46-898"><a href="#cb46-898" aria-hidden="true" tabindex="-1"></a>    <span class="at">te_formula =</span> <span class="fu">formula</span>(<span class="sc">~</span> <span class="fu">I</span>(<span class="fu">exp</span>(x1)<span class="sc">*</span>d)),</span>
<span id="cb46-899"><a href="#cb46-899" aria-hidden="true" tabindex="-1"></a>    <span class="at">n_obs =</span> N <span class="sc">*</span><span class="dv">2</span></span>
<span id="cb46-900"><a href="#cb46-900" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-901"><a href="#cb46-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-902"><a href="#cb46-902" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> dplyr<span class="sc">::</span><span class="fu">select</span>(synth_data, <span class="fu">starts_with</span>(<span class="st">"x"</span>)) <span class="sc">%&gt;%</span> <span class="fu">as.matrix</span>()</span>
<span id="cb46-903"><a href="#cb46-903" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> synth_data[, y]</span>
<span id="cb46-904"><a href="#cb46-904" aria-hidden="true" tabindex="-1"></a>d <span class="ot">&lt;-</span> synth_data[, d]</span>
<span id="cb46-905"><a href="#cb46-905" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-906"><a href="#cb46-906" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-907"><a href="#cb46-907" aria-hidden="true" tabindex="-1"></a>We now split the data into training and test datasets. </span>
<span id="cb46-908"><a href="#cb46-908" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-911"><a href="#cb46-911" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-912"><a href="#cb46-912" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-913"><a href="#cb46-913" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-914"><a href="#cb46-914" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb46-915"><a href="#cb46-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-916"><a href="#cb46-916" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test, d_train, d_test<span class="op">=</span> train_test_split(r.X, r.y, r.d,  test_size <span class="op">=</span> <span class="fl">0.5</span>, random_state <span class="op">=</span> <span class="dv">8923</span>)</span>
<span id="cb46-917"><a href="#cb46-917" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-918"><a href="#cb46-918" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-919"><a href="#cb46-919" aria-hidden="true" tabindex="-1"></a>Here, to train a linear DML model, we use the Python <span class="in">`econml`</span> package, which offers one of the most comprehensive sets of off-the-shelf R-learner (DML) methods <span class="co">[</span><span class="ot">@econml</span><span class="co">]</span>. We can use the <span class="in">`DML`</span> class to implement linear DML.</span>
<span id="cb46-920"><a href="#cb46-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-923"><a href="#cb46-923" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-924"><a href="#cb46-924" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-925"><a href="#cb46-925" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> econml.dml <span class="im">import</span> DML</span>
<span id="cb46-926"><a href="#cb46-926" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-927"><a href="#cb46-927" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-928"><a href="#cb46-928" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-929"><a href="#cb46-929" aria-hidden="true" tabindex="-1"></a><span class="in">`DML`</span> is a child class of <span class="in">`_Rlearner`</span>, which is a private class. The <span class="in">`DML`</span> class has several child classes: <span class="in">`LinearDML`</span>, <span class="in">`SpatseLinearDML`</span>, <span class="in">`NonParamDML`</span>, and <span class="in">`CausalForestDML`</span>. </span>
<span id="cb46-930"><a href="#cb46-930" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-931"><a href="#cb46-931" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-932"><a href="#cb46-932" aria-hidden="true" tabindex="-1"></a>As we saw above in @sec-est-steps, we need to specify three models:</span>
<span id="cb46-933"><a href="#cb46-933" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-934"><a href="#cb46-934" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_y`</span>: model for estimating $E<span class="co">[</span><span class="ot">Y|X,W</span><span class="co">]</span>$</span>
<span id="cb46-935"><a href="#cb46-935" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_t`</span>: model for estimating $E<span class="co">[</span><span class="ot">T|X,W</span><span class="co">]</span>$</span>
<span id="cb46-936"><a href="#cb46-936" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`model_final`</span>: model for estimating $\theta(X)$</span>
<span id="cb46-937"><a href="#cb46-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-938"><a href="#cb46-938" aria-hidden="true" tabindex="-1"></a>In this example, let's use gradient boosting regression for both <span class="in">`model_y`</span> and <span class="in">`model_t`</span> and use lasso with cross-validation for <span class="in">`model_final`</span>. Let's import <span class="in">`GradientBoostingRegressor()`</span> and <span class="in">`LassoCV()`</span> from the <span class="in">`scikitlearn`</span> package.</span>
<span id="cb46-939"><a href="#cb46-939" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-942"><a href="#cb46-942" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-943"><a href="#cb46-943" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-944"><a href="#cb46-944" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingRegressor</span>
<span id="cb46-945"><a href="#cb46-945" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LassoCV</span>
<span id="cb46-946"><a href="#cb46-946" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-947"><a href="#cb46-947" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-948"><a href="#cb46-948" aria-hidden="true" tabindex="-1"></a>We can now set up our DML framework like below:</span>
<span id="cb46-949"><a href="#cb46-949" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-952"><a href="#cb46-952" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-953"><a href="#cb46-953" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-954"><a href="#cb46-954" aria-hidden="true" tabindex="-1"></a>est <span class="op">=</span> DML(</span>
<span id="cb46-955"><a href="#cb46-955" aria-hidden="true" tabindex="-1"></a>    model_y <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb46-956"><a href="#cb46-956" aria-hidden="true" tabindex="-1"></a>    model_t <span class="op">=</span> GradientBoostingRegressor(),</span>
<span id="cb46-957"><a href="#cb46-957" aria-hidden="true" tabindex="-1"></a>    model_final <span class="op">=</span> LassoCV(fit_intercept <span class="op">=</span> <span class="va">False</span>) </span>
<span id="cb46-958"><a href="#cb46-958" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-959"><a href="#cb46-959" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-960"><a href="#cb46-960" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-961"><a href="#cb46-961" aria-hidden="true" tabindex="-1"></a>Note that no training has happened yet at this point. We simply created a recipe. Once we provide ingredients (data), we can cook (train) with the <span class="in">`fit()`</span> method. </span>
<span id="cb46-962"><a href="#cb46-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-965"><a href="#cb46-965" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-966"><a href="#cb46-966" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-967"><a href="#cb46-967" aria-hidden="true" tabindex="-1"></a>est.fit(y_train, d_train, X <span class="op">=</span> X_train, W <span class="op">=</span> X_train)</span>
<span id="cb46-968"><a href="#cb46-968" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-969"><a href="#cb46-969" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-970"><a href="#cb46-970" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>first argument: dependent variable</span>
<span id="cb46-971"><a href="#cb46-971" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span>second argument: treatment variable </span>
<span id="cb46-972"><a href="#cb46-972" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`X`</span>: variables that drive treatment effect heterogeneity</span>
<span id="cb46-973"><a href="#cb46-973" aria-hidden="true" tabindex="-1"></a><span class="ss">+ </span><span class="in">`W`</span>: variables that affect the dependent variable directly</span>
<span id="cb46-974"><a href="#cb46-974" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-975"><a href="#cb46-975" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb46-976"><a href="#cb46-976" aria-hidden="true" tabindex="-1"></a>Here, we set <span class="in">`X = W`</span>.</span>
<span id="cb46-977"><a href="#cb46-977" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-978"><a href="#cb46-978" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-979"><a href="#cb46-979" aria-hidden="true" tabindex="-1"></a>Once, the training is done. We can use the <span class="in">`effect()`</span> method to predict $\theta(X)$.</span>
<span id="cb46-980"><a href="#cb46-980" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-983"><a href="#cb46-983" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb46-984"><a href="#cb46-984" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false</span></span>
<span id="cb46-985"><a href="#cb46-985" aria-hidden="true" tabindex="-1"></a>te_test <span class="op">=</span> est.effect(X_test)</span>
<span id="cb46-986"><a href="#cb46-986" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-987"><a href="#cb46-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-988"><a href="#cb46-988" aria-hidden="true" tabindex="-1"></a>@fig-est-theta-hat presents the estimated and true marginal treatment effect ($\theta(X)$) as a function of <span class="in">`x1`</span>. </span>
<span id="cb46-989"><a href="#cb46-989" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-992"><a href="#cb46-992" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-993"><a href="#cb46-993" aria-hidden="true" tabindex="-1"></a><span class="co">#| eval: false </span></span>
<span id="cb46-994"><a href="#cb46-994" aria-hidden="true" tabindex="-1"></a>plot_data <span class="ot">&lt;-</span> </span>
<span id="cb46-995"><a href="#cb46-995" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.table</span>(</span>
<span id="cb46-996"><a href="#cb46-996" aria-hidden="true" tabindex="-1"></a>    <span class="at">x1 =</span> py<span class="sc">$</span>X_test[, <span class="dv">1</span>],</span>
<span id="cb46-997"><a href="#cb46-997" aria-hidden="true" tabindex="-1"></a>    <span class="at">te =</span> py<span class="sc">$</span>te_test</span>
<span id="cb46-998"><a href="#cb46-998" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb46-999"><a href="#cb46-999" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1000"><a href="#cb46-1000" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(plot_data) <span class="sc">+</span></span>
<span id="cb46-1001"><a href="#cb46-1001" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> te, <span class="at">x =</span> x1)) <span class="sc">+</span></span>
<span id="cb46-1002"><a href="#cb46-1002" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">exp</span>(x1), <span class="at">x =</span> x1), <span class="at">color =</span> <span class="st">"blue"</span>) <span class="sc">+</span></span>
<span id="cb46-1003"><a href="#cb46-1003" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_bw</span>()</span>
<span id="cb46-1004"><a href="#cb46-1004" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-1005"><a href="#cb46-1005" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1008"><a href="#cb46-1008" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb46-1009"><a href="#cb46-1009" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Estimated and true marginal treatment effects</span></span>
<span id="cb46-1010"><a href="#cb46-1010" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-est-theta-hat</span></span>
<span id="cb46-1011"><a href="#cb46-1011" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb46-1012"><a href="#cb46-1012" aria-hidden="true" tabindex="-1"></a><span class="co"># plot_data &lt;- </span></span>
<span id="cb46-1013"><a href="#cb46-1013" aria-hidden="true" tabindex="-1"></a><span class="co">#   data.table(</span></span>
<span id="cb46-1014"><a href="#cb46-1014" aria-hidden="true" tabindex="-1"></a><span class="co">#     x1 = py$X_test[, 1],</span></span>
<span id="cb46-1015"><a href="#cb46-1015" aria-hidden="true" tabindex="-1"></a><span class="co">#     te = py$te_test</span></span>
<span id="cb46-1016"><a href="#cb46-1016" aria-hidden="true" tabindex="-1"></a><span class="co">#   )</span></span>
<span id="cb46-1017"><a href="#cb46-1017" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1018"><a href="#cb46-1018" aria-hidden="true" tabindex="-1"></a><span class="co"># g_het_te &lt;-</span></span>
<span id="cb46-1019"><a href="#cb46-1019" aria-hidden="true" tabindex="-1"></a><span class="co">#   ggplot(plot_data) +</span></span>
<span id="cb46-1020"><a href="#cb46-1020" aria-hidden="true" tabindex="-1"></a><span class="co">#   geom_point(aes(y = te, x = x1)) +</span></span>
<span id="cb46-1021"><a href="#cb46-1021" aria-hidden="true" tabindex="-1"></a><span class="co">#   geom_line(aes(y = exp(x1), x = x1), color = "blue") +</span></span>
<span id="cb46-1022"><a href="#cb46-1022" aria-hidden="true" tabindex="-1"></a><span class="co">#   theme_bw()</span></span>
<span id="cb46-1023"><a href="#cb46-1023" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1024"><a href="#cb46-1024" aria-hidden="true" tabindex="-1"></a>g_het_te <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">"g_hte_te.rds"</span>)</span>
<span id="cb46-1025"><a href="#cb46-1025" aria-hidden="true" tabindex="-1"></a>g_het_te</span>
<span id="cb46-1026"><a href="#cb46-1026" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb46-1027"><a href="#cb46-1027" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1028"><a href="#cb46-1028" aria-hidden="true" tabindex="-1"></a>Since we forced $\theta(X)$ to be linear in <span class="in">`x1`</span>, it is not surprising that the estimated MTE looks linear in <span class="in">`x1`</span> even though the true MTE is an exponential function of <span class="in">`x1`</span>. In the next chapter (@sec-forest-cate), we discuss CATE estimators based on forest, which estimates $\theta(X)$ non-parametrically, relaxing the assumption of $\theta(X)$ being linear-in-parameter.</span>
<span id="cb46-1029"><a href="#cb46-1029" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1030"><a href="#cb46-1030" aria-hidden="true" tabindex="-1"></a>:::{.callout-tip}</span>
<span id="cb46-1031"><a href="#cb46-1031" aria-hidden="true" tabindex="-1"></a>There are many more variations in DML than the one presented here. For those who are interested, I recommend going through examples presented <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/microsoft/EconML/blob/main/notebooks/Double%20Machine%20Learning%20Examples.ipynb)</span> for <span class="in">`DML`</span></span>
<span id="cb46-1032"><a href="#cb46-1032" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb46-1033"><a href="#cb46-1033" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1034"><a href="#cb46-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1035"><a href="#cb46-1035" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-1036"><a href="#cb46-1036" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>